1
00:00:14,150 --> 00:00:18,210
My name is Yuri Besonov, and I'm a
Partner Solution Architect at AWS.

2
00:00:18,600 --> 00:00:21,820
I work with different AWS
customers and partners and help

3
00:00:21,820 --> 00:00:24,060
them to build solutions on AWS.

4
00:00:24,500 --> 00:00:28,210
One of the areas where I'm involved more
is containers, especially Kubernetes.

5
00:00:28,210 --> 00:00:32,970
Kubernetes on AWS is delivered
by Amazon Elastic Kubernetes

6
00:00:32,980 --> 00:00:35,160
Service, in short, Amazon EKS.

7
00:00:35,470 --> 00:00:39,640
And today, I will share with you how
we can build and scale production

8
00:00:39,640 --> 00:00:43,640
grade Kubernetes multi cluster
environment using GitOps on EKS.

9
00:00:44,700 --> 00:00:48,630
But before we go multi clusters,
let's start from the very beginning,

10
00:00:48,630 --> 00:00:52,680
from one cluster and define why do
we need cluster management at all.

11
00:00:53,260 --> 00:00:58,029
We generally see customers with a
Git source control system, some kind

12
00:00:58,029 --> 00:01:01,549
of infrastructure as a code tooling
like Terraform, CloudFormation,

13
00:01:01,550 --> 00:01:08,355
CDK, Pulumi, some infrastructure
as a code state like S3 bucket

14
00:01:08,355 --> 00:01:11,700
for Terraform, and then resources.

15
00:01:11,710 --> 00:01:13,379
And EKS cluster.

16
00:01:13,619 --> 00:01:19,239
In the pipeline, customers usually do
some checks on the source code, they

17
00:01:19,239 --> 00:01:24,349
build an application, then run unit tests,
enforce policies, and after that they

18
00:01:24,349 --> 00:01:27,029
need to deploy application in the cluster.

19
00:01:28,039 --> 00:01:31,879
And as they grow, they may add
additional environments, like for

20
00:01:31,879 --> 00:01:35,419
development, staging, for test
purposes, or for different projects.

21
00:01:35,729 --> 00:01:36,989
It is still manageable.

22
00:01:37,969 --> 00:01:40,819
If growth continues, this
can become unmanageable.

23
00:01:41,179 --> 00:01:46,309
To many versions, to many clusters,
to many pipelines to track, which

24
00:01:46,309 --> 00:01:50,269
cluster is up to date, which cluster
has which version, which needs to be

25
00:01:50,379 --> 00:01:53,429
updated this quarter or next quarter.

26
00:01:53,439 --> 00:01:57,529
And this is even without taking into
account what is inside the clusters.

27
00:01:57,899 --> 00:02:00,380
What are the applications,
what are their update policies.

28
00:02:00,380 --> 00:02:04,559
And it is uncommon, not uncommon,
It's not uncommon to see so many

29
00:02:04,569 --> 00:02:06,869
pipelines in an organization.

30
00:02:08,189 --> 00:02:09,779
Why do we have so many clusters?

31
00:02:09,969 --> 00:02:12,709
Because we have different light
of businesses, we have different

32
00:02:12,709 --> 00:02:14,779
applications, and different workloads.

33
00:02:14,989 --> 00:02:19,009
We could have back end application
system, web application for front

34
00:02:19,059 --> 00:02:20,559
end, or even state workloads.

35
00:02:21,059 --> 00:02:25,139
Workloads to host databases
or streaming workloads.

36
00:02:25,679 --> 00:02:30,379
There are plenty of legacy applications
which are running in the clusters and

37
00:02:30,379 --> 00:02:34,469
also up to date modern applications
like artificial intelligence,

38
00:02:34,469 --> 00:02:37,979
machine learning to work with machine
learning and training and inference.

39
00:02:39,619 --> 00:02:44,639
And besides deploying the clusters, we
also need to think how teams will access

40
00:02:44,679 --> 00:02:47,029
those clusters and will share resources.

41
00:02:47,279 --> 00:02:51,399
How we will configure each clusters
with add ons, maybe with different

42
00:02:51,409 --> 00:02:53,389
configuration for developing and prod.

43
00:02:53,629 --> 00:02:57,109
For example, different number of
replicas in developing and prodding

44
00:02:57,359 --> 00:02:59,659
environment, and also how to deploy teams.

45
00:02:59,764 --> 00:03:02,204
different workloads to different clusters.

46
00:03:02,214 --> 00:03:06,734
So there are plenty of challenges
when you need to work with containers,

47
00:03:06,734 --> 00:03:09,404
with EKS, with Kubernetes at scale.

48
00:03:10,894 --> 00:03:14,714
And of course, our pipeline could
help us to manage the add on,

49
00:03:14,934 --> 00:03:19,744
deploy the infrastructure, and
enforce our compliance and security.

50
00:03:19,944 --> 00:03:27,194
It is possible with pipeline, and in this
case, the actual model will be push model.

51
00:03:27,644 --> 00:03:32,204
We trigger the deployment manually each
time when we decide that we need to

52
00:03:32,204 --> 00:03:34,024
deploy a new version of an application.

53
00:03:34,464 --> 00:03:38,654
But what happens in case of
some issues in the chain?

54
00:03:38,894 --> 00:03:41,159
Or what will be the state of truth?

55
00:03:42,009 --> 00:03:48,049
If there are some problems arise, do we
consider git as an initial state of truth?

56
00:03:48,449 --> 00:03:52,349
Do we consider terraform state
file as a state of truth?

57
00:03:52,839 --> 00:03:56,249
Or do we consider pipeline
itself as a state of truth?

58
00:03:56,399 --> 00:04:00,259
Or maybe it's EKS etcd
database is a state of truth?

59
00:04:01,379 --> 00:04:06,339
With this setup, environment cannot
match what your intention was.

60
00:04:06,429 --> 00:04:11,779
It is not source of truth anymore, and
it's more, I would say, source of hope.

61
00:04:12,439 --> 00:04:17,660
And with this architecture, you need a
lot of auditing and compliance mechanism.

62
00:04:18,100 --> 00:04:21,760
And what about if we need
to integrate new services?

63
00:04:22,085 --> 00:04:26,275
In this case, we need to, for example,
we would like to use generative

64
00:04:26,445 --> 00:04:28,455
AI services like Amazon Bedrock.

65
00:04:28,675 --> 00:04:32,715
In this case, we need product manager
for pipelines who need to integrate this.

66
00:04:32,745 --> 00:04:37,035
And if we have many business units
that they can be overwhelmed and maybe

67
00:04:37,035 --> 00:04:39,450
new services, will never be deployed.

68
00:04:40,470 --> 00:04:45,840
If we rely on GitHub tooling for fleet
management, we can have a process that

69
00:04:45,840 --> 00:04:50,090
will constantly try to reconcile the
source of truth in the Git repository

70
00:04:50,120 --> 00:04:51,930
with the actual state of the cluster.

71
00:04:51,940 --> 00:04:58,230
So we can, and we should solve those
problems which we had with the push model.

72
00:04:59,080 --> 00:05:03,944
In this case, Git becomes a source
of truth instead of source of hoax.

73
00:05:03,955 --> 00:05:08,985
Hope, and it will enable reproducible
automated deployments, cluster

74
00:05:09,025 --> 00:05:10,391
management, and monitoring.

75
00:05:10,391 --> 00:05:17,075
So we can use GitOps and various tooling
to solve our problems with deployment.

76
00:05:18,005 --> 00:05:21,795
And we also use a principle
of GitOps to achieve it.

77
00:05:21,985 --> 00:05:23,415
Those principles are declarative.

78
00:05:24,780 --> 00:05:28,450
We define what do we want to achieve,
not how do we want to achieve.

79
00:05:28,470 --> 00:05:29,790
It's reduce complexity.

80
00:05:30,630 --> 00:05:32,430
The second principle is versions.

81
00:05:32,600 --> 00:05:36,420
All the configuration are in
Git, versionable and immutable,

82
00:05:37,440 --> 00:05:40,060
and it enhance auditability.

83
00:05:40,110 --> 00:05:42,560
We know who did what and when.

84
00:05:43,505 --> 00:05:47,985
We also use pull model, whereas an agent
in the cluster which pull desired state

85
00:05:47,985 --> 00:05:52,975
from the git instead of pushing this
state to the cluster from the pipeline.

86
00:05:53,265 --> 00:05:59,185
And also, we have an agent which is
continuously reconciles it to the cluster.

87
00:05:59,685 --> 00:06:06,894
Agents know how to translate declarative
configuration in the git repository

88
00:06:06,895 --> 00:06:08,995
to the real state of the cluster.

89
00:06:09,380 --> 00:06:15,090
And do it constantly so after each change
we always have the consistent environment.

90
00:06:16,750 --> 00:06:21,760
And let's now go deeper and
talk how we deploy the clusters.

91
00:06:22,410 --> 00:06:26,259
Most of the customers are using
many of the customers using

92
00:06:26,300 --> 00:06:28,284
Terraform to deploy EKS clusters.

93
00:06:28,585 --> 00:06:33,385
We have a nice accelerator called EKS
Blueprints that can help you to achieve

94
00:06:33,385 --> 00:06:38,515
your deployment goals quickly by allowing
you to rely on maintaining and best

95
00:06:38,515 --> 00:06:40,835
practices pattern of EKS deployment.

96
00:06:41,164 --> 00:06:44,914
It can bring you some patterns
like fully private cluster.

97
00:06:45,505 --> 00:06:49,885
Clusters which use APV6 with
Node Group or Carpenter for

98
00:06:49,885 --> 00:06:51,145
analytics or machine learning.

99
00:06:51,145 --> 00:06:55,855
For various purposes, we have various
patterns already developed for you, which

100
00:06:55,855 --> 00:06:58,015
you can use in your own environment.

101
00:06:59,365 --> 00:07:03,304
Let's see the process to deploy
an add on, like a load balancer.

102
00:07:03,325 --> 00:07:07,115
Because the cluster itself,
it's just compute environment.

103
00:07:07,145 --> 00:07:12,325
And in order to use it, you need various
components, like a various add on.

104
00:07:12,725 --> 00:07:18,995
For AWS load balancer, for example in
order to make it work, we will need a

105
00:07:19,245 --> 00:07:25,765
role and a policy which gives a controller
to possibility to access application AWS

106
00:07:26,335 --> 00:07:28,955
resources, such as AWS load balancer.

107
00:07:29,455 --> 00:07:33,259
The role will reference a pro
policy with appropriate right.

108
00:07:33,909 --> 00:07:39,509
If we decide to addon to install the
addon Helm chart with Terraform, we can

109
00:07:39,559 --> 00:07:41,769
configure it with previously created role.

110
00:07:42,599 --> 00:07:45,539
Then Terraform installs the
configured Helm chart into the

111
00:07:45,539 --> 00:07:49,449
cluster, and the service account
can reference the proper AM role.

112
00:07:50,059 --> 00:07:52,529
Then it's again push model from Terraform.

113
00:07:52,689 --> 00:07:57,139
We still hit the problem of of which
Terraform state is a state of truth.

114
00:07:57,329 --> 00:08:01,569
And Terraform apply, it's only
applied when we manually when

115
00:08:01,869 --> 00:08:03,109
we'll be manually triggered.

116
00:08:04,459 --> 00:08:05,299
Can we do better?

117
00:08:05,784 --> 00:08:06,784
Of course, we can do.

118
00:08:06,954 --> 00:08:09,984
Can we use, for example,
Git approach and Argo CD?

119
00:08:10,674 --> 00:08:15,684
We can ask Argo CD to talk to Kubernetes
and do the Helm install on the addons

120
00:08:15,744 --> 00:08:20,384
via creation of application object
that reference the Helm chart repo.

121
00:08:21,014 --> 00:08:25,204
But then, we still need a way to provide
it with appropriate configuration.

122
00:08:25,444 --> 00:08:29,114
In this case, the AM role
for load balancer controller.

123
00:08:29,679 --> 00:08:33,589
With Argo CD we there is a
notion of application set.

124
00:08:33,809 --> 00:08:38,599
Application set allow us to
dynamically create or generate

125
00:08:38,649 --> 00:08:40,579
Argo CD application objects.

126
00:08:40,859 --> 00:08:45,929
Application set are able to read a secret
in the cluster and apply its configuration

127
00:08:46,179 --> 00:08:48,309
to some of the labels of the secret.

128
00:08:48,929 --> 00:08:54,759
But first, we need a way for our Teraform
to create the secrets and then the

129
00:08:54,759 --> 00:08:57,489
specific annotation for that secret.

130
00:08:57,689 --> 00:09:02,289
In this case, Teraform creates a load
balancer controller IAM role, reference

131
00:09:02,339 --> 00:09:06,469
this role as annotation in the secret
and create the secret in Kubernetes.

132
00:09:07,369 --> 00:09:10,839
This way, Argo CD should have
all the necessary materials

133
00:09:10,859 --> 00:09:14,199
to create an application and
install properly the add on.

134
00:09:15,464 --> 00:09:20,874
Once Kubernetes has the secret configured,
Argo CD can create an application for its

135
00:09:20,904 --> 00:09:25,634
application set manifest with appropriate
configuration and install the add on.

136
00:09:26,004 --> 00:09:27,814
So we have complete cycle.

137
00:09:27,824 --> 00:09:30,374
To recap, Terraform creates a role.

138
00:09:31,074 --> 00:09:35,654
Terraform creates the Kubernetes secrets
with appropriate annotation for this role.

139
00:09:36,329 --> 00:09:40,189
Then Argo CD creates the
application from application set.

140
00:09:42,189 --> 00:09:44,589
This is what we call the GitHub bridge.

141
00:09:44,599 --> 00:09:49,939
It is fully integrated with EKS blueprints
and you can rely on this pattern to

142
00:09:49,939 --> 00:09:54,619
keep your Terraform infrastructure as
to keep your Terraform infrastructure

143
00:09:54,619 --> 00:09:58,449
as code management but shift the
Kubernetes deployment part to Argo CD.

144
00:09:58,729 --> 00:10:03,759
So in this case, Terraform will be
responsible for creation of the clusters

145
00:10:04,069 --> 00:10:09,739
and creation of the secrets, but
after that Argo CD will take over and

146
00:10:09,749 --> 00:10:14,389
deploy all the workload and all the
necessary add on using application set.

147
00:10:14,869 --> 00:10:18,739
This can be used for add ons, but
also for workloads when your workloads

148
00:10:18,739 --> 00:10:23,299
can be configured dynamically from
the metadata created by Terraform.

149
00:10:24,714 --> 00:10:29,784
From there, we have different options for
managing Argo CD, our clusters and GitHub

150
00:10:29,784 --> 00:10:32,054
repository for add ons and workload.

151
00:10:32,334 --> 00:10:37,394
We can have a different cluster pointing
to the same Git add ons repository, where

152
00:10:37,394 --> 00:10:40,244
we will store the generic application set.

153
00:10:40,504 --> 00:10:44,484
Each application set can then
be transformed by Argo CD

154
00:10:44,484 --> 00:10:45,734
in different applications.

155
00:10:46,044 --> 00:10:51,274
which can have different values depending
on the target cluster we are running on.

156
00:10:51,274 --> 00:10:58,794
So you have a set of application sets
which are acting like a template and

157
00:10:58,794 --> 00:11:03,094
after that you could have specific
parameters for specific clusters

158
00:11:03,354 --> 00:11:05,779
which can be generated on the fly.

159
00:11:06,539 --> 00:11:12,039
We can also use, in this case, centralized
Argo CD instance in a hub cluster that

160
00:11:12,039 --> 00:11:16,299
will be managed that that will be able to
manage application deployment in different

161
00:11:16,309 --> 00:11:18,809
target cluster from a centralized place.

162
00:11:19,149 --> 00:11:21,929
This is what we call
a hub and spoke model.

163
00:11:22,129 --> 00:11:26,249
When you have a hub management cluster
and you have workloads cluster for

164
00:11:26,249 --> 00:11:31,499
different environment to different
projects to let's say which will be

165
00:11:31,499 --> 00:11:34,169
controlled by one instance of Argo CD.

166
00:11:34,669 --> 00:11:38,609
We can leverage Terraform to create
our hub and spoke clusters with

167
00:11:38,609 --> 00:11:40,609
a simple hub and spoke topology.

168
00:11:40,659 --> 00:11:45,569
We can also leverage Terraform workspaces
to manage a different Terraform

169
00:11:45,599 --> 00:11:50,459
configuration for our different cluster
but reusing the same Terraform code.

170
00:11:51,669 --> 00:11:55,299
With this setup, we need many
secrets created in the hub cluster.

171
00:11:55,749 --> 00:11:57,079
One secret for each of that.

172
00:11:57,354 --> 00:12:03,614
Target cluster, like a hub cluster dev
clusters staging, or production clusters.

173
00:12:03,694 --> 00:12:07,874
Argo CD will be able to leverage
those different secrets when we need

174
00:12:07,874 --> 00:12:09,924
to communicate with each cluster.

175
00:12:10,134 --> 00:12:17,084
So Argo CD will help necessary, will have
necessary credentials to access workloads

176
00:12:17,084 --> 00:12:19,844
cluster from the centralized hub cluster.

177
00:12:20,329 --> 00:12:23,789
Application sets stored in
Git will generate different

178
00:12:23,819 --> 00:12:25,679
applications in the HUB cluster.

179
00:12:26,209 --> 00:12:30,629
We can also specify different add ons
versions and other configurations by

180
00:12:30,649 --> 00:12:32,469
matching labels on the target clusters.

181
00:12:32,889 --> 00:12:36,139
Within the single repository,
you can still control different

182
00:12:36,139 --> 00:12:36,779
versions of the HUB cluster.

183
00:12:37,009 --> 00:12:40,849
to be deployed on different cluster
and centralized in one location.

184
00:12:41,069 --> 00:12:45,029
So you have a benefits of centralization
of configuration, but after that

185
00:12:45,029 --> 00:12:49,579
flexibility to have different different
parameters, different specific

186
00:12:50,209 --> 00:12:51,537
parameters for various clusters.

187
00:12:51,537 --> 00:12:58,397
Clusters, then you can scale
this with many other clusters.

188
00:12:58,397 --> 00:13:03,067
So you can have several clusters
for staging or for example, complete

189
00:13:03,067 --> 00:13:07,177
set of clusters like dev staging
and production for various project

190
00:13:07,177 --> 00:13:08,707
or various lines of business.

191
00:13:09,522 --> 00:13:13,872
As I said, many of our customers are
using Terraform and e Ks blueprints for

192
00:13:13,872 --> 00:13:16,062
Terraform to create their infrastructure.

193
00:13:16,502 --> 00:13:20,812
While Terraform is really powerful
tool for Token to AWS, we have

194
00:13:20,812 --> 00:13:25,072
seen several issues when letting
Terraform manage Kubernetes resources

195
00:13:25,162 --> 00:13:29,372
inside the clusters, like a Don
and workloads and what we just saw.

196
00:13:29,552 --> 00:13:34,052
We can delegate some of the Kubernetes
stuff from Terraform to Argo CD using.

197
00:13:34,587 --> 00:13:35,527
GitOps bridge.

198
00:13:37,267 --> 00:13:40,997
Terraform will still create resources,
AWS resources, and Kubernetes secrets

199
00:13:40,997 --> 00:13:42,827
with with metadata indentation.

200
00:13:42,827 --> 00:13:47,017
From there, Argo CD is able to
configure and install the Kubernetes

201
00:13:47,077 --> 00:13:52,117
add on, like external DDS, GitTip, or
SearchSecret to one or many clusters.

202
00:13:52,617 --> 00:13:57,507
With the GitOps approach, we
could also manage the teams.

203
00:13:57,917 --> 00:14:01,227
We can create with ArgoCD namespaces.

204
00:14:01,417 --> 00:14:05,857
We could enforce role basis access
control and policies and everything

205
00:14:06,077 --> 00:14:10,427
using GitOps and using configuration,
which is stored in ArgoCD.

206
00:14:10,867 --> 00:14:14,727
Some customers are even
able to do one step faster.

207
00:14:15,467 --> 00:14:20,347
further, for example, and let Argo
CD sends to tooling like ACK or cross

208
00:14:20,367 --> 00:14:25,787
plane to also create necessary AWS
resources from VPC to EKS clusters.

209
00:14:26,047 --> 00:14:30,877
In this case, we don't talk about
Kubernetes as container orchestration

210
00:14:30,877 --> 00:14:33,397
system, but as a platform framework.

211
00:14:33,657 --> 00:14:36,937
We are building a fabric for
people To bring different pieces of

212
00:14:36,937 --> 00:14:41,297
infrastructure together using native
constructs like mutating admissions,

213
00:14:41,347 --> 00:14:46,897
Hema validation admissions, and all
those benefits of Kubernetes API.

214
00:14:46,897 --> 00:14:52,637
With that, with the help of GitOps,
Kubernetes API, we could be able

215
00:14:52,677 --> 00:14:57,587
to deploy not only workloads to the
clusters, but also the clusters and

216
00:14:57,597 --> 00:15:02,347
all the necessary resources which you
require in AWS, for example, for your

217
00:15:02,347 --> 00:15:07,757
application to run, like SRE buckets,
databases, and so on and so forth.

218
00:15:08,937 --> 00:15:12,467
Of course In these clusters,
we will need some workloads.

219
00:15:13,167 --> 00:15:16,307
For that workloads, we will need
configuration management for

220
00:15:16,317 --> 00:15:21,187
different applications, for different
versions of those applications.

221
00:15:21,527 --> 00:15:25,067
We also can use one Git
repository to store configuration

222
00:15:25,087 --> 00:15:26,407
for different applications.

223
00:15:26,857 --> 00:15:30,347
Like in this case, for example, as you
can see, you have some UI application,

224
00:15:30,417 --> 00:15:32,057
you have some database application.

225
00:15:32,677 --> 00:15:36,077
And if needed, you can also
differentiate the configuration needed

226
00:15:36,097 --> 00:15:40,547
for different clusters or environment
of clusters in the Git repository.

227
00:15:40,547 --> 00:15:45,377
So you may have different values
for your development clusters and

228
00:15:45,447 --> 00:15:48,677
and for example, for production
clusters, of course, you will have

229
00:15:48,677 --> 00:15:53,377
different, for example, parameters
for secrets or access to the database.

230
00:15:53,427 --> 00:15:58,117
But also you could have a various
number of replicas or other

231
00:15:58,447 --> 00:16:02,147
parameters, which will be different
from environment to environment.

232
00:16:03,937 --> 00:16:06,377
RGCD could reconcile the
appropriate directories.

233
00:16:06,547 --> 00:16:10,147
The directory is dependent on
the target clusters, so you could

234
00:16:10,197 --> 00:16:14,167
have a configuration of specific
cluster in specific directory.

235
00:16:14,727 --> 00:16:19,547
With this, you can create different
configurations like version, scale, and

236
00:16:19,547 --> 00:16:21,887
optimize cost for compute and storage.

237
00:16:22,762 --> 00:16:27,112
As we we saw, you may also choose
to create additional resources with

238
00:16:27,152 --> 00:16:31,932
GitOps using manifest and add ons
for AWS controllers for Kubernetes

239
00:16:32,102 --> 00:16:35,952
or cross plane, for example,
to create Amazon RDS databases

240
00:16:36,022 --> 00:16:38,062
associated with specific application.

241
00:16:38,262 --> 00:16:42,202
So you could have a configuration
for application, but also for

242
00:16:42,212 --> 00:16:46,412
resources which are necessary for
this application in AWS cloud.

243
00:16:47,162 --> 00:16:48,782
And of course, any talk.

244
00:16:49,237 --> 00:16:53,107
cannot be complete without
some mentioning of security.

245
00:16:53,107 --> 00:16:58,207
Security is top priority for AWS and
clusters are not exceptions from it.

246
00:16:59,437 --> 00:17:03,607
You, or you would want to store
the secret materials for your

247
00:17:03,607 --> 00:17:09,287
application, for example, a private
SSH key, keys or secrets in secure

248
00:17:09,287 --> 00:17:12,427
location like AWS Secret Manager.

249
00:17:12,947 --> 00:17:18,377
Then the controller like external
secrets operator would create and

250
00:17:18,377 --> 00:17:22,717
update the secret bases on the
material from AWS Secret Manager.

251
00:17:23,167 --> 00:17:27,087
When external secret operator creates the
Kubernetes secrets with git credentials.

252
00:17:27,612 --> 00:17:33,362
Or and URL hostname, it can be also
validated by Kiverna, by policy agent.

253
00:17:33,362 --> 00:17:41,092
Kiverna can have a policy that only
allows credentials for Argo CD to be

254
00:17:41,232 --> 00:17:43,822
type, for example, type of SSH only.

255
00:17:44,562 --> 00:17:49,262
And it also could check if those
credentials are coming only from

256
00:17:49,262 --> 00:17:53,742
specific Git repository or Git
server or from specific region.

257
00:17:53,882 --> 00:17:55,292
It could be could be quite secure.

258
00:17:56,332 --> 00:18:01,082
And Argo CD, of course, with Argo CD
another let's say tip you should never

259
00:18:01,132 --> 00:18:05,632
access remote EKS clusters using service
account tokens that never expire.

260
00:18:06,092 --> 00:18:07,992
You should never use those tokens.

261
00:18:08,272 --> 00:18:12,712
Argo CD controllers like application
controller, API server, or report server

262
00:18:12,922 --> 00:18:19,752
should always be configured to use IAM
role using IRCA or EKS pod identity.

263
00:18:20,412 --> 00:18:24,172
When adding another remote
cluster, specify the IAM role

264
00:18:24,172 --> 00:18:27,842
that Argo CD should assume when
connecting to the more cluster.

265
00:18:28,142 --> 00:18:31,402
This also could be stored
in the Kubernetes secret.

266
00:18:31,402 --> 00:18:37,912
A Kibernet policy can be configured
to ensure that your cluster secret

267
00:18:37,962 --> 00:18:42,982
created only contains IAM role to
assume and never, uh, KubeConfig token.

268
00:18:43,202 --> 00:18:47,942
Of course, you can replicate this,
the same approach with many clusters

269
00:18:47,972 --> 00:18:52,072
and use it to access not only for
example, staging clusters, but also

270
00:18:52,362 --> 00:18:57,312
production clusters and any other
required clusters in a secured way.

271
00:18:57,972 --> 00:18:59,972
To sum up, AKS blueprints.

272
00:19:00,962 --> 00:19:05,432
and GitOps bridge give you a possibility
to create and manage multi cluster

273
00:19:05,442 --> 00:19:10,202
environments with security and
at scale using GitOps principles.

274
00:19:10,242 --> 00:19:16,402
You can check those QR codes and the links
if you want to dive deeper, get additional

275
00:19:16,402 --> 00:19:18,382
information, or even you can try.

276
00:19:18,642 --> 00:19:24,822
hands on in your own on AWS account
the Argo CD on EKS workshops,

277
00:19:24,852 --> 00:19:26,292
which we prepared for you.

278
00:19:27,162 --> 00:19:29,422
With that, I would like to say thank you.

279
00:19:29,622 --> 00:19:33,672
I hope you enjoyed the session
and please feel free to reach out

280
00:19:33,682 --> 00:19:37,632
on LinkedIn and have a discussion
about platform engineering,

281
00:19:37,672 --> 00:19:39,892
containers application modernization.

282
00:19:40,142 --> 00:19:41,342
I would really appreciate that.

283
00:19:41,602 --> 00:19:45,522
Also, if you spend one minute and
answer on a short survey on the

284
00:19:45,522 --> 00:19:47,972
session, your feedback is very valuable.

285
00:19:48,252 --> 00:19:48,792
Thank you.

