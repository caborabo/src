1
00:00:15,180 --> 00:00:15,879
Hello, everyone.

2
00:00:16,289 --> 00:00:20,600
Welcome to Con 42, the
Platform Engineering Edition.

3
00:00:21,699 --> 00:00:26,559
I'm really excited to share our
experiences and journey so far in building

4
00:00:26,559 --> 00:00:29,490
a serverless generative AI platform.

5
00:00:31,760 --> 00:00:36,210
My name is Murali Malina, and I'm
Chief Technology Officer at SoftRAMS.

6
00:00:37,185 --> 00:00:41,555
I've been really lucky to have been
building teams and software solutions

7
00:00:41,565 --> 00:00:47,254
for more than 25 years and the last
seven years at SoftRAMS itself.

8
00:00:48,475 --> 00:00:52,655
I'm also the co founder and CEO
of a five year old nonprofit

9
00:00:52,655 --> 00:00:54,674
organization called Teaching for Good.

10
00:00:56,104 --> 00:00:59,305
This is a very unique editech nonprofit.

11
00:01:00,195 --> 00:01:05,245
It empowers anybody that is interested
to teach, train, mentor, or coach.

12
00:01:06,345 --> 00:01:10,755
At the same time, you can actually
use this platform to raise funds

13
00:01:10,765 --> 00:01:12,464
for a non profit of your choice.

14
00:01:13,075 --> 00:01:17,565
So in other words, we are a non
profit and we support raising funds

15
00:01:17,565 --> 00:01:22,874
for any non profit of your choice by
leveraging your skills and passion.

16
00:01:23,700 --> 00:01:25,290
To teach and mentor others.

17
00:01:26,340 --> 00:01:31,220
I also had a great privilege of
collaborating and working with

18
00:01:31,860 --> 00:01:38,180
exceptional teams, worldwide teams
in Germany, UK, France, India, China,

19
00:01:38,210 --> 00:01:43,450
Russia, and of course, us and have
built mission critical systems.

20
00:01:44,035 --> 00:01:48,654
In telecom supply chain, particularly
auto industry, healthcare,

21
00:01:49,035 --> 00:01:50,465
working with federal agencies.

22
00:01:51,015 --> 00:01:54,755
And my favorite and pretty
close to my heart is Editech.

23
00:01:55,825 --> 00:01:57,715
I'm not that active on Twitter.

24
00:01:57,755 --> 00:02:01,764
Please hit me up on LinkedIn if you
want to connect and chat about pretty

25
00:02:01,765 --> 00:02:03,164
much anything you want to chat about.

26
00:02:05,295 --> 00:02:09,354
I've been working with SoftRAMS for
almost seven and a half years now.

27
00:02:09,435 --> 00:02:14,975
And SoftRAMS is one of the fastest
growing civic digital services firms.

28
00:02:15,875 --> 00:02:20,365
We support a variety of mission critical
loads for our federal agency customers.

29
00:02:21,715 --> 00:02:25,684
We have been working hard to
bring some of these generative AI

30
00:02:25,685 --> 00:02:31,784
experiences and solutions that depend
on the generative AI into our work.

31
00:02:32,315 --> 00:02:38,815
With our federal agencies, and as
these agencies provide a very unique

32
00:02:38,815 --> 00:02:43,365
opportunities and different levels
of constraints and complexity.

33
00:02:44,375 --> 00:02:48,994
That's one of the factors actually that
led us to build this Gen AI platform.

34
00:02:49,775 --> 00:02:54,185
This can be deployed in entirety into
any customer environment, for example.

35
00:02:54,985 --> 00:03:00,025
And go from an experiment to
production in days to weeks, rather

36
00:03:00,025 --> 00:03:04,084
than weeks to months, it used to
take us to build ML experiences,

37
00:03:04,084 --> 00:03:08,955
for instance, and I will definitely
touch a few aspects and these unique

38
00:03:08,965 --> 00:03:10,755
constraints later in the discussion.

39
00:03:11,725 --> 00:03:12,814
just a shameless plug.

40
00:03:12,834 --> 00:03:15,984
If anybody's looking for an
opportunity, take a look at some

41
00:03:15,984 --> 00:03:18,045
of the open positions at SoftRAMS.

42
00:03:18,855 --> 00:03:22,955
It's a great place to work and it's
one of the top workplaces in the U S.

43
00:03:23,609 --> 00:03:28,399
And it has been recognized for
almost fourth year in a row for

44
00:03:28,419 --> 00:03:30,029
innovation and leadership culture.

45
00:03:33,029 --> 00:03:37,739
Given that this is a, an online
virtual conference, instead of

46
00:03:38,309 --> 00:03:43,689
polling you to see where you are and
what you're doing, I will make a few

47
00:03:43,689 --> 00:03:46,179
assumptions and discuss various aspects.

48
00:03:46,759 --> 00:03:51,709
but please LinkedIn if you have any
specific questions or want to take

49
00:03:51,709 --> 00:03:53,609
this conversation to a different level.

50
00:03:54,609 --> 00:04:02,124
I'm sure many of you are using JNI for
fun and Some probably have also started

51
00:04:02,134 --> 00:04:05,464
using a variety of Gen AI tools at work.

52
00:04:05,694 --> 00:04:10,464
Maybe GitHub Copilot or similar, for
example, or automated peer reviews,

53
00:04:10,494 --> 00:04:15,384
or tools to generate documentation,
release notes, just to start with.

54
00:04:16,484 --> 00:04:20,724
And how about building
new Gen AI applications?

55
00:04:20,724 --> 00:04:25,264
I'm pretty sure you're as excited as
me and everybody else in the ecosystem

56
00:04:25,344 --> 00:04:26,585
when Charged GPT got released.

57
00:04:27,614 --> 00:04:31,945
We all wanted to build these new AI
experiences into new applications

58
00:04:31,965 --> 00:04:36,854
as well as bring these Gen AI
experiences to existing applications.

59
00:04:37,874 --> 00:04:44,104
Or, at least, most of you must be
experimenting with various tools

60
00:04:44,104 --> 00:04:48,025
and LLM models, probably some of
the software as a services that are

61
00:04:48,064 --> 00:04:49,984
out there in the ecosystem as well.

62
00:04:51,634 --> 00:05:01,280
As you all know, AI and ML that we all
know and told as in historians, That

63
00:05:01,430 --> 00:05:09,239
there is an AI or ML before ChargeGPT and
there is an AI and ML after the ChargeGPT.

64
00:05:10,020 --> 00:05:14,820
This transformation is pretty
surreal in many ways and this is

65
00:05:14,820 --> 00:05:17,859
now very pervasive as well across
the board, across the world.

66
00:05:18,799 --> 00:05:22,269
The excitement and ease
of building applications,

67
00:05:22,620 --> 00:05:26,889
ChargeGPT is totally profound.

68
00:05:27,759 --> 00:05:32,299
Suddenly the AI or ML, or I would
say especially generative AI,

69
00:05:33,080 --> 00:05:38,830
is on the list of top priorities
across the board around the world.

70
00:05:40,450 --> 00:05:46,769
Shifting the perception of AI and ML
from what used to be like a little

71
00:05:46,770 --> 00:05:51,839
bit more complicated and costly
process, even more important of the

72
00:05:51,859 --> 00:05:54,359
talent like need for data scientists.

73
00:05:56,119 --> 00:06:00,109
Only so many organizations were
able to afford to build those

74
00:06:00,139 --> 00:06:01,909
end to end ML experiences.

75
00:06:02,609 --> 00:06:08,624
And the chart GPT brought this
into something that is now Totally

76
00:06:08,624 --> 00:06:10,374
accessible to pretty much everyone.

77
00:06:11,314 --> 00:06:16,984
and though we have come a long way in
terms of automated automation, tooling

78
00:06:17,004 --> 00:06:25,094
and systems to build amazing EAML
applications before, but charge GPT and

79
00:06:25,104 --> 00:06:31,959
LLM models in general, are taking us to
a completely different level in order of

80
00:06:31,959 --> 00:06:34,189
magnitude in terms of speed of innovation.

81
00:06:35,959 --> 00:06:42,489
One fundamental pivot for that entire
ecosystem is that LLMs made this

82
00:06:43,249 --> 00:06:49,590
natural language as a new programming
language, making it possible for anybody

83
00:06:49,599 --> 00:06:53,280
in the organization, technical, non
technical, business teams, doesn't

84
00:06:53,299 --> 00:07:00,309
matter, to be able to leverage LLMs,
create apps and assistants, Purely

85
00:07:00,309 --> 00:07:03,109
using plain everyday language.

86
00:07:03,909 --> 00:07:08,669
Of course, this still need to learn
a little bit about how to create

87
00:07:08,769 --> 00:07:12,890
those instructions and how to work
with these prompts, but they can

88
00:07:12,890 --> 00:07:19,209
do it pretty quickly and with that
people from all walks of life now can

89
00:07:19,210 --> 00:07:25,495
create exceptional user experiences
without the need for large teams and

90
00:07:25,495 --> 00:07:28,424
large coding exercises or workflows.

91
00:07:29,644 --> 00:07:32,894
to be able to bring these
experience experiences into life

92
00:07:34,434 --> 00:07:39,164
in practice, I definitely believe,
and I have seen it firsthand.

93
00:07:40,804 --> 00:07:45,724
So many of these enterprise applications
can now be developed without writing

94
00:07:45,724 --> 00:07:50,814
a single line of code by specifying
instructions in plain text and

95
00:07:50,814 --> 00:07:56,155
leveraging any kind of relevant knowledge
basis from variety of data sources.

96
00:07:56,779 --> 00:08:00,499
Be it in documents, presentations,
or even databases, for example.

97
00:08:01,319 --> 00:08:06,939
Teams can now create these custom GPTs, if
you will, or chatbots, or assistants, or

98
00:08:06,959 --> 00:08:09,999
agents, tailored to their specific needs.

99
00:08:11,759 --> 00:08:17,899
And another unique aspect that these
LLMs brought, truly, conversational

100
00:08:17,900 --> 00:08:21,159
interfaces to interact with a
variety of software systems.

101
00:08:22,264 --> 00:08:27,194
Even in conventional software
applications, chart is fast becoming the

102
00:08:27,194 --> 00:08:29,284
preferred and primary interaction model.

103
00:08:30,574 --> 00:08:37,484
And to be able to ensure that these
AI experiments, these AI apps become

104
00:08:37,484 --> 00:08:42,125
successful, that's something that
you can rely on and use it in at your

105
00:08:42,144 --> 00:08:44,625
work, in your organizations and teams.

106
00:08:45,700 --> 00:08:51,659
It is really critical that we provide
access to these models in the first place,

107
00:08:52,669 --> 00:08:57,229
create these capabilities in a way that
those are accessible to regular users,

108
00:08:58,010 --> 00:09:02,309
and provide them that safe and secure
environment so they can actually play

109
00:09:02,309 --> 00:09:04,639
around and build these applications.

110
00:09:06,449 --> 00:09:12,220
The most important part of this is that
now that plain language is becoming the

111
00:09:12,310 --> 00:09:17,639
primary interaction, not only to use
applications, but also to create, It's

112
00:09:17,639 --> 00:09:22,319
very important to make these capabilities
accessible to every team member in your

113
00:09:22,329 --> 00:09:27,869
organization, technical, non technical,
doesn't matter at all, and abstract away

114
00:09:27,869 --> 00:09:32,279
some of these complexities with respect
to how to create the infrastructure,

115
00:09:32,480 --> 00:09:38,479
the workflows, all the other backend
infrastructure tasks, if you will.

116
00:09:39,159 --> 00:09:39,899
And of course.

117
00:09:40,635 --> 00:09:47,194
creating a shareable catalog of sample
applications, reusable prompt libraries,

118
00:09:47,264 --> 00:09:52,514
and a little bit of training so that
you can accelerate the adoption of

119
00:09:52,554 --> 00:09:54,115
that platform in your organization.

120
00:09:55,345 --> 00:09:59,635
And precisely in this context, I
would like to share about the Gen AI

121
00:09:59,635 --> 00:10:04,990
platform that we have built, initially
for our internal teams, but now we're

122
00:10:05,030 --> 00:10:06,960
using it for our customers as well.

123
00:10:09,349 --> 00:10:15,190
We have built this generic platform that
allows anybody in our teams, irrespective

124
00:10:15,200 --> 00:10:20,169
of the technical aptitude to be able
to quickly create a conversational

125
00:10:20,230 --> 00:10:21,609
chart board or an assistant.

126
00:10:22,379 --> 00:10:27,359
But that is also grounded on information
that is provided by the author of this

127
00:10:27,359 --> 00:10:30,220
chart board from variety of data sources.

128
00:10:30,885 --> 00:10:36,115
And kind of this is now
possible to do so in about five

129
00:10:36,175 --> 00:10:37,744
minutes once you have an idea.

130
00:10:38,954 --> 00:10:42,824
So once you can get the chart board
up and running in the five minutes,

131
00:10:43,364 --> 00:10:47,425
it'll allow you to iterate faster,
quickly test them, refine the

132
00:10:47,425 --> 00:10:49,474
prompts, refine the knowledge basis.

133
00:10:50,135 --> 00:10:56,715
And once you feel good about the work, the
quality of the work, the way it is able to

134
00:10:56,715 --> 00:10:58,745
process information, present information.

135
00:10:59,109 --> 00:11:02,719
Then you can actually share with
everybody else in the organization.

136
00:11:03,829 --> 00:11:08,739
And as I mentioned, we do support
federal agencies, and we made sure

137
00:11:08,739 --> 00:11:13,930
that this can be deployed in entirety
into any customer environment.

138
00:11:15,549 --> 00:11:20,609
The initial version of this product was
built as a CDK project with everything

139
00:11:20,609 --> 00:11:24,430
needed, including infrastructure,
the databases for, vector stores,

140
00:11:25,209 --> 00:11:28,959
the orchestration, the workflows,
the pipelines, the access control.

141
00:11:29,489 --> 00:11:33,139
Everything is built using CDK
so that we can deploy to AWS.

142
00:11:33,879 --> 00:11:39,969
We have different versions now available
that will make this entire platform

143
00:11:40,459 --> 00:11:47,290
available to be deployed into Azure or,
Google Cloud or onto on premises as long

144
00:11:47,290 --> 00:11:50,730
as you have a Kubernetes infrastructure.

145
00:11:52,030 --> 00:11:57,860
this platform has been set up to
connect to LLM models across the board.

146
00:11:58,535 --> 00:12:04,304
Either they're offered on AWS Bedrock,
OpenAI directly, or Azure OpenAI.

147
00:12:04,305 --> 00:12:08,815
Our models on Google Vertex are pretty
much anywhere as long as you have

148
00:12:08,865 --> 00:12:12,175
access to the API for hosted models.

149
00:12:12,665 --> 00:12:15,715
And if you want to host your
own models, then, of course, it

150
00:12:15,755 --> 00:12:17,625
is very specific to the cloud.

151
00:12:18,275 --> 00:12:22,985
On AWS, for example, you could set them
up into the SalesMaker to be able to

152
00:12:22,985 --> 00:12:24,595
make them available for the platform.

153
00:12:25,515 --> 00:12:32,025
And the platform comes with handy Prebuilt
features, for example, that will take

154
00:12:32,035 --> 00:12:38,725
care of most of the setup so that the end
users can just concentrate on fine tuning

155
00:12:38,725 --> 00:12:44,005
their apps and making sure everything is
up to snuff in terms of security and by

156
00:12:44,035 --> 00:12:48,995
making automation tools more accessible
across the organization, it definitely

157
00:12:48,995 --> 00:12:55,015
sparks that creativity because everybody
is excited about able to use chart GPT

158
00:12:55,345 --> 00:12:59,505
or a tool, something like chart GPT
that they can build for themselves.

159
00:13:00,225 --> 00:13:02,335
That will help in their own work.

160
00:13:03,245 --> 00:13:05,745
And of course it'll
boost their productivity.

161
00:13:05,755 --> 00:13:07,815
If they could use their own work as well.

162
00:13:08,755 --> 00:13:14,005
this means your team can definitely
streamline some of these workflows

163
00:13:14,495 --> 00:13:20,264
in all, all kinds of shapes and
capabilities and present them in

164
00:13:20,265 --> 00:13:21,855
a safe and secure space so that.

165
00:13:22,360 --> 00:13:26,410
Everybody in the team can
experiment with these ideas

166
00:13:26,410 --> 00:13:28,740
and create amazing applications

167
00:13:30,890 --> 00:13:35,990
to be able to streamline and
automate the infrastructure, the

168
00:13:36,050 --> 00:13:41,519
pipelines, the workflows, and the most
importantly, the security aspects.

169
00:13:42,400 --> 00:13:46,980
We have looked at different use
cases and different applications.

170
00:13:47,635 --> 00:13:51,585
and quickly standardized in all
these varieties of applications

171
00:13:51,585 --> 00:13:57,754
and use cases based on a few basic
capabilities into four different groups.

172
00:13:59,035 --> 00:14:02,185
The first and foremost
important one is chatbots.

173
00:14:02,325 --> 00:14:09,155
These are probably the first application
any user try even on our platform.

174
00:14:09,840 --> 00:14:15,540
And this primary use case is that this
will enable users to interact with

175
00:14:15,540 --> 00:14:17,400
applications using natural language.

176
00:14:18,090 --> 00:14:23,220
And you just can ask questions and
receive answers based on the context.

177
00:14:23,839 --> 00:14:28,399
And this is completely grounded in
the private knowledge basis that the

178
00:14:28,419 --> 00:14:30,220
others of the chartboards provide.

179
00:14:31,140 --> 00:14:34,100
And there are connectors
available to load this information

180
00:14:34,100 --> 00:14:35,310
from SharePoint conference.

181
00:14:36,375 --> 00:14:38,265
Or just upload documents directly.

182
00:14:39,925 --> 00:14:44,935
the next set of capabilities are
grouped into what we call as agents.

183
00:14:45,945 --> 00:14:50,645
The agents are like chat bots,
but they're autonomous, that they

184
00:14:50,645 --> 00:14:55,735
can autonomously make decisions to
decide the flow or the number of

185
00:14:55,735 --> 00:15:01,365
iterations, for example, to prepare
appropriate answers or act on behalf

186
00:15:01,365 --> 00:15:05,940
of the user, or just simply navigate
a multi-step processor, a workflow.

187
00:15:07,689 --> 00:15:12,930
These agents will have the ability
to access different tools, APIs,

188
00:15:13,170 --> 00:15:19,319
or functions, and also will have
access to data sources to gather all

189
00:15:19,350 --> 00:15:24,419
relevant information and let them
make, let them make the decisions

190
00:15:24,459 --> 00:15:26,439
to execute that particular workflow.

191
00:15:27,869 --> 00:15:31,119
And they can iterate through
multiple steps to provide a

192
00:15:31,119 --> 00:15:32,529
final response to the user.

193
00:15:33,259 --> 00:15:38,739
And sometimes they can also act on behalf
of the user, like Creating a task list

194
00:15:38,759 --> 00:15:44,059
or placing an order or updating status
in a tool like Jira, for instance.

195
00:15:46,469 --> 00:15:51,799
And the next one is my favorite,
is what we call as AI for BI.

196
00:15:52,999 --> 00:16:00,299
Every business collects tons of data, and
many enterprises have extensive teams and

197
00:16:00,299 --> 00:16:06,179
systems to be able to extract insights,
analysis, and reports every single day.

198
00:16:07,409 --> 00:16:12,499
However, in, in many cases, it
usually takes days to weeks.

199
00:16:13,394 --> 00:16:16,524
to be able to get an answer
when a business team has a

200
00:16:16,524 --> 00:16:17,944
question about something.

201
00:16:18,814 --> 00:16:24,074
Because this typically requires teams
to go back and identify the right

202
00:16:24,084 --> 00:16:29,534
data sources, fetch the data, put it
in a space area or space or a safe

203
00:16:29,554 --> 00:16:34,784
area to be able to process the data
or create alternate views to be made

204
00:16:34,784 --> 00:16:39,014
them accessible, and then extract those
insights and deliver those insights.

205
00:16:40,164 --> 00:16:44,584
And if the business team happens
to have a follow up question,

206
00:16:44,594 --> 00:16:49,469
which happens all the time based on
the information that is provided.

207
00:16:50,349 --> 00:16:53,239
Typically, the next iteration
goes in a very similar

208
00:16:53,479 --> 00:16:54,929
workflow again, days to weeks.

209
00:16:56,099 --> 00:17:02,239
But now, thanks to LLMs, we can let
these business users ask questions

210
00:17:02,239 --> 00:17:04,889
directly in natural language.

211
00:17:05,599 --> 00:17:12,169
The orchestrator that will rely on
these LLMs, first of all, to identify

212
00:17:12,179 --> 00:17:17,609
what data sources are appropriate,
fetch the data, process the data, And

213
00:17:17,609 --> 00:17:24,549
summarize the data to be able to answer
that question and best of best case is

214
00:17:24,559 --> 00:17:30,129
also that it will also provide all the
necessary background, how it arrived,

215
00:17:30,609 --> 00:17:36,459
how did it process pretty much explaining
the process of going through answering

216
00:17:36,459 --> 00:17:41,409
that question itself, along with the
evidence is presented to the user.

217
00:17:41,829 --> 00:17:47,149
And this can happen within a
matter of one, probably 1 to 5

218
00:17:47,149 --> 00:17:49,559
minutes instead of days or weeks.

219
00:17:50,249 --> 00:17:55,209
We noticed our quickest question
on AIBA solutions is about 30,

220
00:17:55,279 --> 00:17:57,629
35 seconds to three minutes.

221
00:17:58,999 --> 00:18:03,439
It will take longer based on your
use case or quicker based on number

222
00:18:03,439 --> 00:18:05,489
of data sources it need to look at.

223
00:18:05,819 --> 00:18:09,269
number of iterations, number of
queries it need to make kind of stuff.

224
00:18:10,269 --> 00:18:15,049
And it is possible with all the new
frameworks coming up, you can do

225
00:18:15,049 --> 00:18:17,009
all these iterations in parallel.

226
00:18:17,009 --> 00:18:22,089
Sorry, the number of queries in parallel
and quickly iterate that so that you

227
00:18:22,089 --> 00:18:27,399
can actually improve that latency
to get the responses even faster.

228
00:18:28,509 --> 00:18:31,849
And these apps can also support
data visualization, not just

229
00:18:31,849 --> 00:18:36,239
presenting a textual summary, but
also data visualization, prepare.

230
00:18:36,849 --> 00:18:40,719
Powerpoint decks, if you want,
generate reports of dashboards

231
00:18:40,919 --> 00:18:44,629
along with the summaries and
insights in natural language.

232
00:18:45,099 --> 00:18:50,539
So when you prepare a report, you're
not only looking at the visual aspect

233
00:18:50,539 --> 00:18:55,129
of the data presented, but also the
textual explanation of what happened

234
00:18:55,159 --> 00:18:56,649
or what is happening with the data.

235
00:18:56,689 --> 00:18:57,029
And.

236
00:18:57,559 --> 00:19:03,909
The key insights in that report itself,
and it's so easy and totally accessible.

237
00:19:03,909 --> 00:19:05,119
Everybody can understand it.

238
00:19:05,119 --> 00:19:09,009
It's textual, it's graphical,
combined, and it's automated.

239
00:19:09,379 --> 00:19:12,189
The most important part is
this can happen in real time.

240
00:19:13,909 --> 00:19:15,269
And the fourth group of.

241
00:19:15,699 --> 00:19:21,319
Applications, and these are probably
the most powerful in this group,

242
00:19:22,059 --> 00:19:24,329
are what we call as agent crews.

243
00:19:25,339 --> 00:19:30,689
An agent crew represents essentially a
team of self organizing agents that can

244
00:19:30,689 --> 00:19:35,949
collaborate with each other to perform
little bit more complicated tasks.

245
00:19:36,679 --> 00:19:41,369
these agents will work together, assume
different roles and responsibilities,

246
00:19:41,999 --> 00:19:47,214
bring their specialization aspect,
and automate and refine those

247
00:19:47,234 --> 00:19:50,194
processes to create that final answer.

248
00:19:50,994 --> 00:19:55,404
And these are particularly valuable
for multi step tasks, preparing

249
00:19:55,414 --> 00:19:59,174
reports, for example, or doing
analysis, automatic security

250
00:19:59,174 --> 00:20:01,054
testing, for instance, and others.

251
00:20:01,779 --> 00:20:05,489
and even preparing comprehensive
documentation, for example, that

252
00:20:05,489 --> 00:20:08,609
will take multiple iterations,
multiple loads and responsibilities.

253
00:20:09,759 --> 00:20:15,429
So these are the four groups of
capabilities, and for each group, we

254
00:20:15,429 --> 00:20:20,609
were able to identify exactly what
is needed to support these use cases,

255
00:20:21,149 --> 00:20:25,119
the infrastructure, the workflows, the
pipelines for Rack stores, for example,

256
00:20:25,789 --> 00:20:31,607
plus the observability aspect of being
able to see every piece of We have a

257
00:20:31,607 --> 00:20:35,749
lot of back end interactions that are
happening to facilitate that response

258
00:20:36,209 --> 00:20:41,149
so that developers and technically savvy
users have all the information that they

259
00:20:41,149 --> 00:20:46,559
need to be able to evaluate, validate
the responses, look at the performance

260
00:20:46,559 --> 00:20:49,399
issues, and go and refine them as needed

261
00:20:51,399 --> 00:20:57,269
by offering a self service platform
team members throughout the organization

262
00:20:57,269 --> 00:21:02,529
now can easily whip up and launch
these apps without long development

263
00:21:02,529 --> 00:21:03,849
cycles that we used to have.

264
00:21:04,739 --> 00:21:10,289
And it also speeds up innovation because
now everybody that has an idea can

265
00:21:10,379 --> 00:21:15,439
easily and quickly create these apps and
everything else is taken care for them.

266
00:21:15,959 --> 00:21:20,769
And in our journey, of course, we also
teamed up with federal agencies to

267
00:21:20,769 --> 00:21:24,239
see what kind of workloads we want to
support, what kind of use cases we want

268
00:21:24,239 --> 00:21:30,339
to support, and make sure that whatever
we build, that solution, it can smoothly

269
00:21:30,339 --> 00:21:32,719
go live in customers environments.

270
00:21:33,549 --> 00:21:38,309
And every team should be able to
try these things out in a safe and

271
00:21:38,309 --> 00:21:42,259
secure space and smoothly move to
production whenever they're ready.

272
00:21:43,269 --> 00:21:49,629
So to make it happen, we come up with a
serverless platform that is super flexible

273
00:21:50,239 --> 00:21:53,889
and includes all the things that are
required, like an all in one platform,

274
00:21:54,679 --> 00:21:59,619
and it plays nice with all the hosted
models as well as your custom models.

275
00:22:00,279 --> 00:22:03,589
For example, if you want to tap into
any models that are hosted on AWS

276
00:22:03,619 --> 00:22:08,399
Bedrock, You can do or if you want to
connect directly to open AI or host

277
00:22:08,399 --> 00:22:12,519
your custom model, you will be able to
do that as well in the safe confines

278
00:22:12,569 --> 00:22:15,859
of that specific cloud provider.

279
00:22:15,869 --> 00:22:19,969
In this case, the initial version
was built with AWS, so you can

280
00:22:19,969 --> 00:22:24,669
run everything in a safe and
secure way in AWS account itself.

281
00:22:25,399 --> 00:22:29,099
And of course it got the power to reach
into a variety of data sources within your

282
00:22:29,459 --> 00:22:34,709
AWS account as well as across different
accounts, guaranteeing that there is

283
00:22:34,709 --> 00:22:41,799
a safe setup and data privacy across
your accounts and your applications.

284
00:22:42,149 --> 00:22:45,279
Nothing is going beyond the security
boundary with respect to the

285
00:22:45,279 --> 00:22:46,979
data or the privacy is concerned.

286
00:22:48,029 --> 00:22:51,099
I would like to quickly show this
simplified platform architecture.

287
00:22:51,129 --> 00:22:59,279
This is I made sure to bring it to the
essential model so that everybody can

288
00:22:59,289 --> 00:23:01,469
see what it takes to build this platform.

289
00:23:02,059 --> 00:23:04,729
And on top of it, of course,
you will be lots of additional

290
00:23:04,739 --> 00:23:05,649
modules and little customizations.

291
00:23:06,999 --> 00:23:11,669
But this will give you a com
a, a good gist of what it takes

292
00:23:11,669 --> 00:23:13,379
to build a platform like this.

293
00:23:14,329 --> 00:23:18,369
Starting with, you need an interface or
you will be using some kind of client

294
00:23:18,369 --> 00:23:23,289
applications that will interact with API,
so I'm not showing the UI piece of it.

295
00:23:23,819 --> 00:23:28,139
You can build it as an SPA using React or
Wrangler or view, for example, that will

296
00:23:28,379 --> 00:23:32,459
serve as an UI layer for your application
that will interact with the APIs.

297
00:23:33,499 --> 00:23:37,559
And this architecture shows what
it takes to build that API behind

298
00:23:37,559 --> 00:23:42,169
the scenes that can provide these
rich capabilities into the platform.

299
00:23:43,559 --> 00:23:47,709
So you have some kind of authorization
and authentication mechanism.

300
00:23:48,324 --> 00:23:51,994
We're just using Cognito in this case and
federated with single as single sign on

301
00:23:51,994 --> 00:23:58,794
if needed to connect to your enterprise
I am controls and an API gateway that

302
00:23:58,794 --> 00:24:03,444
will accept the request that are coming
in to be able to support streaming.

303
00:24:03,444 --> 00:24:05,174
Of course, you have other mechanisms.

304
00:24:05,224 --> 00:24:11,074
I'll touch upon just in a minute and
the crux of the solution is what we

305
00:24:11,074 --> 00:24:15,794
call as an orchestrator, This could be
a container service or a microservice

306
00:24:15,804 --> 00:24:22,924
or a group or a series of microservices
that are, that will work in collaboration

307
00:24:23,394 --> 00:24:27,704
to orchestrate the workflow that you
need to be able to answer that question.

308
00:24:27,894 --> 00:24:32,284
For example, if it is a straightforward
chatbot, it will directly go and hit the

309
00:24:32,294 --> 00:24:34,654
Bedrock API and get the responses back.

310
00:24:35,224 --> 00:24:39,174
Or if the Rack store, it will include
going to the Rack, bring the context.

311
00:24:39,789 --> 00:24:43,369
include that context and go
back to the bedrock model and

312
00:24:43,379 --> 00:24:44,689
then get the response back.

313
00:24:45,129 --> 00:24:51,639
And every interaction with the agents,
AI for BI, or the multi agent crews,

314
00:24:52,279 --> 00:24:56,059
the, all the crux of the interaction
happens inside the orchestrator.

315
00:24:56,519 --> 00:24:59,529
And it will be relying
on LLMs to do everything.

316
00:25:00,044 --> 00:25:04,014
Some of that work, but orchestrators
are the most important pieces

317
00:25:04,144 --> 00:25:05,474
in this specific context.

318
00:25:06,354 --> 00:25:08,784
And that's as simple as that.

319
00:25:09,214 --> 00:25:14,974
Once you have an orchestrator, and once
you have an API accessible to reach out to

320
00:25:15,054 --> 00:25:20,634
an LLM, this will give you everything you
need to be able to build a Gen I platform.

321
00:25:20,904 --> 00:25:23,104
Of course, you need access
to your data sources.

322
00:25:23,659 --> 00:25:29,819
API is functions and whatnot, as
well as workflows and pipelines set

323
00:25:29,819 --> 00:25:33,769
up that will allow you to upload
documents into your rack store.

324
00:25:34,504 --> 00:25:38,624
And convert them into and store
them into rack store for easy access

325
00:25:38,624 --> 00:25:43,164
later on as part of your queries
on top of it, you will be building

326
00:25:43,334 --> 00:25:44,664
lots of other building blocks.

327
00:25:44,664 --> 00:25:48,974
But this is the essential skeletal
architecture that anybody can build

328
00:25:48,974 --> 00:25:53,084
this platform very quickly and
then refine the platform later on.

329
00:25:55,104 --> 00:26:00,384
It's been close to a year now since
we launched the first version of our

330
00:26:00,454 --> 00:26:05,574
platform, and we have come a long
way and want to share a few things.

331
00:26:06,174 --> 00:26:09,774
That'll probably help you out if you're
also thinking or already building

332
00:26:09,824 --> 00:26:12,044
a platform like this on your own.

333
00:26:13,014 --> 00:26:18,364
the secret sauce to crafting this top
notch platform for your organizations

334
00:26:18,364 --> 00:26:23,854
and clients is training and education
because everybody's excited, but they're

335
00:26:23,854 --> 00:26:29,204
also scared a little bit on not to lose
their data, not to create another security

336
00:26:29,214 --> 00:26:34,764
incident and worried about what kind of
information is fed back into these models.

337
00:26:35,434 --> 00:26:39,234
and that somehow their information
doesn't show up in public anywhere.

338
00:26:40,044 --> 00:26:44,734
So it's very super important to train
everyone in the system, not just

339
00:26:44,734 --> 00:26:49,774
technical folks like developers and
testers, but everyone so that they

340
00:26:49,774 --> 00:26:53,804
will have the foundational skins, like
writing a simple prompt, asking the

341
00:26:53,804 --> 00:26:59,964
right question, right way so that LLM
can bring you more relevant answers.

342
00:27:01,424 --> 00:27:06,844
Since a lot of these folks are also
new to Gen A apps, adding and allowing

343
00:27:06,844 --> 00:27:09,724
them to experiment is really key.

344
00:27:10,284 --> 00:27:17,794
Because we cannot allow them to come up
with the right prompt the first time that

345
00:27:17,794 --> 00:27:23,614
experimentation is key and allowing them
to make mistakes is key and giving them

346
00:27:23,614 --> 00:27:32,094
that immediate feedback as part of the
cost is incurred based on their query.

347
00:27:32,434 --> 00:27:36,374
The latency aspects of performance
aspects, the bias aspects, the

348
00:27:36,374 --> 00:27:39,974
efficiency with how it was able
to pull that information from rag.

349
00:27:40,514 --> 00:27:44,294
So provide all that information
as a feedback to the users, but

350
00:27:44,304 --> 00:27:47,874
make sure that let them quickly
experiment in a private space.

351
00:27:48,549 --> 00:27:51,749
And whenever they're ready, let
them say, let them share it with

352
00:27:51,779 --> 00:27:52,969
everybody else in the system.

353
00:27:53,859 --> 00:28:00,019
And if it is developers, DevOps, security
folks, by allowing them to start using

354
00:28:00,019 --> 00:28:04,839
tools like GitHub Copilot, they get
better with asking questions, working with

355
00:28:04,849 --> 00:28:11,229
Copilots, and then that also allow them
to build applications like Copilots by

356
00:28:11,229 --> 00:28:13,789
themselves by using these capabilities.

357
00:28:14,349 --> 00:28:18,659
And organize some fun hackathons in
safe spaces so that Everybody can dive

358
00:28:18,659 --> 00:28:23,029
into examples, get inspired by looking
at what everybody else is doing, and

359
00:28:23,029 --> 00:28:26,279
get the lowdown on how to use it,
how to create these apps like a pro.

360
00:28:27,269 --> 00:28:31,239
And when you are building up your
platform, it is really crucial to organize

361
00:28:31,549 --> 00:28:37,239
these applications and capabilities
based on skills, based on use cases.

362
00:28:37,649 --> 00:28:39,449
And some sample apps as well.

363
00:28:40,199 --> 00:28:46,629
This will help everybody to understand
what is available, get inspired by

364
00:28:46,629 --> 00:28:51,409
looking at what everybody else in
your organization are doing, and then

365
00:28:51,579 --> 00:28:54,189
quickly start their own experiments.

366
00:28:55,329 --> 00:28:59,599
And make sure that whatever you
build, abstract away all the

367
00:28:59,599 --> 00:29:03,059
complexity and show the simple
interface that everybody can use it.

368
00:29:03,739 --> 00:29:07,239
And that is the key for success
of any of the, any platform.

369
00:29:08,229 --> 00:29:10,369
And it's also really important that.

370
00:29:11,514 --> 00:29:16,804
It is, it's going to be a long journey
for you as your team as well that are

371
00:29:16,814 --> 00:29:21,234
building this platform treated like
a product, start with an MVP, gather

372
00:29:21,234 --> 00:29:25,384
some user input, see how they're
using, where they're fumbling, what

373
00:29:25,384 --> 00:29:29,264
is working, what is not working, and
then constantly beep up those features,

374
00:29:29,944 --> 00:29:35,714
and then you can unlock additional
use cases, additional, capabilities

375
00:29:35,794 --> 00:29:38,074
and additional, security aspects.

376
00:29:38,754 --> 00:29:42,884
And, of course, a lot more metrics that
will make sense to your users as well.

377
00:29:43,314 --> 00:29:46,104
as I said, it's a journey,
it's a long journey.

378
00:29:46,194 --> 00:29:50,844
that learning and adaptation is really
important to be able to build any

379
00:29:50,844 --> 00:29:54,474
platform, but Janai specifically as well.

380
00:29:55,514 --> 00:30:00,594
And when we adopt a little bit more
structured approach to giving training

381
00:30:00,594 --> 00:30:06,104
to all kinds of users, giving them those
space spaces for experimentation, and

382
00:30:06,284 --> 00:30:10,444
taking their feedback and iteratively
build it, I think you definitely

383
00:30:10,444 --> 00:30:14,874
will pave the way for building a
really strong platform that caters

384
00:30:14,874 --> 00:30:20,184
to changing needs and evolving use
cases in your organization and, of

385
00:30:20,184 --> 00:30:21,684
course, for your customers as well.

386
00:30:22,784 --> 00:30:28,524
So with that, I will want to quickly
run down a few highlights as a

387
00:30:28,524 --> 00:30:30,494
summary from this conversation.

388
00:30:31,574 --> 00:30:35,984
It is really important to provide a
safe and secure sandbox for your users.

389
00:30:36,704 --> 00:30:42,014
And as I said earlier, try to optimize
your experiences for the non typical

390
00:30:42,014 --> 00:30:49,525
users first because the language or the
lingua franca for generative experience

391
00:30:49,525 --> 00:30:54,015
is a natural language and we want to
empower everybody in your organization to

392
00:30:54,015 --> 00:30:57,695
be able to do So make sure you optimize
your experiences for the non typical

393
00:30:57,705 --> 00:31:04,275
users and also create that environment
where they can learn from each other.

394
00:31:04,385 --> 00:31:08,220
Looking at the catalog of applications,
catalog of capabilities, demos, as

395
00:31:08,220 --> 00:31:12,125
well as shareable prompt libraries,
for example, go a long way.

396
00:31:13,145 --> 00:31:17,595
with that, I would like to take this
moment to thank you very much for joining

397
00:31:17,595 --> 00:31:23,695
this discussion on platform engineering,
especially building a Janai platform.

398
00:31:24,605 --> 00:31:26,945
Feel free to reach out on LinkedIn
if you would like to connect

399
00:31:26,945 --> 00:31:28,935
and continue this conversation.

400
00:31:29,605 --> 00:31:32,315
Thank you very much, and
have a wonderful day.

