1
00:00:14,220 --> 00:00:17,390
Hey y'all, hope you're doing great.

2
00:00:18,650 --> 00:00:21,949
Welcome to Conf42 Platform
Engineering, I'm Jony Paul.

3
00:00:22,930 --> 00:00:27,040
Today, we will deep dive in
the importance, the role of

4
00:00:27,090 --> 00:00:28,191
observability in platform engineering.

5
00:00:28,191 --> 00:00:28,654
Thanks for tuning in.

6
00:00:28,654 --> 00:00:29,914
I'm Jony Paul.

7
00:00:31,064 --> 00:00:36,941
So here is me, Neerja, a developer
advocate at Middleware and

8
00:00:36,941 --> 00:00:41,495
Observatory Classroom, building
various DevOps communities, running

9
00:00:41,555 --> 00:00:46,535
communities like Google Cloud, CNCF,
Docker, managing more than 15 plus

10
00:00:47,085 --> 00:00:51,239
hackathons, So yeah, let's go ahead.

11
00:00:51,240 --> 00:00:53,429
So what's in store for us?

12
00:00:54,500 --> 00:00:57,190
Why absolutely matters in
a platform engineering.

13
00:00:58,830 --> 00:01:00,190
So what are the key benefits?

14
00:01:01,080 --> 00:01:03,100
First is, optimizes resource allocation.

15
00:01:03,100 --> 00:01:11,189
It will drive the event in the sense
like, is there a resource scarcity?

16
00:01:11,630 --> 00:01:13,119
Or the resources are abundant?

17
00:01:13,120 --> 00:01:18,560
It can easily analyze from
the logs, from the matrices.

18
00:01:19,000 --> 00:01:21,050
AXS accelerates troubleshooting.

19
00:01:21,880 --> 00:01:28,190
From logs, we can easily, not
easily, but yeah, we can get a lot

20
00:01:28,190 --> 00:01:34,529
of things about troubleshooting,
how the error will be going.

21
00:01:36,500 --> 00:01:41,749
AXS enhances developer experience,
improves reliability, enables

22
00:01:42,060 --> 00:01:43,019
data driven decision making.

23
00:01:43,199 --> 00:01:48,369
Decision making always happens
from understanding the data, and

24
00:01:48,380 --> 00:01:50,490
data plays a quite important role.

25
00:01:51,015 --> 00:01:53,315
Of our next future predictions,

26
00:01:55,515 --> 00:01:59,075
so we're going to discuss
all of these points ahead in

27
00:01:59,075 --> 00:02:02,745
our next presentation slides

28
00:02:03,295 --> 00:02:06,455
so core objectives Of how's it ready?

29
00:02:06,705 --> 00:02:11,474
Let's understand it first and then
we can go ahead the core objectives

30
00:02:11,474 --> 00:02:16,351
are three major Log management,
so we collect different type of

31
00:02:16,351 --> 00:02:23,835
logs application logs Service logs
different sort of logs to understand

32
00:02:23,875 --> 00:02:29,840
the performance impact of the behavior
and All services, which are going on

33
00:02:32,520 --> 00:02:38,290
gathering mattresses, even just the
hand performance here and to try to

34
00:02:38,290 --> 00:02:39,689
understand the metrics, isn't it?

35
00:02:39,689 --> 00:02:42,999
The graph format will
understand it in a better way.

36
00:02:43,499 --> 00:02:50,499
So if you want to, and troubleshoot
the applications proactively,

37
00:02:51,289 --> 00:02:56,509
then your application will have
less downtime and will have higher

38
00:02:56,749 --> 00:02:58,379
performance but more efficiency.

39
00:02:59,399 --> 00:03:04,769
That's the general thing, but
yeah, elementary always helps

40
00:03:04,779 --> 00:03:07,469
you to improve your application.

41
00:03:10,229 --> 00:03:10,839
It is tracing.

42
00:03:10,840 --> 00:03:17,279
Traces, track the journey,
request through services.

43
00:03:17,689 --> 00:03:21,599
It can help to understand the bottlenecks.

44
00:03:22,939 --> 00:03:27,639
The issues which you are laying
down behind your performance,

45
00:03:28,139 --> 00:03:29,359
which you are downgrading.

46
00:03:29,969 --> 00:03:38,349
So it will help you to understand what
could be the actual reason of that.

47
00:03:38,899 --> 00:03:44,489
Let's understand the role of
the observability first versus

48
00:03:45,179 --> 00:03:48,309
optimized resource allocation.

49
00:03:50,114 --> 00:03:55,170
So Correlated Usage Data works with
system demand to scale a resource

50
00:03:55,170 --> 00:03:58,394
proactively and efficiently.

51
00:03:58,874 --> 00:04:06,194
So we have data of a workplace
application of how the application

52
00:04:06,244 --> 00:04:11,954
has worked or let's say how a single
piece of product has been sold.

53
00:04:12,514 --> 00:04:16,784
So in that manner we can understand
the demand and in the same manner

54
00:04:16,784 --> 00:04:20,084
we can understand how many resources
are required more in the future.

55
00:04:20,544 --> 00:04:21,344
In that sense.

56
00:04:23,549 --> 00:04:24,769
Let's take one example.

57
00:04:25,089 --> 00:04:26,379
This proactive scaling.

58
00:04:27,019 --> 00:04:31,019
By monitoring CPU and everything,

59
00:04:33,609 --> 00:04:37,239
teams can understand in which
sort of scenario they need

60
00:04:37,239 --> 00:04:39,199
to scale up the resources.

61
00:04:39,479 --> 00:04:42,709
Scale down the resources and when
is the peak time and when is the

62
00:04:42,709 --> 00:04:45,449
low time where they need to upscale.

63
00:04:45,499 --> 00:04:47,969
Teams can easily understand
from evaluating from

64
00:04:48,329 --> 00:04:50,269
observing their applications.

65
00:04:51,249 --> 00:04:53,029
Next is cost efficiency.

66
00:04:54,909 --> 00:04:58,319
Azure AD literally helps
to reduce your cost.

67
00:05:00,560 --> 00:05:09,374
Because some of their resources are under
provision and if you don't know That only

68
00:05:10,174 --> 00:05:18,494
10 20% of the resources are used and you
are being 70, 80% more money than anyone.

69
00:05:18,584 --> 00:05:24,544
It can definitely, you can definitely
understand and from the monitoring

70
00:05:25,674 --> 00:05:33,474
mattresses and everything that you need to
downgrade your resources and that's not,

71
00:05:33,474 --> 00:05:39,364
which can impact you across billing a lot.

72
00:05:41,804 --> 00:05:43,504
Next is extra troubleshooting.

73
00:05:43,994 --> 00:05:49,644
So we can quickly identify
and resolve issues by logs,

74
00:05:49,684 --> 00:05:51,534
traces, patterns, effectively.

75
00:05:51,535 --> 00:05:57,674
So for root cause analysis, one of the
good examples is root cause analysis.

76
00:05:58,254 --> 00:06:03,994
So for that, engineers can trace
issues back to their origin,

77
00:06:04,544 --> 00:06:06,094
whether it's misconfiguration.

78
00:06:06,654 --> 00:06:14,949
The goal, but if the Monitoring of the
ready is not setup, then it will be very

79
00:06:14,959 --> 00:06:22,129
hard to get what's the actual error or
what's the actual problem they are facing.

80
00:06:23,029 --> 00:06:24,639
So it eventually helps.

81
00:06:25,289 --> 00:06:33,054
Next is incident response, so real
time alerts so if they are using Some

82
00:06:33,054 --> 00:06:38,764
of the platforms for us to bring in
there, it can differently alert them

83
00:06:38,784 --> 00:06:45,354
and so they can have a lower downtime
and optimize their product or optimize

84
00:06:45,354 --> 00:06:48,254
their services in that particular time.

85
00:06:50,964 --> 00:06:53,274
Next is enhanced developer experience.

86
00:06:55,104 --> 00:07:00,744
The developer can understand in that
scenario what should be the better

87
00:07:00,744 --> 00:07:06,394
thing, how the performance of the
applications is better in production

88
00:07:06,624 --> 00:07:11,077
or is helping them understand how
changes, how some changes in new

89
00:07:11,077 --> 00:07:16,483
applications could affect the sales or
anything, sales or services or anything.

90
00:07:16,483 --> 00:07:22,339
From monitoring, from process, from logs,
it is definitely helpful for the end.

91
00:07:22,869 --> 00:07:28,149
Because it will lessen the time
for troubleshooting and more time

92
00:07:28,159 --> 00:07:30,882
for delivery of new features.

93
00:07:30,882 --> 00:07:36,623
It has improved reliability, continuously
monitored, refined platform components.

94
00:07:36,623 --> 00:07:39,813
For better uptime and stability.

95
00:07:39,813 --> 00:07:47,284
For uptime monitoring, other
tools, tech systems, and it

96
00:07:47,284 --> 00:07:50,139
immediately kills the alert.

97
00:07:50,140 --> 00:07:59,079
So if you have proper auxiliary setup,
you can have a message on Slack, message

98
00:07:59,079 --> 00:08:01,569
on emails, message on Teams, anywhere.

99
00:08:02,429 --> 00:08:05,519
Most of the auxiliary
platform deals with this.

100
00:08:06,039 --> 00:08:10,819
So if you got the alert, then you
can definitely try troubleshoot and

101
00:08:13,469 --> 00:08:15,329
get back your application in live.

102
00:08:16,999 --> 00:08:18,089
Anyway, rejection.

103
00:08:18,459 --> 00:08:21,279
So it was auxiliary solutions
use machine learning.

104
00:08:22,045 --> 00:08:29,434
We will definitely try to get this in
our next slides, where we will discuss

105
00:08:29,444 --> 00:08:32,424
what are the future trends in obsolete.

106
00:08:33,644 --> 00:08:38,665
Yeah, ML, EI, definitely help you
understand the anomaly detection.

107
00:08:38,665 --> 00:08:41,186
Yeah, that's a great point.

108
00:08:41,186 --> 00:08:43,707
Let's have a lean example.

109
00:08:43,707 --> 00:08:49,254
On a shopping sale, if your
bank is your dad's wallet,

110
00:08:52,884 --> 00:08:56,204
Then you can, nothing can
stop you to buy everything.

111
00:08:57,714 --> 00:09:04,484
Learning it was a black friday, most
of the people shopped, got on the shop

112
00:09:04,484 --> 00:09:09,924
and tried to collect everything because
there is a lot of sale, huge discounts.

113
00:09:10,354 --> 00:09:13,244
People collect a lot of things,
people purchase a lot of things.

114
00:09:15,184 --> 00:09:20,069
So to understand that sort of scenario,
If you are monitoring everything,

115
00:09:20,589 --> 00:09:25,419
so in this year, this sort of
thing happened like X, your sales

116
00:09:25,419 --> 00:09:28,459
were there compared to normal day.

117
00:09:30,069 --> 00:09:32,279
So you can understand like how many times.

118
00:09:34,139 --> 00:09:38,425
So it will eventually have you
to understand how people, which

119
00:09:38,425 --> 00:09:42,904
product, which thing is people
have purchased and that dilution.

120
00:09:44,574 --> 00:09:49,129
So it will eventually help you to
understand the analysis and understand

121
00:09:49,129 --> 00:09:55,534
and do the analysis for the next time for
future why we do analysis and monitoring

122
00:09:55,784 --> 00:10:00,254
to improve our application and our
future prediction and in what manner

123
00:10:00,654 --> 00:10:08,224
it will drive the train how to retrain
so always there are some challenges

124
00:10:08,414 --> 00:10:10,574
so let's see what are the challenges

125
00:10:12,884 --> 00:10:17,774
Data overload, because when we
collect data, we don't know what

126
00:10:17,774 --> 00:10:19,494
data is important, what and not to.

127
00:10:19,874 --> 00:10:24,774
So we always try to understand
which data is important for us.

128
00:10:25,574 --> 00:10:29,934
We don't capture all the data
and make a stack of everything.

129
00:10:31,204 --> 00:10:36,774
Next is integration complexity, because
people nowadays have multi cloud

130
00:10:37,114 --> 00:10:39,274
setup and using different things.

131
00:10:39,994 --> 00:10:43,504
So it is definitely hard
to have an observatory.

132
00:10:44,084 --> 00:10:46,374
So to integrate them,
it is very difficult.

133
00:10:46,924 --> 00:10:48,555
The skill gaps are so big.

134
00:10:48,555 --> 00:10:53,294
People need to understand to
implement EIMO and their operating.

135
00:10:53,634 --> 00:10:54,844
So what are the solutions?

136
00:10:54,854 --> 00:10:57,679
So use automated tools to
filter and monitor the data.

137
00:10:57,679 --> 00:11:01,694
Because as I already told, you
don't need to create stacks of data.

138
00:11:01,694 --> 00:11:03,114
Stacks of logs.

139
00:11:03,754 --> 00:11:05,584
You need to understand that data

140
00:11:07,774 --> 00:11:08,384
is important.

141
00:11:08,394 --> 00:11:09,944
But which data?

142
00:11:10,204 --> 00:11:10,864
Proper data.

143
00:11:12,024 --> 00:11:12,834
Not every data.

144
00:11:12,835 --> 00:11:12,849
EIMO.

145
00:11:13,429 --> 00:11:17,869
We need to understand, we need to
set up rules, flag, and slate, those

146
00:11:18,069 --> 00:11:22,339
logs which are really important
for us, which are like secure to

147
00:11:22,339 --> 00:11:26,869
bridge users, and is significant,
which impacts our performance.

148
00:11:27,989 --> 00:11:31,309
We need to understand that
sort of logs, and we need to

149
00:11:31,359 --> 00:11:33,519
put alerts, filters over them.

150
00:11:33,520 --> 00:11:36,429
This is selective data collection.

151
00:11:36,969 --> 00:11:43,239
We will only select captured data, so
what's our business object, and that's the

152
00:11:43,249 --> 00:11:44,689
sort of thing we will collect the data.

153
00:11:47,439 --> 00:11:53,790
So we always need a unified platform
because we have a multi cloud setup.

154
00:11:53,790 --> 00:11:58,969
We need observating where we go for
logs with other environment, traces with

155
00:11:58,969 --> 00:12:03,761
other environment, monitoring with other
environment, and it always create chaos.

156
00:12:03,761 --> 00:12:09,169
We need a single platform
where logs, traces, monitoring,

157
00:12:09,629 --> 00:12:11,699
everything could be possible.

158
00:12:12,309 --> 00:12:15,869
Even downloads with different
integrations with different third

159
00:12:16,059 --> 00:12:17,559
party applications are always possible.

160
00:12:19,009 --> 00:12:23,529
For example, you can see in middleware,
so in middleware, you can connect

161
00:12:23,529 --> 00:12:29,029
with many databases, every cloud
provider, seamlessly, you don't need

162
00:12:29,039 --> 00:12:31,529
to put your lot of efforts to it.

163
00:12:32,819 --> 00:12:35,599
So always a unified object
platform is required.

164
00:12:37,639 --> 00:12:41,059
What's the future of
obsolete and platforms?

165
00:12:43,439 --> 00:12:48,749
AI amelioration because always, as
I previously discussed, AI plays an

166
00:12:48,749 --> 00:12:50,309
important role for troubleshooting.

167
00:12:50,324 --> 00:12:53,714
We m like that general error.

168
00:12:54,314 --> 00:13:01,584
Using AI to make our absolutely our
analysis, more pro, more impactful,

169
00:13:04,039 --> 00:13:10,564
that can eventually help us to detect
many things and eventually have to

170
00:13:11,194 --> 00:13:19,054
make future decisions, is already
extending ability to edge computing.

171
00:13:19,444 --> 00:13:20,509
That's really a tough.

172
00:13:21,869 --> 00:13:27,759
Very wide topic and eventually in
next few years, it will be a boom.

173
00:13:29,329 --> 00:13:34,979
Open standards, the growth of production
of OpenTelemetry, new releases, new

174
00:13:35,149 --> 00:13:37,369
features every time OpenTelemetry have.

175
00:13:37,789 --> 00:13:42,799
And similar from some framework
for free is giving a lot of

176
00:13:42,899 --> 00:13:44,924
edge to people in our space.

177
00:13:46,344 --> 00:13:50,024
Let's discuss some of the best practices
for implementing observability.

178
00:13:51,694 --> 00:13:52,764
Start with clear objectives.

179
00:13:53,504 --> 00:13:55,494
Implement end to end tracing.

180
00:13:55,794 --> 00:13:57,474
Leverage automation.

181
00:13:57,834 --> 00:14:00,184
Adopt a continuous improvement mindset.

182
00:14:00,974 --> 00:14:06,124
Promote collection of observability
in your company, in your space.

183
00:14:06,504 --> 00:14:09,184
Regulate validated objective
tools and processes.

184
00:14:10,194 --> 00:14:14,477
So it's an end to end observatory
with class measuring what's

185
00:14:14,477 --> 00:14:19,744
important and you need to collaborate
both of thing to improve your

186
00:14:20,184 --> 00:14:22,024
performance, efficiency of your app.

187
00:14:22,674 --> 00:14:25,824
With me for any queries,
feel free to reach out to me.

188
00:14:26,244 --> 00:14:28,744
Any suggestions and feedback
will always appreciate it.

189
00:14:31,004 --> 00:14:31,714
Thank you.

190
00:14:31,715 --> 00:14:33,459
Have a nice day ahead.

