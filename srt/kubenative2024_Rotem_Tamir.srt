1
00:00:14,190 --> 00:00:14,960
Hi, everyone.

2
00:00:15,420 --> 00:00:20,630
My name is Rotem, and welcome to
my talk, Strategies for Reliable

3
00:00:20,880 --> 00:00:23,200
Database Schema Migrations.

4
00:00:24,020 --> 00:00:28,069
Before we jump into what that exactly
means, let me introduce myself.

5
00:00:28,680 --> 00:00:30,059
So my name is Otem.

6
00:00:30,550 --> 00:00:34,080
In the past three and a half
years, I'm the CTO and co founder

7
00:00:34,080 --> 00:00:34,810
of a company called Ariga.

8
00:00:36,129 --> 00:00:42,410
As part of my role, I have the awesome
responsibility to be a co maintainer of

9
00:00:42,410 --> 00:00:44,439
two fairly large open source projects.

10
00:00:45,065 --> 00:00:48,365
One of them is called Ent is
an entity framework for Go.

11
00:00:48,785 --> 00:00:52,354
It's part of the Linux Foundation,
started by my co founder when

12
00:00:52,355 --> 00:00:53,805
he was working at Facebook.

13
00:00:54,465 --> 00:00:59,505
And the second one, which we will go into
at depth today, is called Atlas, which

14
00:00:59,505 --> 00:01:01,385
is a database schema management tool.

15
00:01:04,465 --> 00:01:09,195
Before we go into how to make
schema migrations more reliable,

16
00:01:09,664 --> 00:01:11,065
I want to tell you a story.

17
00:01:11,425 --> 00:01:12,845
And it's my favorite kind of story.

18
00:01:13,265 --> 00:01:15,785
It is a developer horror story.

19
00:01:16,335 --> 00:01:17,315
It's a true story.

20
00:01:17,815 --> 00:01:22,335
Like in the TV show Fargo, all of
the events here really took place.

21
00:01:22,474 --> 00:01:23,615
We just changed the names.

22
00:01:24,315 --> 00:01:27,145
But the rest has been told
exactly as it occurred.

23
00:01:27,695 --> 00:01:29,835
It was a sunny day in Tel Aviv.

24
00:01:31,464 --> 00:01:34,935
The product manager asked our
developer for a simple request.

25
00:01:34,964 --> 00:01:39,664
Can we add a new status to the user
entity in our backend application?

26
00:01:41,115 --> 00:01:42,365
No problem, thought DDEV.

27
00:01:43,200 --> 00:01:44,070
I'm a professional.

28
00:01:44,960 --> 00:01:47,190
In this case, our developer is using an O.

29
00:01:47,190 --> 00:01:47,390
R.

30
00:01:47,390 --> 00:01:47,680
M.

31
00:01:48,410 --> 00:01:49,740
In no J.

32
00:01:49,740 --> 00:01:50,120
S.

33
00:01:50,260 --> 00:01:51,480
That is called sequel eyes.

34
00:01:52,189 --> 00:01:58,320
Sequel eyes lets you define your data
model in as javascript objects and this

35
00:01:58,320 --> 00:02:04,815
object at the status field and In it, we
list the possible values for this enum.

36
00:02:05,315 --> 00:02:08,744
So in this case, we added the
invited status to the list of

37
00:02:08,745 --> 00:02:13,344
possible values for the user status.

38
00:02:15,204 --> 00:02:18,634
Now, when you make a change
to the data model, you need to

39
00:02:18,874 --> 00:02:20,134
change the database as well.

40
00:02:20,345 --> 00:02:21,744
Otherwise, you're going to have drift.

41
00:02:21,744 --> 00:02:25,885
You're going to have an unsynchronized
situation where your application doesn't

42
00:02:26,105 --> 00:02:29,595
understand your database and your database
doesn't understand your application.

43
00:02:30,425 --> 00:02:35,445
For this purpose, Virtually all
frameworks provide some mechanism for

44
00:02:35,445 --> 00:02:38,135
what we call database schema equations.

45
00:02:38,625 --> 00:02:42,825
Basically, it's a way to express
the logic needed to be, that needs

46
00:02:42,825 --> 00:02:44,115
to be applied to the database.

47
00:02:44,685 --> 00:02:48,195
To bring it to the most recent version,
we call it migrations because it

48
00:02:48,285 --> 00:02:53,745
migrates from the previous version
to the next of the database schema.

49
00:02:54,295 --> 00:02:55,545
Our developer did just that.

50
00:02:55,554 --> 00:03:00,004
It was a tiny pull request, 10
lines of migration script, one

51
00:03:00,004 --> 00:03:02,155
line change on the data model.

52
00:03:04,544 --> 00:03:06,975
And our developer did
all the standard things.

53
00:03:07,655 --> 00:03:12,210
He created a pull request, the CI,
All of the automation, the unit

54
00:03:12,210 --> 00:03:14,310
tests, everything worked great.

55
00:03:15,100 --> 00:03:19,109
The team reviewed it, even the
tech lead gave it a thumbs up.

56
00:03:19,749 --> 00:03:22,010
Everything was by the book.

57
00:03:23,809 --> 00:03:28,589
Now came the best part of
any developer's life, right?

58
00:03:29,050 --> 00:03:32,639
All of the hard work that we did into,
we put into our software engineering,

59
00:03:33,069 --> 00:03:34,719
now we get to ship it to the world.

60
00:03:36,529 --> 00:03:37,969
Ship, our developer did.

61
00:03:39,290 --> 00:03:41,379
Can anyone guess what happened?

62
00:03:41,380 --> 00:03:50,969
The

63
00:03:51,529 --> 00:03:56,989
shocking sound of a full
blown database related outage.

64
00:03:59,279 --> 00:04:00,799
The system blows up.

65
00:04:01,919 --> 00:04:04,279
Database CPU shoots to the roof.

66
00:04:05,980 --> 00:04:10,134
100 percent error rate on all
the critical, Back in endpoints.

67
00:04:10,944 --> 00:04:15,184
And of course, 100 percent
unsatisfied management.

68
00:04:15,515 --> 00:04:18,784
The CTO is blowing down
our developers neck.

69
00:04:19,154 --> 00:04:19,854
What's going on?

70
00:04:20,214 --> 00:04:21,994
How do we fix this outage?

71
00:04:23,014 --> 00:04:24,624
So why did this happen?

72
00:04:25,004 --> 00:04:29,085
Let's do a quick postmortem to get
to the bottom of what is the core

73
00:04:29,085 --> 00:04:32,215
reason for this outage happening.

74
00:04:32,765 --> 00:04:36,494
On the technical level, the explanation,
maybe it's not known to everyone,

75
00:04:36,935 --> 00:04:39,474
But it's fairly simple to explain.

76
00:04:40,835 --> 00:04:46,794
Once our migration kicked in, we altered
the table, we modified the enum values.

77
00:04:48,265 --> 00:04:50,314
The way we did the change
caused the table to lock.

78
00:04:50,624 --> 00:04:55,234
When the table is locked,
nobody can write any new data.

79
00:04:55,775 --> 00:04:56,795
into this table.

80
00:04:57,745 --> 00:05:01,734
The reason is that the way my
sequel represents the enums on

81
00:05:01,734 --> 00:05:05,844
this, if we don't do the change
in the right way, the database

82
00:05:05,844 --> 00:05:07,965
needs to rewrite the entire table.

83
00:05:07,965 --> 00:05:10,914
Now, if the table is small, it
may take a few milliseconds.

84
00:05:10,944 --> 00:05:13,784
But in our case, a very busy
database in a very busy table.

85
00:05:14,274 --> 00:05:19,974
This lock can be acquired for hours on
it, which means a very long incident.

86
00:05:19,984 --> 00:05:24,354
By the way, there's nothing you can
do To stop this from rolling out,

87
00:05:24,465 --> 00:05:28,994
the rollback will only start being
applied after you finish this thing

88
00:05:29,425 --> 00:05:31,005
from after this thing completes.

89
00:05:32,345 --> 00:05:36,115
But in postmortems, we're
not usually interested in the

90
00:05:36,115 --> 00:05:38,395
superficial technical mechanics.

91
00:05:38,840 --> 00:05:39,640
of the outage.

92
00:05:39,680 --> 00:05:41,120
You want to get to the bottom of it.

93
00:05:41,530 --> 00:05:43,610
Why did this thing really happen?

94
00:05:43,990 --> 00:05:47,340
And for this, we have the famous
technique of the five whys.

95
00:05:47,800 --> 00:05:52,220
The idea is that we ask why five
times to get to the root cause or a

96
00:05:52,230 --> 00:05:55,100
deeper explanation of the incident.

97
00:05:55,660 --> 00:05:57,450
Why did the outage happen?

98
00:05:57,690 --> 00:05:59,880
Immigration locked the table.

99
00:06:01,235 --> 00:06:04,905
Why did the migration lock the table?

100
00:06:05,435 --> 00:06:07,865
Because our developer shipped broken code.

101
00:06:08,905 --> 00:06:09,515
Very simple.

102
00:06:10,395 --> 00:06:12,335
Why did our developer ship broken code?

103
00:06:12,885 --> 00:06:16,015
It wasn't caught during continuous
integration, and it wasn't caught

104
00:06:16,445 --> 00:06:18,565
in our staging environment.

105
00:06:19,225 --> 00:06:20,385
But why didn't we catch it?

106
00:06:20,935 --> 00:06:25,845
The truth is that we don't really have
automation to verify these changes, and

107
00:06:26,185 --> 00:06:28,365
we actually rely on human reviewers.

108
00:06:28,455 --> 00:06:31,355
In this case, the pull
request was approved.

109
00:06:32,070 --> 00:06:34,150
And it passed all of our quality checks.

110
00:06:36,030 --> 00:06:41,310
But how can something dissevere
all of our quality checks?

111
00:06:41,860 --> 00:06:43,370
Let's try to explore that.

112
00:06:45,599 --> 00:06:47,359
Okay, but why should we care?

113
00:06:47,359 --> 00:06:53,664
Why should we be even talking about making
Database schema changes more reliable.

114
00:06:54,215 --> 00:06:59,814
For many teams, there is an inherent
tradeoff between velocity, how fast

115
00:06:59,834 --> 00:07:04,695
they can move, how fast they can
make changes to their database, and

116
00:07:04,965 --> 00:07:07,235
the reliability of their service.

117
00:07:07,914 --> 00:07:13,835
Because the negative impact of a
bad schema change is very high,

118
00:07:15,184 --> 00:07:17,105
people start to fear change.

119
00:07:17,425 --> 00:07:18,625
They become slow.

120
00:07:18,815 --> 00:07:20,725
They don't do different refactorings.

121
00:07:20,775 --> 00:07:23,685
They maybe batch many changes together.

122
00:07:24,025 --> 00:07:26,450
In general, 13 becomes slow.

123
00:07:27,000 --> 00:07:34,660
So there is a very big payoff to be
able to make this tension obsolete.

124
00:07:34,850 --> 00:07:38,700
If we can both be faster and
more reliable at more time.

125
00:07:39,020 --> 00:07:42,889
At the same time, we can
provide a much better service.

126
00:07:45,824 --> 00:07:49,875
Okay, with the introductions
behind us, we are finally ready

127
00:07:49,924 --> 00:07:57,845
to discuss five strategies for
reliable database schema iterations.

128
00:07:59,255 --> 00:08:04,414
The first one I want to talk about is so
important that it gets the digit zero.

129
00:08:04,544 --> 00:08:07,144
It's not included in the five
strategies, but it's just a big one.

130
00:08:07,545 --> 00:08:10,734
Baseline that I want to get out of
the way before we start discussing

131
00:08:10,734 --> 00:08:16,604
this stuff for a surprisingly amount,
large amount of companies that I've

132
00:08:16,604 --> 00:08:18,494
talked to over the past three years.

133
00:08:19,185 --> 00:08:22,174
Database schema changes are not automated.

134
00:08:22,174 --> 00:08:27,215
It means that when you want to deploy a
version of your application that requires

135
00:08:27,215 --> 00:08:32,254
a change to the database schema, someone
manually or semi manually directly

136
00:08:32,274 --> 00:08:37,564
connects to the database And applies these
changes before this version is deployed.

137
00:08:37,624 --> 00:08:43,449
Now this is A very bad
practice for multiple reasons.

138
00:08:43,979 --> 00:08:45,949
One, it's error prone.

139
00:08:46,199 --> 00:08:50,119
We know from the DevOps movement
that automation is all about

140
00:08:50,119 --> 00:08:53,209
reducing the rate of defects.

141
00:08:53,399 --> 00:08:57,049
If we let a machine do something
that a human might mess up, we

142
00:08:57,049 --> 00:08:59,339
greatly reduce the chances of error.

143
00:08:59,879 --> 00:09:03,224
Also, migrations Become the
slowest link in the chain.

144
00:09:03,685 --> 00:09:07,594
If you automate everything except
for database schema changes, your

145
00:09:07,614 --> 00:09:11,515
velocity is limited by the rate
where you can do schema migrations.

146
00:09:11,564 --> 00:09:13,665
If that's manual, that is slow.

147
00:09:14,454 --> 00:09:14,915
It's not repeatable.

148
00:09:15,515 --> 00:09:16,944
It has no audit log.

149
00:09:17,284 --> 00:09:21,854
And I think maybe most importantly,
it's super unfair to your

150
00:09:21,854 --> 00:09:23,564
engineers and team members.

151
00:09:23,864 --> 00:09:27,564
Making a manual change on the
production database of a real database

152
00:09:27,839 --> 00:09:32,769
application is one of the most
stressful things you can do an engineer.

153
00:09:33,240 --> 00:09:39,460
So if you are not automating
yet, please start doing so today.

154
00:09:40,040 --> 00:09:43,109
The next principle I want to
talk about is something that I

155
00:09:43,109 --> 00:09:45,990
call database schema as code.

156
00:09:46,710 --> 00:09:50,949
This is the core principle behind
Atlas database schema management tool

157
00:09:51,369 --> 00:09:54,550
that my company Riga is building.

158
00:09:55,519 --> 00:09:59,579
It was started by my co
founder and I around 21 today.

159
00:09:59,589 --> 00:10:03,419
It's very popular in many
organizations and projects.

160
00:10:04,319 --> 00:10:05,260
all around the world.

161
00:10:05,870 --> 00:10:13,229
And the main idea with it is that you,
similar to Terraform, instead of planning

162
00:10:13,380 --> 00:10:19,770
changes in a manual way and listing out
every change to the database by yourself,

163
00:10:20,270 --> 00:10:25,930
you define the desired state of the
database and let the tool figure out the

164
00:10:25,930 --> 00:10:28,950
diff and calculate the migrations for you.

165
00:10:29,370 --> 00:10:35,605
So by further reducing Another
manual step in the chain of creating

166
00:10:36,105 --> 00:10:41,895
database changes, you can get a more
consistent and less error prone result.

167
00:10:42,385 --> 00:10:46,035
I want to show a quick demo
of this now of using Atlas.

168
00:10:47,785 --> 00:10:49,275
So let's see what we have here.

169
00:10:50,135 --> 00:10:53,525
So in our small project,
we have two files.

170
00:10:53,815 --> 00:10:55,475
One is the Atlas HCL file.

171
00:10:55,475 --> 00:10:59,210
This is the configuration file
that tells Atlas The desired state

172
00:10:59,210 --> 00:11:03,890
of the database is stored in this
schema file and the URL, the target

173
00:11:03,890 --> 00:11:08,480
database, which we are managing,
is going to be a local SQLite file.

174
00:11:08,779 --> 00:11:14,740
Now, when I want to apply this schema, I
run a simple command atlas schema apply,

175
00:11:15,330 --> 00:11:19,530
the local environment, and what Atlas will
do is it connects to the database, which

176
00:11:19,530 --> 00:11:23,925
currently does not exist, Let's plan the
migration, run some diagnostics, in this

177
00:11:23,925 --> 00:11:28,315
case it's a simple additive operation,
so no diagnostic found, and prompt us

178
00:11:28,315 --> 00:11:30,365
whether we want to approve the plan.

179
00:11:30,884 --> 00:11:31,625
Let's approve it.

180
00:11:32,405 --> 00:11:37,785
Now, the next time we run an Atlas schema
apply, as you can guess, Atlas detects

181
00:11:37,785 --> 00:11:42,285
that there is no difference between the
current and desired state, and therefore

182
00:11:42,675 --> 00:11:44,725
tells us that there is nothing left to do.

183
00:11:45,535 --> 00:11:49,745
Additionally, let's now show what
happens when we add an additional column.

184
00:11:50,150 --> 00:11:55,020
As you might expect, Atlas will plan
the addition of the email column by

185
00:11:55,170 --> 00:11:56,850
planning an ALTER TABLE statement.

186
00:11:57,200 --> 00:12:00,910
Again, this is a very simple
operation, so no diagnostics found,

187
00:12:01,180 --> 00:12:04,669
and we can safely approve and apply.

188
00:12:06,955 --> 00:12:12,565
The next strategy I want to mention
today is to test database logic the same

189
00:12:12,565 --> 00:12:15,815
way that you test code with unit tests.

190
00:12:16,215 --> 00:12:23,055
So databases are not only just
containers of information in tables.

191
00:12:23,564 --> 00:12:28,055
Databases have lots of application
logic that can be expressed inside them.

192
00:12:28,115 --> 00:12:34,134
For example, constraints, triggers,
stored procedures, functions.

193
00:12:34,790 --> 00:12:36,500
extensions and more.

194
00:12:36,740 --> 00:12:43,580
So the way that we ensure a reliable
application with code is that we write

195
00:12:43,670 --> 00:12:50,100
unit tests to verify that everything
works correctly, but also that future

196
00:12:50,100 --> 00:12:54,420
changes don't break the logic and
the expectations of the application.

197
00:12:55,190 --> 00:13:00,110
To this day, it's very difficult
to express this test for the logic

198
00:13:00,140 --> 00:13:02,100
that resides in your database.

199
00:13:02,480 --> 00:13:07,330
But like we said, the core principle
of Atlas is to take database

200
00:13:07,330 --> 00:13:09,610
schema and to make it into code.

201
00:13:10,030 --> 00:13:15,360
And using this principle, we're
also able to create a testing

202
00:13:15,360 --> 00:13:17,790
infrastructure for our database logic.

203
00:13:18,370 --> 00:13:19,660
Let's see what this looks like.

204
00:13:21,130 --> 00:13:22,780
Okay, let's take a look at our project.

205
00:13:22,940 --> 00:13:24,770
So we have a new schema file here.

206
00:13:25,175 --> 00:13:27,475
You will notice it's called schema.

207
00:13:27,475 --> 00:13:28,114
pg.

208
00:13:28,115 --> 00:13:28,345
hcl.

209
00:13:28,375 --> 00:13:32,725
This is a Postgres schema,
but we are using HCL.

210
00:13:33,105 --> 00:13:36,135
This is the Atlas HCL dialect.

211
00:13:36,135 --> 00:13:39,745
It's our configuration language
for defining databases.

212
00:13:40,035 --> 00:13:44,075
You can find here stuff like tables
and columns, and it will be familiar to

213
00:13:44,075 --> 00:13:46,225
you if you used Terraform in the past.

214
00:13:46,515 --> 00:13:50,065
I want to point your attention
to a bit of logic that is

215
00:13:50,065 --> 00:13:51,695
called the positive function.

216
00:13:52,105 --> 00:13:56,705
This block will end up becoming a
function defined on the database.

217
00:13:57,025 --> 00:14:01,505
Now, if database schema is code,
we should be able to test it.

218
00:14:01,604 --> 00:14:03,765
And Atlas provides you
with the testing framework.

219
00:14:04,025 --> 00:14:08,324
You can see this little green arrow,
see that your IDE recognized this

220
00:14:08,474 --> 00:14:13,084
block of text as a test, and you
can make assertions, for instance,

221
00:14:13,384 --> 00:14:18,025
that this statement, select positive
one, returns a truthy statement.

222
00:14:18,505 --> 00:14:23,074
Now, let's try to make this test fail
before to, to verify that it works.

223
00:14:24,054 --> 00:14:27,674
I run it and you will see
that this test failed.

224
00:14:28,084 --> 00:14:34,714
Now let's correct the input and now
we can show that the test passes.

225
00:14:35,864 --> 00:14:41,724
So by treating our database schema as
code, we are able to write the unit test

226
00:14:41,724 --> 00:14:43,864
for it just like we do for our code.

227
00:14:44,264 --> 00:14:45,304
We can make our.

228
00:14:45,844 --> 00:14:50,244
Database changes more reliable
by preventing from regressions.

229
00:14:50,534 --> 00:14:55,884
This test protects our users from any
developer in the future that makes

230
00:14:55,884 --> 00:14:58,024
a change that will break this logic.

231
00:14:58,614 --> 00:15:02,964
Most database migrations are about
making changes to the structure

232
00:15:03,034 --> 00:15:04,874
of the database, to its schema.

233
00:15:05,464 --> 00:15:11,104
But, oftentimes, teams need to
make changes to the actual data.

234
00:15:11,444 --> 00:15:14,624
For instance, if you have a full
name column, and you would like to

235
00:15:14,624 --> 00:15:17,514
split it into a first and last name.

236
00:15:17,864 --> 00:15:23,234
Now, the trouble with these types of
changes is that they are especially risky

237
00:15:23,534 --> 00:15:25,434
if you make this change in the wrong way.

238
00:15:25,839 --> 00:15:30,439
In most modern relational databases,
there is no undo button that is going

239
00:15:30,439 --> 00:15:34,079
to revert the changes to your data set.

240
00:15:34,559 --> 00:15:38,049
You might accidentally delete
data or cause some other very

241
00:15:38,059 --> 00:15:39,639
negative impact to the business.

242
00:15:40,359 --> 00:15:45,819
The second piece of trouble is that
to this day, there is no framework

243
00:15:45,849 --> 00:15:47,979
or harness that makes it easy.

244
00:15:48,629 --> 00:15:49,789
to write these kinds of tests.

245
00:15:50,379 --> 00:15:57,109
But thankfully, for people who adopt the
database schema is called Mindset, Atlas

246
00:15:57,169 --> 00:16:03,159
has a testing framework that enables
you to write tests for data migrations.

247
00:16:03,609 --> 00:16:04,239
Let's see how.

248
00:16:06,399 --> 00:16:08,589
Let's see how this works.

249
00:16:08,789 --> 00:16:13,459
In our example, we have a migration
directory with a bunch of migrations.

250
00:16:13,489 --> 00:16:18,344
Now, we are now in this scenario
where we create some trigger and we

251
00:16:18,364 --> 00:16:21,104
need to backfill existing records.

252
00:16:21,234 --> 00:16:24,194
Okay, so we have a trigger that's
going to populate some column, but

253
00:16:24,194 --> 00:16:27,104
we need to make sure that all of the
existing records in the users table

254
00:16:27,104 --> 00:16:29,014
also will contain the correct value.

255
00:16:29,464 --> 00:16:34,434
We create this data migration, this
backfill operation that updates

256
00:16:34,434 --> 00:16:39,804
the existing records in the users
table with the correct value.

257
00:16:40,244 --> 00:16:44,024
Now, how can we be sure
that this is correct?

258
00:16:44,374 --> 00:16:49,004
This query, this backfill
statement is correct.

259
00:16:49,564 --> 00:16:53,184
The only way that I know to
verify software quality in a

260
00:16:53,184 --> 00:16:55,114
reliable way is to use testing.

261
00:16:55,114 --> 00:17:00,034
So Atlas provides you with this
framework to write tests for migrations.

262
00:17:00,324 --> 00:17:01,454
And it works like this.

263
00:17:01,824 --> 00:17:05,474
We start by telling Atlas to migrate
the database to the version before

264
00:17:05,714 --> 00:17:06,994
the migration we want to test.

265
00:17:07,484 --> 00:17:10,204
Then we seed some data using insert into.

266
00:17:10,639 --> 00:17:15,659
Statements, then we run the migration
that we're interested in testing.

267
00:17:15,979 --> 00:17:17,609
And finally, we make some assertions.

268
00:17:17,609 --> 00:17:22,079
In this case, we verify that
the latest post timestamp

269
00:17:22,109 --> 00:17:24,429
column is populated correctly.

270
00:17:24,829 --> 00:17:27,229
Let's see that this works.

271
00:17:27,729 --> 00:17:28,209
Amazing.

272
00:17:28,549 --> 00:17:34,869
So what Atlas did was run this
test scenario on our local dev

273
00:17:34,869 --> 00:17:39,514
database to verify that the
that we get a reliable result.

274
00:17:42,574 --> 00:17:47,684
So far, we mostly covered strategies
that look at the application logic.

275
00:17:47,974 --> 00:17:52,524
How do we ensure that the application
logic that is stored in the database

276
00:17:53,009 --> 00:17:58,299
Behaves correctly and reliably remains
doing what it is supposed to do.

277
00:17:58,869 --> 00:18:02,649
But if you remember the beginning
of the talk, we looked at something

278
00:18:02,669 --> 00:18:03,959
that was completely different.

279
00:18:03,999 --> 00:18:10,629
We looked at cases where the actual
change of the schema is a risk factor.

280
00:18:11,569 --> 00:18:16,609
And if you think about it,
migrations are a very risky business.

281
00:18:16,619 --> 00:18:20,349
Let's mention some types of ways
that you can shoot yourself in

282
00:18:20,349 --> 00:18:21,979
the foot if you're not careful.

283
00:18:22,619 --> 00:18:30,189
You can accidentally drop a column
or a table if you're not careful

284
00:18:30,189 --> 00:18:34,089
causing you one to potentially
lose data that you cannot recover.

285
00:18:34,409 --> 00:18:36,819
And of course, if your application
relies on this resource

286
00:18:36,819 --> 00:18:39,019
to exist, you can cause a.

287
00:18:39,479 --> 00:18:40,309
Production outage.

288
00:18:41,089 --> 00:18:46,529
This might sound to you like something
that, never happens, but if you look at

289
00:18:46,559 --> 00:18:51,669
industry postmortems that are published,
such as this one that was published

290
00:18:51,669 --> 00:18:54,309
by recent in February of this year.

291
00:18:54,919 --> 00:19:00,919
You will notice that in this outage
that this company suffered around 5 a.

292
00:19:00,919 --> 00:19:01,179
m.

293
00:19:01,179 --> 00:19:05,459
They started the database
migration around a minute later.

294
00:19:05,509 --> 00:19:09,829
They noticed that accidentally some tables
were dropped from the production database.

295
00:19:10,264 --> 00:19:15,024
And the next 24 hours were not a lot
of fun for this team that need to work

296
00:19:15,024 --> 00:19:17,524
really hard to recover from this outage.

297
00:19:19,044 --> 00:19:24,894
Next, we have many migrations
may succeed in dev.

298
00:19:25,294 --> 00:19:28,964
They may succeed in staging when we
are dealing with smaller empty tables.

299
00:19:29,724 --> 00:19:34,564
But when we are, for example
changing constraints, like adding a

300
00:19:34,564 --> 00:19:40,599
uniqueness check, On a column, our
migration might fail in production,

301
00:19:40,669 --> 00:19:43,579
whereas it succeeded in development.

302
00:19:43,929 --> 00:19:48,489
Now, if this happens to us midway
immigration, depending on our database

303
00:19:48,489 --> 00:19:52,419
and different circumstances, we might
find ourselves in a limbo state where

304
00:19:52,419 --> 00:19:57,289
we are not at version a anymore, but
we are not yet at version B, causing

305
00:19:57,869 --> 00:20:01,019
rollbacks to be a potentially an issue.

306
00:20:01,259 --> 00:20:04,289
And of course, our server
doesn't necessarily know how

307
00:20:04,289 --> 00:20:06,259
to handle this situation.

308
00:20:07,889 --> 00:20:11,839
Additionally, we have the
potential to make breaking changes.

309
00:20:12,189 --> 00:20:16,249
So everybody today is talking about
data contracts, mostly between the

310
00:20:16,599 --> 00:20:18,549
production database and data warehouse.

311
00:20:18,859 --> 00:20:23,369
But there is also a data contract between
our backend application and our database.

312
00:20:23,794 --> 00:20:28,634
If we rename the column in a way that
was not, we didn't think it through

313
00:20:28,914 --> 00:20:32,704
all the way, we might end up in a way
where we break, broke the contract

314
00:20:32,704 --> 00:20:37,874
between backend and database, and
our queries are beginning to fail.

315
00:20:39,374 --> 00:20:46,159
Finally, as we saw in the horror story in
the beginning, Certain types of operations

316
00:20:46,559 --> 00:20:52,079
require the database to rewrite the table
on disk, which is a slow operation and

317
00:20:52,079 --> 00:20:57,949
an operation that requires the database
to take a lock on the database resource.

318
00:20:58,589 --> 00:21:03,899
This usually translates into a
production outage for any processes

319
00:21:03,899 --> 00:21:06,509
that rely on this table during runtime.

320
00:21:09,299 --> 00:21:13,099
So how do we prevent such
dangerous stuff from happening

321
00:21:13,119 --> 00:21:15,249
to our database in production?

322
00:21:16,469 --> 00:21:21,269
The way to do this is by automating
testing and verification to catch

323
00:21:21,269 --> 00:21:25,629
this kind of dangerous change
early in the process way before

324
00:21:25,779 --> 00:21:28,269
it hits our production database.

325
00:21:29,289 --> 00:21:36,029
Luckily, Atlas comes with a migration
analysis engine that knows how to

326
00:21:36,029 --> 00:21:39,609
understand the semantics of the
schema changes that are planned and

327
00:21:39,679 --> 00:21:42,609
classify them according to their risk.

328
00:21:42,924 --> 00:21:43,564
factors.

329
00:21:43,944 --> 00:21:45,554
Let's see how this looks like.

330
00:21:46,284 --> 00:21:50,414
So in this case, we have a small project.

331
00:21:50,864 --> 00:21:55,794
This is an SQLite database
with three tables, T1, T2, T3.

332
00:21:55,794 --> 00:21:58,474
Let's apply this locally.

333
00:21:59,684 --> 00:22:01,664
We are now creating these resources.

334
00:22:02,334 --> 00:22:08,964
And suppose now we want to
make a change and T3 table.

335
00:22:09,689 --> 00:22:15,899
As I'm commenting, I'm deleting
this table completely, and now let's

336
00:22:15,909 --> 00:22:18,129
see the change as it is planned.

337
00:22:18,779 --> 00:22:25,049
Now, first of all, the
plan is to drop table T3.

338
00:22:26,229 --> 00:22:29,159
Next, what Atlas does is it
uses its analysis engine.

339
00:22:29,649 --> 00:22:34,039
And what it tells us is that
destructive change detected.

340
00:22:34,309 --> 00:22:35,859
Dropping table T3.

341
00:22:36,789 --> 00:22:43,859
And it gives us a suggestion, but
we'll get into that into a later phase.

342
00:22:43,859 --> 00:22:48,659
Okay, so now Atlas warned us that
this type of thing might be risky

343
00:22:49,149 --> 00:22:50,929
and perhaps we should not do this.

344
00:22:51,289 --> 00:22:53,809
Let's look at another small example.

345
00:22:55,159 --> 00:22:57,749
Suppose we want to rename a column.

346
00:22:58,549 --> 00:23:03,649
If you recall from previous examples,
Our examples before, renaming a column is

347
00:23:03,649 --> 00:23:07,069
considered a backward incompatible change.

348
00:23:07,139 --> 00:23:11,439
So when we do this, first of
all, Atlas asks us if our intent

349
00:23:11,459 --> 00:23:14,169
was to rename or to drop an ad.

350
00:23:14,619 --> 00:23:18,889
We choose the rename option, but
then Atlas gives us the diagnostics

351
00:23:19,329 --> 00:23:23,259
and it tells us that a backward
incompatible change was detected.

352
00:23:23,629 --> 00:23:28,754
This warns us in time just before we apply
the dangerous change to the database.

353
00:23:29,824 --> 00:23:34,804
Now, this is very powerful during
development when I want a tool to assist

354
00:23:34,804 --> 00:23:41,044
me in finding these risky changes, but
it becomes much more powerful when we

355
00:23:41,044 --> 00:23:44,564
combine it with continuous integration.

356
00:23:45,064 --> 00:23:50,914
What if we could have Atlas run
and analyze these changes and

357
00:23:51,274 --> 00:23:56,034
during the CI phase to warn us way
before we merge the code to master.

358
00:23:56,344 --> 00:23:58,044
and deploy it to production.

359
00:23:58,474 --> 00:24:02,554
If we can catch these risky changes
early, we can end up with much

360
00:24:02,554 --> 00:24:06,674
more reliable database schema
migration deployment pipelines.

361
00:24:07,189 --> 00:24:11,859
Detecting risky migrations during
CI is a great strategy to enable

362
00:24:11,889 --> 00:24:14,269
reliable database schema migrations.

363
00:24:14,589 --> 00:24:20,819
However, some changes can only be verified
against a specific target database.

364
00:24:21,469 --> 00:24:25,589
For instance, Suppose that you
are adding a unique constraint to

365
00:24:25,609 --> 00:24:27,119
a column in one of your tables.

366
00:24:28,069 --> 00:24:32,699
Adding this unique constraint will
always succeed on an empty database,

367
00:24:32,709 --> 00:24:35,679
such as the one you might be
developing against, or the one that

368
00:24:35,679 --> 00:24:37,489
you're using in your CI environment.

369
00:24:37,859 --> 00:24:41,719
However, in production, if your
table already contains a duplicate

370
00:24:41,719 --> 00:24:48,819
value for this column, This migration
will, as we have shown in the,

371
00:24:49,029 --> 00:24:50,009
in one of the previous slides.

372
00:24:50,899 --> 00:24:52,919
So to help you,

373
00:24:53,449 --> 00:24:57,299
to help you get around this problem,
Atlas supports a really neat feature

374
00:24:57,299 --> 00:24:59,779
that is called pre migration checks.

375
00:25:01,069 --> 00:25:05,779
Essentially, what you can do, instead
of providing just a plain SQL file when

376
00:25:05,779 --> 00:25:11,789
defining an emigration, you can define a
file using the txtar text archive format.

377
00:25:12,489 --> 00:25:17,099
If we provide this txtar directive
at the top of the file, it tells

378
00:25:17,139 --> 00:25:21,189
Atlas that our migration file is
comprised of two different sections.

379
00:25:21,519 --> 00:25:23,089
One is the checks section.

380
00:25:23,549 --> 00:25:27,189
This allows us to run some logic
before the migration begins.

381
00:25:27,189 --> 00:25:31,639
For example, here we are checking
that the users table is not

382
00:25:32,129 --> 00:25:34,649
is empty before dropping it.

383
00:25:35,099 --> 00:25:41,474
During runtime, Atlas will run the
pre migration checks before deploying

384
00:25:41,484 --> 00:25:46,384
the migration, ensuring that we
don't lose any data in production.

385
00:25:52,074 --> 00:25:57,104
Okay, wrapping up, let's consider how
the five strategies that we presented

386
00:25:57,104 --> 00:26:02,244
today can improve and make database
schema migrations more reliable.

387
00:26:02,604 --> 00:26:05,644
So database schema is code
Terraform for databases.

388
00:26:05,914 --> 00:26:10,024
In general, automatically planned
migrations are less error prone

389
00:26:10,294 --> 00:26:14,664
and more predictable than manually
planned changes most of the time.

390
00:26:15,744 --> 00:26:20,344
Testing schema logic, being able to
write unit tests for your database

391
00:26:20,344 --> 00:26:22,074
logic can prevent regressions.

392
00:26:22,544 --> 00:26:27,094
As your application evolves, testing
data migrations when we need to

393
00:26:27,094 --> 00:26:31,474
rewrite data in our tables, part of
the immigration process can prevent

394
00:26:31,804 --> 00:26:36,394
data corruption and getting us
into a very nasty incident where we

395
00:26:36,394 --> 00:26:39,534
need to restore data from backups.

396
00:26:40,104 --> 00:26:44,547
Automated quality checks can detect
stuff like destructive changes,

397
00:26:44,547 --> 00:26:49,754
table logs and more early in the
software development lifecycle.

398
00:26:51,284 --> 00:26:55,684
locally during development
or during CI automation.

399
00:26:56,834 --> 00:27:02,444
Finally, we demoed we talked about
pre immigration checks that allow you

400
00:27:02,464 --> 00:27:07,714
to verify data dependent changes just
a moment before you roll them out

401
00:27:07,964 --> 00:27:10,264
because they depend on the actual data.

402
00:27:10,564 --> 00:27:12,634
That's inside the database.

403
00:27:13,354 --> 00:27:15,154
Thanks a lot for your time.

404
00:27:15,604 --> 00:27:16,684
I really appreciate it.

405
00:27:17,004 --> 00:27:21,584
And if any of this is interesting
to you, please visit us at atlasgo.

406
00:27:21,754 --> 00:27:22,324
io.

407
00:27:23,354 --> 00:27:23,894
See you soon.

