1
00:00:14,120 --> 00:00:14,990
Hi, everyone.

2
00:00:15,220 --> 00:00:16,320
I'm Ankit Virmani.

3
00:00:16,519 --> 00:00:19,720
I am an ethical AI and data
engineering specialist.

4
00:00:20,629 --> 00:00:27,139
today I'll be talking about the backend
AI solution and what goes into making it.

5
00:00:27,684 --> 00:00:33,224
the backend AI part for a very
exciting solution that all three

6
00:00:33,224 --> 00:00:36,014
of us will be presenting, today.

7
00:00:36,325 --> 00:00:43,095
And this solution will focus on
how we can use the marriage between

8
00:00:43,195 --> 00:00:46,725
artificial intelligence, software
development, and human computer

9
00:00:46,725 --> 00:00:52,245
interaction principles to help EV1A,
extraordinary ability, green card,

10
00:00:52,615 --> 00:00:55,184
achievers, potential achievers, and sorry.

11
00:00:55,525 --> 00:01:00,195
achieve their dream by learning through
this chat bot over to you, Tina.

12
00:01:01,535 --> 00:01:02,185
Hi everyone.

13
00:01:02,215 --> 00:01:03,165
I'm Tina Gada.

14
00:01:03,215 --> 00:01:06,115
I'm a senior UX designer for Vanguard.

15
00:01:06,165 --> 00:01:11,765
and today I will be presenting about how a
user experience and design works in a chat

16
00:01:11,805 --> 00:01:16,975
bot for EB1A, bot, as well as I will be
talking about how the human psychic works

17
00:01:17,015 --> 00:01:19,089
in terms of, response and the process.

18
00:01:19,330 --> 00:01:21,990
Reply for any chatbot experiences.

19
00:01:22,070 --> 00:01:27,770
Also how development cycle works and
integration of AI with human computer

20
00:01:27,860 --> 00:01:29,700
interaction within the mobile device.

21
00:01:29,790 --> 00:01:33,090
So I will be talking more
details about it over to you.

22
00:01:33,090 --> 00:01:33,700
Namaste.

23
00:01:35,000 --> 00:01:35,730
Hello, everyone.

24
00:01:35,760 --> 00:01:37,070
I'm Namashree Chandrana.

25
00:01:37,400 --> 00:01:41,990
I am a mobile application development
expert focusing on building applications,

26
00:01:42,010 --> 00:01:44,360
which, enhances user performance.

27
00:01:44,380 --> 00:01:50,120
And there'll be, I will be discussing
about how did we integrate our

28
00:01:50,160 --> 00:01:54,060
client and backend to talk with
LLM models to get responses, smart

29
00:01:54,120 --> 00:01:56,210
responses, from, The rag model.

30
00:01:56,830 --> 00:02:02,410
and, yeah, I'll also be focusing on
just telling tools that we used for, our

31
00:02:02,410 --> 00:02:04,030
client side and backend side as well.

32
00:02:05,940 --> 00:02:06,440
Thanks so much.

33
00:02:07,130 --> 00:02:08,490
Tina, do you mind putting the slides?

34
00:02:09,320 --> 00:02:09,740
Sure.

35
00:02:10,510 --> 00:02:14,390
All three of us are very excited to be
here and the solution that we are going

36
00:02:14,470 --> 00:02:19,610
to talk about today called the intelligent
conversational system for personalized

37
00:02:19,610 --> 00:02:22,104
EB1A guidance and service discovery.

38
00:02:23,175 --> 00:02:28,845
Why we came through this solution was
because, based on the market survey

39
00:02:28,845 --> 00:02:34,005
we did, it is becoming increasingly
difficult to get concise, consolidated,

40
00:02:34,105 --> 00:02:38,745
and, accurate information about
EV1A, which is also called the

41
00:02:38,745 --> 00:02:44,145
Extraordinary Ability Green Card,
as information is scattered online.

42
00:02:44,925 --> 00:02:49,695
So we thought, how about we bring together

43
00:02:50,695 --> 00:02:52,784
Manifested in chat

44
00:02:55,765 --> 00:02:56,405
bot.

45
00:02:56,785 --> 00:03:00,695
And that's why it's called an
intelligent conversational system.

46
00:03:01,085 --> 00:03:06,875
It's intelligent because it brings
the intelligence of talking.

47
00:03:09,235 --> 00:03:13,739
A human, it's conversational
because it's a bot and it's a system

48
00:03:13,739 --> 00:03:18,885
because it's a conglomeration of
UI, AI, and, software development.

49
00:03:19,155 --> 00:03:22,975
So we'll be talking about all those
three components in their capacity

50
00:03:23,015 --> 00:03:24,365
throughout this, presentation.

51
00:03:25,010 --> 00:03:26,210
Can you go to the next slide, Tina?

52
00:03:27,210 --> 00:03:30,811
So I think we've already done the speaker
introduction, so we can skip that.

53
00:03:30,811 --> 00:03:36,020
We'll talk a little bit about the
background, then how we had to

54
00:03:36,020 --> 00:03:39,490
implement the Retrieval Augmented
Generation from an AI standpoint.

55
00:03:40,300 --> 00:03:44,400
And then Namaste, we'll talk
about the mobile application

56
00:03:44,410 --> 00:03:46,716
with AI user experience.

57
00:03:46,716 --> 00:03:51,314
Tina will shed some light on how the user
experience integrates with everything.

58
00:03:52,525 --> 00:03:55,695
We'll talk about the final product
from challenges that we see while

59
00:03:55,725 --> 00:04:00,015
bringing all these three components
together and what we are thinking

60
00:04:00,015 --> 00:04:01,465
about from the future aspect.

61
00:04:02,465 --> 00:04:04,875
So as I was talking about
the background before.

62
00:04:06,240 --> 00:04:10,900
Ev1a expert bot was created to
simplify the complications that

63
00:04:11,850 --> 00:04:14,790
Ev1a has been in state as of today.

64
00:04:14,850 --> 00:04:19,280
And some of those complications,
are stemmed from the fact that there

65
00:04:19,280 --> 00:04:23,610
is so much information online, some
of it accurate, some of it not.

66
00:04:24,080 --> 00:04:29,420
And most of it is the time investment that
needs to be made to find a single correct

67
00:04:29,430 --> 00:04:34,790
source of truth So we wanted to cut down
the cycles of time That are required for

68
00:04:34,790 --> 00:04:39,530
someone to get their queries answered
and we thought what if we take All the

69
00:04:39,530 --> 00:04:45,345
correct data all the nice good quality
data that's available All the wisdom from

70
00:04:45,345 --> 00:04:50,545
someone who's really knowledgeable in this
space, bring that together in a bot and

71
00:04:50,545 --> 00:04:56,535
then have that manifest as an intelligent
conversational product or even, aspirin.

72
00:04:58,525 --> 00:05:02,815
we recognize need of something accessible,
which is something easy to use.

73
00:05:03,425 --> 00:05:08,765
Personalized guidance, because
being extraordinary is about being

74
00:05:08,805 --> 00:05:13,115
different from others, being different
from others, being, being unique.

75
00:05:13,645 --> 00:05:18,844
And with uniqueness comes the need
of having a personalized solution, a

76
00:05:18,845 --> 00:05:20,945
personalized guidance, easy to use.

77
00:05:21,315 --> 00:05:26,835
We did not want users to invest time in
figuring out what to do, rather than get

78
00:05:26,835 --> 00:05:33,695
the, get answers to the question, and a
24 7 tool available for talent worldwide.

79
00:05:33,985 --> 00:05:38,995
So those were the core tenets of
why we designed this board and

80
00:05:38,995 --> 00:05:40,445
what we designed this board on.

81
00:05:41,460 --> 00:05:47,430
And as I was mentioning before, this
bot is a unique combination of three

82
00:05:47,440 --> 00:05:49,060
schools of thought, Artifact and Dungeon.

83
00:05:50,180 --> 00:05:54,270
mobile application and,
and, user experience.

84
00:05:55,270 --> 00:05:58,720
Let's talk about the
artificial intelligence part.

85
00:06:00,540 --> 00:06:04,220
usually, large language models
operate on a huge corpus of

86
00:06:04,220 --> 00:06:06,500
data, that they're trained on.

87
00:06:07,200 --> 00:06:13,760
And, they might or might not have all
the information that while we were

88
00:06:13,760 --> 00:06:20,510
designing the B1A conversational system,
this was manifested as hallucination.

89
00:06:20,900 --> 00:06:26,030
And based on the testing that we did a lot
of times, then we would ask the question,

90
00:06:26,540 --> 00:06:32,460
we would promptly understand that the
answers that we got weren't accurate.

91
00:06:32,775 --> 00:06:36,875
to alleviate that concern that we had
during the initial development stages,

92
00:06:36,895 --> 00:06:42,165
we understood that we will have to
ground the model using a technology

93
00:06:42,165 --> 00:06:46,625
called Retrieval Augmented Generation
or a methodology rather to call, that's

94
00:06:46,635 --> 00:06:48,415
called Retrieval Augmented Generation.

95
00:06:50,025 --> 00:06:55,545
What it does is it retrieves the relevant
information from the document we feed

96
00:06:56,145 --> 00:07:01,260
into the system, augments the prompt
with that retrieved information, And

97
00:07:01,270 --> 00:07:05,730
then goes to the line language model
with the prompt and the retrieved

98
00:07:05,730 --> 00:07:07,610
information to get the accurate answer.

99
00:07:08,850 --> 00:07:12,120
So the important part here is the model
is not using its own intelligence,

100
00:07:13,000 --> 00:07:17,320
but it's using the intelligence from
the retrieved information that we have

101
00:07:17,580 --> 00:07:19,485
given to the model using a document.

102
00:07:19,485 --> 00:07:24,570
Now we know, or now we can expect the
kind of information we are going to get.

103
00:07:25,250 --> 00:07:29,790
So this is called grounding, where we are
grounding the model with the information.

104
00:07:30,345 --> 00:07:33,775
And this meant that all three
of us had to scout for a lot of

105
00:07:33,785 --> 00:07:38,670
good accurate documentation about
various aspects of EV1A and feed

106
00:07:38,670 --> 00:07:39,730
that into the model as document.

107
00:07:41,340 --> 00:07:45,130
whatever I just said is presented on
the slide in form of these four boxes.

108
00:07:46,060 --> 00:07:52,640
User issues a query, Knowledge Retrieval
System uses that query to fetch accurate

109
00:07:52,640 --> 00:07:57,870
document, information from accurate
document that we've already fed before.

110
00:07:58,720 --> 00:08:02,580
And then that fetched information
augments the user input.

111
00:08:02,960 --> 00:08:05,320
Now you have the prompt
plus that information.

112
00:08:05,860 --> 00:08:07,860
And that goes to the LLM model.

113
00:08:07,860 --> 00:08:12,030
And the model uses the augmented
information to give the answer.

114
00:08:13,100 --> 00:08:15,590
So this was a central
basis for the backend.

115
00:08:16,565 --> 00:08:22,531
Information that the bot would present on
the front end using software, development.

116
00:08:22,531 --> 00:08:24,735
Over to the next slide.

117
00:08:26,885 --> 00:08:31,895
So this is the end to end design
for the mobile application, that

118
00:08:31,915 --> 00:08:33,629
number three will walk us through.

119
00:08:34,020 --> 00:08:39,879
Which shows you the interface between
user, backend, and the middleware.

120
00:08:40,740 --> 00:08:41,290
Namaste, over to you.

121
00:08:42,610 --> 00:08:43,550
Thank you so much, Ankit.

122
00:08:43,870 --> 00:08:47,110
so yeah, for, for this slide I
will be discussing, specifically

123
00:08:47,110 --> 00:08:50,700
the primary feature of the
application, which is getting back

124
00:08:50,700 --> 00:08:52,990
the response, for a user query.

125
00:08:53,380 --> 00:08:55,720
I will break this
discussion into two parts.

126
00:08:55,940 --> 00:08:58,519
First, the client side
and the server side.

127
00:08:58,920 --> 00:09:01,760
For the client side, we have
currently just launched the

128
00:09:01,760 --> 00:09:03,440
application for iOS users.

129
00:09:03,790 --> 00:09:07,940
So the app is natively developed
using Swift, SwiftUI, and

130
00:09:07,940 --> 00:09:09,730
follows a TCA architecture.

131
00:09:10,340 --> 00:09:15,420
The core feature of the app is the
chatbot, which addresses the primary

132
00:09:15,420 --> 00:09:17,220
issue that we identified before.

133
00:09:17,760 --> 00:09:20,890
This is where the user
interacts with the chatbot.

134
00:09:21,010 --> 00:09:25,080
It sends a request to our backend,
and then our backend is responsible

135
00:09:25,120 --> 00:09:29,450
to fetch the Correct response for
us and get it back to the client.

136
00:09:30,230 --> 00:09:33,130
we will be discussing more about the
different screens that we have on

137
00:09:33,130 --> 00:09:34,530
the client side on our next slide.

138
00:09:34,710 --> 00:09:37,220
but I'll just move on to
the server side for now.

139
00:09:38,090 --> 00:09:43,200
The server is built using node JS with
JavaScript as a programming language.

140
00:09:43,590 --> 00:09:47,190
And it handles key functions like
user authentication, listening

141
00:09:47,190 --> 00:09:50,180
to the request from the client,
and also fetching the responses.

142
00:09:51,030 --> 00:09:55,640
So just as a user journeys upon receiving
a request from the client side, the

143
00:09:55,640 --> 00:09:57,700
server performs prompt engineering.

144
00:09:58,220 --> 00:10:03,130
So this is to ensure that the response
that we get from a RAG model is

145
00:10:03,130 --> 00:10:04,990
in the right format that we want.

146
00:10:05,650 --> 00:10:10,340
to make this request, we, the back
end request it to the LLM model for

147
00:10:10,340 --> 00:10:14,310
processing, and the back end continuously
monitors these requests because it

148
00:10:14,380 --> 00:10:19,800
takes some time to fetch the response
back as LLM model takes time to,

149
00:10:19,900 --> 00:10:24,290
process the query, and once that is
ready, we get it back on our back end,

150
00:10:24,580 --> 00:10:28,670
again, clean it up for the client side
and then send it back to the client.

151
00:10:29,260 --> 00:10:33,530
And to do the right LLM model, we just
experimented with different models that

152
00:10:33,560 --> 00:10:37,290
were available and went ahead with one
of the popular ones that is available.

153
00:10:37,670 --> 00:10:41,330
And this was purely based on
the ease of integration and

154
00:10:41,330 --> 00:10:43,700
the responses and the accuracy.

155
00:10:44,490 --> 00:10:47,750
now I'll just pass on to Tina to talk
about the user experience of our app.

156
00:10:49,675 --> 00:10:50,965
Thank you so much, Namaste.

157
00:10:51,125 --> 00:10:55,625
from the user experience standpoint, I
think one of the key element that I was

158
00:10:55,625 --> 00:11:01,465
primarily focused on is taking the user
interviews, making sure that the prospect

159
00:11:01,465 --> 00:11:08,115
E B 1 A client or applicant who is looking
for, Information online, or it could be

160
00:11:08,115 --> 00:11:11,955
a traditional way where they are reaching
out to our mentors or professional

161
00:11:11,985 --> 00:11:13,815
lawyers for getting all the information.

162
00:11:14,095 --> 00:11:17,785
How would we, how would they want to
process this information and what are the

163
00:11:17,875 --> 00:11:20,225
key, responses that they are looking for?

164
00:11:20,455 --> 00:11:23,845
So that was the first initial
task where I was trying to gather

165
00:11:23,865 --> 00:11:25,925
as many information as possible.

166
00:11:26,255 --> 00:11:28,875
The, another thing which
was playing an advantageous.

167
00:11:29,150 --> 00:11:34,180
We already have a very good tool
such as chat GPT and custom, GPT

168
00:11:34,590 --> 00:11:36,410
available and their mobile application.

169
00:11:36,410 --> 00:11:40,860
So one of the very key feature which
helped me was how the UI elements are

170
00:11:40,860 --> 00:11:43,880
working, what are the things that they
are doing as a part of the competitive

171
00:11:44,110 --> 00:11:46,560
analysis, which could be leveraged.

172
00:11:46,590 --> 00:11:50,080
So that certain things, certain elements
that they are doing, we are trying to

173
00:11:50,080 --> 00:11:55,300
leverage those elements as a part of
the application design and based on the

174
00:11:55,310 --> 00:12:00,140
close collaboration with the development,
such as that was we and understanding

175
00:12:00,140 --> 00:12:04,140
how the request response are working,
what is the response time that we are

176
00:12:04,140 --> 00:12:09,129
getting and how would we, Showcase
that response time in our UI pattern.

177
00:12:09,179 --> 00:12:11,099
That was something which
was very important.

178
00:12:11,379 --> 00:12:15,689
but, looking at the screen, we have
a very simple flow where users, if

179
00:12:15,689 --> 00:12:18,509
they are coming to the application
for the first time, they would be

180
00:12:18,779 --> 00:12:22,789
seeing and they have to register to
the app and use the sign up feature.

181
00:12:23,029 --> 00:12:26,849
But once they are signed up and they
come to the app, they have to log in the.

182
00:12:27,384 --> 00:12:30,064
Screen, log in and use the application.

183
00:12:30,334 --> 00:12:35,194
And the first time experiences since
user would be seeing the dashboard,

184
00:12:35,444 --> 00:12:40,534
where we are providing them the
questions such as what are the most

185
00:12:40,704 --> 00:12:44,824
big question or what are the questions
that we have known that users are

186
00:12:44,874 --> 00:12:46,604
asking based out of our research.

187
00:12:46,624 --> 00:12:51,414
And we have populated those questions as a
part of our first user experience screen.

188
00:12:51,754 --> 00:12:56,454
And upon clicking on any of the given
screen, given questions or entering

189
00:12:56,454 --> 00:13:02,424
certain question in a certain way, this
responses is very accurately provided

190
00:13:02,424 --> 00:13:06,384
where we are giving a summarization
of each and every responses, and then

191
00:13:06,384 --> 00:13:11,054
bulleted point of the sub-task or the
action item that they might be, able

192
00:13:11,054 --> 00:13:13,304
to do it and follow the certain steps.

193
00:13:13,654 --> 00:13:17,894
Over here, there were a couple of things
that we had focused, is brand guidelines

194
00:13:17,894 --> 00:13:19,844
since everything was from the scratch.

195
00:13:19,844 --> 00:13:24,254
So the brand guideline and visual
hierarchy was completely managed by,

196
00:13:24,514 --> 00:13:29,334
me in a way where we are building the
entire design system, the coding, which

197
00:13:29,334 --> 00:13:33,704
was done in a swift design because of
which it was easier so that all the

198
00:13:33,704 --> 00:13:35,644
guidelines which we have followed is iOS.

199
00:13:35,799 --> 00:13:40,819
These and ensuring the consistency
across differently and, making sure

200
00:13:40,819 --> 00:13:44,779
that we are focusing on accessibility
and inclusivity, with respect to the

201
00:13:44,779 --> 00:13:48,929
colors that we have choose and making
sure that each and every, contrast

202
00:13:48,929 --> 00:13:53,749
guidelines has been followed to make
this mobile application accessible,

203
00:13:53,749 --> 00:13:58,339
user friendly, as well as preparing
them to have a very good friendly

204
00:13:58,479 --> 00:14:00,719
experience at the past response time.

205
00:14:01,719 --> 00:14:02,949
What do you get?

206
00:14:04,439 --> 00:14:04,859
Thanks.

207
00:14:04,899 --> 00:14:06,189
Can you go to the next slide, please?

208
00:14:07,189 --> 00:14:11,399
Yeah, so this slide elucidates some
of the challenges that we face.

209
00:14:11,979 --> 00:14:17,119
accuracy of the model, as I was
mentioning before, large language models

210
00:14:17,119 --> 00:14:23,689
are trained on a corpus of data and it
is expected for them, to hallucinate.

211
00:14:24,349 --> 00:14:28,079
So we had to use retrieval
augmented generation to avoid

212
00:14:28,079 --> 00:14:30,979
some of the hallucinated
responses that we were getting.

213
00:14:31,949 --> 00:14:37,049
And it was imperative for us to do so
because this board endeavors to provide

214
00:14:37,069 --> 00:14:38,769
accurate information about each one.

215
00:14:38,770 --> 00:14:41,499
Namaste,

216
00:14:44,059 --> 00:14:46,827
do you want to take up the
rest of the challenge regarding

217
00:14:46,827 --> 00:14:48,234
the software development?

218
00:14:48,234 --> 00:14:49,172
Yes, definitely.

219
00:14:49,172 --> 00:14:54,649
I will cover the faster response request
response and the issues with integration

220
00:14:54,649 --> 00:14:56,639
of LLM model and the application.

221
00:14:56,640 --> 00:14:59,949
So I'm going to talk
about this both together.

222
00:15:00,494 --> 00:15:05,014
One of the primary issues that we faced
was the response time, and also, the

223
00:15:05,014 --> 00:15:09,114
requests that we sent to our model
were usually airing out if you're just

224
00:15:09,124 --> 00:15:11,804
trying to fetch the request in one go.

225
00:15:12,384 --> 00:15:17,314
And this was basically because,
the APIs had some token limits set.

226
00:15:18,014 --> 00:15:21,874
Per minute, for the current here,
or, that we were on for that model,

227
00:15:22,424 --> 00:15:26,614
therefore, report repeated requests
to the model often surpass the token

228
00:15:26,624 --> 00:15:28,814
limit, hence airing out our requests.

229
00:15:29,404 --> 00:15:33,714
Therefore, to solve this issue, we
added an exponential backoff to our

230
00:15:33,734 --> 00:15:36,694
backend, to request to our LL model.

231
00:15:36,954 --> 00:15:40,464
And that actually helped us to
decrease the response time to around

232
00:15:40,534 --> 00:15:42,184
five to seven seconds, which was.

233
00:15:42,340 --> 00:15:44,079
10 to 15 seconds before.

234
00:15:44,709 --> 00:15:48,479
this also helped reduce the error
rate because it, it solved the

235
00:15:48,479 --> 00:15:52,869
challenge where it, allowed us to
not reach the token limit or minute,

236
00:15:52,939 --> 00:15:54,709
because of the exponential back off.

237
00:15:55,069 --> 00:15:58,159
although we are still not at a
two or three second, which is

238
00:15:58,189 --> 00:16:02,289
ideal, for, users, to get, Get
a response, but that's something

239
00:16:02,309 --> 00:16:04,979
for future that we want to cover.

240
00:16:05,289 --> 00:16:09,129
but for now we still were able to
decrease it almost 10 seconds from

241
00:16:09,129 --> 00:16:13,139
what we were initially, over to you,
Tina, for the rest of the challenges.

242
00:16:14,369 --> 00:16:17,879
There are a couple of things that
we wanted to focus on is ensuring

243
00:16:17,879 --> 00:16:20,009
the consistency across the platform.

244
00:16:20,009 --> 00:16:24,749
So currently, we only have iOS
device and in future, we would be

245
00:16:24,749 --> 00:16:28,869
planning to have Android as well
as the web application where it's

246
00:16:28,889 --> 00:16:32,449
more accessible across different
platform based on the user's need.

247
00:16:32,759 --> 00:16:36,898
So that's one thing, which, is
challenging because every devices

248
00:16:36,898 --> 00:16:41,294
was the be and, to maintain that
consistency, something that we are.

249
00:16:41,599 --> 00:16:45,589
Figuring out, handling the
user feedback and iteration.

250
00:16:45,609 --> 00:16:51,019
So in the current functionality, we
do not have any way where users can

251
00:16:51,049 --> 00:16:56,869
provide their, detail of feedback
about how the interaction is happening.

252
00:16:56,869 --> 00:16:59,339
What are the things that they
can like possibly follow?

253
00:16:59,609 --> 00:17:03,526
And that's something, which is
limiting of another application.

254
00:17:03,526 --> 00:17:05,869
And that's what we want to focus on.

255
00:17:05,879 --> 00:17:06,199
And.

256
00:17:06,584 --> 00:17:09,384
Balancing the aesthetic and
the functionality part of it.

257
00:17:09,414 --> 00:17:11,254
So there are three key challenges.

258
00:17:11,294 --> 00:17:14,054
That is, what we are working towards.

259
00:17:15,054 --> 00:17:15,984
Over to you, Namasthi.

260
00:17:17,364 --> 00:17:23,134
yeah, for future work, we are currently
focusing on just personalized guidance.

261
00:17:24,354 --> 00:17:28,164
That's something we already provide
with our AI model, but just more

262
00:17:28,214 --> 00:17:32,104
towards, any action items that we
could auto generate for our users.

263
00:17:32,434 --> 00:17:36,134
That is something that we are looking for,
that would help in their EV1A journey.

264
00:17:36,644 --> 00:17:39,684
obviously the implementation, that's
something that Tina already talked about.

265
00:17:39,704 --> 00:17:42,204
Implementation of Android and
web applications currently

266
00:17:42,204 --> 00:17:43,434
available just on iOS.

267
00:17:43,954 --> 00:17:47,779
having a voiceover functionality as
well, this is, To reduce the typing

268
00:17:47,799 --> 00:17:50,819
time and also improve accessibility
of the application as well.

269
00:17:51,399 --> 00:17:55,229
and yeah, some reminders and notifications
of to do's that would be generated

270
00:17:55,249 --> 00:17:59,909
out of personal guidance, feature, and
also designing for global audiences.

271
00:17:59,939 --> 00:18:05,309
Currently, the application is just
released to us, audiences and it's not,

272
00:18:05,869 --> 00:18:10,089
unable for like global, audiences or
something that is again, We're targeting

273
00:18:10,089 --> 00:18:14,289
for because any money, like any individual
can apply for EB one, it, it could be

274
00:18:14,339 --> 00:18:17,069
even if they're outside of United States.

275
00:18:17,369 --> 00:18:21,089
So that's something also we are looking
to go blow global in the future.

276
00:18:22,649 --> 00:18:23,849
Yeah, that's about it.

277
00:18:23,849 --> 00:18:24,269
I think.

278
00:18:24,279 --> 00:18:24,819
Thank you.

279
00:18:25,239 --> 00:18:25,479
Thanks.

280
00:18:25,649 --> 00:18:25,959
Thanks.

281
00:18:25,959 --> 00:18:26,389
I must be.

282
00:18:26,409 --> 00:18:27,519
Thanks, Tina.

283
00:18:28,129 --> 00:18:28,409
Thank you.

284
00:18:28,449 --> 00:18:30,219
I hope all of you enjoyed.

285
00:18:31,174 --> 00:18:37,524
The idea, the thought and the work that
we have put in into the solution, we

286
00:18:37,524 --> 00:18:43,014
deliberately did not go into the specific,
the actual NLM module, the tooling, et

287
00:18:43,014 --> 00:18:48,054
cetera, because we wanted to keep it
very, neutral and objective and wanted

288
00:18:48,054 --> 00:18:53,304
to showcase our overall approach on what
happens when three different individuals

289
00:18:53,304 --> 00:18:54,914
with three different skill sets.

290
00:18:55,614 --> 00:19:00,234
Come together to solve a problem that
is so prominent and common in today's

291
00:19:00,274 --> 00:19:09,464
world using ai using ui using using
software development and a common

292
00:19:09,474 --> 00:19:13,304
skill that all of us have which is
naturally In addition to artificial

293
00:19:13,304 --> 00:19:15,334
intelligence to solve this problem.

294
00:19:15,894 --> 00:19:23,134
We do hope that you you like that
presentation once again Thank you

295
00:19:25,774 --> 00:19:26,394
Etc.

296
00:19:26,424 --> 00:19:30,074
Please feel free to reach out to us
You we would be more than happy to,

297
00:19:30,074 --> 00:19:32,054
to walk you through the specific.

298
00:19:32,624 --> 00:19:34,744
thanks once again, everyone, and
have a good rest of your day.

299
00:19:35,344 --> 00:19:35,974
Thank you.

300
00:19:36,284 --> 00:19:36,634
Thank you.

