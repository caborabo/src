1
00:00:14,100 --> 00:00:14,810
Hello, everyone.

2
00:00:15,170 --> 00:00:18,090
Welcome to my talk on building
a network telemetry platform

3
00:00:18,189 --> 00:00:19,619
to minimize security threats.

4
00:00:20,079 --> 00:00:24,869
As part of this presentation, we'll
dive into network telemetry, the

5
00:00:24,869 --> 00:00:30,405
need for a platform and what are
the things from the platform needed

6
00:00:30,415 --> 00:00:31,845
to minimize security threats.

7
00:00:32,885 --> 00:00:34,205
With that, let's get started.

8
00:00:35,265 --> 00:00:40,494
First, we'll take a look at why
we need network telemetry and the

9
00:00:40,494 --> 00:00:42,355
motivation for building a platform.

10
00:00:42,845 --> 00:00:47,315
Second, we'll look into the
fundamental building blocks required

11
00:00:48,185 --> 00:00:50,054
for creating such a platform.

12
00:00:50,754 --> 00:00:56,525
Third, we'll use the blocks and create an
architecture that will be able to ingest

13
00:00:56,545 --> 00:00:59,095
billions of network events every day.

14
00:00:59,095 --> 00:01:06,060
And Fourth, once we have the data
from the platform, how we can use

15
00:01:06,060 --> 00:01:08,030
it to minimize security threats.

16
00:01:08,500 --> 00:01:09,809
That is what we look into.

17
00:01:10,169 --> 00:01:15,360
Last but not the least, we'll take a
look at how we can extend our network

18
00:01:15,360 --> 00:01:18,169
telemetry platform to other feature sets.

19
00:01:19,169 --> 00:01:20,520
Why we need network telemetry.

20
00:01:22,170 --> 00:01:27,569
Gartner predicts by end of, by
2028, 50 percent of the enterprise

21
00:01:27,570 --> 00:01:28,769
companies will be on cloud.

22
00:01:30,295 --> 00:01:34,865
With the, with such rapid
adoption, companies are also facing

23
00:01:34,875 --> 00:01:36,765
increased cyber security risks.

24
00:01:37,924 --> 00:01:43,594
Zero Trust, a famous cloud security
model, also emphasizes the need for

25
00:01:43,685 --> 00:01:51,085
having, also emphasizes the need for
having network segmentation so that

26
00:01:51,335 --> 00:01:57,265
during an attack, or, yeah, during an
attack, the attack surface is minimized.

27
00:01:57,265 --> 00:01:57,494
Zero Trust.

28
00:01:58,479 --> 00:02:00,939
So how can we achieve this segmentation?

29
00:02:02,240 --> 00:02:06,690
One way is you have to first understand
the network topology of your organization.

30
00:02:07,099 --> 00:02:10,259
And in order to understand
network topology, that is where

31
00:02:10,619 --> 00:02:12,260
network telemetry will help.

32
00:02:13,869 --> 00:02:17,419
Second, threat detection
and anomaly detection.

33
00:02:17,849 --> 00:02:21,469
Imagine a threat actor has
entered your infrastructure.

34
00:02:21,849 --> 00:02:23,109
How will you detect that?

35
00:02:23,799 --> 00:02:28,084
Either using either by identifying
a malicious or an unknown IP.

36
00:02:29,354 --> 00:02:33,264
Next, let's say the threat actor is
trying to access a bunch of different

37
00:02:33,274 --> 00:02:34,844
resources in a short duration,

38
00:02:37,404 --> 00:02:40,273
which is definitely an
anomaly or an abnormality.

39
00:02:40,273 --> 00:02:44,894
You can run machine learning
algorithms on your network telemetry

40
00:02:45,274 --> 00:02:46,524
data to even identify these.

41
00:02:46,915 --> 00:02:56,864
So you have telemetry to identify unknown
or malicious IPs as well as anomalies.

42
00:02:58,245 --> 00:03:00,484
Lastly, compliance.

43
00:03:00,704 --> 00:03:05,825
Imagine you are a network service
provider or a service provider in the

44
00:03:05,825 --> 00:03:12,634
cloud, and you are offering services
to a ton of government agencies or you

45
00:03:12,635 --> 00:03:14,415
run in the national security regions.

46
00:03:15,285 --> 00:03:18,454
Network telemetry is an
important part of your audit.

47
00:03:19,454 --> 00:03:20,635
Why we need a platform.

48
00:03:22,265 --> 00:03:26,160
Think of platform as a framework
That you're setting up so

49
00:03:26,160 --> 00:03:27,750
that others can build on it.

50
00:03:27,980 --> 00:03:33,480
So it is not just one solution, but
it is an enabler for endless solutions

51
00:03:35,019 --> 00:03:39,149
Now that you have built a platform if
there are a bunch of scenarios that you

52
00:03:39,149 --> 00:03:43,890
want to enable on this It is easy for
the service teams to onboard what they

53
00:03:43,890 --> 00:03:48,539
have to do is Come to your platform
take the data you have and run with it.

54
00:03:48,940 --> 00:03:53,740
So you're Saving a lot of
cost and time for the company

55
00:03:55,779 --> 00:04:00,980
Third, we, you have also achieved
consistency and standardization because

56
00:04:01,149 --> 00:04:02,940
there is only one source of truth.

57
00:04:03,754 --> 00:04:08,765
You now have consistency with the way
how resources are accessed because you

58
00:04:08,765 --> 00:04:13,714
have one single store where customers
can come in and access the data and

59
00:04:13,714 --> 00:04:20,434
standardization because your schema and
contracts are fixed and whatever customers

60
00:04:20,434 --> 00:04:24,944
have and any partner teams that want
to onboard have to run with the schema.

61
00:04:25,944 --> 00:04:30,589
So what are the critical fundamental
blocks in a network telemetry platform?

62
00:04:31,169 --> 00:04:38,479
Like any other platform you have Services
that are collecting data Then you have

63
00:04:38,539 --> 00:04:44,079
enrichment going on which is responsible
for adding meaningful data to whatever you

64
00:04:44,089 --> 00:04:49,029
have right now And then standardization
as we were discussing previously One

65
00:04:49,029 --> 00:04:53,529
single way or one single pane of glass
experience for our customer teams

66
00:04:56,289 --> 00:04:59,259
Let's look at a typical
architecture on the left.

67
00:04:59,309 --> 00:05:04,879
You see there are a bunch of vms
And the VMs have something called

68
00:05:04,879 --> 00:05:06,819
an agent running in the behind.

69
00:05:07,009 --> 00:05:12,119
This is a background agent which runs
at regular intervals, maybe every

70
00:05:12,119 --> 00:05:18,229
two minutes or every one minute, and
identify all the ingress and decrease

71
00:05:18,259 --> 00:05:20,579
traffic and log that onto your system.

72
00:05:22,469 --> 00:05:27,799
If it is a Linux based system, you can use
tcpdump to take the snapshot, and if it is

73
00:05:27,799 --> 00:05:29,709
a Windows system, you can use windowsdump.

74
00:05:30,489 --> 00:05:35,994
Now, with all that information, logged
onto the disk, you have another agent that

75
00:05:35,994 --> 00:05:41,204
is responsible for shipping the telemetry
data from there to a data store or a SIC.

76
00:05:42,754 --> 00:05:48,604
One critical thing to remember here
is, it is better to think about the

77
00:05:48,605 --> 00:05:51,374
schema design from the beginning itself.

78
00:05:52,084 --> 00:05:57,364
So what you see below is a
schema that emit, that is

79
00:05:57,364 --> 00:05:59,214
emitted from the TCP dump, right?

80
00:05:59,924 --> 00:06:03,624
Source IP, source port,
destination IP, destination port.

81
00:06:03,694 --> 00:06:06,554
And then the VM ID is
something you attach.

82
00:06:06,934 --> 00:06:12,784
Now with all this information available
in the data store, also one more thing to

83
00:06:12,784 --> 00:06:14,674
emphasize is these are billions of events.

84
00:06:15,274 --> 00:06:19,944
Now you need a big data processing
pipeline to capture all this data.

85
00:06:20,124 --> 00:06:25,719
So either you can use streaming or
a bad job to Start processing the

86
00:06:25,719 --> 00:06:28,149
data and add additional enrichments.

87
00:06:28,759 --> 00:06:34,649
These enrichments can be anywhere from
adding more VM metadata like VM names,

88
00:06:34,650 --> 00:06:42,569
the account the VM belongs to, or the
VM SKU details to mapping this mapping

89
00:06:42,569 --> 00:06:47,169
the IP address, either the source or
destination to a particular IP range.

90
00:06:47,679 --> 00:06:54,139
generally have all the data stores
hosted between a particular IP range.

91
00:06:54,509 --> 00:07:00,739
And once you have a particular
IP, determining which IP range

92
00:07:00,739 --> 00:07:07,074
it belongs to will definitely
smoothen your operations later.

93
00:07:08,704 --> 00:07:13,014
So your big data or your
streaming jobs can also do that.

94
00:07:13,354 --> 00:07:18,034
And once you have enriched all this
information, you can put this in a

95
00:07:18,164 --> 00:07:22,734
final data store, which will become
the source of truth for your consumers.

96
00:07:23,604 --> 00:07:28,541
To reiterate, our platform architecture
consists of collectors, which is your

97
00:07:28,591 --> 00:07:33,951
agent and fluency agent gathering all
the data, sending it to a data store.

98
00:07:34,391 --> 00:07:36,271
And sending it to a data store.

99
00:07:36,711 --> 00:07:40,301
Then you have enrichment, which is
going on in your big data processing

100
00:07:40,301 --> 00:07:44,681
pipeline, where you add bulk of
data or additional metadata, and

101
00:07:44,681 --> 00:07:49,251
then you have your destination
where all the events are present

102
00:07:49,561 --> 00:07:52,971
so that the consumers can use that.

103
00:07:55,636 --> 00:07:59,846
Now with that information available,
what we have here is an alerting service

104
00:07:59,946 --> 00:08:05,346
that is able to go through the telemetry
data and alert the security teams

105
00:08:05,386 --> 00:08:07,686
based on any vulnerability threats.

106
00:08:09,376 --> 00:08:12,696
Let's look at how we can implement
the network security itself.

107
00:08:13,646 --> 00:08:18,066
First and foremost, for implementing
network security, you need baselines.

108
00:08:19,476 --> 00:08:25,626
At its core, baselines are the minimal
security policies that every team

109
00:08:25,636 --> 00:08:27,796
on the organizations should follow.

110
00:08:28,516 --> 00:08:36,346
These policies can range anywhere
from mandating Static analysis tools

111
00:08:36,496 --> 00:08:42,716
and secret analyzers into your build
process to blocking high risk ports

112
00:08:42,726 --> 00:08:47,876
like 22 on your virtual machines
where SSH brute force can happen.

113
00:08:50,076 --> 00:08:55,256
Now let's dive into our
network security architecture.

114
00:08:56,076 --> 00:09:00,076
So on the left, this is the
data store that we have created

115
00:09:00,156 --> 00:09:02,116
previously using a platform.

116
00:09:02,941 --> 00:09:09,601
And then you have your traffic analyzer,
which is reading data from the store And

117
00:09:09,611 --> 00:09:17,131
then it evaluates this data against a
baseline the baseline here can have rules

118
00:09:17,201 --> 00:09:25,181
something like Here is an example where
we are saying This is conformant traffic.

119
00:09:25,221 --> 00:09:31,541
That means the destination here,
let's say It belongs to a SQL server.

120
00:09:32,101 --> 00:09:37,271
Anyone communicating to the SQL
server must belong, must have this IP

121
00:09:37,301 --> 00:09:40,151
only, or must be from this VM only.

122
00:09:41,621 --> 00:09:45,821
If there is any other communication
going on to this destination,

123
00:09:45,821 --> 00:09:46,901
that is not confirm it.

124
00:09:47,541 --> 00:09:51,581
And then we immediately
alert those security teams.

125
00:09:52,556 --> 00:09:59,216
To reiterate, our rule is basic,
simply stating any communication

126
00:09:59,216 --> 00:10:06,146
to the destination, which is an
ingress, should be only from source 1.

127
00:10:06,146 --> 00:10:09,816
2, which can be a VM or
maybe an app service.

128
00:10:10,636 --> 00:10:16,586
Anything, any other communications
are non conformant and immediately be

129
00:10:16,586 --> 00:10:17,826
taken care of by the security team.

130
00:10:19,016 --> 00:10:21,256
Now, of course, this is
a very simple scenario.

131
00:10:21,686 --> 00:10:24,416
Let's took look, take a look
at a little complicated one.

132
00:10:26,246 --> 00:10:32,156
So here we have bunch of data
stores that are hosted in a

133
00:10:32,156 --> 00:10:33,986
particular IP test range, right?

134
00:10:34,016 --> 00:10:35,786
2.3 to two point 30.

135
00:10:36,386 --> 00:10:41,666
And these data stores might be, assigned
in an IP address from one of these ranges.

136
00:10:42,656 --> 00:10:46,316
Now I go and tag this IP
address ranges data store.

137
00:10:48,786 --> 00:10:55,856
Next, what I have is a VM that is
trying to communicate to this IP address

138
00:10:55,856 --> 00:11:02,316
range, which also has another tag,
which is called VM for simplicity.

139
00:11:03,626 --> 00:11:07,156
So your baseline rule can simply
say, if it is an ingress data,

140
00:11:07,176 --> 00:11:10,746
the source should be VM and the
destination should be a data store.

141
00:11:11,326 --> 00:11:16,266
And if the destination is the data
stored, and if the source is not in.

142
00:11:16,811 --> 00:11:19,811
In the ones you're looking
for, you can immediately mark

143
00:11:19,811 --> 00:11:20,961
the data as non compliant.

144
00:11:22,901 --> 00:11:29,361
Actually, you can take a step further
saying, if the source or destination

145
00:11:29,361 --> 00:11:33,711
is not a service tag, I immediately
mark the data as non compliant.

146
00:11:35,131 --> 00:11:38,701
In this way, by step, I can
improve the overall security

147
00:11:38,701 --> 00:11:40,611
posture of my organizations.

148
00:11:41,731 --> 00:11:44,921
Now, one more thing we've,
I forgot to discuss this.

149
00:11:46,161 --> 00:11:52,351
This telemetry platform we see
here is, will take time to build.

150
00:11:53,301 --> 00:11:57,811
Now, if you're on cloud, you
can leverage existing solutions.

151
00:11:57,821 --> 00:12:04,681
For example, AWS, Azure, or Oracle have
flow logs that give you information about

152
00:12:05,551 --> 00:12:08,721
ingress and egress data in your cloud.

153
00:12:10,106 --> 00:12:14,646
Now, with that information, what you have
to store is, what you have to do is just

154
00:12:14,646 --> 00:12:19,956
store the data in a, maybe an S3 bucket
or an Azure storage, and then pull the

155
00:12:19,956 --> 00:12:21,756
data from there for your processing.

156
00:12:22,186 --> 00:12:28,446
So in that way, you have completely
get rid of the agent and the

157
00:12:28,446 --> 00:12:32,866
Fluentd that is responsible for
sending your data to the data sink.

158
00:12:33,216 --> 00:12:36,596
You can just rely on the cloud
providers to send them to your sink.

159
00:12:36,676 --> 00:12:38,996
And from there, you can do
your additional processing.

160
00:12:39,996 --> 00:12:42,846
With that, let's get to extensions.

161
00:12:43,546 --> 00:12:45,456
now you have a very good platform, right?

162
00:12:45,476 --> 00:12:47,426
Now you can add more scenarios to it.

163
00:12:47,796 --> 00:12:50,826
So one scenario is
security recommendation.

164
00:12:51,196 --> 00:12:55,066
Let's say with the telemetry
data you have, you are able to

165
00:12:55,086 --> 00:12:57,346
achieve network segmentations.

166
00:12:57,756 --> 00:13:00,966
And what you observe is some
of the service teams are

167
00:13:00,996 --> 00:13:02,986
communicating across these segments.

168
00:13:03,646 --> 00:13:05,716
Which you want to drastically reduce.

169
00:13:06,136 --> 00:13:11,266
Now you can provide recommendations based
on this traffic to the team saying how

170
00:13:11,306 --> 00:13:18,336
they can reduce the segmentation so that
how they can reduce the cross traffic

171
00:13:18,346 --> 00:13:23,866
communication across the segment so that
the overall security posture improves.

172
00:13:25,266 --> 00:13:33,621
Similarly, because you have the data right
now, You can identify if your network is

173
00:13:33,651 --> 00:13:38,231
reaching to a capacity and immediately
look for capacity provisioning.

174
00:13:38,341 --> 00:13:42,821
For example, let's say there is a bunch of
communication between the virtual machines

175
00:13:42,821 --> 00:13:48,191
and your data store, and you see the
bandwidth is at 60 to 70 percent capacity.

176
00:13:48,561 --> 00:13:52,581
That is when you will go and decide
that, okay, we need more capacity.

177
00:13:52,581 --> 00:13:53,551
So we'll add it there.

178
00:13:54,641 --> 00:13:57,281
These are the further, these
are further extensions that

179
00:13:57,321 --> 00:13:58,691
you can add to the platform.

180
00:14:01,611 --> 00:14:06,061
To conclude, as cloud adoption
grows, network telemetry will

181
00:14:06,101 --> 00:14:11,231
start becoming important to
monitor and protect organizations.

182
00:14:11,771 --> 00:14:16,471
So it is important that we start
investing in such platforms so that

183
00:14:16,471 --> 00:14:21,911
when the time comes, we are resilient
from infrastructure failures and hacks.

184
00:14:23,521 --> 00:14:25,351
With that, I conclude my talk.

185
00:14:26,581 --> 00:14:30,016
If you have any further questions or
if you have any feedback, Good luck.

186
00:14:30,346 --> 00:14:31,826
Please feel free to reach out to me.

187
00:14:31,866 --> 00:14:34,146
This is my LinkedIn email and Twitter.

188
00:14:34,716 --> 00:14:35,536
Thank you everyone.

189
00:14:35,736 --> 00:14:37,274
Thank you for listening to the talk

