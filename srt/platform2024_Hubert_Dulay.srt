1
00:00:14,580 --> 00:00:15,550
Hello, everyone.

2
00:00:15,660 --> 00:00:19,760
Welcome to the streaming plane,
the plane that brings all

3
00:00:19,799 --> 00:00:21,490
other data planes together.

4
00:00:23,359 --> 00:00:27,260
I'm Hubert Dulay, developer advocate
at StarTree, the company that provides

5
00:00:27,260 --> 00:00:30,159
Apache a real time OLAP database.

6
00:00:30,835 --> 00:00:34,985
I'm really happy to be presenting among
many other data experts here at COMP42.

7
00:00:35,485 --> 00:00:40,095
About me, I'm the primary author
of two O'Reilly books, Streaming

8
00:00:40,095 --> 00:00:42,184
Data Mesh and Streaming Databases.

9
00:00:42,724 --> 00:00:47,175
And in this presentation, you'll get
to see some ideas from both books.

10
00:00:48,734 --> 00:00:51,745
In this session, you'll learn
about a few concepts that are

11
00:00:51,745 --> 00:00:53,214
shaping the future of data.

12
00:00:53,395 --> 00:00:58,345
First, we'll explore the data divide,
what it is and why it's becoming a

13
00:00:58,375 --> 00:01:00,304
critical challenge in data management.

14
00:01:01,050 --> 00:01:04,639
Next, we'll discuss data gravity
and how it influences where

15
00:01:04,639 --> 00:01:06,329
and how data is processed.

16
00:01:06,850 --> 00:01:10,360
We'll also introduce the
streaming plane, a crucial layer

17
00:01:10,829 --> 00:01:13,289
for handling real time data.

18
00:01:13,859 --> 00:01:19,389
And finally, we'll cover how to
effectively consume real time analytics.

19
00:01:20,060 --> 00:01:23,380
Enabling you to make data
driven decisions instantly.

20
00:01:24,380 --> 00:01:27,509
The data divide describes data
movement within a business and

21
00:01:27,509 --> 00:01:31,339
is crucial for understanding how
data drives business decisions.

22
00:01:32,070 --> 00:01:36,380
In summary, The data divide
distinguishes between two main

23
00:01:36,389 --> 00:01:41,530
data planes, the operational
and the analytical data planes.

24
00:01:42,270 --> 00:01:45,999
The operational data plane consists
of data stores that support the

25
00:01:45,999 --> 00:01:50,039
application's powering a business,
while the analytical data plane is

26
00:01:50,039 --> 00:01:52,399
focused on data analysis and insights.

27
00:01:52,829 --> 00:01:57,884
The idea is that the insights derive
from the Analysis are fed back to

28
00:01:57,884 --> 00:02:02,404
the operational plane in hopes of
generating more revenue or, more

29
00:02:02,404 --> 00:02:04,734
importantly, preventing revenue loss.

30
00:02:06,554 --> 00:02:11,544
As data moves through a typical
pipeline, it doesn't just get copied.

31
00:02:11,924 --> 00:02:17,024
It undergoes transformations, cleansing,
and security processes like encryption.

32
00:02:17,475 --> 00:02:21,165
The data is secure and reliable
by the time it reaches the end.

33
00:02:21,610 --> 00:02:25,930
However, getting this refined data
out of analytical systems is tough

34
00:02:25,960 --> 00:02:30,900
because these systems often reformatted
into formats like Parquet, which

35
00:02:30,900 --> 00:02:35,559
are great for analysis, but make it
hard to access complete data sets.

36
00:02:36,040 --> 00:02:41,780
This is where ETL, Extract Transform
Load, and ELT, Extract Load

37
00:02:41,800 --> 00:02:44,930
Transform, processes come into play.

38
00:02:45,289 --> 00:02:48,219
While there's debate on which
is better, the lines between

39
00:02:48,219 --> 00:02:49,719
them are starting to blur.

40
00:02:52,189 --> 00:02:55,140
Each plane has its own type of database.

41
00:02:55,170 --> 00:02:59,129
On the operational plane, you get
OLTP databases that are optimized for

42
00:02:59,129 --> 00:03:04,899
operational workloads like Insert,
Update, Delete, and Single Row Lookups.

43
00:03:04,940 --> 00:03:07,180
These databases are usually row based.

44
00:03:07,875 --> 00:03:12,005
On the analytical plane, databases
are optimized for analytical

45
00:03:12,005 --> 00:03:14,445
workloads like aggregations and joins.

46
00:03:14,774 --> 00:03:19,774
These are called OLAP databases, or
Online Analytical Processing databases.

47
00:03:20,054 --> 00:03:24,474
What makes them special is that they store
data in columnar formats, which is more

48
00:03:24,474 --> 00:03:26,954
efficient for running complex analyses.

49
00:03:27,285 --> 00:03:30,984
OLAP systems keep a history of
all the data that originated

50
00:03:31,295 --> 00:03:32,875
from the operational side.

51
00:03:33,344 --> 00:03:37,865
That's really useful for tracking changes
over time and seeing how things evolve.

52
00:03:38,244 --> 00:03:41,274
In the operational plane,
you'll see microservices

53
00:03:41,274 --> 00:03:43,184
supporting various applications.

54
00:03:43,535 --> 00:03:47,355
And on the analytical side,
you'll find data lakes, data

55
00:03:47,355 --> 00:03:49,105
warehouses, and lake houses.

56
00:03:49,605 --> 00:03:54,324
But here's the thing, since the data on
the analytical side is already clean and

57
00:03:54,324 --> 00:03:59,475
transformed, why should transformations?

58
00:04:00,135 --> 00:04:03,184
Moving data from analytical
to operational is hard.

59
00:04:03,535 --> 00:04:04,824
It's an upstream path.

60
00:04:05,220 --> 00:04:08,140
OLAPs don't like to return
all rows and columns.

61
00:04:08,400 --> 00:04:10,240
That's not what they are optimized to do.

62
00:04:10,270 --> 00:04:15,129
Remember that these databases are
intended for analytical workloads.

63
00:04:15,450 --> 00:04:19,790
Selecting all the raw records from a
table in an OLAP is expensive and slow.

64
00:04:20,129 --> 00:04:25,360
Solutions like we're Reverse ETL and data
activation are designed to help bring this

65
00:04:25,380 --> 00:04:28,000
polished data back into your applications.

66
00:04:30,820 --> 00:04:36,140
Data gravity is a concept that compares
data to a planet, where accumulated data

67
00:04:36,150 --> 00:04:41,299
attracts services and applications, much
like a planet's mass pulls in moons.

68
00:04:42,110 --> 00:04:46,950
In traditional data architectures,
data flows from operational systems,

69
00:04:47,270 --> 00:04:54,430
moons to an analytical system, the
planet, leading to potential overload

70
00:04:54,430 --> 00:04:58,780
and latency as the analytical system
becomes burdened with historical data.

71
00:04:59,389 --> 00:05:04,099
However, with a streaming plane, data
can be processed closer to its source,

72
00:05:04,179 --> 00:05:08,910
acting like satellites that alleviate
the gravitational pull, enabling smoother

73
00:05:08,910 --> 00:05:11,150
data flow and real time analytics.

74
00:05:11,520 --> 00:05:16,660
Data gravity Highlights the challenges
of managing growing data, while the

75
00:05:16,670 --> 00:05:21,530
streaming plane offers a solution for more
effective data movement and processing.

76
00:05:22,530 --> 00:05:26,940
In the streaming plane, you'll typically
find several key systems working together.

77
00:05:27,340 --> 00:05:31,655
First, There are connectors, which
enable seamless data flow between

78
00:05:31,655 --> 00:05:34,205
various sources and destinations.

79
00:05:34,625 --> 00:05:40,215
Then, we have streaming databases that
store and manage real time data streams.

80
00:05:40,885 --> 00:05:45,924
Real time OLAP data stores provide
the ability to perform fast

81
00:05:45,955 --> 00:05:48,225
analytical queries on streaming data.

82
00:05:48,905 --> 00:05:53,545
Streaming platforms like Kafka, Red
Panda, and Pulsar are the backbone.

83
00:05:53,925 --> 00:05:57,315
Handling the distribution,
and routing of data streams.

84
00:05:57,474 --> 00:06:00,495
And finally, stream processing
frameworks, which allow you to

85
00:06:00,495 --> 00:06:05,544
process and analyze data in motion,
ensuring timely insights and actions.

86
00:06:07,415 --> 00:06:13,004
There are two ways to serve streams of
data, synchronously and asynchronously.

87
00:06:13,315 --> 00:06:16,905
Synchronous serving is handled by
databases that consume directly

88
00:06:16,905 --> 00:06:22,575
from the stream, such as streaming
databases and real time OLAP databases.

89
00:06:22,905 --> 00:06:27,565
Real time OLAP databases are specifically
optimized for analytical queries,

90
00:06:27,824 --> 00:06:32,505
allowing you to query real time data
with low latency and high concurrency.

91
00:06:32,970 --> 00:06:36,020
High concurrency means these
systems can efficiently serve

92
00:06:36,030 --> 00:06:38,530
many end users simultaneously.

93
00:06:38,930 --> 00:06:42,310
On the other hand, asynchronous
serving of processed data

94
00:06:42,310 --> 00:06:44,159
streams is managed by Kafka.

95
00:06:44,729 --> 00:06:48,250
In the diagram, the two Kafka
icons represent either the same

96
00:06:48,250 --> 00:06:52,560
Kafka cluster or different clusters
replicating data across them.

97
00:06:53,050 --> 00:06:57,410
The key difference between synchronous
and asynchronous serving lies in

98
00:06:57,410 --> 00:06:59,510
how data is consumed and delivered.

99
00:07:00,085 --> 00:07:04,224
In synchronous serving, the client
requests data and waits for an immediate

100
00:07:04,224 --> 00:07:09,244
response, which can lead to delays
if the data is large or complex.

101
00:07:09,795 --> 00:07:15,630
Conversely, Asynchronous serving allows
clients to subscribe to data changes

102
00:07:15,630 --> 00:07:20,670
and receive updates in real time without
waiting for a request response cycle.

103
00:07:21,160 --> 00:07:24,799
This approach is more efficient
for handling continuous streams

104
00:07:24,799 --> 00:07:28,959
of data as it enables clients to
react to changes as they occur.

105
00:07:29,210 --> 00:07:31,320
Ensuring that no updates are missed.

106
00:07:32,020 --> 00:07:36,880
Asynchronous systems, like those
utilizing Kafka, can handle high volumes

107
00:07:36,880 --> 00:07:41,470
of data and provide a more scalable
solution for real time data processing.

108
00:07:44,149 --> 00:07:48,500
Data locality and replication are
crucial concepts in the streaming plane.

109
00:07:48,850 --> 00:07:52,800
For example, if your operational
data is in EMEA but you need to serve

110
00:07:52,800 --> 00:07:56,950
it in APAC, you wouldn't want your
APAC systems to constantly reach

111
00:07:56,950 --> 00:07:59,270
out to EMEA for real time data.

112
00:07:59,530 --> 00:08:02,810
This would create latency
and potential bottlenecks.

113
00:08:03,140 --> 00:08:06,210
Instead, you replicate that
data between regions, and tools

114
00:08:06,210 --> 00:08:07,840
like Kafka make this easy.

115
00:08:08,190 --> 00:08:11,820
By creating replicas of your
data in other regions, you ensure

116
00:08:11,820 --> 00:08:15,139
that applications local to those
regions can consume streaming

117
00:08:15,139 --> 00:08:17,780
data efficiently and in real time.

118
00:08:18,200 --> 00:08:20,670
And keep in mind, because
this data is still within a

119
00:08:20,670 --> 00:08:22,270
Kafka topic, it's streaming.

120
00:08:22,700 --> 00:08:26,260
In real time, operating within
the physical limits of speed,

121
00:08:26,600 --> 00:08:27,680
like the speed of light.

122
00:08:28,720 --> 00:08:32,910
A materialized view is a database
object that contains the results of a

123
00:08:32,910 --> 00:08:36,190
query, storing them as a physical table.

124
00:08:37,085 --> 00:08:42,924
Unlike traditional views, which execute
the underlying SQL statement at query time

125
00:08:42,924 --> 00:08:47,754
and do not store results, materialized
views pre compute and cache the results,

126
00:08:47,775 --> 00:08:50,025
allowing for faster data retrieval.

127
00:08:50,485 --> 00:08:54,755
They can be refreshed periodically or
on demand to keep the data up to date.

128
00:08:55,165 --> 00:08:59,835
But in the context of stream processing,
materialized views are continuously and

129
00:08:59,855 --> 00:09:02,975
incrementally updated as new data arrives.

130
00:09:03,365 --> 00:09:08,275
This capability makes them particularly
valuable for improving query performance,

131
00:09:08,605 --> 00:09:13,855
reducing data duplication, and simplifying
analytics, especially in environments

132
00:09:13,865 --> 00:09:16,265
where real time data access is crucial.

133
00:09:16,585 --> 00:09:21,724
Balancing between push and pull queries is
essential for optimizing performance and

134
00:09:21,725 --> 00:09:24,735
meeting specific use case requirements.

135
00:09:25,425 --> 00:09:30,175
One effective approach is to utilize
materialized views, which can act as

136
00:09:30,175 --> 00:09:32,425
a bridge between the two query types.

137
00:09:32,755 --> 00:09:37,974
By submitting a push query to create a
materialized view, clients can benefit

138
00:09:37,974 --> 00:09:42,974
from the heavy lifting done by the push
query, while simultaneously subscribing

139
00:09:42,974 --> 00:09:45,149
to changes in the materialized view.

140
00:09:45,609 --> 00:09:49,069
The balance between push and
pull queries can be adjusted

141
00:09:49,069 --> 00:09:50,869
based on the application's needs.

142
00:09:51,170 --> 00:09:56,690
For instance, if low latency is paramount,
a greater reliance on push queries may

143
00:09:56,690 --> 00:10:01,890
be warranted, while scenarios requiring
more complex queries might benefit

144
00:10:01,890 --> 00:10:04,184
from the flexibility of pull queries.

145
00:10:04,564 --> 00:10:07,514
Ultimately, the choice depends
on the specific requirements of

146
00:10:07,524 --> 00:10:10,764
the application and the nature
of the data being processed.

147
00:10:12,895 --> 00:10:17,324
The diagram that models how to
balance push and pull queries

148
00:10:17,365 --> 00:10:21,385
illustrates the tradeoff between
query flexibility and latency.

149
00:10:21,854 --> 00:10:25,204
It features a box in the middle
representing a materialized

150
00:10:25,204 --> 00:10:29,625
view, which serves as a bridge
between the two types of queries.

151
00:10:30,405 --> 00:10:34,080
As you move down the diagram, The
materialized view provides less

152
00:10:34,080 --> 00:10:37,600
flexible queries but offers better
performance, meaning that the

153
00:10:37,600 --> 00:10:39,880
queries execute with lower latency.

154
00:10:40,359 --> 00:10:44,380
This is ideal for scenarios where
immediate data availability is critical,

155
00:10:44,380 --> 00:10:48,560
such as user facing applications
that require real time updates.

156
00:10:49,000 --> 00:10:52,069
Conversely, as you move up the
diagram, the queries become more

157
00:10:52,069 --> 00:10:55,930
flexible, allowing for deeper
insights and more complex queries.

158
00:10:56,420 --> 00:11:01,310
However, This increased flexibility
comes at the cost of higher latencies,

159
00:11:01,880 --> 00:11:05,960
as a serving engine has to perform
more work to fulfill these requests.

160
00:11:06,460 --> 00:11:09,689
The overall concept is that
push and pull queries can work

161
00:11:09,689 --> 00:11:13,839
together to find the right balance
between latency and flexibility.

162
00:11:14,399 --> 00:11:18,690
Push queries are preferred for low
latency requirements, while pull

163
00:11:18,690 --> 00:11:23,909
queries offer the flexibility needed
for more complex analytical tasks.

164
00:11:24,460 --> 00:11:28,310
The materialized view acts as
a compromise, allowing users

165
00:11:28,319 --> 00:11:33,010
to benefit from both approaches
depending on their specific use case.

166
00:11:33,490 --> 00:11:38,740
This balance is crucial for optimizing
real time analytics, as it enables

167
00:11:38,980 --> 00:11:43,290
systems to react to events while
also providing the capability to

168
00:11:43,290 --> 00:11:46,040
perform ad hoc queries when necessary.

169
00:11:48,975 --> 00:11:52,125
Global replication and local
consumption are vital in the

170
00:11:52,125 --> 00:11:55,845
streaming plane for optimizing
performance and reducing latency.

171
00:11:56,455 --> 00:12:02,215
Global replication duplicates data across
multiple nodes, ensuring consistency and

172
00:12:02,215 --> 00:12:08,234
enabling efficient workload distribution,
while local consumption allows for faster

173
00:12:08,244 --> 00:12:12,764
access to data at its source, enhancing
performance and resource optimization.

174
00:12:13,245 --> 00:12:17,805
Together, we They create a robust
framework for efficient data processing

175
00:12:17,805 --> 00:12:21,685
and scalability in streaming environments,
supporting federated governance

176
00:12:21,685 --> 00:12:23,505
and tailored security measures.

177
00:12:25,195 --> 00:12:28,784
The streaming plane enables the
creation of virtual data products that

178
00:12:28,785 --> 00:12:33,164
can be consumed locally, even if the
source of the data resides remotely.

179
00:12:33,595 --> 00:12:37,435
This is achieved through a
streaming platform like Kafka.

180
00:12:37,795 --> 00:12:42,845
Users can query and interact with
data locally while it is incrementally

181
00:12:42,845 --> 00:12:45,285
replicated from different global regions.

182
00:12:45,855 --> 00:12:49,175
A streaming data catalog is
essential to managing these

183
00:12:49,185 --> 00:12:51,315
virtual data products effectively.

184
00:12:52,014 --> 00:12:57,444
It serves as an inventory of data and
its metadata, enabling users to discover

185
00:12:57,444 --> 00:12:59,984
and subscribe to streaming data products.

186
00:13:00,395 --> 00:13:04,655
The catalog provides crucial
metadata, including table definitions,

187
00:13:05,175 --> 00:13:10,770
validation rules, data types,
and lineage information, which

188
00:13:10,770 --> 00:13:14,690
helps consumers understand the
data's provenance and processing.

189
00:13:15,290 --> 00:13:19,290
In summary, the streaming plane
facilitates the consumption of virtual

190
00:13:19,300 --> 00:13:25,050
data products that may exist remotely,
while a robust streaming data catalog

191
00:13:25,060 --> 00:13:29,100
ensures effective governance and
understanding of these data products.

192
00:13:31,310 --> 00:13:34,560
The Venn diagram of the
operational, analytical, and

193
00:13:34,560 --> 00:13:39,200
streaming planes illustrates how
these areas of data processing

194
00:13:39,230 --> 00:13:41,849
are distinct yet interconnected.

195
00:13:42,140 --> 00:13:46,630
The operational plane focuses on
transaction processing and generating

196
00:13:46,630 --> 00:13:50,599
real time data, while the analytical
plane is dedicated to complex tasks.

