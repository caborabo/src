1
00:00:14,180 --> 00:00:16,830
Hi, I'm Daniel Fedotov.

2
00:00:16,840 --> 00:00:22,519
I'm a senior open source engineer in
custom by Veeam and today I'd like to

3
00:00:22,520 --> 00:00:29,219
talk about how can we use cloud native
approach and tools to organize data

4
00:00:29,219 --> 00:00:36,050
protection in our applications deployed
in cloud native and talk about using

5
00:00:36,090 --> 00:00:41,399
Kinesis CEO is which is, CNCF project
and an open source tool to do that.

6
00:00:42,379 --> 00:00:46,370
starting from why do we do that, right?

7
00:00:46,469 --> 00:00:51,320
Kubernetes deployments have come a
long way, since first introduction.

8
00:00:51,645 --> 00:00:58,125
But there's still some, myths around
data on Kubernetes, such as everything

9
00:00:58,125 --> 00:01:05,695
is stateless, which isn't true because
Kubernetes itself has a state and,

10
00:01:05,755 --> 00:01:10,355
it changes and there's something new
being added, something being removed.

11
00:01:10,835 --> 00:01:16,280
And also, stateful workloads, people run
stateful workloads on Kubernetes because

12
00:01:16,280 --> 00:01:18,200
they need state in their applications.

13
00:01:18,200 --> 00:01:21,290
And if you want to run the application
as Kubernetes, they need state.

14
00:01:22,060 --> 00:01:27,260
the myth being that why would I need
to protect my data when I can just

15
00:01:27,330 --> 00:01:30,380
recreate my application, which is true.

16
00:01:30,380 --> 00:01:35,580
You can recreate your application,
but the application has data and apart

17
00:01:35,770 --> 00:01:42,375
without this data, it could be, useless
to the point plus all the, security audit

18
00:01:42,465 --> 00:01:48,925
requirements, forensics, all those things
require you to actually save your data.

19
00:01:48,925 --> 00:01:53,485
And more than that, it might require
you point in time, snapshot of your

20
00:01:53,485 --> 00:01:58,525
data, or point in time recovery, even
for disaster recovery, for example.

21
00:01:58,875 --> 00:02:02,165
the, common myth in the
cloud development is that.

22
00:02:03,595 --> 00:02:08,195
My cloud provider is going to do
the backups, which is again, true

23
00:02:08,205 --> 00:02:12,705
only partially because your cloud
provider might just lose your account.

24
00:02:12,735 --> 00:02:13,705
That happened.

25
00:02:13,805 --> 00:02:18,765
your cloud provider explicitly
says in the, all the, instructions

26
00:02:18,785 --> 00:02:21,235
on how to, backup your data.

27
00:02:21,265 --> 00:02:25,295
They say, please do some
sort of export, of your data.

28
00:02:25,305 --> 00:02:25,695
and.

29
00:02:26,110 --> 00:02:28,500
That's something that they
can't really do for you.

30
00:02:29,150 --> 00:02:34,170
and finally, there are some tools
which can back up the etcd database

31
00:02:34,170 --> 00:02:39,600
in your Kubernetes, but recovering
it, restoring it into something

32
00:02:39,680 --> 00:02:43,910
that works is almost impossible.

33
00:02:43,910 --> 00:02:49,390
And there's literally almost no
evidence that it might actually work.

34
00:02:49,690 --> 00:02:51,084
Although backups are still possible.

35
00:02:51,245 --> 00:02:57,965
still important for, for tracing and,
forensics, with all that, amount of data

36
00:02:57,965 --> 00:03:00,945
we have in the Kubernetes deployment
and the cloud native deployment

37
00:03:01,385 --> 00:03:07,294
is growing more and more users are
adopting, data services, volumes,

38
00:03:07,764 --> 00:03:12,034
databases, on the Kubernetes over time.

39
00:03:12,709 --> 00:03:17,819
And the most, one of the most
common applications, run on

40
00:03:17,819 --> 00:03:19,799
Kubernetes is Redis, right?

41
00:03:20,189 --> 00:03:21,719
Or Boster, elastic Search.

42
00:03:21,719 --> 00:03:27,509
All of these things need some sort
of a data, storage disks, et cetera.

43
00:03:27,879 --> 00:03:29,109
and people actually run those.

44
00:03:29,139 --> 00:03:33,579
So this is the, this is something that
you want to do and this is something

45
00:03:33,579 --> 00:03:38,829
that, really needs, management because
all of this data is running on this.

46
00:03:39,509 --> 00:03:46,389
on disks, which are vulnerable, which
needs to be secured for many reasons.

47
00:03:47,079 --> 00:03:53,889
and finally, another thing that we face
in another challenge that we're facing

48
00:03:53,889 --> 00:03:58,839
with cloud deployments is that, in order
to follow the three to one backup rule,

49
00:03:58,839 --> 00:04:03,679
which says that you have multiple copies,
have them in different media, and you have

50
00:04:03,679 --> 00:04:06,399
them, at least one of them is off site.

51
00:04:06,505 --> 00:04:10,155
this is additional challenge for a
Kubernetes deployments because we

52
00:04:10,155 --> 00:04:15,344
need to move data out outside of the,
cluster that we actually run it on.

53
00:04:16,584 --> 00:04:22,074
so some extra challenges of the,
Kubernetes deployment in particular

54
00:04:22,074 --> 00:04:27,495
compared to other types of deployment,
like VMs, being that, with, The

55
00:04:27,495 --> 00:04:33,265
way how with how easy it is to
create, heterogeneous apps, right?

56
00:04:33,645 --> 00:04:35,295
You can run microservices.

57
00:04:35,295 --> 00:04:39,045
They can have access
to some data services.

58
00:04:39,405 --> 00:04:44,255
They can include multiple, span over
multiple domains, have many moving

59
00:04:44,255 --> 00:04:49,925
parts, use different cloud, backups,
cloud, backends, So managing all this

60
00:04:49,925 --> 00:04:54,895
backups, which could happen in your
cloud infrastructure, or which may not

61
00:04:54,905 --> 00:05:00,095
happen in the cloud infrastructure,
managing disks, managing the workloads

62
00:05:00,135 --> 00:05:03,965
and, application life cycles, such as
your application can actually be slowed

63
00:05:03,975 --> 00:05:09,655
down and backup can be performed and
then application can be, restored again.

64
00:05:10,145 --> 00:05:15,245
this is all getting more
and more complex as we.

65
00:05:15,570 --> 00:05:21,300
actually have very different ways
of deployments, for our Kubernetes

66
00:05:21,300 --> 00:05:25,940
application and the ways that
our deployments access the data.

67
00:05:26,510 --> 00:05:30,830
so we could have deployments,
which access some cloud database.

68
00:05:30,910 --> 00:05:36,230
We can have some database in the cluster
in separate namespace, or we can have

69
00:05:36,520 --> 00:05:42,520
Namespaces, data services, co located
with the actual application code.

70
00:05:42,630 --> 00:05:46,080
All of these things exist and
all of these things need some

71
00:05:46,080 --> 00:05:47,970
approaches to backup and restore.

72
00:05:49,160 --> 00:05:54,265
and on top of that, there's another
challenge, which is, again, being

73
00:05:54,305 --> 00:05:59,315
more and more pronounced with the
Kubernetes, more microservices, is that,

74
00:05:59,935 --> 00:06:06,805
we can't just have, a VM with all of
our application, slow down, shut down,

75
00:06:07,735 --> 00:06:09,915
data collected and restarted, right?

76
00:06:09,965 --> 00:06:11,465
We have all the microservices.

77
00:06:11,865 --> 00:06:17,065
So running things like
application centric, backups.

78
00:06:17,505 --> 00:06:21,605
in which your application should be
consistent with your data backup,

79
00:06:21,985 --> 00:06:27,025
in which you can have multiple data
storage, all taken, all backups

80
00:06:27,025 --> 00:06:31,455
taken at the same moment, that
becomes, that becomes a challenge.

81
00:06:32,075 --> 00:06:37,965
and a lot of Tools that we have, in the
cloud services, they would just do one

82
00:06:37,965 --> 00:06:45,975
thing like, an RDS snapshot or, volume
snapshots in, Kubernetes or in the, on,

83
00:06:46,015 --> 00:06:48,225
in the cloud providers infrastructure.

84
00:06:49,165 --> 00:06:52,755
So how do we manage that?

85
00:06:54,185 --> 00:06:57,955
And, to manage that, I'd like
to introduce the canister.

86
00:06:57,955 --> 00:07:01,425
Canister is a product, created by Kasten.

87
00:07:01,815 --> 00:07:05,225
it is currently CNCF, sandbox project.

88
00:07:05,225 --> 00:07:05,625
So it's.

89
00:07:05,895 --> 00:07:12,265
It's officially a part of CNCF org and
it's moving towards, incubating stage.

90
00:07:12,735 --> 00:07:21,555
what Canister contributes is essentially
a framework, which can, which is open

91
00:07:21,555 --> 00:07:26,945
source, which can be used by anyone
and which, can have integrations with

92
00:07:26,945 --> 00:07:29,535
all these, different data services.

93
00:07:30,085 --> 00:07:36,485
And, different data storages and
this, integrations, can be shared

94
00:07:36,925 --> 00:07:41,795
between different organizations
and can be, they can be reused

95
00:07:41,825 --> 00:07:43,485
between different organizations.

96
00:07:44,115 --> 00:07:52,655
And this really just putting
a standard on the Kubernetes,

97
00:07:53,025 --> 00:07:54,985
a soft standard, I would say.

98
00:07:55,350 --> 00:08:01,450
Similar to how, Istio was introduced as
a soft standard, to just teach people

99
00:08:01,460 --> 00:08:06,160
how do they, how can they organize
their, the backup and restore process

100
00:08:06,220 --> 00:08:09,590
and give the tools out of the box.

101
00:08:09,990 --> 00:08:12,620
Here's your tool, how to back
up the passwords, for example.

102
00:08:13,440 --> 00:08:14,540
How does it work?

103
00:08:14,980 --> 00:08:19,960
So how can we achieve all these
things with application consistency?

104
00:08:20,280 --> 00:08:25,230
With supporting multiple, topologies
and multiple services, right?

105
00:08:25,330 --> 00:08:26,990
How would you do that?

106
00:08:27,885 --> 00:08:35,615
In home, in your custom bespoke
scripts, you would have a script which

107
00:08:35,645 --> 00:08:44,475
would call all the, data services,
disk APIs, and they will perform some

108
00:08:44,475 --> 00:08:46,465
sort of a snapshotting operation.

109
00:08:46,800 --> 00:08:49,620
And then it will collect all
the data, all the artifacts from

110
00:08:49,620 --> 00:08:51,150
them, present them in some way.

111
00:08:51,690 --> 00:08:56,490
Then you need to run the script somehow,
somewhere and some at some point in time.

112
00:08:56,490 --> 00:08:59,730
And then you need to store
your artifacts somewhere.

113
00:09:00,060 --> 00:09:04,020
What Estu does it, it
moves that to Kubernetes.

114
00:09:04,300 --> 00:09:07,960
so what we have there is a bunch of
custom resource definitions, which is a

115
00:09:07,960 --> 00:09:10,500
way that, you can interact with canister.

116
00:09:10,840 --> 00:09:12,370
first one being the blueprint.

117
00:09:12,905 --> 00:09:19,345
blueprint is a description of how
do you want to perform a backup or

118
00:09:19,345 --> 00:09:29,225
a store, such as I want to, let's
say scale down the application.

119
00:09:29,620 --> 00:09:31,170
I want to back up the disks.

120
00:09:31,230 --> 00:09:32,750
I want to back up the database.

121
00:09:33,050 --> 00:09:34,590
I want to scale up the application.

122
00:09:34,590 --> 00:09:37,430
These are several phases you
would have in your script.

123
00:09:38,140 --> 00:09:43,450
They just described in a slightly
different manner, in the blueprint.

124
00:09:43,870 --> 00:09:49,540
Then action set is a custom resource
definitions, which runs the backup or

125
00:09:49,540 --> 00:09:52,150
restore operational cleanup operation.

126
00:09:52,630 --> 00:09:53,290
which.

127
00:09:53,580 --> 00:09:58,550
Upon creation, performs an operation,
records the status of this operation,

128
00:09:58,550 --> 00:10:05,240
and records the artifacts which
were, produced by this operation.

129
00:10:05,970 --> 00:10:11,720
So this is your, essentially log
of actions, the action sets in your

130
00:10:11,780 --> 00:10:14,970
Kubernetes, they will be stored
in the Kubernetes database, right?

131
00:10:15,575 --> 00:10:18,335
And there will be a log of the operations.

132
00:10:18,585 --> 00:10:24,045
And finally, profile is a configuration
which allows us to point to different.

133
00:10:24,560 --> 00:10:28,890
destinations for data, such
as, S3 buckets, Google objects,

134
00:10:28,900 --> 00:10:31,430
storage, Azure objects, storage.

135
00:10:31,930 --> 00:10:36,390
so we can export data into
different, destinations.

136
00:10:37,450 --> 00:10:41,140
now this is roughly how it works, right?

137
00:10:41,190 --> 00:10:44,760
Your blueprint describes what kind
of actions do you need to take.

138
00:10:45,240 --> 00:10:47,460
you would create an action set.

139
00:10:47,970 --> 00:10:52,640
canister controller will pick this
action set up, find the blueprint,

140
00:10:53,030 --> 00:10:57,910
build an execution plan, run all the
operations on Kubernetes runners.

141
00:10:58,410 --> 00:11:03,280
the operations would do some, do
some extraction of, let's say from

142
00:11:03,370 --> 00:11:07,110
MySQL app or some application,
some data storage, and they will

143
00:11:07,110 --> 00:11:09,270
save it into some object storage.

144
00:11:09,280 --> 00:11:10,120
And finally.

145
00:11:10,375 --> 00:11:15,019
They would report an artifact,
the status of the artifact.

146
00:11:15,330 --> 00:11:18,800
Back to you to the action set so
you can read it from the action set

147
00:11:20,920 --> 00:11:29,330
And if you look closer into The blueprints
essentially are custom resources which

148
00:11:29,950 --> 00:11:35,530
can be created in your Kubernetes
database There are some, example,

149
00:11:35,530 --> 00:11:42,990
blueprints in a canister, repository,
those, custom resources includes actions.

150
00:11:43,310 --> 00:11:47,960
So actions could be something like
backup or restore or cleanup or delete.

151
00:11:47,970 --> 00:11:54,640
In this case, each action would
execute, several phases, one or more.

152
00:11:55,320 --> 00:11:57,040
And those phases.

153
00:11:58,040 --> 00:12:03,400
Execute, sequentially and they would
do each phase would do something

154
00:12:03,410 --> 00:12:10,240
like run a pod or, create an RDS
snapshot or do something else.

155
00:12:10,790 --> 00:12:14,630
what blueprints provide is a template.

156
00:12:15,175 --> 00:12:17,365
For what needs to be done.

157
00:12:17,995 --> 00:12:23,065
now in order to fill in the template
variables, we have the action set.

158
00:12:23,445 --> 00:12:27,435
Action set is a command to
execute a certain action.

159
00:12:28,150 --> 00:12:32,430
And it fills in values of the template.

160
00:12:32,910 --> 00:12:38,600
It could reference an object such as
config map or stateful set or deployment.

161
00:12:39,020 --> 00:12:43,670
It points to a profile, which
essentially points to a destination

162
00:12:43,680 --> 00:12:45,720
where data will be saved.

163
00:12:46,330 --> 00:12:52,010
And it's, describes the actions, which
actions needs to run and what values, what

164
00:12:52,020 --> 00:12:54,710
template values needs to be, filled in.

165
00:12:55,220 --> 00:13:01,190
in there, then action sets also
this important thing that they

166
00:13:01,240 --> 00:13:03,990
track the status of the operations.

167
00:13:04,340 --> 00:13:09,050
So if a phase fails, the action
set will have information of which

168
00:13:09,050 --> 00:13:11,210
phase failed and with what error.

169
00:13:11,780 --> 00:13:17,180
And, if phase completes, it contains
information about the artifacts that this,

170
00:13:17,450 --> 00:13:23,010
phase, and then we have the, resume of all
the artifacts produced by the phases in

171
00:13:23,010 --> 00:13:31,685
this and this action set, so action sets
in this way becomes your log of operations

172
00:13:32,245 --> 00:13:37,935
and blueprints are your definitions
of, which operations need to be run.

173
00:13:39,515 --> 00:13:43,735
yeah, we can continue with
the more concrete example.

174
00:13:43,765 --> 00:13:45,345
I'm going to run.

175
00:13:45,755 --> 00:13:52,365
An RDS backup, and I'm going to
describe what I'm doing in the process

176
00:13:52,425 --> 00:13:57,165
of, setting up a canister, creating
a blueprint, and then, performing

177
00:13:57,165 --> 00:13:59,765
a backup of RDS Postgres database.

178
00:14:00,885 --> 00:14:07,085
as, set up in this, demo, we have an
RDS database, we have our Kubernetes

179
00:14:07,095 --> 00:14:08,855
cluster with database client.

180
00:14:09,135 --> 00:14:14,015
There's going to be a config map
pointing to this RDS database.

181
00:14:14,385 --> 00:14:18,425
then we'll have canister installed
in the Kubernetes cluster.

182
00:14:18,815 --> 00:14:23,095
And this canister would
have access to an S3 bucket.

183
00:14:23,095 --> 00:14:24,735
The important note here that.

184
00:14:25,055 --> 00:14:31,355
Although we use S3, it could be
actually any object storage, it was

185
00:14:31,375 --> 00:14:36,525
just easier to set up for the demo,
but, RDS and S3, in this case, don't

186
00:14:36,645 --> 00:14:41,885
really have to be, in the same, cluster,
in the same, data center or anything.

187
00:14:42,555 --> 00:14:44,075
These are separate things.

188
00:14:44,115 --> 00:14:46,774
Our, or S3 could be not S3, but we will.

189
00:14:47,655 --> 00:14:48,625
and.

190
00:14:51,195 --> 00:14:53,435
Okay, let's run the demo.

191
00:14:53,455 --> 00:15:00,795
I have it pre recorded, so sorry for the
aspect ratio and for the mouse movements.

192
00:15:02,055 --> 00:15:09,255
as mentioned, we have an RDS database,
we have a Kubernetes cluster, we

193
00:15:09,265 --> 00:15:16,470
have our test app deployment, and
We have our S3 bucket, which we want

194
00:15:16,480 --> 00:15:18,380
to actually save our backups to.

195
00:15:19,470 --> 00:15:24,060
So now let's populate some
data into the database.

196
00:15:26,450 --> 00:15:29,890
Let's have some just Postgres tables.

197
00:15:32,840 --> 00:15:35,360
we have some, we have some
data we want to protect.

198
00:15:36,425 --> 00:15:43,085
so next step would be to install kinister,
which is, pretty straightforward,

199
00:15:43,805 --> 00:15:48,335
what it takes is just, install on Helm
chart and that's, it's pretty standard.

200
00:15:49,005 --> 00:15:50,875
so we have a Helm repo.

201
00:15:51,815 --> 00:15:55,795
then we have, actual
Helm releases installed.

202
00:15:56,735 --> 00:16:00,895
we create it in the kinister
namespace in this case.

203
00:16:04,975 --> 00:16:11,245
all the defaults, for, canister,
usable out of the box, there's some

204
00:16:11,315 --> 00:16:16,475
additional parameters you can configure
such as cluster role bindings, maybe.

205
00:16:16,750 --> 00:16:21,020
security, what cuts us to the
namespaces, but this works out of

206
00:16:21,050 --> 00:16:22,780
the box just with Helm install.

207
00:16:24,090 --> 00:16:29,130
We see there's an operator running
and we have a few custom resource

208
00:16:29,270 --> 00:16:32,610
definitions such as blueprints, section
sets, and profiles that we're going

209
00:16:32,610 --> 00:16:34,400
to create as a part of this demo.

210
00:16:34,450 --> 00:16:38,090
so in here we create
a blueprint, which is.

211
00:16:38,795 --> 00:16:45,685
In this case, we take it from canister
repository, ideally you would, maybe

212
00:16:45,685 --> 00:16:52,545
take some example blueprints, as an
inspiration and create a blueprint

213
00:16:52,555 --> 00:16:56,655
for your infrastructure, because you
might have more than one moving part.

214
00:16:56,655 --> 00:17:01,845
I might want to, actually
coordinate, so one executes first,

215
00:17:01,845 --> 00:17:03,285
another executes next, et cetera.

216
00:17:06,990 --> 00:17:10,330
Blueprint here was created
as a custom resource.

217
00:17:10,760 --> 00:17:11,450
It's there.

218
00:17:11,810 --> 00:17:15,290
now our cluster contains
information, how to.

219
00:17:15,785 --> 00:17:23,635
backup, RDS databases, and as you can see,
it's all template variables, which needs

220
00:17:23,635 --> 00:17:26,265
to be filled with, with the action set.

221
00:17:32,265 --> 00:17:36,885
next step, we want to create the
profile, which is a reference

222
00:17:36,915 --> 00:17:38,445
to the, S3 bucket essentially.

223
00:17:39,515 --> 00:17:45,335
and, profile ID, we'll need that just in
order to reference it from the action set.

224
00:17:46,405 --> 00:17:48,215
That's why I'm creating
profile here in the demo.

225
00:17:49,455 --> 00:17:55,705
finally, we want to create an action set,
which will perform a backup operation.

226
00:17:55,715 --> 00:17:59,515
So as, as soon as action set is
created, canister, controller.

227
00:17:59,860 --> 00:18:02,960
Will perform the backup
operation in this case.

228
00:18:02,960 --> 00:18:08,980
We're using con CTL tool, which comes
with canister Which is just a helper

229
00:18:08,980 --> 00:18:10,550
tool to create custom resources.

230
00:18:10,640 --> 00:18:16,600
it's all it does It's just more
convenient to do it with a bunch of

231
00:18:17,380 --> 00:18:23,040
parameters than to create A young
file with all the definitions.

232
00:18:23,070 --> 00:18:26,910
That's why we're using it here,
but you can create the young file

233
00:18:26,935 --> 00:18:30,865
So with, with the definitions and,
with the right spec and just create

234
00:18:30,865 --> 00:18:32,685
it as normal Kubernetes resource.

235
00:18:40,065 --> 00:18:44,305
we reference, the blueprint, we
reference the profile, we reference

236
00:18:44,335 --> 00:18:49,825
the objects, which is, which is our
database config in this, particular case.

237
00:18:52,375 --> 00:18:56,455
In some other cases, it could be a
deployment or a stateful set, for example.

238
00:19:00,230 --> 00:19:09,740
So now as we get our action set created,
we can, get its action set ID, which

239
00:19:10,460 --> 00:19:15,100
a record in your Kubernetes database,
for which action set can be identified.

240
00:19:15,670 --> 00:19:20,840
pretty useful in order to, create restore,
for example, from backup operation.

241
00:19:21,970 --> 00:19:26,940
And we're going to look into what's
going on in there while it's running.

242
00:19:28,230 --> 00:19:32,920
And so while it's running, we have,
the current running face and we

243
00:19:32,920 --> 00:19:35,910
have the artifacts in the status.

244
00:19:35,930 --> 00:19:40,020
And as you can see, those are
currently not populated and I will

245
00:19:40,020 --> 00:19:45,920
get populated as the action actually
gets executed as phases get finished.

246
00:19:46,425 --> 00:19:52,665
And they put, artifacts information
into, into the artifacts of, in

247
00:19:52,665 --> 00:19:53,760
the status of the action set.

248
00:19:54,730 --> 00:19:57,920
So here, when everything is
completed, of course, there's, I

249
00:19:57,920 --> 00:20:01,550
did some editing here because this
particular action runs for some time.

250
00:20:02,070 --> 00:20:04,670
after it's all completed,
we have a state complete.

251
00:20:05,020 --> 00:20:10,990
We have, the time when actions were
each phases, each phase was executed

252
00:20:11,440 --> 00:20:15,840
and we have, artifacts, which
were produced by all this phases.

253
00:20:17,720 --> 00:20:20,220
So this is our complete operation.

254
00:20:21,710 --> 00:20:28,700
so we could take the artifacts and combine
them with a profile and the blueprint to

255
00:20:28,700 --> 00:20:35,200
then create or store operation, because
this action set contains everything

256
00:20:35,200 --> 00:20:39,350
you need to know about the operation,
like what blueprints was there.

257
00:20:39,730 --> 00:20:44,890
what profile, where do we send the
data and what was the artifacts

258
00:20:44,920 --> 00:20:48,200
named and also when it was executed.

259
00:20:48,210 --> 00:20:51,500
So this is like full
information of the operation.

260
00:20:52,250 --> 00:20:56,910
so in the S3 bucket, now we have
this file, which is our artifact

261
00:20:56,910 --> 00:20:58,610
that we created from this operation.

262
00:21:04,360 --> 00:21:05,260
so now.

263
00:21:06,810 --> 00:21:13,170
Let's say something happens
With our table in this case.

264
00:21:13,170 --> 00:21:15,500
I'm just gonna do very simple thing.

265
00:21:15,500 --> 00:21:19,880
I'm just going to draw table
Which something that happens more

266
00:21:19,880 --> 00:21:22,150
often than these corruptions?

267
00:21:22,690 --> 00:21:27,960
Really in the real world people drop
tables all the time So that's one of

268
00:21:27,990 --> 00:21:31,750
the main scenarios for a cover really
but of course there are other scenarios

269
00:21:31,800 --> 00:21:36,080
possible for backup and restore is
just, going to go for the simple one.

270
00:21:37,510 --> 00:21:42,380
And, in this, command, I'm also
using const TL tool to create one

271
00:21:42,380 --> 00:21:44,210
action set out of another action set.

272
00:21:44,240 --> 00:21:48,540
That's, even more convenience
for this const TL tool, because.

273
00:21:48,915 --> 00:21:55,095
we will need to create the YAML file
and then fill it up with output from the

274
00:21:55,095 --> 00:22:01,715
status of the action set resource that
we just seen for the backup operation.

275
00:22:02,155 --> 00:22:04,065
While this one can do that automatically.

276
00:22:04,995 --> 00:22:09,785
All it does, again, is just, creates
a custom resource as a result, it's

277
00:22:09,785 --> 00:22:12,595
just a simpler command in here.

278
00:22:15,215 --> 00:22:20,595
And here we select, action and we
point to, a previous action set

279
00:22:20,765 --> 00:22:22,215
from which it gets the blueprint.

280
00:22:25,340 --> 00:22:31,800
so now we can take a look at what
this, restore, action set, looks like.

281
00:22:34,830 --> 00:22:40,030
so it exists, it completed, has
a time when it completes it.

282
00:22:40,120 --> 00:22:43,460
And of course we can take a look
inside of what it looks like.

283
00:22:43,950 --> 00:22:49,710
So inside of it, you can see that it got,
Input artifacts in the spec, which were

284
00:22:49,710 --> 00:22:52,430
populated from the backup, action set.

285
00:22:52,460 --> 00:22:55,890
We have a blueprint in the spec,
which was populated from the backup.

286
00:22:55,900 --> 00:22:59,050
We have a profile, which was
populated from the backup, action set.

287
00:22:59,810 --> 00:23:03,250
And we have a operation name, which is
restore, which is something different

288
00:23:03,250 --> 00:23:04,930
that we specify in the arguments.

289
00:23:05,680 --> 00:23:12,270
then in the, status of this action set,
we see an operation that was performed.

290
00:23:12,955 --> 00:23:18,285
some output that it produced, which
is not really too relevant right now.

291
00:23:18,285 --> 00:23:20,905
and then we have a status
that it's complete.

292
00:23:32,735 --> 00:23:34,775
this is our restore operation session.

293
00:23:36,495 --> 00:23:43,495
And, yeah, now what we want to do is
to verify that our table, is back.

294
00:23:49,325 --> 00:23:51,845
gonna just check the table.

295
00:23:54,020 --> 00:23:54,740
Here it is.

296
00:23:54,790 --> 00:23:58,170
so we do have a bug.

297
00:23:59,120 --> 00:24:02,020
so that's pretty much it for the demo.

298
00:24:02,860 --> 00:24:07,100
the only last thing, is that, we have

299
00:24:09,270 --> 00:24:15,280
the action sets in our both action
sets for backup and restore in our.

300
00:24:16,290 --> 00:24:16,860
Kubernetes database.

301
00:24:16,870 --> 00:24:19,200
So this is our log of operations.

302
00:24:19,610 --> 00:24:25,150
and it contains all you need to know
about what was performed, right?

303
00:24:25,150 --> 00:24:27,390
It has a reference to blueprints.

304
00:24:27,400 --> 00:24:34,670
It has reference to artifacts, reference
to profiles, and it has a log of

305
00:24:34,670 --> 00:24:36,880
all the phases that were executed.

306
00:24:37,770 --> 00:24:38,580
so that's.

307
00:24:39,970 --> 00:24:42,070
Let's go back to the presentation.

308
00:24:42,760 --> 00:24:47,830
so what we just did right in this
demo, we created an RDS snapshot.

309
00:24:47,870 --> 00:24:53,540
We exported it to an object storage, S3
in this case, but could be something else.

310
00:24:53,900 --> 00:24:58,050
we run everything, all the
operations in the Kubernetes runners.

311
00:24:58,060 --> 00:25:02,720
So don't need any provision, any new
machines or run anything locally.

312
00:25:03,315 --> 00:25:10,425
we have blueprints describing what exactly
we did, which stored in the Kubernetes

313
00:25:11,185 --> 00:25:16,865
database, or it could be in your
GitOps, which are there documented and,

314
00:25:16,925 --> 00:25:19,015
could be well, represented and tested.

315
00:25:19,455 --> 00:25:24,125
and we have all the operation
log in the, form of action sets.

316
00:25:24,405 --> 00:25:25,505
So all the action sets.

317
00:25:26,010 --> 00:25:28,420
give you an idea of what was running.

318
00:25:28,430 --> 00:25:33,270
So this way, what was running,
what was the output of it?

319
00:25:33,280 --> 00:25:34,430
when it was running.

320
00:25:34,720 --> 00:25:41,650
So you can really have a holistic, view
on your, process of backup and restore

321
00:25:41,660 --> 00:25:45,730
for your application design specifically
for application user blueprints.

322
00:25:47,600 --> 00:25:51,640
canister right now has a bunch of
functions that you can run, kubexec

323
00:25:51,640 --> 00:25:56,540
and kubetask are quite useful
because they run pod with a command.

324
00:25:56,980 --> 00:26:01,480
So that's quite universal for
a lot of things you can do such

325
00:26:01,480 --> 00:26:03,180
as database, dumps, for example.

326
00:26:03,700 --> 00:26:08,380
we also support some, resource life
cycles, such as scaling up, down.

327
00:26:08,770 --> 00:26:17,380
workloads, PVC operations to get files
from PVC, pro from volumes, volume

328
00:26:17,380 --> 00:26:22,810
snapshots, Amazon RTS, custom function,
which we demonstrated in this demo.

329
00:26:23,255 --> 00:26:27,685
And we support a whole bunch
of, object storage destinations.

330
00:26:28,715 --> 00:26:29,655
yeah, and that's it.

331
00:26:29,715 --> 00:26:33,015
thank you very much
for, joining this talk.

332
00:26:33,405 --> 00:26:39,275
here's some links for, our GitHub
repo and our Slack channel.

333
00:26:39,645 --> 00:26:44,435
please take a look, download the
blueprint, try it out yourself.

334
00:26:44,975 --> 00:26:45,275
Thank you.

