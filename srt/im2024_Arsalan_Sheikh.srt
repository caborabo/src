1
00:00:00,000 --> 00:00:04,560
So we're going to be talking about
building software prototypes using

2
00:00:04,580 --> 00:00:08,219
AI tools and the programming language
of choice, of course, is Python.

3
00:00:08,639 --> 00:00:14,589
And we will be discussing examples
of time series analysis and the

4
00:00:14,590 --> 00:00:18,749
domain specific area that we will be
talking about is financial analysis.

5
00:00:19,110 --> 00:00:23,240
And we'll be using this kind
of a capability to build an

6
00:00:23,270 --> 00:00:24,630
algorithmic trading system.

7
00:00:24,740 --> 00:00:25,770
So let's get to it.

8
00:00:26,770 --> 00:00:30,130
Now, we are familiar with all these.

9
00:00:30,990 --> 00:00:36,919
Concepts of machine learning, data
analytics, rules based data, driven.

10
00:00:37,375 --> 00:00:38,015
Decisions.

11
00:00:38,325 --> 00:00:42,415
However, the application off
building software using these E I

12
00:00:42,415 --> 00:00:46,075
tools is very recent innovation.

13
00:00:46,155 --> 00:00:50,045
Thanks to impart by the genAI tools
that are now available for us.

14
00:00:50,565 --> 00:00:55,315
So we'll be discussing how we can
adopt and adapt these AI tools in

15
00:00:55,315 --> 00:00:56,684
building these financial applications.

16
00:00:57,664 --> 00:01:04,575
But before we get to that, let's look
into what are the base skills necessary

17
00:01:04,745 --> 00:01:06,385
to achieve something like this, right?

18
00:01:06,874 --> 00:01:11,444
It's not set in stone that we should
follow one approach to the other,

19
00:01:11,474 --> 00:01:15,014
but more importantly, the technical
skills and those and the business

20
00:01:15,014 --> 00:01:19,984
skills that are essential to build such
applications are very much important

21
00:01:20,244 --> 00:01:22,114
because an AI tool is just a tool.

22
00:01:22,114 --> 00:01:26,564
The more the success or the secret sauce
in all of this is the individual or the

23
00:01:26,564 --> 00:01:30,844
human being with the relevant and required
skill sets necessary to achieve this.

24
00:01:30,894 --> 00:01:34,044
So there are certain foundational
skills, there are data specific

25
00:01:34,044 --> 00:01:38,514
skills, there are problem solving
skills, there are professionalism and

26
00:01:38,684 --> 00:01:41,114
collaboration expertise that are required.

27
00:01:41,364 --> 00:01:46,564
And of course there is this
knowledge that a person should have

28
00:01:46,614 --> 00:01:48,384
to be able to build such things.

29
00:01:48,385 --> 00:01:49,264
And.

30
00:01:49,654 --> 00:01:52,754
Not the least interpersonal skills,
because if you're not able to

31
00:01:52,754 --> 00:01:56,824
communicate and not able to collaborate,
we will not be able to build things

32
00:01:57,074 --> 00:01:59,484
at scale that we are accustomed to.

33
00:02:00,594 --> 00:02:01,064
All right.

34
00:02:01,354 --> 00:02:05,664
So the next thing is, we all are aware.

35
00:02:06,214 --> 00:02:10,674
Where we are today, but it's
important to realize how we got there.

36
00:02:11,224 --> 00:02:15,364
So in the 1950s to 1970s,
the early foundations of the

37
00:02:15,364 --> 00:02:17,514
software development was made.

38
00:02:18,064 --> 00:02:23,044
And from there on, we were, we came across
this object oriented programming concept.

39
00:02:23,704 --> 00:02:26,714
And then, of course, there was this
internet revolution in the 90s.

40
00:02:28,064 --> 00:02:32,334
But why I'm discussing this is we have
to realize that this journey that we

41
00:02:32,354 --> 00:02:37,014
have come across where we are today in
this AI revolution that we are in today.

42
00:02:37,314 --> 00:02:42,334
So every stage of every step that we
passed led us to where we are today.

43
00:02:42,574 --> 00:02:45,474
And more importantly, this
is where we have to consider

44
00:02:45,564 --> 00:02:49,224
adopting to such technologies
because over time, things evolve.

45
00:02:49,744 --> 00:02:57,904
So what is, Important to realize is in
the early 2000s to mid 2000s, we had

46
00:02:57,904 --> 00:03:02,354
this cloud transformation journey or
cloud journey that we are now aware of

47
00:03:02,374 --> 00:03:03,884
and how things have turned out to be.

48
00:03:04,144 --> 00:03:07,064
And then from late 2020 tense up to.

49
00:03:08,184 --> 00:03:08,924
Pandemic level.

50
00:03:08,924 --> 00:03:15,554
We were all, using some way or
form algorithms or data driven

51
00:03:15,564 --> 00:03:19,364
machine learning models in our daily
lives without even noticing it.

52
00:03:19,364 --> 00:03:23,374
For example, these recommendation
engines from Netflix or from Spotify.

53
00:03:23,384 --> 00:03:25,494
You were having these playlists
that are being recommended.

54
00:03:25,784 --> 00:03:30,194
And of course, there were a lot of other
things that we were getting exposed to.

55
00:03:30,194 --> 00:03:32,174
But It was very much behind the scenes.

56
00:03:32,704 --> 00:03:38,114
Now, from the advent of this Gen AI
tools that have now come into mainstream,

57
00:03:38,124 --> 00:03:43,464
especially the LLM models that are out
there as individuals, as users, we are

58
00:03:43,464 --> 00:03:49,039
now directly interacting with AI, and
this has opened up A whole new paradigm

59
00:03:49,049 --> 00:03:52,069
of things that are possible with the
possibilities that are endless style.

60
00:03:52,449 --> 00:03:57,139
And I am really excited during this
period because I come from a technology

61
00:03:57,139 --> 00:03:58,739
background and a business background.

62
00:03:58,749 --> 00:04:02,969
So what happens is if a person like me
who understands business problems and

63
00:04:02,969 --> 00:04:08,389
solutions, I can now use these Gen AI
tools to quickly iterate and prototype

64
00:04:08,619 --> 00:04:12,809
without waiting for a large team to come
in and be available for me to do this.

65
00:04:13,009 --> 00:04:14,399
So this is.

66
00:04:14,704 --> 00:04:18,634
Enabling a lot of creativity is
enabling a lot of rapid prototyping.

67
00:04:18,634 --> 00:04:22,044
It's enabling a lot of innovation,
which was pretty much there in the

68
00:04:22,044 --> 00:04:25,284
past, but the space at which we
are doing it now has accelerated.

69
00:04:27,424 --> 00:04:30,944
as I mentioned, beginning in the
beginning of the session, we are going

70
00:04:30,954 --> 00:04:32,974
to be talking about financial analysis.

71
00:04:33,154 --> 00:04:36,104
Which is a specific domain
area of time series analysis.

72
00:04:36,104 --> 00:04:40,134
So some of you may have already
experienced in one shape or form

73
00:04:40,134 --> 00:04:41,444
time series analysis, right?

74
00:04:41,784 --> 00:04:46,444
So the first point, obviously, is
the financial use case of algorithmic

75
00:04:46,474 --> 00:04:49,194
trading and risk management, which
we'll be covering in this part

76
00:04:49,194 --> 00:04:50,654
of this discussion and topic.

77
00:04:51,324 --> 00:04:54,964
In the case of health care, this
patient monitoring and epidemiology.

78
00:04:55,274 --> 00:04:58,864
in the case of, maintenance is predictive
maintenance quality control, which is

79
00:04:58,874 --> 00:05:03,874
used by facilities, industries, process
industries and manufacturing industries is

80
00:05:03,874 --> 00:05:07,104
demand forecasting and industry management
across many different industries.

81
00:05:07,474 --> 00:05:12,284
in the in energy and power generation and
power management, there is energy load

82
00:05:12,284 --> 00:05:13,994
forecasting and smart grid management.

83
00:05:14,004 --> 00:05:17,444
Again, they are based on time series
data that comes in and they are able.

84
00:05:17,644 --> 00:05:20,144
They are managing their
business around that.

85
00:05:20,684 --> 00:05:23,114
We all know, whether it's time driven.

86
00:05:23,114 --> 00:05:28,244
every minute, every hour, every day, every
week, we know how the weather is behaving

87
00:05:28,244 --> 00:05:33,014
and forecast, and we're able to see these
forecasting events day in, day out, and

88
00:05:33,104 --> 00:05:35,154
we interact with them on a regular basis.

89
00:05:35,399 --> 00:05:37,519
Network traffic analysis
and fraud detection.

90
00:05:37,529 --> 00:05:39,689
This is again for the data networks.

91
00:05:39,949 --> 00:05:43,139
so every packet every
information is times timestamp.

92
00:05:43,489 --> 00:05:48,349
fraud detection is also, in the form of
time series where we know the behavior

93
00:05:48,359 --> 00:05:49,949
in the past based on particular time.

94
00:05:49,949 --> 00:05:53,249
And if it's currently not
following a certain pattern.

95
00:05:53,529 --> 00:05:56,969
Based on the time, of course,
we can determine what's going

96
00:05:56,979 --> 00:05:59,829
on, and then we can, behave,
manage the behaviors accordingly.

97
00:06:00,119 --> 00:06:03,359
Economic forecasting and public
health monitoring is also time

98
00:06:03,359 --> 00:06:06,629
based, obviously not at the granular
level, but it's usually on a weekly,

99
00:06:06,659 --> 00:06:10,969
daily, monthly, quarterly, so those
are the aspects of time series.

100
00:06:11,829 --> 00:06:17,049
By the way, if you see there is a
LinkedIn link or details, if you have

101
00:06:17,049 --> 00:06:21,289
any questions around any of these
topics, feel free to drop me a note.

102
00:06:21,569 --> 00:06:24,109
On LinkedIn, and I'll be
happy to respond to that.

103
00:06:25,034 --> 00:06:27,194
Again, we all know AI is here.

104
00:06:27,314 --> 00:06:28,204
It's here to stay.

105
00:06:29,144 --> 00:06:34,554
Now we are accelerating the adoption
and adaption of AI into our daily lives.

106
00:06:35,574 --> 00:06:40,044
Up to 26 percent of the world's
GDP will be increased, will be

107
00:06:40,044 --> 00:06:44,429
contributed, or there will be a
contribution of increase of 26% by

108
00:06:44,429 --> 00:06:46,269
AI in the next four to five years.

109
00:06:46,589 --> 00:06:48,889
we are really in an exciting time.

110
00:06:48,929 --> 00:06:52,249
Of course, some of us are a bit
concerned that what will happen to

111
00:06:52,529 --> 00:06:54,139
the current way of doing things.

112
00:06:55,329 --> 00:06:58,059
As, I mentioned earlier, it's
an evolutionary journey that we

113
00:06:58,059 --> 00:06:59,809
already have been accustomed to.

114
00:06:59,809 --> 00:07:01,139
So we have to adapt.

115
00:07:01,364 --> 00:07:06,584
It's, this into our daily lives, into
our professional lives, and then leverage

116
00:07:06,584 --> 00:07:10,864
it for the next stage in our careers, in
our profession, in our personal lives.

117
00:07:12,084 --> 00:07:14,444
Okay, so what am I doing?

118
00:07:14,454 --> 00:07:16,274
This chart, what does it depict?

119
00:07:17,279 --> 00:07:20,029
I come from a program
management background.

120
00:07:20,029 --> 00:07:21,909
I come from a business
solution background.

121
00:07:21,929 --> 00:07:23,679
I come from a technology background.

122
00:07:25,029 --> 00:07:28,789
So it's important that there's a method
to the madness that we do, right?

123
00:07:28,949 --> 00:07:30,659
So everything has to have a flow.

124
00:07:30,719 --> 00:07:33,119
Everything has to have
a structure this way.

125
00:07:33,169 --> 00:07:33,609
It is repeatable.

126
00:07:34,479 --> 00:07:35,989
It is comprehensible.

127
00:07:37,229 --> 00:07:38,569
People can collaborate in it.

128
00:07:38,749 --> 00:07:42,819
So what I've done is to
build such a prototype.

129
00:07:43,029 --> 00:07:45,949
I have mapped two methodologies onto one.

130
00:07:46,249 --> 00:07:50,609
I've taken the data management methodology
using data science called crisp and

131
00:07:50,699 --> 00:07:54,889
aligned it with the lean development
methodologies, which we all are aware of.

132
00:07:54,919 --> 00:07:57,789
It's in the software development
cycle to come up with this model.

133
00:07:58,259 --> 00:07:58,799
However, Okay.

134
00:07:59,164 --> 00:08:05,524
Why I'm doing this is I'm training my GPT,
which I will talk later on, to recognize

135
00:08:05,524 --> 00:08:09,834
that this is the flow of information,
this is the flow of the method of

136
00:08:10,194 --> 00:08:14,204
interaction that I want it to follow,
so that there's a repeatable discipline

137
00:08:14,494 --> 00:08:19,894
in the AI model that I'm training
to help me, Develop this prototype.

138
00:08:20,544 --> 00:08:21,044
we are.

139
00:08:21,114 --> 00:08:25,274
We are aware that sometimes a I
models and especially in the case

140
00:08:25,274 --> 00:08:26,584
of L and M, they can hallucinate.

141
00:08:26,604 --> 00:08:26,834
They can.

142
00:08:26,924 --> 00:08:28,224
They can go into different directions.

143
00:08:28,254 --> 00:08:31,444
I want to give them a precise
context of how I want to get things

144
00:08:31,444 --> 00:08:34,314
done and use that as an approach.

145
00:08:34,324 --> 00:08:37,634
Use that as a method to give
me the output that I want.

146
00:08:37,854 --> 00:08:41,264
So in the subsequent, slide, I will
talk about what else am I doing?

147
00:08:41,334 --> 00:08:44,744
So I'm using such
approach such methodology.

148
00:08:44,764 --> 00:08:47,254
Sorry to say to, saying the model.

149
00:08:47,620 --> 00:08:50,410
To realize and recognize this
is the flow of information.

150
00:08:50,430 --> 00:08:51,250
I wanted to follow.

151
00:08:51,510 --> 00:08:58,899
Okay, more or what I'm doing is
I'm training the AI model for me

152
00:08:58,930 --> 00:09:04,300
for them to develop the software
prototype that I require realizing

153
00:09:04,300 --> 00:09:08,510
the real world structure that is we
are accustomed to and which works.

154
00:09:08,529 --> 00:09:09,140
So why?

155
00:09:09,805 --> 00:09:12,875
Why reinvent the wheel when we
know a structure works like this?

156
00:09:12,885 --> 00:09:16,965
So I'm giving a team structure, assuming
that there are multiple team members

157
00:09:16,965 --> 00:09:20,615
involved into a program, into a project,
and they're building this prototype.

158
00:09:20,875 --> 00:09:24,805
So I've trained the model to realize and
recognize that this is a team structure.

159
00:09:25,154 --> 00:09:28,715
They should be able to interact with
each other, question each other, and come

160
00:09:28,715 --> 00:09:31,585
up with the right software prototype.

161
00:09:31,765 --> 00:09:36,045
which is validated by all these different
teams that are out there in this.

162
00:09:36,045 --> 00:09:39,515
So we all know there are software
developers, data scientists, data

163
00:09:39,515 --> 00:09:44,225
analysts, domain experts, quality
assurance team members, security

164
00:09:44,225 --> 00:09:48,795
specialists, DevOps engineers,
data engineers, and so forth.

165
00:09:48,795 --> 00:09:52,155
So all of that I've used as an
information and I've trained an

166
00:09:52,165 --> 00:09:55,815
AI model to realize and recognize
and build me a software prototype.

167
00:09:56,140 --> 00:09:57,190
Based on these conditions.

168
00:09:59,300 --> 00:10:05,270
Another thing that I was talking about
earlier is, I've adopted the lean

169
00:10:05,280 --> 00:10:11,500
approach mapped onto a data management
approach to, let the model realize

170
00:10:11,500 --> 00:10:13,950
recognize what process to follow, right?

171
00:10:14,270 --> 00:10:18,340
So it has to follow certain
process to give me the design

172
00:10:18,850 --> 00:10:20,060
output or design out for that.

173
00:10:20,060 --> 00:10:21,790
I'm looking for now.

174
00:10:22,435 --> 00:10:27,815
I've also trained the model to
realize that this is the architecture

175
00:10:27,815 --> 00:10:29,085
that I'm looking for, right?

176
00:10:29,145 --> 00:10:33,175
So there's a data ingestion or data
collection, data pre processing,

177
00:10:33,505 --> 00:10:36,584
there's a strategy implementation
for the algorithmic trading, model

178
00:10:36,584 --> 00:10:37,795
that I'm, system that I'm building.

179
00:10:38,125 --> 00:10:40,435
There's a backtesting agent
that you need to recognize.

180
00:10:40,445 --> 00:10:43,909
There's a risk management, criteria that
needs to follow and how it should be used.

181
00:10:43,990 --> 00:10:44,960
Execute the trades.

182
00:10:45,250 --> 00:10:48,140
What are the optimization
parameter that needs to consider?

183
00:10:48,160 --> 00:10:50,620
And what are the monitoring
and logging capabilities?

184
00:10:50,620 --> 00:10:54,090
I want to be able to debug
and then understand how the

185
00:10:54,120 --> 00:10:55,100
application is behaving.

186
00:10:55,220 --> 00:11:02,449
So I even trained the AI model to realize
the architecture that I'm looking for.

187
00:11:03,640 --> 00:11:06,530
Another thing of what I did was,
if you some of you are from the

188
00:11:06,530 --> 00:11:08,800
computer science background, you
will be aware that there are design

189
00:11:08,800 --> 00:11:09,950
patterns and everything that we do.

190
00:11:10,000 --> 00:11:15,720
So I went a step further and I define
the modules that I'm looking for.

191
00:11:15,890 --> 00:11:18,600
I listed out what the
functionalities I'm looking for.

192
00:11:19,020 --> 00:11:19,510
And.

193
00:11:19,765 --> 00:11:22,945
What potential design patterns
that can be considered.

194
00:11:23,035 --> 00:11:28,755
So even though I'm like prompting
this to the air model that consider

195
00:11:28,755 --> 00:11:33,655
these factors, but I've also asked
the model to continuously learn from

196
00:11:33,655 --> 00:11:39,185
what prompts that I initiate as a
continue as a chain of thought and

197
00:11:39,305 --> 00:11:40,725
engagement that I have with our model.

198
00:11:40,725 --> 00:11:46,285
So as and when the prototype of
walls of the software walls on I

199
00:11:46,295 --> 00:11:51,175
engage in certain prompts with that
model, it should evolve itself.

200
00:11:51,325 --> 00:11:55,995
So even though this is a starting bit,
but I've also kept a room for evolution.

201
00:11:57,375 --> 00:11:59,305
Now, how did I use these ER tools?

202
00:11:59,695 --> 00:11:59,975
Okay.

203
00:12:00,315 --> 00:12:03,235
you're all aware there's
a chat GPT out there.

204
00:12:03,265 --> 00:12:04,490
So chap GPT 4.

205
00:12:04,490 --> 00:12:06,285
0 was the LLM model that I had used.

206
00:12:06,625 --> 00:12:11,805
there's a feature within chat GPT where
you can build your own custom GPTs.

207
00:12:11,995 --> 00:12:16,325
So I built, this custom GPT called
quant lab, which allows me to

208
00:12:16,325 --> 00:12:21,825
research, Allows me to define
certain delivery model methodology

209
00:12:21,825 --> 00:12:24,255
and structures it I can do this.

210
00:12:24,565 --> 00:12:26,235
Use it for requirements analysis.

211
00:12:26,555 --> 00:12:30,425
I can use it for solution
architecture design and I can use.

212
00:12:30,505 --> 00:12:35,335
I then eventually obviously I will be
using it for generating boiler code

213
00:12:35,345 --> 00:12:40,985
or template code, which then goes into
GitHub Copilot using Visual Studio Code.

214
00:12:41,105 --> 00:12:45,515
So in GitHub Copilot, the code
that was generated by quant lab.

215
00:12:45,815 --> 00:12:47,264
Built using the UPD 4.

216
00:12:47,265 --> 00:12:52,535
0 LLM now and get have
copilot the interface.

217
00:12:52,555 --> 00:12:53,895
I'm using a visual studio code.

218
00:12:54,445 --> 00:12:56,395
The code refactoring happens.

219
00:12:56,435 --> 00:12:58,595
The debugging and testing
of that code happens.

220
00:12:58,755 --> 00:13:03,094
And of course, since I'm building an
algorithmic trading system using time

221
00:13:03,094 --> 00:13:10,005
series analysis capable process or the
structure, I have to identify certain

222
00:13:10,105 --> 00:13:13,895
parameters and I have to tune and
optimize them to get the desired output.

223
00:13:14,344 --> 00:13:17,894
Even though I'm referencing an example
of financial services, this time

224
00:13:17,894 --> 00:13:22,124
series based data analysis can be done
on any kind of a time series data.

225
00:13:22,364 --> 00:13:22,614
Okay.

226
00:13:24,344 --> 00:13:27,794
Now, what is the approach that I used?

227
00:13:27,844 --> 00:13:32,614
And this is what I also used to
train my GPT 40 model, right?

228
00:13:32,974 --> 00:13:37,074
using GPT 40 LLM, I provided
certain training data.

229
00:13:37,084 --> 00:13:37,794
I'll talk about that.

230
00:13:38,604 --> 00:13:42,374
I did prompt engineering and I
trained it using certain prompts,

231
00:13:42,664 --> 00:13:44,004
which I will showcase to you.

232
00:13:44,604 --> 00:13:47,934
And more importantly, I also
provided a contextual input.

233
00:13:48,224 --> 00:13:52,474
Now this contextual input is historical
data, which is a time series data for it

234
00:13:52,484 --> 00:13:54,544
to realize and recognize what it's doing.

235
00:13:54,824 --> 00:13:59,784
So instead of it, hallucinating, I gave
it specific data points that it should

236
00:13:59,854 --> 00:14:02,174
consider for building such a prototype.

237
00:14:02,654 --> 00:14:07,434
And more importantly, it's important
to give context to the model.

238
00:14:08,174 --> 00:14:09,344
Now, what are we doing?

239
00:14:09,344 --> 00:14:11,544
We're building an algorithmic
trading strategy, right?

240
00:14:11,604 --> 00:14:14,864
So what's important is
I gave a strategy input.

241
00:14:15,024 --> 00:14:19,864
So there are certain research documents
out there, which I came across what

242
00:14:19,864 --> 00:14:22,574
I felt has a promising, potential.

243
00:14:23,745 --> 00:14:29,494
I used that research document and I loaded
it into GPT 40 LLM into my custom GPT.

244
00:14:30,044 --> 00:14:35,524
And with all that input, And of course, a
lot of iteration and a lot of refactoring.

245
00:14:35,874 --> 00:14:37,484
I came across a boiler code.

246
00:14:38,104 --> 00:14:42,504
This boiler code as a step one eventually
went into the step two, which is the

247
00:14:42,514 --> 00:14:45,334
Visual Studio code and using GitHub.

248
00:14:45,354 --> 00:14:45,914
Go pilot.

249
00:14:45,954 --> 00:14:48,234
I refactored and retested that code.

250
00:14:48,809 --> 00:14:52,689
And it was able to generate process data.

251
00:14:52,799 --> 00:14:58,589
Now, of course, what I did was,
if you remember, there was a data

252
00:14:58,699 --> 00:15:02,409
ingestion and data collection class
or process that I was considering.

253
00:15:02,419 --> 00:15:07,934
So the market data would be, Pulled
out from the broker data source, and

254
00:15:07,984 --> 00:15:12,854
that will be then process and then this
process data goes back into the custom

255
00:15:12,854 --> 00:15:16,414
GPT, which is based on GPT for LLM.

256
00:15:16,914 --> 00:15:20,594
I can do exploratory data analysis
of their data analysis and analytical

257
00:15:20,604 --> 00:15:22,724
capabilities in GPT for all.

258
00:15:23,024 --> 00:15:24,274
I can do visualizations.

259
00:15:24,304 --> 00:15:29,244
I can do insights and based on
those insights, I can understand

260
00:15:29,244 --> 00:15:31,054
what is the behavior of that data.

261
00:15:31,414 --> 00:15:33,754
I can go back into Visual Studio code.

262
00:15:33,999 --> 00:15:38,409
And do a optimization run or
parameterization tuning run and

263
00:15:38,419 --> 00:15:42,459
eventually once I'm happy or I'm when
I feel it's getting the right output,

264
00:15:42,779 --> 00:15:45,769
I can consider this as a prototype,
which is based on and I can take

265
00:15:45,769 --> 00:15:47,419
this, take it next, next step forward.

266
00:15:49,379 --> 00:15:49,999
All right, good.

267
00:15:50,619 --> 00:15:52,964
So one other thing to have.

268
00:15:53,114 --> 00:15:57,514
I did was I had, as if you remember,
there was a system architecture

269
00:15:57,514 --> 00:15:58,514
that I put together, right?

270
00:15:58,514 --> 00:16:02,454
So I trained the AI model using the
system architecture, which is again,

271
00:16:02,454 --> 00:16:06,804
not a hard and fast rule, but it was a
starting point for the model to realize

272
00:16:06,814 --> 00:16:11,074
that this is the output I'm looking for
and follow this architecture design that

273
00:16:11,074 --> 00:16:13,474
I intend to follow, intend to generate.

274
00:16:13,584 --> 00:16:13,874
Okay.

275
00:16:15,024 --> 00:16:15,814
All right.

276
00:16:17,794 --> 00:16:21,724
Some of the prerequisites for
building such an AI model or custom

277
00:16:21,724 --> 00:16:27,084
GPD model was, I had to train it
a lot for over a couple of days.

278
00:16:27,134 --> 00:16:32,774
But it was a week of training, prompt
engineering to and fro, eventually

279
00:16:32,814 --> 00:16:34,944
to a stage where I felt this is okay.

280
00:16:35,054 --> 00:16:39,094
The output of the code is sufficient
enough for me to play around with or

281
00:16:39,094 --> 00:16:41,434
get the necessary desired results.

282
00:16:41,744 --> 00:16:46,234
by the way, this AI model or the
custom GPT, I call it QuantLab.

283
00:16:46,514 --> 00:16:49,644
So the link you see here,
it's publicly available.

284
00:16:49,854 --> 00:16:55,434
You can copy paste this, or you can
follow this link into your GPT, chat

285
00:16:55,434 --> 00:16:59,664
GPT, and it should give you, it should
take you to that custom GPT that I've

286
00:16:59,674 --> 00:17:01,024
built, and you're free to use that.

287
00:17:02,454 --> 00:17:05,999
There's another, thing I need to
highlight is the, You need to provide

288
00:17:05,999 --> 00:17:08,589
certain specific context to the model.

289
00:17:09,529 --> 00:17:11,139
Someone may call it rag.

290
00:17:11,139 --> 00:17:12,959
Someone may call it, context.

291
00:17:13,729 --> 00:17:19,089
I ended up pulling this research
paper, which defined a very promising

292
00:17:19,109 --> 00:17:23,299
trading strategy, but of course,
this is not a, like a talk on

293
00:17:23,449 --> 00:17:27,329
financial advice or on building,
commercial grade, training systems.

294
00:17:27,639 --> 00:17:33,209
This is just for educational purposes,
but using this educational document, I

295
00:17:33,209 --> 00:17:38,039
was able to, give a context to the model
for it to realize and recognize what

296
00:17:38,039 --> 00:17:39,389
are the rules I'm looking for, right?

297
00:17:39,859 --> 00:17:42,369
And it does, it did a pretty good job.

298
00:17:42,849 --> 00:17:47,869
More importantly, I also provided
The model, a starter code from my

299
00:17:47,869 --> 00:17:51,809
previous projects, which I knew works
fine and there were no bugs in it.

300
00:17:51,809 --> 00:17:56,529
So at least it understands that
the structure of the code the way

301
00:17:56,559 --> 00:18:00,349
I prefer to write or before to read
because it's personalized to me.

302
00:18:00,369 --> 00:18:06,419
So these inputs were all provided to the
quant lab GPD model that I had trained.

303
00:18:08,129 --> 00:18:08,609
Now.

304
00:18:09,129 --> 00:18:09,689
Let's see.

305
00:18:10,089 --> 00:18:11,149
Let's do a walkthrough.

306
00:18:11,299 --> 00:18:12,079
All right, enough talk.

307
00:18:12,439 --> 00:18:13,869
Let me show you what it looks like.

308
00:18:14,869 --> 00:18:15,359
All right.

309
00:18:16,289 --> 00:18:17,289
So here we are.

310
00:18:18,839 --> 00:18:21,019
This is, all right, let's
start from the beginning.

311
00:18:22,019 --> 00:18:23,959
Well, a lot of training as you can see.

312
00:18:24,969 --> 00:18:29,579
So I provided like a starter
code, which is a Python script.

313
00:18:30,289 --> 00:18:36,409
I provided certain, I provided
that contextual trading strategy.

314
00:18:36,704 --> 00:18:37,644
To the model.

315
00:18:38,204 --> 00:18:41,304
And of course, it started
generating certain outputs.

316
00:18:41,314 --> 00:18:43,654
I thought I gave all these
different prompts to it.

317
00:18:43,714 --> 00:18:45,444
You can see all these
different prompts to it.

318
00:18:46,044 --> 00:18:51,914
And eventually, after several iterations,
and by the way, you can see you can even

319
00:18:51,964 --> 00:18:55,504
do graphical visualizations in GPT four.

320
00:18:55,504 --> 00:18:57,814
Oh, so this is an amazing tool for that.

321
00:18:57,964 --> 00:19:00,055
And, You can do tables.

322
00:19:00,365 --> 00:19:01,605
I kept on prompting.

323
00:19:01,615 --> 00:19:03,685
It keeps on giving me different results.

324
00:19:03,945 --> 00:19:06,075
It started giving me a
code that I'm looking for.

325
00:19:06,485 --> 00:19:10,715
And with a lot of to and fro, and
to and fro, eventually I got to a

326
00:19:10,715 --> 00:19:14,335
point where I was satisfied that
this is something I can work with.

327
00:19:16,060 --> 00:19:16,850
And then what?

328
00:19:17,430 --> 00:19:21,320
But before long, before I go to the
execution side of it, let me show you

329
00:19:21,330 --> 00:19:23,320
what this quant lab is all about, right?

330
00:19:23,760 --> 00:19:27,390
So let me just go into this edit
functionality of this custom GPT.

331
00:19:27,780 --> 00:19:29,360
I'm going to configure, right?

332
00:19:29,610 --> 00:19:33,510
So I'm showing you all these
things of how, I had actually built

333
00:19:33,510 --> 00:19:35,740
this quant lab as a custom GPT.

334
00:19:35,920 --> 00:19:37,460
So there is a capability within GPT 4.

335
00:19:37,460 --> 00:19:40,050
0 where you can build your own custom GPT.

336
00:19:40,600 --> 00:19:43,740
I'm sure you can find more details
around it, but just to give you

337
00:19:43,740 --> 00:19:46,780
a summary of how it works, you
have to give it instructions.

338
00:19:47,070 --> 00:19:48,850
There are certain compositional starters.

339
00:19:49,120 --> 00:19:51,510
there are certain knowledge,
inputs that I have provided.

340
00:19:51,540 --> 00:19:52,850
You can see it over here.

341
00:19:53,335 --> 00:19:57,065
And if you remember, these
were the diagrams and charts.

342
00:19:57,275 --> 00:19:59,525
So I gave it tabular information.

343
00:19:59,865 --> 00:20:02,115
I gave it visual information.

344
00:20:02,535 --> 00:20:05,905
so it was able to read and comprehend
what I was expecting from it.

345
00:20:05,945 --> 00:20:09,285
And of course, there were a lot
of prompt exercises or prompt

346
00:20:10,145 --> 00:20:11,515
that I had provided to it.

347
00:20:11,735 --> 00:20:15,195
And eventually ended up giving me
the results that I was looking for.

348
00:20:16,215 --> 00:20:19,045
All right, That's QuantLab using GPD 4.

349
00:20:19,045 --> 00:20:19,905
0.

350
00:20:20,655 --> 00:20:23,685
Now, let's go to Visual Studio.

351
00:20:23,815 --> 00:20:28,245
All right, so in Visual Studio,
eventually, what I did was, the code

352
00:20:28,255 --> 00:20:32,345
that was generated using QuantLab,
this was a Jupyter Notebook, by

353
00:20:32,345 --> 00:20:33,790
the way, I was a Jupyter Notebook.

354
00:20:34,840 --> 00:20:36,600
I could transfer that code over here.

355
00:20:36,680 --> 00:20:39,510
Of course, I executed some of the code
to make sure there are no bugs and

356
00:20:39,510 --> 00:20:45,840
everything, and more importantly, I
was using GitHub Copilot to refactor

357
00:20:45,840 --> 00:20:51,260
some of the code to give me, let's
say, for example, here, I asked it to

358
00:20:51,260 --> 00:20:53,860
give me a project structure of how my
project should be structured, right?

359
00:20:53,870 --> 00:20:57,050
So this is using Python scripts,
but eventually I moved on to Jupyter

360
00:20:57,050 --> 00:20:59,160
Notebook because of ease of execution.

361
00:20:59,400 --> 00:21:01,330
So I had some preferences around that.

362
00:21:02,105 --> 00:21:06,195
And, so all might configuration
document or configuration files on

363
00:21:06,265 --> 00:21:07,865
a configuration is kept separately.

364
00:21:08,105 --> 00:21:10,085
I did not want to pull in to the court.

365
00:21:10,085 --> 00:21:15,425
So the way I designed was tomorrow, if I
interface code or this application with

366
00:21:15,875 --> 00:21:20,910
another front end, the JSON file will
be able to take all that data inputs

367
00:21:20,910 --> 00:21:25,250
that are necessary for it to, take the
capture user determine parameters from

368
00:21:25,250 --> 00:21:27,010
the user and configuration from the users.

369
00:21:27,010 --> 00:21:31,800
And then you can then dynamically
update my code or my trading strategy.

370
00:21:31,910 --> 00:21:34,240
Okay, so that's how I use JSON over here.

371
00:21:35,310 --> 00:21:39,280
yeah, so you can see there are
certain code that's been generated.

372
00:21:39,440 --> 00:21:40,210
I'm doing certain.

373
00:21:41,635 --> 00:21:43,315
And this is a very recursive

374
00:21:46,315 --> 00:21:49,925
and refactoring exercise that
we, when you get to a stage where

375
00:21:49,925 --> 00:21:52,715
the code is sufficient for you,
then obviously you can start.

376
00:21:52,715 --> 00:21:55,745
But in the field of technology
and we're never happy.

377
00:21:55,745 --> 00:21:57,885
We always want new versions,
new book, new features.

378
00:21:57,885 --> 00:21:59,895
So it becomes an.

379
00:22:00,055 --> 00:22:05,015
A very fun exercise where you're
interacting with a GPT and, you're telling

380
00:22:05,015 --> 00:22:06,615
it what you want next, what you want next.

381
00:22:06,645 --> 00:22:11,365
And then over time you build things which
you like, and then you take it from there.

382
00:22:11,515 --> 00:22:14,495
So a lot of to and fro using GPT 4.

383
00:22:14,495 --> 00:22:18,105
0 and of course, good to get up
co pilot to eventually get to a

384
00:22:18,105 --> 00:22:21,765
stage where I'm happy with the
current structure of the code.

385
00:22:22,135 --> 00:22:25,875
And it's giving me the desired outcomes
and outputs that I'm looking for.

386
00:22:26,325 --> 00:22:27,405
And, yes.

387
00:22:29,605 --> 00:22:35,175
Let's get back to where we are now.

388
00:22:35,535 --> 00:22:37,815
Some of my, for me to
wrap up things over here.

389
00:22:39,285 --> 00:22:40,715
It's a new world altogether.

390
00:22:40,725 --> 00:22:46,315
It's a great world altogether, especially
in the field of data analytics in a I, It

391
00:22:46,315 --> 00:22:53,325
has been democratized, to a lot of people
out there who were a bit skeptical or

392
00:22:53,325 --> 00:22:57,455
concerned about using these tools because
now these LLM models that are out there

393
00:22:57,635 --> 00:23:02,945
makes it so much convenient, easier for
a business user, a technical user to

394
00:23:02,945 --> 00:23:09,075
collaborate to build Prototype to build
applications in a very, natural way off

395
00:23:09,375 --> 00:23:11,105
doing things the way human beings do it.

396
00:23:11,545 --> 00:23:16,375
And, and also for software engineers,
it is an amazing capability,

397
00:23:16,545 --> 00:23:21,835
which typically improves their
productivity and generating.

398
00:23:22,435 --> 00:23:24,585
new innovations, new
technologies out there.

399
00:23:24,915 --> 00:23:29,215
So I look forward to this, next
evolution of AI that is out there.

400
00:23:29,525 --> 00:23:30,715
we have to adapt to it.

401
00:23:30,735 --> 00:23:31,875
We have to adopt to it.

402
00:23:32,235 --> 00:23:37,115
And, we will be in, we, this is a very
good, direction that I feel I'm fairly

403
00:23:37,115 --> 00:23:40,785
confident that I'm going to be, I'm going
to be taking a lot of benefit from it.

404
00:23:41,225 --> 00:23:45,725
So go to this quant lab, GPT,
custom GPT that I have built.

405
00:23:46,030 --> 00:23:47,160
It's free to use.

406
00:23:47,190 --> 00:23:47,830
if you have a GPT 4.

407
00:23:47,830 --> 00:23:50,600
0 subscription, you can easily access it.

408
00:23:51,040 --> 00:23:56,270
And, if you need any assistance or any
guidance, please reach out to me on

409
00:23:56,280 --> 00:23:57,960
LinkedIn and I will be able to help you.

410
00:23:58,590 --> 00:24:01,230
Thank you so very much all
the best with your journeys.

