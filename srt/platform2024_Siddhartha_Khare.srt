1
00:00:14,209 --> 00:00:17,919
Hey everyone, let's talk about the
road ahead is due observability.

2
00:00:19,285 --> 00:00:22,005
Before we talk about it, who am I?

3
00:00:22,325 --> 00:00:23,095
I'm Siddharth Kare.

4
00:00:23,435 --> 00:00:26,195
I'm working as a technical
account manager with New Relic.

5
00:00:26,695 --> 00:00:30,784
I spent almost a decade in
the industry and worked prior

6
00:00:30,784 --> 00:00:32,204
to working with New Relic.

7
00:00:32,204 --> 00:00:34,804
I was working with Citrix
as a software developer.

8
00:00:35,435 --> 00:00:41,894
I'm a mobile enthusiast and I'm usually
work on creating the awareness about

9
00:00:41,985 --> 00:00:48,174
why the observability is required for
your mobile application and how It

10
00:00:48,175 --> 00:00:54,915
will help you So a brief agenda today
will be around the introduction of

11
00:00:54,945 --> 00:01:02,580
microservices Istio recap, what and why,
of Istio, key metrics for monitoring

12
00:01:02,580 --> 00:01:05,000
the Istio, followed by a short demo.

13
00:01:07,020 --> 00:01:08,590
So what are microservices?

14
00:01:09,170 --> 00:01:14,570
So it's an architectural style that
structures an application as a collection

15
00:01:14,570 --> 00:01:20,590
of services that are independently
deployable and loosely coupled.

16
00:01:21,150 --> 00:01:22,600
Services are typically.

17
00:01:23,729 --> 00:01:30,380
Organized around business capabilities, e
services often owned by single small team.

18
00:01:30,670 --> 00:01:35,009
You can see in the background
how we categorize different teams

19
00:01:35,069 --> 00:01:38,359
and they own their own services.

20
00:01:39,119 --> 00:01:43,859
Basically, with microservice, you will
have an autonomous structure like each

21
00:01:43,889 --> 00:01:48,109
component service in a microservice
architecture can be developed, deployed,

22
00:01:48,369 --> 00:01:52,689
operated, and scaled without affecting
the functioning of their services.

23
00:01:53,149 --> 00:01:58,559
It is specialized like each service is
designed for a set of capabilities and

24
00:01:58,559 --> 00:02:01,639
focuses on solving a specific problem.

25
00:02:02,029 --> 00:02:03,549
And there are multiple benefits.

26
00:02:04,939 --> 00:02:11,649
like agility, flexibility, easy
deployment, and there are many more.

27
00:02:12,619 --> 00:02:21,379
Now, let's talk about what is Istio
So Istio is a service mesh, dedicated

28
00:02:21,689 --> 00:02:26,719
infrastructure layer that you can add
transparently to your applications.

29
00:02:27,489 --> 00:02:32,889
This new layer adds extra capabilities to
the infrastructure, allowing you to manage

30
00:02:32,889 --> 00:02:35,279
the traffic between your microservices.

31
00:02:36,039 --> 00:02:40,249
So you Can create your own
rules to balance the traffic

32
00:02:40,789 --> 00:02:42,559
based on their preference.

33
00:02:42,959 --> 00:02:45,579
Implement the fault injection rules.

34
00:02:45,949 --> 00:02:50,489
To apply chaos engineering to your
code and many more options, right?

35
00:02:50,989 --> 00:02:57,949
And Istio service mesh is made up
of many different components split

36
00:02:57,989 --> 00:03:01,699
mainly split into two layers like
control plane and the data plane.

37
00:03:03,689 --> 00:03:08,779
So there are some of the features that
the Istio control plane provides like

38
00:03:08,919 --> 00:03:12,959
load balancing for the HTTP, traffic.

39
00:03:13,849 --> 00:03:18,549
Control flow mechanism of traffic
behavior by implementing rich routing

40
00:03:18,569 --> 00:03:21,019
rules, fault injection, failovers.

41
00:03:21,514 --> 00:03:22,294
Et cetera.

42
00:03:23,334 --> 00:03:27,884
with Istio, control Train is Studio
is named, mainly the name for the

43
00:03:27,914 --> 00:03:29,824
Istio service mesh, controlled plane.

44
00:03:30,094 --> 00:03:33,864
It consists of few components
which are listed here, like

45
00:03:33,924 --> 00:03:36,744
Pilot Citadel, ga, gallery.

46
00:03:38,104 --> 00:03:43,214
So what Pilot does is it is a
component, which is responsible for

47
00:03:43,214 --> 00:03:45,254
configuring the proxies at the runtime.

48
00:03:45,934 --> 00:03:49,219
It propagates new
configurations to steer objects.

49
00:03:51,539 --> 00:03:53,149
Through the ny proxy.

50
00:03:53,559 --> 00:03:57,679
So see if it's seated in what it
does is it issues a certificate

51
00:03:57,679 --> 00:04:00,804
and ensures They are being rotated.

52
00:04:01,154 --> 00:04:04,534
It's like a, internal certificate
authority, you can consider.

53
00:04:05,524 --> 00:04:08,454
And then last we have Galley.

54
00:04:08,814 --> 00:04:12,544
So this, basically validates and
distributes the configuration

55
00:04:13,304 --> 00:04:15,504
within the Istio service mesh.

56
00:04:15,564 --> 00:04:20,944
So after validation, configurations
are being sent to the pilot and

57
00:04:20,944 --> 00:04:22,454
then pilot distributes these.

58
00:04:23,374 --> 00:04:25,949
Now, if We spoke about the control plane.

59
00:04:26,449 --> 00:04:29,089
So what is there in the data plane?

60
00:04:29,289 --> 00:04:34,179
So you might have heard
multiple times about NY, right?

61
00:04:34,479 --> 00:04:40,229
So NY is a data plane component in
The issue service mesh architecture.

62
00:04:40,579 --> 00:04:46,099
It is not the part of we can't say
it's a part of a Control plane, but

63
00:04:46,099 --> 00:04:51,769
its role is key to make the institution
service work n y is a proxy that

64
00:04:51,769 --> 00:04:54,889
is collated in Pods as a sidecar.

65
00:04:55,339 --> 00:05:00,989
So along with the original container,
which is being deployed So we need to

66
00:05:00,989 --> 00:05:06,229
make just make sure that the injection
is enabled So this sidecar proxy is

67
00:05:06,279 --> 00:05:12,299
responsible for handling the traffic
between services in your cluster from

68
00:05:12,299 --> 00:05:17,649
internal to the external services
and We can say like without in why

69
00:05:17,649 --> 00:05:22,189
it wouldn't be possible to propagate
any changes You or establishing the

70
00:05:22,189 --> 00:05:26,599
communication from one service to
others of, services in your service

71
00:05:26,599 --> 00:05:30,119
mesh in short, nothing will work, right?

72
00:05:30,529 --> 00:05:35,629
So now, the question comes
how you can monitor, right?

73
00:05:36,099 --> 00:05:40,224
So And once you start monitoring,
what are the key metrics?

74
00:05:40,324 --> 00:05:43,268
So these will be the key metrics like
this your request total request duration

75
00:05:43,268 --> 00:05:51,344
milliseconds tcp connection open total
the request total to the destination

76
00:05:51,344 --> 00:05:53,204
service and how it is being monitored.

77
00:05:53,684 --> 00:05:59,439
So Istio uses envoy And it's a
very high performance service proxy

78
00:05:59,599 --> 00:06:03,849
to handle inbound and outbound
traffic through, a service mesh.

79
00:06:04,309 --> 00:06:09,989
Istio's envoy proxies automatically
collect and report the detailed metrics

80
00:06:10,019 --> 00:06:14,919
that provide high level application
information via Prometheus endpoint.

81
00:06:15,199 --> 00:06:20,849
So there are multiple ways how you can
monitor your Prometheus endpoints, right?

82
00:06:21,399 --> 00:06:24,529
so for today's demo, I'm
leveraging New Relic.

83
00:06:27,369 --> 00:06:32,579
So if you go to New Relic to add
your Kubernetes integration, you just

84
00:06:32,579 --> 00:06:37,659
have to click on integrations and
within the integrations, you will

85
00:06:37,679 --> 00:06:40,689
have a, Kubernetes, option available.

86
00:06:41,179 --> 00:06:43,759
Once you go to Kubernetes, you
can leverage any of the method.

87
00:06:44,529 --> 00:06:48,879
and you can start monitoring once
that, once it is being monitored

88
00:06:49,419 --> 00:06:52,469
at that particular time, you will
start seeing that the cluster

89
00:06:52,469 --> 00:06:54,109
will start coming up into new day.

90
00:06:54,359 --> 00:07:00,029
So in my case, the cluster name is con
42 and you can see the metrics here.

91
00:07:00,029 --> 00:07:04,609
So if I click on this particular
cluster, so you will see the overview

92
00:07:04,609 --> 00:07:08,779
of the cluster where it will show
you how the clusters are performing.

93
00:07:08,779 --> 00:07:10,399
If there is anything pending or.

94
00:07:12,029 --> 00:07:14,369
what all things are in
running state, right?

95
00:07:14,589 --> 00:07:16,369
So in my scenario, it's Istio.

96
00:07:16,369 --> 00:07:19,339
So I'll just search for the Istio proxy.

97
00:07:19,339 --> 00:07:23,049
So here you can see that there
is a Istio ingress, right?

98
00:07:23,059 --> 00:07:26,099
So if I click on this, here,
you will have an option.

99
00:07:26,099 --> 00:07:28,399
You will start seeing the Istio ingress.

100
00:07:28,699 --> 00:07:32,979
Let's say now, if you want to
understand the pod details, you click

101
00:07:32,979 --> 00:07:36,359
on the pod details, you will get the
complete information about how the

102
00:07:36,359 --> 00:07:40,899
metrics looks like, what is the CPU
utilization, throttling, memory usage.

103
00:07:41,309 --> 00:07:44,849
all these details you will start
seeing here now at any point

104
00:07:44,849 --> 00:07:49,109
of time Let's say you just want
to see the logs of your issue.

105
00:07:49,229 --> 00:07:50,809
so Ingress, right?

106
00:07:50,809 --> 00:07:56,539
So you click here you go to click on see
logs Once you click on that, you will

107
00:07:56,549 --> 00:07:58,309
start seeing the logs coming up here.

108
00:07:58,309 --> 00:08:00,659
So Let me just increase the time frame.

109
00:08:01,229 --> 00:08:06,189
So once I have, increased the time frame,
you can see all the logs coming up here.

110
00:08:06,529 --> 00:08:09,539
and you can use these
logs to debug any problem.

111
00:08:10,289 --> 00:08:14,019
Now, what are the metrics
which, we discussed, right?

112
00:08:14,019 --> 00:08:17,969
So there are multiple counter
metric, which we spoke about.

113
00:08:17,969 --> 00:08:21,649
So this is a kind of, there are
N number of metrics, actually.

114
00:08:21,659 --> 00:08:28,284
If you see here, I just went to metric
and there are agent certificate related.

115
00:08:28,294 --> 00:08:30,684
There are, expiry related metrics.

116
00:08:30,684 --> 00:08:34,804
There are, It's go, routine
related metrics for his two agent.

117
00:08:35,124 --> 00:08:39,574
there are go threads, related
metrics that request by counts

118
00:08:39,594 --> 00:08:42,974
request by terms durations, which
is what we were talking about.

119
00:08:43,324 --> 00:08:49,774
So the counter metric here, the counter
metric is issue request total which

120
00:08:49,774 --> 00:08:54,794
measures the total number of requests
handled by an issue proxy and the

121
00:08:54,794 --> 00:08:59,614
distribution matrix is issue request
duration milliseconds which measures,

122
00:08:59,724 --> 00:09:04,794
time it has It takes for the STO
proxy to process the HTTP request.

123
00:09:05,174 --> 00:09:10,504
And then another distribution metric
is STO request bytes and STO response

124
00:09:10,544 --> 00:09:15,184
bytes, which measures the HTTP
request and response body size, right?

125
00:09:15,414 --> 00:09:18,774
so you can see here, the list of metrics.

126
00:09:19,124 --> 00:09:25,174
And let's say if you want to see a
specific metrics to NY, so you will get

127
00:09:25,434 --> 00:09:28,445
the whole set of NY, metrics as well.

128
00:09:28,875 --> 00:09:30,735
And it will be listed here.

129
00:09:31,295 --> 00:09:35,985
Now, let's say you have these
many metrics, but now you want

130
00:09:35,995 --> 00:09:37,485
to visualize your data, right?

131
00:09:37,800 --> 00:09:42,140
So if you just want to see what is
the request volume per minute for your

132
00:09:42,140 --> 00:09:45,779
application You will be able to see
the information coming up here where

133
00:09:45,779 --> 00:09:52,310
you can see the app name and sorry the
pod name and the app names you will

134
00:09:52,329 --> 00:09:56,610
start seeing here You can start seeing
the request duration milliseconds.

135
00:09:56,620 --> 00:10:02,075
You can start seeing the traffic on
front end and from which particular

136
00:10:02,105 --> 00:10:05,935
front end application and from
what source the traffic is coming.

137
00:10:05,935 --> 00:10:09,295
You can start seeing the traffic
on your back end application and

138
00:10:09,650 --> 00:10:11,650
What is the source of that traffic?

139
00:10:12,590 --> 00:10:17,040
So in this particular scenario on my
back end database i'm generating the

140
00:10:17,040 --> 00:10:22,630
traffic through my sleep pod and through
my front end But and here you can see

141
00:10:22,630 --> 00:10:28,079
the outbound request by The response
and the source application so you can

142
00:10:28,080 --> 00:10:33,915
see that there are 200 okays for and 400
404 errors, and then we have a histogram

143
00:10:33,925 --> 00:10:36,045
for the client request in milliseconds.

144
00:10:36,855 --> 00:10:38,415
So it's very simple.

145
00:10:38,475 --> 00:10:45,320
you just have to write, the nrql, which
is new relic Query language and you will

146
00:10:45,320 --> 00:10:47,440
be able to create these visualizations.

147
00:10:47,730 --> 00:10:52,910
Similarly, we have something called
Visualization for the request response

148
00:10:52,950 --> 00:10:59,079
code where you can see how much
percentage of time it is Going for 200.

149
00:10:59,079 --> 00:11:00,940
Okay, and of 404.

150
00:11:01,419 --> 00:11:07,010
So this is how easy it is to
Monitor your issue service mesh by

151
00:11:07,010 --> 00:11:11,070
leveraging any specific tool again,
as in this case, it was New Relic.

152
00:11:11,670 --> 00:11:15,720
So I hope you enjoyed this session.

153
00:11:15,760 --> 00:11:20,340
If there are any queries related
to how to set up the environment

154
00:11:20,340 --> 00:11:25,210
or how to start monitoring it, feel
free to reach out to me on LinkedIn

155
00:11:25,580 --> 00:11:27,230
and happy to connect with you.

156
00:11:27,790 --> 00:11:29,170
Thank you and have a nice day.

