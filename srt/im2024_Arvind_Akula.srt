1
00:00:00,180 --> 00:00:00,870
Hello everyone.

2
00:00:01,130 --> 00:00:02,400
My name is Arvind Kumar Akola.

3
00:00:02,760 --> 00:00:05,830
I work as a staff software
engineer in Guaranteed Rate.

4
00:00:06,330 --> 00:00:09,900
Today my talk is about revolutionizing
incident management with cloud

5
00:00:09,930 --> 00:00:11,400
computing and java technologies.

6
00:00:12,400 --> 00:00:17,670
We will discuss on the introduction to
cloud computing and java technologies

7
00:00:18,319 --> 00:00:22,740
and we will discuss about the challenges
with the traditional incident management

8
00:00:23,440 --> 00:00:28,720
and also we'll see how cloud is taking
the advantage of this particular issue.

9
00:00:29,330 --> 00:00:33,380
And how the synergy between Java and
cloud services, along with microservices,

10
00:00:33,380 --> 00:00:40,489
serverless computing, CI CD integration
helps in incident management.

11
00:00:41,400 --> 00:00:43,739
We'll also discuss about
real time monitoring tools.

12
00:00:45,695 --> 00:00:49,035
We'll see how we can do
automation incident responses.

13
00:00:49,635 --> 00:00:52,885
we'll discuss about how we can
collaborate and communicate better

14
00:00:52,885 --> 00:00:56,535
with the teams, in case, we have
to handle the incident management.

15
00:00:57,764 --> 00:01:01,654
We'll also discuss about some
data driven insights and also a

16
00:01:01,655 --> 00:01:04,925
case study, done by IBM for one
of the e commerce applications.

17
00:01:05,925 --> 00:01:07,985
Introduction to cloud computing
and Java technologies.

18
00:01:08,725 --> 00:01:14,075
We all know the cloud computing has become
the cornerstone of digital transformation.

19
00:01:15,485 --> 00:01:21,234
So the reason is like it, cloud computing
offers many big features which are like

20
00:01:21,234 --> 00:01:24,405
scalability, cost efficiency and agility.

21
00:01:24,970 --> 00:01:29,630
With this, the, with this current
global market, the cloud computing

22
00:01:29,650 --> 00:01:32,550
is projected to reach around 832.

23
00:01:32,600 --> 00:01:36,080
1 billion dollars by 2025, right?

24
00:01:36,730 --> 00:01:40,889
So with this, we can assume that,
that cloud computing has become one

25
00:01:40,889 --> 00:01:42,169
of the modern business strategies.

26
00:01:42,715 --> 00:01:48,515
For most of the enterprise applications
like Netflix, Amazon and eBay and a lot

27
00:01:48,515 --> 00:01:53,714
of other companies use cloud computing
along with that, like Java is one of the

28
00:01:53,795 --> 00:01:56,874
main application programming language.

29
00:01:57,320 --> 00:02:01,219
Which is very reliable, and been used
in enterprise environments, right?

30
00:02:01,699 --> 00:02:05,319
The java's main philosophy was
platform independence, which is

31
00:02:05,319 --> 00:02:07,169
write once and run anywhere, right?

32
00:02:07,569 --> 00:02:11,320
This perfectly fits with the distributed
nature of the cloud computing, right?

33
00:02:11,709 --> 00:02:15,190
Where the this will help the
developers to write portable

34
00:02:15,190 --> 00:02:19,320
applications which run seamlessly
across multiple cloud platforms.

35
00:02:20,050 --> 00:02:24,719
the combination of this platform
independence and the distributed

36
00:02:24,720 --> 00:02:29,219
nature of cloud computing, this is
a powerful synergy which enables

37
00:02:29,219 --> 00:02:34,210
the business to develop robust,
scalable, and efficient applications.

38
00:02:35,520 --> 00:02:38,280
And, Java have an extensive ecosystem.

39
00:02:38,330 --> 00:02:40,220
it have many frameworks.

40
00:02:40,220 --> 00:02:44,510
The main frameworks were Spring
Boot, Micronaut, using which we

41
00:02:44,510 --> 00:02:47,500
can develop in, production ready
application within a few days.

42
00:02:48,800 --> 00:02:53,490
So this makes the ideal technology for
driving the digital transformation.

43
00:02:55,350 --> 00:02:56,040
That's about it.

44
00:02:56,480 --> 00:02:58,040
Let's go ahead.

45
00:02:59,650 --> 00:03:03,500
Here we are going to discuss
about the challenges of the

46
00:03:03,530 --> 00:03:04,970
traditional incident management.

47
00:03:05,550 --> 00:03:09,250
earlier before cloud computing
and, microservices and Java, right?

48
00:03:09,640 --> 00:03:13,430
We were struggling with siloed
systems and slow response time, right?

49
00:03:13,839 --> 00:03:18,540
So based on a study from Gartner,
We found that the, the downturn per

50
00:03:18,540 --> 00:03:22,399
minute cost around, 5, 600 per minute.

51
00:03:23,689 --> 00:03:30,109
So we can assume that, in a holiday season
where the traffic speaks, whenever there

52
00:03:30,109 --> 00:03:34,239
is an outage, it's going to cost that
particular, usage of the customers, right?

53
00:03:34,859 --> 00:03:36,709
We are going to miss
that particular, traffic.

54
00:03:37,889 --> 00:03:41,659
So that's the last which was,
included here by the Gartner

55
00:03:44,019 --> 00:03:47,549
and, the manual process which leads
to the human errors right here.

56
00:03:47,909 --> 00:03:51,459
there are a lot of things which we
do manually where we need to search

57
00:03:51,459 --> 00:03:54,569
logs, copy the, ID, request IDs.

58
00:03:55,009 --> 00:03:58,089
And, we update the, spreadsheets
and contact the team

59
00:03:58,089 --> 00:03:59,199
members individually, right?

60
00:03:59,509 --> 00:04:02,489
There is a high probability
here we, We will have manual

61
00:04:02,489 --> 00:04:06,459
exceptions and manual errors due
to which, this traditional incident

62
00:04:06,469 --> 00:04:08,599
management is not, up to the mark.

63
00:04:08,879 --> 00:04:12,959
And the siloed system, hinders the,
collaboration and visibility, Because

64
00:04:12,959 --> 00:04:17,839
we have a lot of monitoring tools, which
are not like, we used to directly go to

65
00:04:17,839 --> 00:04:20,749
Tomcat and, and other application servers.

66
00:04:21,059 --> 00:04:26,899
We used to Check the errors there
and we don't have an integration

67
00:04:26,909 --> 00:04:32,090
with this particular logger mechanism
with our communication channels.

68
00:04:32,169 --> 00:04:33,229
So that was the issue.

69
00:04:34,229 --> 00:04:37,579
And also legacy infrastructure
lacks the scalability to handle

70
00:04:37,579 --> 00:04:38,819
the modern demands, right?

71
00:04:39,289 --> 00:04:41,809
So the infrastructure which
we used to have earlier.

72
00:04:42,534 --> 00:04:47,344
Let's say we have 10 nodes to serve the
traffic, whenever there is a holiday

73
00:04:47,344 --> 00:04:52,724
season, we need to scale up, and we
need to plan ahead and have a team which

74
00:04:52,784 --> 00:04:56,704
to work on, building up the servers
and deploy the application and make

75
00:04:56,704 --> 00:04:58,354
it ready at that particular peak time.

76
00:04:58,799 --> 00:05:01,509
this all can be avoided
with, cloud computing.

77
00:05:02,119 --> 00:05:03,379
We'll see that in the next slide.

78
00:05:03,619 --> 00:05:06,840
So here we are going to discuss how
cloud, is staying in the advantage

79
00:05:06,840 --> 00:05:12,250
of, and these are the main things,
which already we, we touched just now.

80
00:05:12,610 --> 00:05:15,340
So the solution which cloud
provides is the agility,

81
00:05:15,340 --> 00:05:16,900
scalability, and resilience, right?

82
00:05:17,450 --> 00:05:20,420
See, the on demand resource,
scale up and scale down can

83
00:05:20,420 --> 00:05:22,550
automatically happen in cloud.

84
00:05:22,875 --> 00:05:28,185
And automatically we can, accelerate
the incident responses, and whenever

85
00:05:28,185 --> 00:05:33,054
there is a system or a database or
something is down, we can sell, we can

86
00:05:33,155 --> 00:05:35,685
add the cell feeling, in cloud computing.

87
00:05:36,180 --> 00:05:39,380
And we can have the centralized
platform enhancement collaboration

88
00:05:39,730 --> 00:05:43,550
like integrated monitoring,
logging and communication tools.

89
00:05:43,810 --> 00:05:45,660
We have a lot of examples for this.

90
00:05:45,660 --> 00:05:49,280
We can, we'll discuss in a minute,
like Kibana, Grafana and a lot

91
00:05:49,280 --> 00:05:53,330
of other integration tools, where
we can integrate all the K8,

92
00:05:53,410 --> 00:05:55,390
clusters and the local instances.

93
00:05:55,810 --> 00:05:57,690
We can get all the logs in one place.

94
00:05:58,880 --> 00:06:03,330
And the main important feature here is
the reducing the infrastructure cost.

95
00:06:03,625 --> 00:06:07,855
So whenever there is a traffic, we will
increase the number of resources we

96
00:06:07,865 --> 00:06:12,734
scale up and whenever we don't have, we
can eliminate those particular, we can

97
00:06:12,745 --> 00:06:18,284
free up those resources so that we can,
we can decrease the, maintenance cost.

98
00:06:19,284 --> 00:06:22,564
So here we are going to discuss
how the Java, is going to be

99
00:06:22,564 --> 00:06:26,724
the powerhouse of cloud native
implementation for incident management.

100
00:06:28,044 --> 00:06:32,174
So the platform independence for, is
the main feature where we can write

101
00:06:32,194 --> 00:06:36,794
once and, run anywhere, which will
help for seamless deployments across

102
00:06:37,054 --> 00:06:38,774
multiple cloud platforms, right?

103
00:06:39,204 --> 00:06:43,385
Using this, we can, build a robust,
like we have, A framework like

104
00:06:43,385 --> 00:06:48,165
Spring Boot where we can build the
microservices and we have Spring

105
00:06:48,175 --> 00:06:51,365
Cloud for Cloud service discovery.

106
00:06:51,365 --> 00:06:57,375
We can do configuration management and
load balancing Using, this framework

107
00:06:58,415 --> 00:07:03,185
and we have an extensive library of,
monitoring and logging tools along

108
00:07:03,185 --> 00:07:08,885
with alerting, like log four JSFL,
four J and micrometer from Spring Boot.

109
00:07:09,525 --> 00:07:13,505
So these libraries, will help
us in logging, the application

110
00:07:13,505 --> 00:07:14,885
errors or info messages.

111
00:07:15,740 --> 00:07:22,550
this can be easily, Help for help the
java application and we have a large,

112
00:07:22,620 --> 00:07:27,240
an active community For supporting
an innovation new tech new things,

113
00:07:27,490 --> 00:07:29,500
can be integrated in java, right?

114
00:07:32,100 --> 00:07:34,180
We'll discuss more about this now.

115
00:07:34,590 --> 00:07:36,100
This is about microservices.

116
00:07:36,420 --> 00:07:39,780
How, Earlier right when we were
discussing about this iload environment

117
00:07:40,140 --> 00:07:44,750
Which was a single monolithic
application where, which, which can be

118
00:07:44,750 --> 00:07:48,340
divided into multiple smaller, logic.

119
00:07:48,690 --> 00:07:54,080
So here we'll take a separate example for
this where, we have a framework where we

120
00:07:54,080 --> 00:07:55,700
have a module called user authentication.

121
00:07:56,800 --> 00:08:02,060
We have an instant logging option and
also a notification dispatcher, right?

122
00:08:02,440 --> 00:08:04,810
So we can assume a name.

123
00:08:05,680 --> 00:08:09,480
monolithic application architecture,
whenever there is an issue with

124
00:08:09,670 --> 00:08:14,310
user authentication, we, it is going
to impact the incident logging and

125
00:08:14,310 --> 00:08:15,790
notification dispatching, right?

126
00:08:16,580 --> 00:08:20,100
So similarly, whenever we have an issue
with incident logging, it is going to

127
00:08:20,100 --> 00:08:25,650
impact the user authentication because all
are running in one single instance, right?

128
00:08:25,880 --> 00:08:29,370
So this can be avoided using
the microservices, right?

129
00:08:29,820 --> 00:08:35,800
In microservices, we can isolate each and
every module here has We have incident,

130
00:08:35,810 --> 00:08:39,470
user authentication and everything
has a separate whenever there is an

131
00:08:39,470 --> 00:08:43,730
issue with one particular, incident
logging, it is not going to impact

132
00:08:43,750 --> 00:08:46,250
the user authentication microservice.

133
00:08:46,800 --> 00:08:50,040
Similarly, we have deployment
updates independently without

134
00:08:50,040 --> 00:08:51,490
affecting other services, right?

135
00:08:51,530 --> 00:08:56,010
Whenever we want to scale up, let's say
we in traffic peak hours, we want to

136
00:08:56,010 --> 00:08:58,360
handle the more number of users, right?

137
00:08:58,770 --> 00:09:01,950
So at that point of time, we can
scale up user authentication module.

138
00:09:02,440 --> 00:09:05,730
microservice and then we can handle
that particular, only service

139
00:09:05,730 --> 00:09:09,840
can, and we can save here, like
not increasing the others, right?

140
00:09:10,810 --> 00:09:11,550
and also we,

141
00:09:12,550 --> 00:09:15,990
and, so this will help, during
the high traffic situations.

142
00:09:16,990 --> 00:09:17,240
Yeah.

143
00:09:17,320 --> 00:09:20,170
So coming to cloud computing, we
have something called serverless

144
00:09:20,190 --> 00:09:23,880
computing, where we, where, we can
achieve the similar kind of thing,

145
00:09:23,880 --> 00:09:28,590
whatever we discussed without a,
without we focus on, we can, instead

146
00:09:28,590 --> 00:09:32,600
of focusing on infra, we can just focus
on code and business logic, right?

147
00:09:33,030 --> 00:09:36,550
this is a effortless scalability
and reducing the overall

148
00:09:36,550 --> 00:09:37,670
operation costs, right?

149
00:09:38,250 --> 00:09:39,510
Using serverless, computing.

150
00:09:40,290 --> 00:09:42,850
the best example is, AWS Lambda.

151
00:09:42,850 --> 00:09:45,460
We have one, here, the diagram
which we are seeing here.

152
00:09:45,820 --> 00:09:50,160
We have one AWS Lambda and this can
be automatically triggered instant

153
00:09:50,170 --> 00:09:54,440
responses, when, function to send
the notification whenever there

154
00:09:54,440 --> 00:09:56,150
is an incident created, right?

155
00:09:56,400 --> 00:09:57,790
So this will send a notification.

156
00:09:58,260 --> 00:10:02,435
So automatically scale, the resources
based on the real time demand, right?

157
00:10:02,475 --> 00:10:05,425
This is only, triggers only
when there is an incident.

158
00:10:05,555 --> 00:10:07,315
That means it's only real time, right?

159
00:10:08,195 --> 00:10:12,675
and here we pay only for the
computation time which we actually used.

160
00:10:12,985 --> 00:10:16,175
We don't need to pay whenever
the server is, not used, right?

161
00:10:16,625 --> 00:10:21,265
and also we don't have to worry about
the, number of servers used and we don't

162
00:10:21,265 --> 00:10:23,885
want, have, the users, to use this, right?

163
00:10:24,265 --> 00:10:29,425
this will free up the developer where they
can focus on incident management logic

164
00:10:29,745 --> 00:10:31,985
instead of focusing on the infrastructure.

165
00:10:32,985 --> 00:10:38,275
Here we are going to discuss about CI
and CD pipelines, which will continuously

166
00:10:38,275 --> 00:10:40,495
improve for the faster resolution, right?

167
00:10:40,985 --> 00:10:45,535
the main logic here is like we have
couple of tools in market right

168
00:10:45,535 --> 00:10:47,975
now, Jenkins, Git, Git actions.

169
00:10:48,525 --> 00:10:51,395
And, here whenever there's
a new, deployment happens.

170
00:10:52,030 --> 00:10:54,180
our microservice is, created, right?

171
00:10:54,570 --> 00:10:58,300
We deploy that and, the
automatic code deployment will

172
00:10:58,300 --> 00:10:59,860
happen using Jenkins, right?

173
00:11:00,370 --> 00:11:03,270
And, whenever a build is
deployed, bill is, triggered.

174
00:11:03,600 --> 00:11:07,980
It'll deploy into a particular docker
and COU K eight, and, it'll run.

175
00:11:08,030 --> 00:11:12,450
we can also have the automatic,
automa automated test cases, right?

176
00:11:12,660 --> 00:11:14,760
So this will improve the code quality.

177
00:11:15,160 --> 00:11:18,830
And it will run all the J units and
end to end testing will happen, right?

178
00:11:19,340 --> 00:11:23,250
This will also, the other example
which we can take here is, even

179
00:11:23,250 --> 00:11:24,600
in the case of issues, right?

180
00:11:24,600 --> 00:11:28,310
Whenever there is an issue, the
rollback can happen easily, right?

181
00:11:28,690 --> 00:11:29,460
using Jenkins.

182
00:11:29,470 --> 00:11:33,060
Whenever there is an issue, it won't
be deployed into the server, right?

183
00:11:33,730 --> 00:11:38,285
We can stop the deployment and, the
particular, and also we can rollback

184
00:11:38,285 --> 00:11:41,545
easily in other environments and
we can check, what was failing.

185
00:11:42,955 --> 00:11:46,175
So this is going to help, the,
improve the faster incidence

186
00:11:46,215 --> 00:11:48,635
resolutions using C and CD pipelines.

187
00:11:51,095 --> 00:11:54,875
So here we are going to discuss about
real time monitoring and alerting, right?

188
00:11:55,365 --> 00:11:58,895
We have multiple tools to achieve
this in current, applications.

189
00:11:59,365 --> 00:12:01,845
Prometheus is one of the popular thing.

190
00:12:02,205 --> 00:12:07,185
And, we have Grafana and we have
Dryna Trace, where, we can identify

191
00:12:07,575 --> 00:12:09,615
if there are any CP outages, right?

192
00:12:09,965 --> 00:12:13,885
there are a couple of, scenarios
here where we can, enable alerts.

193
00:12:14,380 --> 00:12:20,080
whenever, the, here we are taking example
of whenever the CPU, usage, exceeds more

194
00:12:20,080 --> 00:12:24,860
than 80%, let's say, create an alert
and, send it to the application data.

195
00:12:25,210 --> 00:12:30,920
So here, we can trigger an alert based
on, based on the, based on this particular

196
00:12:31,050 --> 00:12:36,440
parameters, And also we can analyze data
in, in identify the anomalies, with the

197
00:12:36,460 --> 00:12:40,850
potential issues, With this can easily, we
can easily see the number of spikes also.

198
00:12:40,850 --> 00:12:45,780
We can have this, and also we can,
Have the, collection of the real time

199
00:12:45,780 --> 00:12:50,810
data, with respect to the monitoring
the CPU's usage, memory usage, and

200
00:12:50,820 --> 00:12:52,630
network traffic and error rates.

201
00:12:52,740 --> 00:12:54,590
We can also monitor the user logins.

202
00:12:55,000 --> 00:12:58,510
Whenever there is a huge number of
logins, let's say we want to track

203
00:12:58,510 --> 00:13:02,030
it and we want the alerts to be
sent to the application team, right?

204
00:13:02,310 --> 00:13:06,180
We can do that with this real time
monitoring and, alerting systems.

205
00:13:08,605 --> 00:13:11,755
Here we, we saw about real
time monitoring alert, right?

206
00:13:12,025 --> 00:13:15,425
We want to do an automatic
incident response, right?

207
00:13:15,815 --> 00:13:20,305
Whenever there is an incident reported,
we want to, send it to the particular

208
00:13:20,415 --> 00:13:24,445
application team and we want somebody
to address that particular issue, right?

209
00:13:24,755 --> 00:13:28,725
If they complete this, there are a
couple of examples where we have P0

210
00:13:28,725 --> 00:13:32,865
issues like database server is down or
the vault is down for an application.

211
00:13:33,655 --> 00:13:37,705
For these kind of issues, we, we
need somebody to manually check this.

212
00:13:38,245 --> 00:13:43,285
So for that, we can integrate it with
the pager, so that the notification.

213
00:13:43,315 --> 00:13:47,065
So we can see here the how the
incident are managed and automatically

214
00:13:47,065 --> 00:13:48,565
integrated with pager duty.

215
00:13:48,995 --> 00:13:52,135
and we can escalate based on
the severity of the issues.

216
00:13:53,850 --> 00:13:57,520
And a couple of examples
here is the CPU high usage.

217
00:13:57,940 --> 00:14:01,830
And if some application is
completely down, we can trigger this.

218
00:14:04,620 --> 00:14:06,100
And collaboration and community.

219
00:14:06,230 --> 00:14:09,610
This is one of the, main thing,
which, and has the dream work

220
00:14:09,840 --> 00:14:13,270
with centralized, communication
channels and collaboration site.

221
00:14:13,970 --> 00:14:18,220
Here, main things which we want to discuss
here is, we should have a shared platform

222
00:14:18,220 --> 00:14:20,320
for incident communications, right?

223
00:14:20,680 --> 00:14:25,410
Like Jira, we have Jira boards, and
also we can have, we can have the

224
00:14:25,410 --> 00:14:27,060
team, we can have a group channels.

225
00:14:27,285 --> 00:14:33,525
where we can discuss about the incidents
and we can have, the slack channels

226
00:14:33,525 --> 00:14:38,675
and Microsoft teams, where we can
easily communicate about the issues.

227
00:14:38,975 --> 00:14:44,230
So earlier, whenever we, had issues, In
automatic incident responses and real

228
00:14:44,230 --> 00:14:48,510
time monitoring, we want to send them to
this particular Slack channels, right?

229
00:14:49,000 --> 00:14:52,260
So where we can integrate
them with the Slack channels.

230
00:14:52,270 --> 00:14:56,740
So whenever there is a high priority
issues, we can directly send it to

231
00:14:56,740 --> 00:15:01,260
a particular application team and we
can address to all the stakeholders

232
00:15:01,260 --> 00:15:02,920
related to that particular application.

233
00:15:03,520 --> 00:15:07,305
So this will help in, collaborating
and we can have a centralized

234
00:15:07,335 --> 00:15:08,835
communication for all the teams.

235
00:15:09,710 --> 00:15:12,260
So that we can address the issues easily.

236
00:15:12,750 --> 00:15:17,090
And we can also create a
knowledge base for this using

237
00:15:17,090 --> 00:15:19,290
wiki pages or any of this, right?

238
00:15:19,610 --> 00:15:25,760
Whenever and also we can
have a weekly credence for

239
00:15:26,220 --> 00:15:27,675
discussing this kind of issues.

240
00:15:28,675 --> 00:15:32,775
So here we are going to discuss about,
the data driven insights, right?

241
00:15:33,175 --> 00:15:38,395
So here we have, we can do, detailed
comprehensive, data analysis.

242
00:15:38,885 --> 00:15:40,575
So there are multiple ways to do it.

243
00:15:40,675 --> 00:15:42,875
We can use, use Tableau reports.

244
00:15:43,145 --> 00:15:46,945
We can, we have Elasticsearch
dashboards and we have Kibana.

245
00:15:47,445 --> 00:15:48,495
reports, right?

246
00:15:49,065 --> 00:15:53,425
And, based on this, we can have multi
monthly and weekly meetings where we

247
00:15:53,425 --> 00:15:57,475
can discuss about, what happened when
a production release happens, right?

248
00:15:57,825 --> 00:16:00,975
We can see the Tableau reports
and we can discuss, about,

249
00:16:01,425 --> 00:16:04,835
how the traffic is getting,
communicated with the new release.

250
00:16:05,215 --> 00:16:09,225
Whenever there's a new feature,
released, we can see how the users are,

251
00:16:10,225 --> 00:16:12,060
how the users are, communicated.

252
00:16:12,535 --> 00:16:16,155
And we can identify the patterns,
proactively and prevent the

253
00:16:16,215 --> 00:16:17,285
future incidents, right?

254
00:16:17,295 --> 00:16:20,795
Whenever there is a issue,
we can see those, common root

255
00:16:20,795 --> 00:16:23,015
causes and we can identify them.

256
00:16:23,565 --> 00:16:27,935
the key, metric to track here
is the mean, time to resolution.

257
00:16:28,730 --> 00:16:30,190
which is called as MTTR.

258
00:16:31,650 --> 00:16:35,950
So we can see the incident and we
can see we can track the frequency

259
00:16:35,950 --> 00:16:38,060
of the resolution for this.

260
00:16:39,060 --> 00:16:41,360
So this is how we handle the data.

261
00:16:42,920 --> 00:16:44,140
Going on next.

262
00:16:45,140 --> 00:16:48,340
So here we are going to discuss
about a case study, which is done

263
00:16:48,340 --> 00:16:52,400
by IBM with a, one of the leading
e commerce, application, right?

264
00:16:52,870 --> 00:16:57,060
So this application, e commerce company
was, struggling with slow response

265
00:16:57,060 --> 00:17:01,624
time and frequent outages using,
during the peak up, peak season.

266
00:17:01,975 --> 00:17:03,115
Peak shopping season, right?

267
00:17:03,685 --> 00:17:09,905
So once they're migrated to, microservice
architecture with AWS, are using Lambda

268
00:17:09,905 --> 00:17:12,765
and, for our automated incident responses.

269
00:17:13,275 --> 00:17:17,485
So below the, highlighted, results
they achieved, they achieved 78

270
00:17:17,485 --> 00:17:19,375
percentage of scalability improvement.

271
00:17:19,915 --> 00:17:25,145
And they reduce the, m empty TR by
50 percentage, and they decrease

272
00:17:25,145 --> 00:17:27,215
the incidents by 30 percentage.

273
00:17:27,845 --> 00:17:31,155
See, overall, the scalability
has been improved by 78%.

274
00:17:32,215 --> 00:17:38,695
This is a great achievement, I say, using
both the Java microservices and also

275
00:17:38,705 --> 00:17:41,835
using the cloud based application, right?

276
00:17:42,455 --> 00:17:45,565
So this is the survey result.

277
00:17:45,965 --> 00:17:47,455
So this is a great achievement.

278
00:17:49,995 --> 00:17:51,945
And here are the key takeaways, guys.

279
00:17:52,265 --> 00:17:55,495
the cloud and Java enable the
efficient incident management.

280
00:17:55,955 --> 00:18:00,085
we discussed about how we are, how
both cloud and, Java, doing this.

281
00:18:00,475 --> 00:18:04,635
We are, we already discussed about,
microservices and serverless computing

282
00:18:04,635 --> 00:18:09,825
and has the scalability, how the
scalability, applies for both, serverless

283
00:18:09,825 --> 00:18:12,175
lambda and also mic, boot microservices.

284
00:18:12,865 --> 00:18:18,745
We see the CNCD monitoring ML
drive faster for quicker responses.

285
00:18:19,500 --> 00:18:24,490
And also we discussed about moving
beyond the incident management, right?

286
00:18:25,540 --> 00:18:31,050
Where we can create the dashboards and
we can see the, preventive measures

287
00:18:31,370 --> 00:18:33,640
based on the, historical data, right?

288
00:18:33,980 --> 00:18:38,230
Agility screen here, where we respond
to the incident which, Speed and

289
00:18:38,230 --> 00:18:43,930
efficiency so and also we have we can
take the decisions based on data, right?

290
00:18:44,370 --> 00:18:49,500
So based on this data we can see how we
can continuously improve We can identify

291
00:18:49,510 --> 00:18:54,320
the issues and we can make sure that the
issues cannot Occur the next time right?

292
00:18:54,680 --> 00:19:00,810
So these are the key takeaways guys with
both the cloud and java technologies on

293
00:19:00,840 --> 00:19:03,570
how we can handle the incident management.

294
00:19:04,170 --> 00:19:06,210
Thank you everyone Bye.

295
00:19:06,230 --> 00:19:06,570
Bye

