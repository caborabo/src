1
00:00:14,190 --> 00:00:15,710
Hey guys, thanks for joining in.

2
00:00:16,100 --> 00:00:19,530
Today, we're going to talk about a less
common approach to production monitoring

3
00:00:19,530 --> 00:00:21,710
called business driven monitoring.

4
00:00:22,380 --> 00:00:25,040
But before I begin, I
want to ask you something.

5
00:00:26,199 --> 00:00:30,189
Do you know that exciting
feeling of yes, it works.

6
00:00:31,925 --> 00:00:34,415
That feeling is why I
love developing software.

7
00:00:35,095 --> 00:00:39,435
Some people get this thrill from looking
at a task pass after multiple failures.

8
00:00:39,475 --> 00:00:42,425
But me, I get it from looking at Grafana.

9
00:00:43,585 --> 00:00:47,144
Seeing traffic from real users
going through a brand new process I

10
00:00:47,174 --> 00:00:49,265
created and getting new experience.

11
00:00:49,950 --> 00:00:52,720
It's something that gives
me tremendous satisfaction.

12
00:00:53,490 --> 00:00:57,560
The way I see it, monitoring is
the gift wrapper you put on before

13
00:00:57,570 --> 00:00:59,129
you ship the feature to production.

14
00:01:00,200 --> 00:01:04,289
And I bet some of you are thinking,
we don't need to worry about that.

15
00:01:04,409 --> 00:01:06,509
Monitoring is out of the box.

16
00:01:07,539 --> 00:01:09,110
And in many cases, it's true.

17
00:01:09,759 --> 00:01:14,080
In large tech companies like Wix, there
are great out of the box production

18
00:01:14,080 --> 00:01:19,360
monitoring solutions, but they tend
to focus on a single microservice.

19
00:01:20,190 --> 00:01:21,610
Or even a single pod.

20
00:01:22,400 --> 00:01:27,000
Now, I hope that by the end of this talk,
you will see monitoring a bit differently.

21
00:01:27,929 --> 00:01:31,190
Instead of monitoring latency
and errors, you will switch your

22
00:01:31,190 --> 00:01:33,310
focus to monitoring business KPIs.

23
00:01:34,190 --> 00:01:38,869
I will guide you step by step in creating
your first business driven dashboard.

24
00:01:39,370 --> 00:01:43,650
That's how you'll become a true owner of
the product, and not just a developer.

25
00:01:43,970 --> 00:01:45,320
Hi, I'm Oren.

26
00:01:45,340 --> 00:01:47,949
I've been creating Grafana
dashboards for the past five years.

27
00:01:48,320 --> 00:01:52,039
In the past two years, I've been
working as a backend developer at Wix.

28
00:01:52,039 --> 00:01:52,420
com.

29
00:01:52,980 --> 00:01:57,099
There, I'm part of the Wix e commerce
platform, a platform for building

30
00:01:57,120 --> 00:01:59,860
e commerce sites and stores online.

31
00:02:01,269 --> 00:02:06,510
For those of you who don't know Wix, Wix
is a site building platform that powers

32
00:02:06,530 --> 00:02:09,040
over 10 million sites across the internet.

33
00:02:09,970 --> 00:02:12,090
One million of them are e commerce sites.

34
00:02:13,040 --> 00:02:20,280
In terms of monitoring, Wix microservices
expose over 150 million unique metrics

35
00:02:20,450 --> 00:02:25,219
per hour and half a trillion logs a day.

36
00:02:26,170 --> 00:02:29,290
So huge scale, huge global impact.

37
00:02:30,010 --> 00:02:31,510
And that's why I come to work every day.

38
00:02:32,729 --> 00:02:35,520
When I say business driven, what
do I'm not talking about devs

39
00:02:35,530 --> 00:02:37,350
doing analyst's work, not at all.

40
00:02:38,010 --> 00:02:42,380
Business analysts, they set KPIs and
measure them monthly for business growth.

41
00:02:42,840 --> 00:02:47,960
But what I'm talking about is end to end
monitoring of product funnels, tracking

42
00:02:47,970 --> 00:02:53,160
business KPIs to identify crucial bugs
that affect users before they notice them.

43
00:02:54,870 --> 00:02:59,570
When you look at a single service and you
examine its stats like latency and errors,

44
00:03:00,225 --> 00:03:04,775
You have no idea if users get the wanted
experience from your product as a whole.

45
00:03:05,605 --> 00:03:10,605
But if you change perspective and think a
bit like a product, you can find metrics

46
00:03:10,605 --> 00:03:12,005
that will tell you the full story.

47
00:03:12,885 --> 00:03:17,145
Alright, now that we know why it
matters, let's get into the how.

48
00:03:17,665 --> 00:03:20,515
As developers, we have two
main ways to gather live data.

49
00:03:21,635 --> 00:03:23,835
Logs and metrics.

50
00:03:24,635 --> 00:03:28,015
Logs capture what happened, while
metrics capture how well it happened.

51
00:03:28,950 --> 00:03:33,670
Logs are great for debugging and
tracing specific issues, while

52
00:03:33,670 --> 00:03:37,640
metrics are ideal for monitoring
system health and performance.

53
00:03:38,310 --> 00:03:42,210
They are both trimmed into graphs
that compose meaningful dashboards.

54
00:03:44,240 --> 00:03:47,570
And there are so many tools out
there for any of these purposes.

55
00:03:48,855 --> 00:03:54,245
But today we're going to focus on these
three, Loki, Prometheus, and Grafana.

56
00:03:55,455 --> 00:03:59,905
I know this sounds a bit like characters
from a Marvel movie, but from the very

57
00:03:59,905 --> 00:04:04,425
beginning of my career, these were the
tools I used for production monitoring.

58
00:04:05,035 --> 00:04:09,395
They're all open source, so even when
I worked at a low budget startup, I ran

59
00:04:09,395 --> 00:04:12,155
them on premise with Docker Compose.

60
00:04:12,835 --> 00:04:16,015
So you don't have to be a
big company to be monitored.

61
00:04:16,635 --> 00:04:17,885
Now let's present them.

62
00:04:18,385 --> 00:04:20,845
Loki is your log aggregation system.

63
00:04:21,380 --> 00:04:24,150
It consumes the logs
and stores it in its DB.

64
00:04:24,860 --> 00:04:28,410
Prometheus does the exact
same thing for metrics.

65
00:04:29,240 --> 00:04:33,810
They are both integrated into Grafana,
where we create visualizations and alerts.

66
00:04:34,330 --> 00:04:37,630
Now that we've got our tools lined
up, it's time to put them to work.

67
00:04:38,310 --> 00:04:41,050
Let's break down the implementation
process step by step.

68
00:04:42,670 --> 00:04:47,850
Alright, so the first step is to define
the business KPIs and product funnels.

69
00:04:48,640 --> 00:04:52,020
Then, we'll light things
up with logs and metrics.

70
00:04:52,020 --> 00:04:52,094
Alright.

71
00:04:52,625 --> 00:04:55,784
And finally, we'll create
visualization in Grafana.

72
00:04:58,665 --> 00:05:02,805
Imagine walking to the office, you've
got the keys, you're in charge.

73
00:05:03,575 --> 00:05:07,925
The system is already in production and
you want to know how well are we doing.

74
00:05:08,515 --> 00:05:11,065
But there is zero monitoring.

75
00:05:12,225 --> 00:05:14,595
So how the hell will
you know where we stand?

76
00:05:16,925 --> 00:05:20,195
You'll start out by mapping your
business funnels, identifying crucial

77
00:05:20,195 --> 00:05:22,315
flows, breaking them down steps.

78
00:05:23,505 --> 00:05:26,845
At this phase, you should already
know what you expect the system to do.

79
00:05:28,145 --> 00:05:30,865
You should be able to
define your business KPIs.

80
00:05:32,140 --> 00:05:35,850
This is the part you want your product
and analysts on board because they

81
00:05:35,850 --> 00:05:39,630
will enrich your tech perspective
with more business oriented goals.

82
00:05:41,510 --> 00:05:45,940
Each funnel should have at least one
business KPI or else why it exists.

83
00:05:46,540 --> 00:05:51,090
For example, in e com platform, our
main KPI is checkout conversion,

84
00:05:51,770 --> 00:05:56,300
but within this huge funnel until
checkout conversion, we have

85
00:05:56,300 --> 00:06:00,450
more specific per step KPIs.

86
00:06:03,190 --> 00:06:05,469
So now you know what you
expect the system to do.

87
00:06:06,140 --> 00:06:10,860
But more importantly, you should notice
what you're not seeing, what data is

88
00:06:10,880 --> 00:06:13,020
missing, where are your dark spots.

89
00:06:14,800 --> 00:06:16,800
And that's where it gets interesting.

90
00:06:17,000 --> 00:06:21,670
Because once you got the funnels, you can
start to get intimate with every step.

91
00:06:22,520 --> 00:06:26,350
If you see a dark spot, you
can light it up with matrix.

92
00:06:27,345 --> 00:06:31,105
Now don't stick to what could go
wrong and the error flows, but

93
00:06:31,125 --> 00:06:33,075
think about your business KPIs.

94
00:06:34,345 --> 00:06:37,135
Think about what will make
you happy with the product.

95
00:06:38,105 --> 00:06:39,695
Light up those paths as well.

96
00:06:40,735 --> 00:06:42,355
My advice here is to be generous.

97
00:06:42,445 --> 00:06:46,905
Add so many metrics, so you'll feel
like you know every corner of the flow.

98
00:06:49,780 --> 00:06:53,400
For those of you who never used
Matrix, once you did the hard

99
00:06:53,400 --> 00:06:59,140
work of integrating Prometheus and
Grafana, adding one is super easy.

100
00:06:59,660 --> 00:07:04,270
You only need one line of code and
one line in Grafana, and you got it.

101
00:07:04,930 --> 00:07:07,420
I repeat, one line of code

102
00:07:09,520 --> 00:07:10,890
and one line in Grafana.

103
00:07:11,480 --> 00:07:12,800
Mind blowing, right?

104
00:07:13,120 --> 00:07:18,350
Behind the scenes, there is a library that
takes this log of Matrix and translates

105
00:07:18,350 --> 00:07:20,560
it to low key and Prometheus clients.

106
00:07:21,365 --> 00:07:25,965
But also without a proper infrastructure
in your company, there are super

107
00:07:25,965 --> 00:07:29,435
friendly client packages that will
make your production ready in no time.

108
00:07:30,265 --> 00:07:33,925
Prometheus, for example, has
client libraries in almost any

109
00:07:33,935 --> 00:07:35,575
programming language that exists.

110
00:07:38,345 --> 00:07:41,655
So now that we've got a metric
set up, let's visualize the data.

111
00:07:44,175 --> 00:07:46,087
That's how it looks in the most basic way.

112
00:07:46,087 --> 00:07:51,222
What you see here is a time series that
shows the value of the metric per minute.

113
00:07:51,222 --> 00:07:51,524
But

114
00:07:53,865 --> 00:07:57,405
Grafana offers so many
visualizations and unitypes.

115
00:07:58,325 --> 00:08:02,385
Feel free to mix and match till you find
the right ones for your specific step.

116
00:08:04,085 --> 00:08:08,235
Now, I know it looks a bit intimidating,
all these graphs, but in a few

117
00:08:08,235 --> 00:08:12,065
minutes, we'll dive into the demo
and you'll see how easy that is.

118
00:08:13,925 --> 00:08:18,295
Okay, so up until now, we created
a dashboard that is measuring

119
00:08:18,315 --> 00:08:20,075
KPIs in our business funnel.

120
00:08:21,980 --> 00:08:25,360
Before we jump into the demo, I
want to share with you some other

121
00:08:25,440 --> 00:08:28,790
tips to light things up, and I
will do it by a real example.

122
00:08:30,600 --> 00:08:35,500
In the Wix delivery system, we serve
as a platform, so we call delivery

123
00:08:35,500 --> 00:08:41,230
carriers like USPS, for example, to get
real time delivery options and costs.

124
00:08:42,595 --> 00:08:46,605
Now, if you remember earlier, I said
that the Wix e commerce platform

125
00:08:46,605 --> 00:08:48,875
main KPI is checkout conversion.

126
00:08:49,665 --> 00:08:55,335
But within checkout, there is a delivery
step where buyers choose how they want

127
00:08:55,335 --> 00:08:58,075
the product to be shipped to their house.

128
00:08:59,075 --> 00:09:02,535
Now having delivery options is
crucial to completing checkout.

129
00:09:02,935 --> 00:09:06,945
So we must monitor that USPS
returns good options to the buyers.

130
00:09:07,935 --> 00:09:09,545
So we need to let up this flow.

131
00:09:09,635 --> 00:09:11,025
We need to add metrics.

132
00:09:11,655 --> 00:09:14,955
But when we did that, we
got a very blurry picture.

133
00:09:15,685 --> 00:09:20,855
Because we saw success, but we don't
know which delivery carrier succeeded.

134
00:09:21,215 --> 00:09:24,865
We saw a failure, and we don't
know which one failed and why.

135
00:09:27,195 --> 00:09:28,905
And that's where labels come in hand.

136
00:09:29,645 --> 00:09:33,915
Once we added the identifier of
the carrier as a label, we got in

137
00:09:33,915 --> 00:09:36,745
seconds, dozens of flows monitored.

138
00:09:37,470 --> 00:09:39,350
One per delivery carrier.

139
00:09:39,790 --> 00:09:44,800
What down below is identifiers
internally to different delivery

140
00:09:44,800 --> 00:09:47,870
carriers like USPS and pickup locations.

141
00:09:50,290 --> 00:09:51,730
And that's the power of labels.

142
00:09:52,260 --> 00:09:57,110
They allow you to expose multiple metrics
from a single one with different labels.

143
00:09:58,160 --> 00:10:01,960
And all I need to do is to add
the by and the label name at

144
00:10:01,970 --> 00:10:03,670
the end of the Grafana query.

145
00:10:04,950 --> 00:10:08,790
Labels are super useful when it
comes to an open platform because

146
00:10:09,470 --> 00:10:14,050
every site on Wix can have different
delivery carriers installed.

147
00:10:14,910 --> 00:10:17,480
And I need to be open and flexible.

148
00:10:18,410 --> 00:10:21,920
But at the same time, this
is a crucial business flow.

149
00:10:22,160 --> 00:10:26,690
So I must be monitored and
labels allow me to do just that.

150
00:10:29,935 --> 00:10:33,185
So I guess I convinced you that
labels are great, but with great

151
00:10:33,185 --> 00:10:35,045
power comes great responsibility.

152
00:10:35,770 --> 00:10:39,190
Labels can make your service blow up.

153
00:10:40,270 --> 00:10:44,270
Every new value you pass to a label
actually generates a new metric.

154
00:10:44,940 --> 00:10:48,380
And the more metrics your
service exposes, the harder it

155
00:10:48,380 --> 00:10:50,370
works on just being monitored.

156
00:10:51,310 --> 00:10:55,300
So you need to make sure you control
the values of the labels you're passing.

157
00:10:55,780 --> 00:10:59,340
Because if you incidentally
pass an infinite label, your

158
00:10:59,340 --> 00:11:03,680
service will exponentially
expose more and more metrics.

159
00:11:05,070 --> 00:11:09,490
And at a certain point in time, it
will work too hard and it will just

160
00:11:09,730 --> 00:11:11,780
stop being monitored completely.

161
00:11:12,740 --> 00:11:18,040
And later on, it will stop working
completely, which is crazy.

162
00:11:19,180 --> 00:11:21,860
So we want to keep our microservices safe.

163
00:11:22,385 --> 00:11:28,525
We want to control the metrics we're
exposing, and if you can see above, Wix

164
00:11:28,935 --> 00:11:36,455
actually exposes a monitoring alert on the
number of metrics we use for monitoring,

165
00:11:37,375 --> 00:11:42,825
which is a monitoring cannibalism, if
you ask me, but it's for this very reason

166
00:11:43,265 --> 00:11:45,495
we want to safeguard our microservices.

167
00:11:46,670 --> 00:11:49,370
But at the same time to
monitor them properly.

168
00:11:50,170 --> 00:11:50,730
Okay.

169
00:11:50,730 --> 00:11:51,920
It's time for a demo.

170
00:11:52,330 --> 00:11:55,460
We're going to dive into the system
I've been working on in the past

171
00:11:55,460 --> 00:11:57,330
year, the Wix delivery system.

172
00:11:58,010 --> 00:12:02,380
Our goal is to allow stores to offer
diverse delivery options for each of

173
00:12:02,380 --> 00:12:06,500
their products so that every buyer will
find the right one for their needs.

174
00:12:07,440 --> 00:12:09,810
And I'm going to walk you
through its main business flow.

175
00:12:12,860 --> 00:12:17,189
The first step is where a buyer opens the
checkout page and wants to buy a product

176
00:12:17,240 --> 00:12:18,650
that will be delivered to his house.

177
00:12:20,060 --> 00:12:24,480
The next thing we want to know is
how many options the store offers.

178
00:12:24,990 --> 00:12:28,880
Do they offer pickup, local
delivery, maybe USPS shipments?

179
00:12:29,670 --> 00:12:33,960
We want to see how diverse the delivery
carriers that operate in the store.

180
00:12:34,550 --> 00:12:37,940
Because the more diverse they are,
the higher the chance the buyer

181
00:12:37,940 --> 00:12:39,510
will find one that suits him.

182
00:12:40,740 --> 00:12:46,730
The next thing we do is actually call
these delivery carriers through API and

183
00:12:46,730 --> 00:12:48,620
get from them the options and the costs.

184
00:12:49,860 --> 00:12:53,480
So we want to see that they
display good options at checkout

185
00:12:53,600 --> 00:12:54,770
and that they don't fail.

186
00:12:55,790 --> 00:12:58,530
And finally, we want to see them click.

187
00:12:58,980 --> 00:13:02,280
We want to see buyers completing
the delivery step at checkout

188
00:13:02,480 --> 00:13:03,670
and continuing to payment.

189
00:13:05,260 --> 00:13:08,020
So what we're going to do is
we're going to create four

190
00:13:08,020 --> 00:13:10,080
steps and four visualizations.

191
00:13:11,695 --> 00:13:15,465
In Grafana, but before we do it,
there are some things we need to know.

192
00:13:17,635 --> 00:13:22,464
What we're actually going to do is we're
going to query on top of Prometheus DB.

193
00:13:23,045 --> 00:13:26,865
And Prometheus offers some
functions and some special syntax.

194
00:13:27,454 --> 00:13:33,235
So what we're going to use is we're
going to use sum to sum the metric values

195
00:13:33,265 --> 00:13:35,565
across different pods in a production.

196
00:13:36,200 --> 00:13:41,090
Because the microservice and Twix
is deployed on multiple pods and

197
00:13:41,100 --> 00:13:42,970
all of them expose the same metric.

198
00:13:43,820 --> 00:13:47,440
But for our use case, for business
driven monitoring, we don't

199
00:13:47,440 --> 00:13:49,420
actually care about a single pod.

200
00:13:49,990 --> 00:13:51,560
We care about the business flow.

201
00:13:52,250 --> 00:13:54,400
So we want to monitor them all together.

202
00:13:55,455 --> 00:14:00,535
The next thing we'll use is M1 rate,
which is the one minute average

203
00:14:00,545 --> 00:14:02,075
of the metrics we're getting.

204
00:14:03,795 --> 00:14:10,065
This average will help us see graphs more
smoother and will enrich our perspective.

205
00:14:11,185 --> 00:14:14,715
Okay, the next thing we'll use
is the Wix internal labels.

206
00:14:15,455 --> 00:14:18,095
We'll use two of them, service and method.

207
00:14:19,075 --> 00:14:24,564
Service is the microservice that exposes
this metric, and method is the specific

208
00:14:24,575 --> 00:14:26,355
endpoint that exposes this metric.

209
00:14:27,935 --> 00:14:29,525
Alright, I guess we're ready.

210
00:14:30,035 --> 00:14:31,265
Let's dive into the demo.

211
00:14:32,975 --> 00:14:36,944
Alright, so we're starting from
a blank page, an empty dashboard.

212
00:14:37,620 --> 00:14:39,670
And we'll create our first visualization.

213
00:14:42,440 --> 00:14:48,630
We're going to use Prometheus as a data
source, and we're going to do the first

214
00:14:48,630 --> 00:14:53,650
visualization, which is the top of the
funnel where a buyer creates checkout and

215
00:14:53,660 --> 00:15:01,720
wants delivery, and we'll measure it by
the calls to the delivery system entry

216
00:15:01,720 --> 00:15:06,990
point, which every time a buyer creates
a checkout and wants something delivered.

217
00:15:07,510 --> 00:15:09,430
It triggers a call to this endpoint.

218
00:15:10,020 --> 00:15:15,830
So the traffic will signify the
amount of buyers that want delivery.

219
00:15:17,990 --> 00:15:18,270
Okay.

220
00:15:18,270 --> 00:15:27,700
So let's start, we'll do service, which is
the microservice that we're working on and

221
00:15:30,600 --> 00:15:35,930
this microservice is called delivery
rates and what we're going to do

222
00:15:35,950 --> 00:15:37,640
is we're going to use the method.

223
00:15:38,290 --> 00:15:41,830
Which is the entry point to
the entire delivery system.

224
00:15:43,200 --> 00:15:45,020
It is called get delivery options.

225
00:15:46,570 --> 00:15:54,940
And now if I run just that, you can see,
I got a lot of pods that are sending the

226
00:15:54,940 --> 00:15:59,700
same metric, but I don't actually care
about different pods in my production.

227
00:15:59,700 --> 00:16:02,380
I want to see the entire
microservice as a whole.

228
00:16:02,790 --> 00:16:05,820
So I'll use the M1 rate we
talked about and the sum,

229
00:16:06,340 --> 00:16:08,930
and now I'm seeing a clear graph.

230
00:16:10,050 --> 00:16:15,735
Side note on that, don't mind the
numbers because we're using test data.

231
00:16:16,285 --> 00:16:21,560
On the left hand side, there is a
number of calls and It's a time series.

232
00:16:21,950 --> 00:16:25,470
So you see it throughout
the time, six hours.

233
00:16:26,030 --> 00:16:29,890
So the next step is the
delivery carrier diversity.

234
00:16:31,810 --> 00:16:37,880
We want to measure how many carriers
are available for each request we get.

235
00:16:39,200 --> 00:16:42,830
So we're monitoring the same microservice.

236
00:16:44,265 --> 00:16:46,825
And we'll use now a custom metric.

237
00:16:47,975 --> 00:16:49,065
I defined my code.

238
00:16:49,925 --> 00:16:52,485
It is called active delivery
carriers for requests.

239
00:16:54,365 --> 00:16:59,815
And in this metric, I actually calculate
how many delivery carriers are active

240
00:17:00,235 --> 00:17:03,175
pair requests that I get from checkout.

241
00:17:04,974 --> 00:17:08,705
And again, I'll use the
M1 rate and the sum.

242
00:17:09,265 --> 00:17:12,795
But if you think about it, I don't
actually care about the trend here.

243
00:17:12,885 --> 00:17:14,205
I care about the value.

244
00:17:14,845 --> 00:17:18,805
How many active delivery
carriers do I get per request?

245
00:17:19,805 --> 00:17:23,265
So I'm going to switch from
a time series to stats.

246
00:17:24,535 --> 00:17:30,465
And here I can decide how this value will
be calculated on the right hand side.

247
00:17:30,465 --> 00:17:36,105
There is calculation and currently
the default is the last value,

248
00:17:37,455 --> 00:17:38,795
but I don't want the last value.

249
00:17:38,795 --> 00:17:39,865
I want the average.

250
00:17:40,790 --> 00:17:42,040
Across this time frame.

251
00:17:43,040 --> 00:17:44,860
So we'll use mean instead.

252
00:17:53,070 --> 00:17:59,170
The next step, we're going to
check how many delivery carriers

253
00:17:59,650 --> 00:18:01,420
display options at checkout.

254
00:18:02,710 --> 00:18:09,290
And the way for us to measure it is to
take the API calls we do per carrier and

255
00:18:09,330 --> 00:18:12,177
to check how many successful there were.

256
00:18:12,177 --> 00:18:14,264
So we're monitoring the same microservice.

257
00:18:17,735 --> 00:18:19,725
And we're using the custom metric again,

258
00:18:22,125 --> 00:18:25,745
that is called successful
delivery rate SPI calls.

259
00:18:27,405 --> 00:18:30,975
So we'll do the same thing,
M1 rate, and then sum.

260
00:18:31,485 --> 00:18:36,905
So again, sum is sum across pods,
and M1 rate is one minute average.

261
00:18:37,485 --> 00:18:42,785
But if you remember, when I talked
about labels, I talked about

262
00:18:42,815 --> 00:18:45,089
exactly these kinds of graphs.

263
00:18:45,690 --> 00:18:48,260
Because now I get a blurry picture.

264
00:18:48,900 --> 00:18:52,580
I don't know which delivery
carrier displayed at checkout.

265
00:18:53,790 --> 00:18:56,550
So I want to break it down by carrier.

266
00:18:56,550 --> 00:19:03,550
So I'll add the label by, and carrier
is my label that I wrote in my code.

267
00:19:05,610 --> 00:19:09,840
And now I get multiple graphs,
one per delivery carrier.

268
00:19:09,850 --> 00:19:17,940
These IDs you see below are identifiers
internally in our system to different

269
00:19:17,950 --> 00:19:20,180
carriers, for example, to USPS.

270
00:19:20,900 --> 00:19:23,180
Or to pick up locations, etc.

271
00:19:26,460 --> 00:19:26,940
Cool.

272
00:19:27,220 --> 00:19:31,540
Now, let's do the same thing for
failed carriers, which I think

273
00:19:31,550 --> 00:19:37,520
personally is more interesting because
successes are nice, but if I see a

274
00:19:37,520 --> 00:19:39,500
failure, I can do something about it.

275
00:19:40,000 --> 00:19:50,904
Okay, so we'll change the tile to
Delivery carrier failed to display,

276
00:19:55,985 --> 00:19:59,545
display options on checkout.

277
00:20:00,245 --> 00:20:04,415
And now all we need to do is
to change the metric, because

278
00:20:04,415 --> 00:20:05,845
I have the same label there.

279
00:20:07,615 --> 00:20:11,755
So we'll, oh sorry about
that, something went wrong.

280
00:20:12,975 --> 00:20:19,215
Okay, again, failed, false, nice.

281
00:20:19,815 --> 00:20:23,225
And now I get the same
graph, just for failures.

282
00:20:23,325 --> 00:20:29,175
And as you can see There is a certain
app that fails pretty frequently,

283
00:20:29,895 --> 00:20:31,705
and that's something I can act on.

284
00:20:32,155 --> 00:20:38,285
I can talk to this app, I can debug the
issues, which is super powerful because

285
00:20:38,285 --> 00:20:40,285
it actually affects the bottom line.

286
00:20:42,695 --> 00:20:49,905
Alright, the last bit, the
actual delivery step conversion.

287
00:20:50,475 --> 00:20:55,365
So for this one, I'm not going to
use regular from exist metrics.

288
00:20:56,405 --> 00:21:00,075
I'll use ones that are used
by our business analysts.

289
00:21:01,100 --> 00:21:07,750
So what you're seeing here, it's a bit
different syntax, but it's the same thing.

290
00:21:08,390 --> 00:21:14,620
So I have that delivery method
completion in checkout and I divided

291
00:21:14,630 --> 00:21:18,419
by the contact details, which is
the previous step at checkout.

292
00:21:19,890 --> 00:21:27,179
So it's a good approximation of
how many buyers actually go through

293
00:21:27,380 --> 00:21:31,250
filling up the details and then
continue to delivery and find.

294
00:21:32,045 --> 00:21:35,015
A good option and then
continue to payment.

295
00:21:37,335 --> 00:21:39,625
All right, we did it.

296
00:21:40,685 --> 00:21:44,855
It took us a few minutes and we
actually visualize the entire business

297
00:21:44,875 --> 00:21:46,404
funnel of the delivery system.

298
00:21:46,895 --> 00:21:51,195
I hope you're excited because
I am now let's continue.

299
00:21:51,205 --> 00:21:54,385
Now that we've got a kick ass dashboard,
there are some things that can make

300
00:21:54,385 --> 00:21:56,814
us more alert and attentive to it.

301
00:21:57,095 --> 00:21:59,065
The first one, you got it, right?

302
00:21:59,325 --> 00:22:04,305
Alerts in a week or two, everyone
will forget you built this dashboard.

303
00:22:04,965 --> 00:22:07,035
The most proven way to make it relevant.

304
00:22:07,405 --> 00:22:11,275
is to integrate with your regular
production on call alerts.

305
00:22:12,035 --> 00:22:15,745
Here you can see I added an alert to one
of the graphs we created in the demo.

306
00:22:16,625 --> 00:22:19,345
The alert will be sent to
our on call channel with this

307
00:22:19,355 --> 00:22:21,005
custom message I defined below.

308
00:22:21,865 --> 00:22:25,135
Now remember, our goal in this
talk is to find crucial bugs

309
00:22:25,135 --> 00:22:28,614
that affect users quickly and
solve them with minimal impact.

310
00:22:29,240 --> 00:22:31,430
And alerts, they help us to do just that.

311
00:22:32,280 --> 00:22:36,100
To identify the issue before users
start complaining, troubleshoot

312
00:22:36,140 --> 00:22:38,180
quickly, and find the root cause.

313
00:22:40,160 --> 00:22:44,700
So now that we have actionable alerts,
the most common thing we do, straight

314
00:22:44,700 --> 00:22:47,530
after we jump, is to investigate deeper.

315
00:22:48,400 --> 00:22:53,145
And a great thing you can do with Grafana,
It's to provide an investigation dashboard

316
00:22:53,195 --> 00:22:58,775
to really drill down because you start
from a business issue and now you need

317
00:22:58,845 --> 00:23:00,845
to understand it and quickly resolve.

318
00:23:01,385 --> 00:23:04,695
So if you have a dashboard with
pre made investigation, queries,

319
00:23:04,855 --> 00:23:09,535
filters, and latest logs, it can
make you super quick in finding the

320
00:23:09,535 --> 00:23:12,265
issue and actually solving it faster.

321
00:23:14,095 --> 00:23:18,305
So just to quickly recap,
ownership is a choice.

322
00:23:19,145 --> 00:23:22,615
For me personally, it made
development much more interesting.

323
00:23:23,285 --> 00:23:27,285
Now, if you are ready to ownership,
monitoring is the ultimate tool to

324
00:23:27,285 --> 00:23:31,735
help you get intimate with the product
and lead it in the right direction.

325
00:23:32,935 --> 00:23:36,405
To monitor a business, you should start
out by mapping your business funnels,

326
00:23:37,055 --> 00:23:39,445
then light them up with metrics and logs.

327
00:23:40,295 --> 00:23:43,995
So you'll know every corner of the
flow and you can quickly troubleshoot

328
00:23:44,145 --> 00:23:47,015
every issue then add alerts.

329
00:23:47,375 --> 00:23:51,035
So you'll know in time that an
issue arises, and that's how

330
00:23:51,045 --> 00:23:54,435
you become a true owner of the
product and not just a developer.

331
00:23:55,280 --> 00:23:56,510
Thank you so much for listening.

332
00:23:56,510 --> 00:23:59,280
Feel free to reach out and enjoy
the rest of your conference.

333
00:23:59,620 --> 00:24:00,350
Bye.

