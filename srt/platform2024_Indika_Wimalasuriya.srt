1
00:00:14,360 --> 00:00:15,110
Hi everyone,

2
00:00:17,170 --> 00:00:23,170
a recent CatPoint survey identified
that 66 percent of organizations use

3
00:00:23,170 --> 00:00:26,509
2 5 monitoring hubs or build tools.

4
00:00:27,880 --> 00:00:33,200
And it also identified that 24 percent
of organizations have breached a

5
00:00:33,220 --> 00:00:38,355
contractual service level agreement
obligation during last 12 months.

6
00:00:39,395 --> 00:00:42,435
Those are two very important numbers.

7
00:00:43,654 --> 00:00:50,935
Having more than two to three or more
than two observable dual is a little

8
00:00:50,935 --> 00:01:00,135
problematic because you will struggle to
identify a unified, a single truth state.

9
00:01:00,920 --> 00:01:05,889
And the 24 percent number about
contractual failures are alarming as well.

10
00:01:05,890 --> 00:01:11,690
What it shows is even with multiple
tools, the organizations are struggling.

11
00:01:11,690 --> 00:01:14,799
My name is Indic Vimalasuriyath.

12
00:01:16,960 --> 00:01:19,249
Welcome to Platform Engineering 2024.

13
00:01:20,380 --> 00:01:23,940
My presentation is based out
of AWS observability as code.

14
00:01:24,960 --> 00:01:30,420
And I'll focus on leveraging Datadog to
enable advanced platform engineering.

15
00:01:31,149 --> 00:01:36,529
As part of my presentation, I will
provide you a quick overview of challenges

16
00:01:36,679 --> 00:01:41,769
faced in the modern day observability
platforms due to distributed nature.

17
00:01:42,619 --> 00:01:46,699
And we will quickly discuss about role
of observability in platform engineering.

18
00:01:47,399 --> 00:01:52,460
And we will touch about Datadog,
which I will be using to

19
00:01:52,460 --> 00:01:54,149
enable observability as code.

20
00:01:54,720 --> 00:01:57,660
in AWS based infrastructures.

21
00:01:58,539 --> 00:02:04,530
And we will look at how we can enable
or implement observability as solutions,

22
00:02:04,650 --> 00:02:06,600
real world implementation details.

23
00:02:07,379 --> 00:02:10,579
And we will wrap it up with
some of the best practices and

24
00:02:10,580 --> 00:02:13,167
pitfalls you may need to avoid.

25
00:02:13,167 --> 00:02:15,323
So quick intro about myself.

26
00:02:15,323 --> 00:02:18,839
I, my name is Sindik Vimalsuri.

27
00:02:18,890 --> 00:02:20,269
I'm based out of Colombo.

28
00:02:20,320 --> 00:02:22,230
I live with my daughter and wife.

29
00:02:23,274 --> 00:02:27,825
I'm coming from a very strong
reliability engineering and

30
00:02:27,825 --> 00:02:29,445
solution architect background.

31
00:02:29,974 --> 00:02:33,534
My specialties are site reliability
engineering, observability,

32
00:02:33,535 --> 00:02:36,504
AIOps, and generative AI.

33
00:02:37,365 --> 00:02:39,094
I'm currently employed at Virtus.

34
00:02:39,094 --> 00:02:39,204
R.

35
00:02:39,284 --> 00:02:42,904
I oversee technical delivery
and capability development.

36
00:02:43,685 --> 00:02:48,604
I'm a very passionate technical trainer
and an energetic technical blogger.

37
00:02:49,690 --> 00:02:54,610
I am, AWS Community Builder,
part of Cloud Operations and also

38
00:02:54,790 --> 00:02:56,610
Ambassador at DevOps Institute.

39
00:02:57,319 --> 00:03:04,499
So to start, the distributed systems
and modern day systems are evolving

40
00:03:04,499 --> 00:03:07,890
fast and with that it's also

41
00:03:10,330 --> 00:03:13,440
increasing the complexities
we need to manage.

42
00:03:13,440 --> 00:03:18,250
The traditional monolith systems have
already moved into microservices.

43
00:03:18,940 --> 00:03:24,650
And on from my data centers, which
we use to host our applications,

44
00:03:24,970 --> 00:03:28,940
we now move into cloud and some
instance we move it from cloud to

45
00:03:28,940 --> 00:03:30,689
the serverless architecture as well.

46
00:03:31,610 --> 00:03:35,569
So what this has done is there's
an expansion of data sources,

47
00:03:36,070 --> 00:03:40,620
surging data volume and exponential
rising failure scenarios.

48
00:03:41,279 --> 00:03:48,400
So while it's good and while it add
lot of value in modern day systems.

49
00:03:49,790 --> 00:03:56,820
it has bringing in certain level of,
increased failure scenarios as well.

50
00:03:57,069 --> 00:04:05,169
So which, which resulted in difficulties
in managing these environments and also it

51
00:04:05,190 --> 00:04:07,579
has increased the role of observability.

52
00:04:09,970 --> 00:04:16,250
So the traditional monitoring, which was
mainly rule based, predefined approach of

53
00:04:16,380 --> 00:04:18,760
looking at systems are no longer enough.

54
00:04:19,069 --> 00:04:22,530
We have moved into observability,
and that's mainly due to

55
00:04:22,809 --> 00:04:28,270
distributed systems complexities,
dynamic nature, and elasticity.

56
00:04:28,799 --> 00:04:31,599
And most of our systems
are now container based.

57
00:04:32,140 --> 00:04:36,829
We have CI, CD deployments,
integrations, we are connecting

58
00:04:36,829 --> 00:04:43,050
to API gateways, and there's a
increased, in cloud service providers.

59
00:04:43,340 --> 00:04:46,719
Some of the systems are in poly
cloud, multi cloud, leveraging

60
00:04:46,719 --> 00:04:48,050
multi welder solutions.

61
00:04:48,699 --> 00:04:53,510
And our systems have scalability
challenges, which sometimes we are using

62
00:04:53,520 --> 00:04:59,275
these cloud service providers solutions
to, resolute, to, rectify and this require

63
00:04:59,535 --> 00:05:04,934
observability into this as scalability
triggers and we would like to detect

64
00:05:04,944 --> 00:05:09,585
things much faster, resolve things much
faster and we want to have end to end

65
00:05:09,595 --> 00:05:12,595
visibility of our, the user journeys.

66
00:05:13,005 --> 00:05:16,935
So these are some of the key things
which is, increasing or which

67
00:05:17,705 --> 00:05:18,885
result, the need for observability.

68
00:05:21,515 --> 00:05:25,065
So if I quickly touch upon
observability about logs are

69
00:05:25,095 --> 00:05:27,235
the, what is your code is doing.

70
00:05:27,335 --> 00:05:31,045
We typically use logs to, for
our root cause understanding.

71
00:05:31,455 --> 00:05:32,515
And we have metrics.

72
00:05:32,545 --> 00:05:37,045
Metrics are nothing but numbers, a point
in time performance of your application.

73
00:05:37,575 --> 00:05:41,705
And metrics are generally used for
alerting because it's a number,

74
00:05:41,745 --> 00:05:46,025
it's a good way of allowing
us to generate our alerts.

75
00:05:46,045 --> 00:05:46,160
Thank you very much.

76
00:05:46,630 --> 00:05:47,680
And we have tracing.

77
00:05:47,940 --> 00:05:51,400
Tracing is what is your code
is doing at a snap point.

78
00:05:51,430 --> 00:05:56,420
You can see what that code is doing,
method level, the time taken, and

79
00:05:56,460 --> 00:06:01,870
even you can trace a request from a
front end request to middleware to

80
00:06:01,870 --> 00:06:03,770
the backend, which is database calls.

81
00:06:03,980 --> 00:06:05,370
So tracing is very important.

82
00:06:05,590 --> 00:06:11,660
It's allowing us to understand what to
time taken in our code, and it's allowing

83
00:06:11,710 --> 00:06:13,860
us to see what is our code is doing.

84
00:06:14,940 --> 00:06:18,960
And on top of that, we are building
alarms, which are our monitors.

85
00:06:19,220 --> 00:06:21,210
We are developing a lot of dashboards.

86
00:06:21,490 --> 00:06:23,410
We are coming up with synthetic monitors.

87
00:06:23,740 --> 00:06:27,170
We are looking at real user monitoring,
which is trying to understand what

88
00:06:27,170 --> 00:06:29,290
is your actual end users are doing.

89
00:06:29,840 --> 00:06:33,690
We are looking at the infrastructure,
we are looking at the network, we are

90
00:06:33,730 --> 00:06:38,180
looking at the security aspects of
our ecosystem, and obviously we are

91
00:06:38,190 --> 00:06:43,070
looking at how we can optimize cost,
the infrastructure cost, AWS or the

92
00:06:43,070 --> 00:06:45,510
cloud provider and other cost as well.

93
00:06:45,850 --> 00:06:48,790
So pretty much these are the key
fundamentals when it comes to

94
00:06:49,270 --> 00:06:51,150
observability which you want to achieve.

95
00:06:53,090 --> 00:06:57,950
So when it comes to platform engineering,
I would like to take a one example.

96
00:06:57,960 --> 00:07:02,010
Let's say you have one organization
which is having around three

97
00:07:02,780 --> 00:07:06,900
departments or line of businesses
and each department have multiple

98
00:07:07,850 --> 00:07:10,040
applications or engagements running.

99
00:07:11,005 --> 00:07:14,535
And sometimes what can happen is that
these engagements or the application

100
00:07:14,565 --> 00:07:19,745
teams may find their own comfortable
observability tool based solutions and

101
00:07:19,745 --> 00:07:24,895
observability tools, alerting tools,
log management tools, security aspects.

102
00:07:25,095 --> 00:07:29,250
So they will leveraging
things they prefer.

103
00:07:29,650 --> 00:07:33,130
So what this happened is, over a
period of time, we are losing the

104
00:07:33,130 --> 00:07:35,330
unification, the unified approach.

105
00:07:35,600 --> 00:07:37,850
It's very difficult to
enable consistencies.

106
00:07:39,820 --> 00:07:43,650
It's very difficult to build
consistencies across these systems.

107
00:07:43,970 --> 00:07:47,240
And it difficult to, whenever
new applications and new

108
00:07:47,240 --> 00:07:48,360
services are coming in.

109
00:07:48,690 --> 00:07:50,970
We are having trouble and challenges.

110
00:07:51,440 --> 00:07:55,940
So as part of platform engineering, what
we are trying to do into this specific

111
00:07:55,970 --> 00:08:01,110
area of observability is we want to build
a unified observability strategy, which

112
00:08:01,110 --> 00:08:06,040
is about, which is to make observability
consistent across teams and ensure that

113
00:08:06,050 --> 00:08:07,770
there's a centralized observability.

114
00:08:08,295 --> 00:08:11,965
And we want to build efficient
troubleshooting and incident response

115
00:08:11,975 --> 00:08:17,045
framework, leveraging cross team
collaborations, which will derive fast

116
00:08:17,235 --> 00:08:19,515
and efficient root cause analysis.

117
00:08:20,015 --> 00:08:24,435
And we also want to ensure we have
scalability and reliability, leveraging

118
00:08:24,435 --> 00:08:28,325
proactive monitoring, predictive
capabilities, and other advanced

119
00:08:28,325 --> 00:08:30,675
features, and things like capacity plan.

120
00:08:31,310 --> 00:08:35,600
And we will also develop, enhance
developer experience because developers

121
00:08:35,600 --> 00:08:40,310
are important and they had to have the
end to end visibility observability

122
00:08:40,310 --> 00:08:41,930
into our production systems.

123
00:08:42,250 --> 00:08:46,560
So this allows us to, there's
a need of us to build like self

124
00:08:46,560 --> 00:08:48,170
service observability solution.

125
00:08:48,450 --> 00:08:51,540
Access and dashboards is
specific to developers as well.

126
00:08:51,540 --> 00:08:52,730
And we will.

127
00:08:53,040 --> 00:08:57,900
Figuring, enable some services
related to security and compliance

128
00:08:58,180 --> 00:09:01,640
and cost official and cost
tracking and those things as well.

129
00:09:01,910 --> 00:09:04,730
So those are the key aspects or
the key part of, observability

130
00:09:05,010 --> 00:09:09,990
in platform engineering, and that
will enable us to get the true.

131
00:09:10,290 --> 00:09:13,500
value of platform engineering
in observability area.

132
00:09:16,350 --> 00:09:20,760
And let me talk about Datadog because
here we are trying to use Datadog

133
00:09:21,880 --> 00:09:28,150
on top of that AWS and trying to
see what And what, capabilities of,

134
00:09:28,240 --> 00:09:32,100
observability and, observability as
code solutions which we can enable.

135
00:09:32,880 --> 00:09:36,010
So here, if you look at it,
we have multiple data sources,

136
00:09:36,150 --> 00:09:40,300
like Datadog supports around
750 plus, source integrations.

137
00:09:40,690 --> 00:09:46,350
It supports logs, traces, metrics,
and metadata sessions as well.

138
00:09:46,700 --> 00:09:50,410
So it also provides a lot of dashboards.

139
00:09:50,775 --> 00:09:56,295
alerts, collaboration, mobile,
monitoring workflows, what dog, which

140
00:09:56,295 --> 00:10:00,965
is the, it's on AI platform and also
integration into open telemetry.

141
00:10:01,545 --> 00:10:06,165
So some of the use cases, observable
use cases, data dog is providing our

142
00:10:06,165 --> 00:10:09,955
infrastructure, monitoring applications,
performance, monitoring, unified,

143
00:10:11,225 --> 00:10:13,255
universal monitoring, log management.

144
00:10:14,080 --> 00:10:18,280
The continuous integration visibility,
continuous profiling, real user

145
00:10:18,280 --> 00:10:21,840
monitoring, network monitoring,
synthetic monitoring, cloud

146
00:10:21,840 --> 00:10:26,660
security, application security,
observability pipeline, and many more.

147
00:10:27,150 --> 00:10:34,220
So all of this allowed our, the key
partners or the teams like development

148
00:10:34,230 --> 00:10:38,835
teams, IT operations teams, Security
team, support team and business to

149
00:10:38,835 --> 00:10:41,955
have a full view of our ecosystem.

150
00:10:44,525 --> 00:10:49,255
So when you are building a AWS
base, observability driven platform

151
00:10:49,255 --> 00:10:53,175
engineering solution, there are a
few things we need to be, focused.

152
00:10:53,505 --> 00:10:56,295
So one is our centralized
Datadog integration.

153
00:10:56,565 --> 00:10:58,305
So if it is the sim standard.

154
00:10:59,130 --> 00:10:59,900
workloads.

155
00:11:00,170 --> 00:11:04,350
We might have to integrate, example
for EC2s, the agents as well.

156
00:11:04,760 --> 00:11:08,140
And if it is containers, then we'll
have to do the integration as well.

157
00:11:08,550 --> 00:11:13,550
If it is, less like AWS Lambdas, we
might have to intercept the Lambda

158
00:11:13,750 --> 00:11:19,010
the libraries and then enable this
AWS integration, especially for ACM.

159
00:11:19,630 --> 00:11:24,280
And then with this, what we are trying
to do is enable, the key, aspects or

160
00:11:24,280 --> 00:11:28,290
the elements of observability, which
is about enabling the standard matrix

161
00:11:28,600 --> 00:11:33,030
and the dashboards and, locks, which
we want to make sure it's consistent.

162
00:11:33,350 --> 00:11:37,290
And also the traces, the spans and
those things so that we can troubleshoot

163
00:11:37,290 --> 00:11:39,140
and identify what's happening at.

164
00:11:39,490 --> 00:11:42,410
microservices hosted in
AWS or in the containers.

165
00:11:42,950 --> 00:11:44,750
Or even AWS Lambda as well.

166
00:11:45,160 --> 00:11:50,580
So on top of that, Datadog allows us to
develop alerting and incident workloads.

167
00:11:50,970 --> 00:11:54,640
And also there are other services
like looking at the performance and

168
00:11:54,640 --> 00:11:59,970
scalability, resource management, cost
management, and other CI, CD integrations.

169
00:12:00,325 --> 00:12:04,985
And looking at things like automated
setup and looking at the governance,

170
00:12:04,985 --> 00:12:09,265
how we can build different access
controls and how we can enable

171
00:12:09,575 --> 00:12:14,665
compliance control and other developer
related services such as developer

172
00:12:14,665 --> 00:12:17,344
access, documentations and trainings.

173
00:12:17,345 --> 00:12:22,165
So those will allow us to develop a
comprehensive observability platform

174
00:12:22,165 --> 00:12:24,675
engineering framework for AWS.

175
00:12:25,365 --> 00:12:26,275
so moving on.

176
00:12:28,015 --> 00:12:32,195
So when you look at observability
as code, so there are key elements.

177
00:12:32,265 --> 00:12:37,135
One is, treat your observability
configuration as codes, which

178
00:12:37,145 --> 00:12:42,235
is about agent integrations or
integration with Datadog in AWS.

179
00:12:42,620 --> 00:12:49,430
Looking at metrics, logs and traces
and how you can set up, them with AWS

180
00:12:49,460 --> 00:12:55,760
based ecosystem and how we can leverage
Datadog to achieve those things.

181
00:12:56,910 --> 00:12:59,660
And next one is about
versioning and management.

182
00:13:00,010 --> 00:13:01,820
We want to do versioning control.

183
00:13:01,840 --> 00:13:06,880
We can reuse the components like Git.

184
00:13:07,240 --> 00:13:11,000
So which is allowing us to do version
control and tracking our, changes

185
00:13:11,020 --> 00:13:13,450
and increased the collaborations.

186
00:13:14,150 --> 00:13:19,840
Of course, this, the observability as code
solutions, we will have to enable with a

187
00:13:19,850 --> 00:13:22,940
CI, CD related deployments, automations.

188
00:13:23,240 --> 00:13:27,370
So that way we can, while the
development teams are developing these.

189
00:13:27,870 --> 00:13:28,530
solutions.

190
00:13:28,860 --> 00:13:33,410
They can push all these, the
observability as code solutions into

191
00:13:33,750 --> 00:13:36,140
a multiple pre live environments.

192
00:13:36,460 --> 00:13:41,150
From there, we can start deploying
and until we deployed into production.

193
00:13:42,200 --> 00:13:46,620
So this we can enable consistency
and standardization, implement

194
00:13:46,710 --> 00:13:50,650
standardized templates, come up with
some quality gates, and we can come

195
00:13:50,650 --> 00:13:55,110
up with modules for observability
configuration, and apply some consistent

196
00:13:55,120 --> 00:13:57,230
settings across multiple environments.

197
00:13:57,700 --> 00:14:01,070
And this will enable us to do
a comprehensive observability

198
00:14:01,130 --> 00:14:02,280
monitoring and maintenance.

199
00:14:02,850 --> 00:14:07,530
conduct reviews, validations of our
configuration, implementing test

200
00:14:07,530 --> 00:14:12,420
frameworks and, and to ensure that
we have a proper quality gauge as

201
00:14:12,440 --> 00:14:16,020
when we are moving from our pre
life to the production environment.

202
00:14:16,480 --> 00:14:19,830
And also we can have a
standardization in documentation.

203
00:14:20,130 --> 00:14:23,310
And this will allow a lot of
collaborations in multiple teams.

204
00:14:23,720 --> 00:14:29,260
And the whole idea is that we will not
that data doc, but we will develop our

205
00:14:29,340 --> 00:14:31,240
solutions as observability as code.

206
00:14:31,510 --> 00:14:36,040
And this code has, can be moved from
one environment, one environment until.

207
00:14:36,635 --> 00:14:40,655
We move into production and different
teams can contribute this we can do

208
00:14:40,655 --> 00:14:44,995
the version tracking we can enable
Configure the collaboration and

209
00:14:44,995 --> 00:14:46,925
we can have better quality as well

210
00:14:49,215 --> 00:14:53,465
So moving on some of the benefits
of observability as code solution

211
00:14:53,465 --> 00:14:58,050
when you are thinking of aws It
will improve accuracy, there's

212
00:14:58,140 --> 00:15:03,540
enhanced visibility because, you are
working as code and because of that

213
00:15:03,540 --> 00:15:05,460
visibility drives a lot of accuracy.

214
00:15:05,460 --> 00:15:10,520
So it's code, you can do a lot of, a
lot of validations and a lot of, and

215
00:15:10,520 --> 00:15:12,010
even a lot of collaborations as well.

216
00:15:12,690 --> 00:15:16,490
While we enable a lot of corroborations,
we can build a lot of quality gates on

217
00:15:16,500 --> 00:15:19,150
top of our code and it's much faster.

218
00:15:19,380 --> 00:15:22,460
So we can have much
faster turnaround time.

219
00:15:22,900 --> 00:15:25,140
It can be consistent
across the environment.

220
00:15:25,170 --> 00:15:26,530
So that's one of our challenges.

221
00:15:26,860 --> 00:15:31,575
We may lack Observability, when it comes
to the consistency in environments,

222
00:15:31,575 --> 00:15:35,365
example, you may have some sort of,
some degree of observability in your

223
00:15:35,365 --> 00:15:40,425
production environment, but it might not
be, identical in your lower environment.

224
00:15:40,645 --> 00:15:43,275
And what that happens,
developers will have a challenge.

225
00:15:43,605 --> 00:15:48,275
And even there can be misunderstanding,
misinterpretations, and there can

226
00:15:48,275 --> 00:15:52,315
be some challenges in, achieving
what we're trying to achieve.

227
00:15:52,815 --> 00:15:57,445
And obviously observability as code
Promote better collaboration and

228
00:15:57,445 --> 00:16:01,465
it's allow us to do a continuous
improvements in our systems.

229
00:16:02,075 --> 00:16:02,975
So moving on.

230
00:16:04,635 --> 00:16:09,285
with AWS there are a lot of observability
called, tools, which we can use

231
00:16:09,345 --> 00:16:15,105
things like Terraform, Ansible, j
pmi, or AWS code formation as well.

232
00:16:15,375 --> 00:16:19,865
And this systems we are going to
leverage Terraform, which is widely

233
00:16:19,865 --> 00:16:21,605
being used, across the board.

234
00:16:23,145 --> 00:16:26,385
And what we are trying to
achieve is we want to ride entire

235
00:16:26,925 --> 00:16:29,175
observability as code solutions using.

236
00:16:30,140 --> 00:16:32,820
Terraform and then ship push into Datadog.

237
00:16:33,190 --> 00:16:36,190
And what we are trying to achieve
is we want to create things like,

238
00:16:36,500 --> 00:16:38,670
enable the Datadog integration.

239
00:16:38,700 --> 00:16:44,400
So we can completely automate AWS and
Datadog integration using Terraform.

240
00:16:44,960 --> 00:16:49,230
And we want to ship this logs into
AWS based logs into Terraform,

241
00:16:49,270 --> 00:16:53,570
either it's your EC2s, the workloads,
or the container based workloads,

242
00:16:53,570 --> 00:16:55,120
or your serverless framework.

243
00:16:55,350 --> 00:16:58,460
So all of those things
we can ship to Datadog.

244
00:16:58,890 --> 00:17:04,640
And we can streamline that using Terraform
and enabling APM in your containers

245
00:17:04,670 --> 00:17:11,170
or the EC2 based workloads or even
in your serverless based frameworks.

246
00:17:11,480 --> 00:17:14,300
We can leverage observability
as code solutions.

247
00:17:14,770 --> 00:17:19,250
And then we want to build common
metrics and enable common metrics and

248
00:17:19,500 --> 00:17:23,390
develop common dashboards So this is
very important because generally the

249
00:17:23,390 --> 00:17:28,180
developers and the devops teams srs
They will refer some of these standard

250
00:17:28,210 --> 00:17:32,670
dashboards And what we can do is it's
not just these standard dashboards

251
00:17:32,670 --> 00:17:36,820
are available in your production, but
you can enable those in different to

252
00:17:36,830 --> 00:17:38,580
your pre live environments as well.

253
00:17:38,580 --> 00:17:43,310
Example, test and development environment,
test environment into an integration

254
00:17:43,310 --> 00:17:45,380
environments, staging environment.

255
00:17:45,630 --> 00:17:50,050
So this way you can have unification and
developers are able to look at things.

256
00:17:50,320 --> 00:17:54,070
And before they are trying to see
how their code is going to behave

257
00:17:54,070 --> 00:17:57,230
in production, they have the
ability of trying to understand

258
00:17:57,230 --> 00:18:00,870
how things are behaving in the
pre live environments as well.

259
00:18:01,550 --> 00:18:03,040
And then we can automate the.

260
00:18:03,340 --> 00:18:05,940
synthetic monitoring creation,
the synthetic monitors,

261
00:18:05,970 --> 00:18:07,120
this is very important.

262
00:18:07,440 --> 00:18:12,820
This about creating production end user
and mimicking them and what actual end

263
00:18:12,820 --> 00:18:16,580
users are doing so that way we have
more control of trying to see how our

264
00:18:16,580 --> 00:18:21,120
application is behaving and we can of
course generate a lot of alerts on top of

265
00:18:21,160 --> 00:18:25,800
these synthetic monitors or the metrics
or some of these log events as well.

266
00:18:26,825 --> 00:18:30,185
And we can automate the entire
account creation, the access

267
00:18:30,215 --> 00:18:32,565
control in as observable as code.

268
00:18:32,895 --> 00:18:37,595
We can enable the CI CD pipeline
integrations, and in some instances, the

269
00:18:37,595 --> 00:18:40,345
distributed insulating setup as well.

270
00:18:40,425 --> 00:18:44,765
And one of the important aspects when it
comes to site reliability engineering is

271
00:18:44,975 --> 00:18:49,285
define your service level indicators and
define your service level objectives.

272
00:18:49,415 --> 00:18:53,655
DataDog as an observability tool is
providing a very good capability of

273
00:18:53,695 --> 00:18:55,895
defining service level objectives.

274
00:18:55,915 --> 00:19:00,175
You can either create with your good
events divided by total, or you can

275
00:19:00,765 --> 00:19:06,145
create SLOs based on your synthetic
pointers based on to monitor uptime and

276
00:19:06,145 --> 00:19:10,945
things like that, or you can have SLOs
based on different time slices as well.

277
00:19:11,385 --> 00:19:16,215
So all of these options which DataDog is
providing, you can automate, you can write

278
00:19:16,275 --> 00:19:18,715
your, we can get our developers to write.

279
00:19:19,085 --> 00:19:23,915
SLOs and write it using observability
as code solutions and that can

280
00:19:23,915 --> 00:19:27,295
be navigated through multiple
product pre production environments

281
00:19:27,295 --> 00:19:29,145
until it moves into production.

282
00:19:29,345 --> 00:19:33,800
So that way we can enable consistency
across the Service level objectives

283
00:19:33,800 --> 00:19:36,410
from pre live environment to
the production environment.

284
00:19:36,920 --> 00:19:42,270
We are obviously able to use automated
incident management workflows, enable that

285
00:19:42,440 --> 00:19:44,760
using our observability as code solutions.

286
00:19:45,110 --> 00:19:48,090
And finally, our compliance
and governance control as well.

287
00:19:49,100 --> 00:19:54,400
So what we will do is we will look at
some of the cost snippets of how we can

288
00:19:54,410 --> 00:19:57,630
do some of the terraform code snippets.

289
00:19:57,880 --> 00:20:00,740
So that will give you some
idea about these integrations.

290
00:20:03,385 --> 00:20:09,865
So if I take a step back, so if I want
to Define or develop the observability

291
00:20:09,865 --> 00:20:16,365
as a code solution leveraging datadog for
aws So what we will do is the step one

292
00:20:16,545 --> 00:20:21,035
is we have to define our observability
configuration What we'll generally do is

293
00:20:21,055 --> 00:20:25,555
we'll identify and create configuration
files Covering the key observability

294
00:20:25,565 --> 00:20:30,625
components such as metrics logs and
traces dashboards Events and most of

295
00:20:30,625 --> 00:20:34,905
the things I have covered part of the
previous slide and we will look at version

296
00:20:34,905 --> 00:20:41,535
control We can have our the observability
as code our code in git And then we can

297
00:20:41,535 --> 00:20:45,585
manage the versioning, we can enable
collaboration, we can enable branching,

298
00:20:45,865 --> 00:20:47,795
and we can follow merging strategies.

299
00:20:48,005 --> 00:20:53,145
So that way that we can have more
comprehensive control of our observability

300
00:20:53,735 --> 00:20:59,005
And we can build a lot of test solution
as well, the unit testing and other

301
00:20:59,525 --> 00:21:01,605
form of validations such as syntax.

302
00:21:02,085 --> 00:21:04,215
And other validations as well.

303
00:21:04,295 --> 00:21:07,795
And we can have to then the fourth step
is to enable this with the continuous

304
00:21:07,835 --> 00:21:12,535
integration, integrate with the CI
pipelines, enable it automatically

305
00:21:12,535 --> 00:21:17,805
run test on to ensure these things
go through multiple environments

306
00:21:17,835 --> 00:21:19,275
before we move into production.

307
00:21:19,515 --> 00:21:25,165
So we can have multiple quality gates
and part of before CI, you can do

308
00:21:25,175 --> 00:21:27,345
the automated deployments as well.

309
00:21:27,725 --> 00:21:30,345
And then we'll have to build
the monitoring and validation.

310
00:21:30,715 --> 00:21:35,555
Monitor the automated deployments
moving across multiple, instances,

311
00:21:35,675 --> 00:21:37,145
and then validation process.

312
00:21:37,685 --> 00:21:41,885
We can ignore multiple teams who
are owning these pre live anonymous,

313
00:21:41,885 --> 00:21:45,915
like the developers, the testers,
the integrate into end-to-end teams

314
00:21:46,185 --> 00:21:51,085
and into an integration teams and,
even the DevOps and SRA teams.

315
00:21:51,295 --> 00:21:54,425
So they can go through this,
observability as called solutions.

316
00:21:54,425 --> 00:21:58,295
Those outputs in multiple
environments, pre-live environments.

317
00:21:58,575 --> 00:22:00,815
for continuous review and validations.

318
00:22:01,245 --> 00:22:04,675
So this will typically enable your
meters and compliance as well.

319
00:22:06,565 --> 00:22:10,185
So if you look at, because this, we
are trying to focus on Terraform.

320
00:22:10,435 --> 00:22:13,245
So this is a typical
Terraform folder structure.

321
00:22:13,465 --> 00:22:17,515
So you will have your observability
as code, the folder, and then

322
00:22:17,515 --> 00:22:18,475
we'll have the deployments.

323
00:22:18,665 --> 00:22:24,820
You will have main A TF and your providers
for the, which will enable you to, do the

324
00:22:24,820 --> 00:22:26,890
provider configuration with data talks.

325
00:22:27,130 --> 00:22:31,420
You can define your variables and you
can version your Terraform as well.

326
00:22:31,890 --> 00:22:36,600
And then we can have a set of your,
the YAML files, which are looking

327
00:22:36,600 --> 00:22:40,530
at your creating monitors, service
level objectives, dashboards,

328
00:22:40,620 --> 00:22:44,870
creating maintenance windows,
or other integrations other.

329
00:22:45,560 --> 00:22:48,260
the form of automations,
which you want to enable.

330
00:22:50,510 --> 00:22:54,110
So if you look at typically, if you
want to integrate, the data dog, what

331
00:22:54,110 --> 00:22:59,090
we'll do is we'll have to enable data
dog agent running in your workloads,

332
00:22:59,360 --> 00:23:03,610
or, we can do a direct, integration
with our serverless framework as well.

333
00:23:04,220 --> 00:23:06,280
So here we can use data form.

334
00:23:06,575 --> 00:23:08,235
to do this configuration.

335
00:23:08,245 --> 00:23:11,305
So you can see we are using
Datadog, APS and other keys.

336
00:23:11,655 --> 00:23:15,555
So you don't have to actually, what
you can do is we can use AWS secret

337
00:23:15,555 --> 00:23:20,835
manager, and then we can read these
keys part of a reading secret manager

338
00:23:20,835 --> 00:23:24,775
so that we have a better mechanism
of handling secret keys as well.

339
00:23:25,765 --> 00:23:31,125
And we are able to, Some of our
logs in AWS, which is typically

340
00:23:31,125 --> 00:23:35,065
reside in cloud work, and then we
can ship these logs into data dog.

341
00:23:35,365 --> 00:23:38,765
And while doing that, we can do
a lot of, regular expression.

342
00:23:38,775 --> 00:23:41,445
We can level at them to
split our knocks and then.

343
00:23:42,890 --> 00:23:48,270
Some of those important locks and we
can filter locks based on the lock type,

344
00:23:48,270 --> 00:23:54,290
like it's on the error or the warnings
or likewise, so we can identify extract

345
00:23:54,290 --> 00:23:58,390
some of these different lock exceptions
and said, so we have a lot of exceptions.

346
00:23:58,400 --> 00:24:03,850
So we had to be mindful that data dog is
a paid solution and it can be sometimes

347
00:24:03,850 --> 00:24:05,970
a little expensive when we are using.

348
00:24:06,295 --> 00:24:10,485
Lot of, log related, when you are trying
to ship the entire log into Datadog.

349
00:24:10,715 --> 00:24:13,485
So what you can do is you
can use a lot of filtering.

350
00:24:13,685 --> 00:24:18,535
So that way that you can save
some of the cost when it comes to

351
00:24:19,005 --> 00:24:20,865
using Datadog for log management.

352
00:24:21,525 --> 00:24:27,215
moving on, so one of the other important
things which I personally like is lot

353
00:24:27,225 --> 00:24:29,005
develop lot of synthetic monitors.

354
00:24:29,265 --> 00:24:33,095
So we can develop a lot of synthetic
monitors to test, different pages

355
00:24:33,135 --> 00:24:38,945
or some of user journeys and we can
provide some, the failure, the retries.

356
00:24:39,415 --> 00:24:41,885
And here again, those are
very important things.

357
00:24:41,905 --> 00:24:45,015
So this will, the synthetic
monitors will actually try to mimic.

358
00:24:46,185 --> 00:24:50,825
end user in our production systems,
so it has a lot of value and, so we

359
00:24:50,825 --> 00:24:53,495
can again use, Terraform to get this.

360
00:24:55,645 --> 00:24:59,215
And one thing I, personal of
my favorite is creating alerts.

361
00:24:59,225 --> 00:25:02,685
So we'll have to create alerts
based on, we, first it's about

362
00:25:02,685 --> 00:25:06,005
service level objective based
alerts based on your caching layer.

363
00:25:06,060 --> 00:25:08,621
you have to create a list based
on your, the middleware, the

364
00:25:08,631 --> 00:25:10,301
logic layer, the service layer.

365
00:25:10,601 --> 00:25:14,361
and you have to create some of
these alerts based on your other

366
00:25:14,471 --> 00:25:15,651
end to end journeys as well.

367
00:25:15,911 --> 00:25:19,881
So it's, so what you had to do is
your alert has to be more or less

368
00:25:19,881 --> 00:25:21,751
correlated with service level objectives.

369
00:25:22,146 --> 00:25:26,026
So it's level objectives will correlate
with end user experience, and you

370
00:25:26,026 --> 00:25:29,566
can, of course, have a lot of triggers
when it related to infrastructure

371
00:25:29,566 --> 00:25:33,646
monitoring, network monitoring and
other anomaly monitoring as well.

372
00:25:34,046 --> 00:25:37,836
Alert can be standard is that,
the metric driven alerts.

373
00:25:38,276 --> 00:25:42,506
Or you can enable some of the alerts
like, AI capabilities like anomaly

374
00:25:42,506 --> 00:25:44,366
related alerts or forecasting.

375
00:25:44,866 --> 00:25:48,836
And then alerts, you can define what
are the thresholds, or you can let,

376
00:25:48,926 --> 00:25:53,366
in case of anomaly detection and
forecast anomaly detection, especially

377
00:25:53,436 --> 00:25:57,141
let Datadog handle those things,
the thresholds, diamond thresholds.

378
00:25:57,291 --> 00:25:58,291
Based on baseline.

379
00:25:58,561 --> 00:26:02,701
So you can configure what are the teams
these alerts has to go through and

380
00:26:02,701 --> 00:26:04,131
you can come up with a lot of tagging.

381
00:26:04,321 --> 00:26:09,121
So the using observability as code
solution in AWS in this area that

382
00:26:09,121 --> 00:26:14,711
will provide you a lot of options,
a lot of standardizations and that

383
00:26:14,881 --> 00:26:19,151
will add a lot of value in a large
organization managing multiple teams.

384
00:26:20,981 --> 00:26:25,271
And then, most of the teams assuming
they use some workloads like EC2.

385
00:26:25,301 --> 00:26:26,381
So the containers.

386
00:26:26,666 --> 00:26:30,436
Or, yeah, they are using serverless
based solutions, like Lambdas.

387
00:26:30,806 --> 00:26:34,936
And, pretty much, sometimes your,
what you monitor might be same,

388
00:26:34,946 --> 00:26:39,526
if your caching metrics, if your,
the service layer related metrics,

389
00:26:39,856 --> 00:26:43,946
which are your, the backend related
metrics, frontend related metrics,

390
00:26:43,946 --> 00:26:46,151
if you, Enable real user monitoring.

391
00:26:46,451 --> 00:26:49,891
So there can be a lot of common metrics.

392
00:26:50,091 --> 00:26:54,381
And on top of that, we can even absorb a
lot of common dashboards as well, which

393
00:26:54,381 --> 00:27:00,041
can be aligned, which can be even Carter
into multiple different end user journeys.

394
00:27:01,096 --> 00:27:04,506
Because the technology is same, the
what's happening at the background

395
00:27:04,506 --> 00:27:08,476
is same, so we can create some of
these very standard dashboards.

396
00:27:08,716 --> 00:27:12,786
So those these dashboards can be
using observability as code solution.

397
00:27:12,796 --> 00:27:17,966
We can move in different environments
in AWS like your pre live.

398
00:27:18,291 --> 00:27:20,031
The staging of production.

399
00:27:20,211 --> 00:27:22,101
So that way you have a lot of consistence.

400
00:27:22,106 --> 00:27:27,301
You enable, you allow your developers
to go and, look at, how the

401
00:27:27,301 --> 00:27:31,501
application is behaving in multiple
environments, not only in production.

402
00:27:31,681 --> 00:27:34,981
So this is a very value added
thing and with this we can make

403
00:27:34,981 --> 00:27:36,571
it lot of, standardization.

404
00:27:36,721 --> 00:27:40,001
So when the same
capabilities we can, allow.

405
00:27:40,301 --> 00:27:43,611
Other engagements,
other teams use as well.

406
00:27:43,981 --> 00:27:47,411
So whenever new applications, new
engagements are getting onboarded,

407
00:27:47,711 --> 00:27:49,241
things will be very straightforward.

408
00:27:49,251 --> 00:27:53,871
They can just simply plug into the
Git, look at these Terraform scripts,

409
00:27:53,941 --> 00:27:59,541
observability as code solutions, and then
integrate these in their AWS environment.

410
00:28:00,241 --> 00:28:04,461
So moving on, one of the
other thing is enabling APM,

411
00:28:04,461 --> 00:28:05,981
application performance monitoring.

412
00:28:06,231 --> 00:28:11,201
Here again, if it's like the workload
based, Or using open telemetry or

413
00:28:11,281 --> 00:28:14,821
serverless blade integrating apm
with your serverless frameworks.

414
00:28:14,861 --> 00:28:22,181
We can leverage there are observability
as code solutions in aws as well And

415
00:28:22,181 --> 00:28:26,661
finally, some of these, the platform
engineering typical use cases are

416
00:28:26,671 --> 00:28:31,871
account creation, access control, and we
can use observability as code solution

417
00:28:31,881 --> 00:28:36,961
here in AWS, but we can do is we can
have a different access layers for your

418
00:28:36,961 --> 00:28:39,131
dashboards to the monitors, your logs.

419
00:28:39,436 --> 00:28:43,446
synthetic ability to recreate
the admin users, read write

420
00:28:43,446 --> 00:28:47,436
privileges, account creations, cost
views, and all of those things.

421
00:28:47,436 --> 00:28:52,596
So we can leverage Terraform and
which mean your observability as

422
00:28:52,606 --> 00:28:57,556
code solutions with AWS, leveraging
Datadog to achieve these capabilities.

423
00:28:59,026 --> 00:29:03,836
And finally, of course, like we can
use this to streamline our CI CD

424
00:29:03,836 --> 00:29:06,066
pipeline integrations using Terraform.

425
00:29:06,356 --> 00:29:09,966
So this will be very, beneficial
because we want to ensure this

426
00:29:10,036 --> 00:29:13,936
observability as code solution
goes through multiple environments

427
00:29:13,956 --> 00:29:15,576
so that we can take this benefit.

428
00:29:16,846 --> 00:29:20,796
And, in case if required, there's
a specific customization needed

429
00:29:20,806 --> 00:29:24,360
for your distributed tracing setup,
we can leverage this as well.

430
00:29:25,821 --> 00:29:30,091
And as I said, one of the other important
thing is defining service level objectives

431
00:29:30,451 --> 00:29:34,991
and sometimes we have seen there's a
common framework, common aspects when

432
00:29:35,001 --> 00:29:40,451
we are defining because in a typical
organizations we are using some of these,

433
00:29:40,751 --> 00:29:46,601
the AWS based workloads, the containers
and serverless frameworks and that

434
00:29:46,621 --> 00:29:51,071
enable us to leverage some of these,
standardizations and the common factors.

435
00:29:51,441 --> 00:29:56,191
So using SLO as code, what we want
is instead of defining SLOs at

436
00:29:56,201 --> 00:30:01,731
last, or developing SLOs as once the
application goes live, we want our

437
00:30:01,781 --> 00:30:05,301
developer community to think about
SLOs, service level objectives, when

438
00:30:05,311 --> 00:30:10,991
they're designing, developing, testing,
and try deploying these, the code into

439
00:30:11,281 --> 00:30:16,911
multiple environments, so they can
write the SLO as part of your code.

440
00:30:16,911 --> 00:30:16,930
Okay.

441
00:30:17,181 --> 00:30:21,271
And then ship and let it go through
multiple environments until production

442
00:30:21,591 --> 00:30:25,911
even to add production so that way that we
can monitor our service level objectives

443
00:30:26,171 --> 00:30:30,161
and even example in one of our pre
live environment we can do performance

444
00:30:30,161 --> 00:30:34,361
testing we can do soft testing we can
do security testing we can do other

445
00:30:34,361 --> 00:30:39,911
form of stress testing and we can see
how our SLOs are behaving we can mimic

446
00:30:39,911 --> 00:30:45,481
some of the high peak traffic the high
concurrent traffic and simulate some of

447
00:30:46,636 --> 00:30:51,796
or, spike, or the flood of traffics and
different type of user behaviors, and we

448
00:30:51,796 --> 00:30:54,536
can see our, how our SLOs are behaving.

449
00:30:54,606 --> 00:30:56,536
So this is a very powerful feature.

450
00:30:56,786 --> 00:31:02,766
So typically what happened was people
define SLOs in Datadog ecosystems

451
00:31:02,766 --> 00:31:04,716
at large state for production.

452
00:31:04,956 --> 00:31:08,286
But this way, from the very
beginning in multiple environments,

453
00:31:08,286 --> 00:31:12,046
from the start, we can do that so
that there's a lot of visibility.

454
00:31:12,046 --> 00:31:12,256
Okay.

455
00:31:13,711 --> 00:31:17,611
Consistence and we can achieve a
lot of good things by doing this.

456
00:31:19,691 --> 00:31:25,451
And obviously Datadog provides whenever
there are, events created, we can invoke

457
00:31:25,451 --> 00:31:29,781
some webhooks and from there we can,
invoke some remediation engines running

458
00:31:29,781 --> 00:31:34,551
in our AWS workloads or serverless
framework like lambdas with that we

459
00:31:34,551 --> 00:31:38,371
can do a lot of, self healing, we can
build a lot of self healing solutions.

460
00:31:38,371 --> 00:31:40,551
We can do a lot of automation solutions.

461
00:31:40,861 --> 00:31:45,261
So observability as code is
providing those capabilities as well.

462
00:31:45,901 --> 00:31:49,241
And then we can, of course, build
our compliance and governance

463
00:31:49,241 --> 00:31:52,441
control based out of this
observability as code solution.

464
00:31:53,311 --> 00:31:56,251
And finally, in case, when,
whenever we have any scheduled

465
00:31:56,251 --> 00:31:58,311
deployment, scheduled downtimes.

466
00:31:58,571 --> 00:32:01,471
or downtime related to back
end teams, which will have an

467
00:32:01,471 --> 00:32:03,831
impact on some of our monitors.

468
00:32:04,101 --> 00:32:08,401
We can enable maintenance windows, or
whenever there are CI CD deployment,

469
00:32:08,401 --> 00:32:12,721
unless if you are using a very
sophisticated deployment strategy, you

470
00:32:12,721 --> 00:32:15,241
are calling out a certain level of outage.

471
00:32:15,551 --> 00:32:20,111
You can create your maintenance
windows as observability as code,

472
00:32:20,441 --> 00:32:22,341
and then you can suppress your traps.

473
00:32:22,341 --> 00:32:26,731
So you can integrate that part of
your the release the CACD pipelines so

474
00:32:26,741 --> 00:32:30,211
that way you can test it as well and
whenever you are doing this production

475
00:32:30,211 --> 00:32:32,691
deployment automatically pipeline will.

476
00:32:33,731 --> 00:32:39,221
enable the maintenance window, which is
suppressing your relevant traps during

477
00:32:39,221 --> 00:32:40,741
that particular deployment window.

478
00:32:40,971 --> 00:32:43,931
And after that you can enable
it and do a testing as well.

479
00:32:44,201 --> 00:32:48,881
So this whole aspect, instead of
doing manually, you can leverage

480
00:32:49,001 --> 00:32:53,891
the observability as code solutions
in AWS to achieve this thing.

481
00:32:54,626 --> 00:32:59,856
So moving on, so those are some of
the things which we can do as part

482
00:32:59,856 --> 00:33:04,816
of observability as code, which will
support our ultimate goal of developing

483
00:33:04,816 --> 00:33:10,796
a comprehensive observability related
components, services, things when

484
00:33:10,796 --> 00:33:12,166
it comes to platform engineering.

485
00:33:12,526 --> 00:33:15,496
So while you're doing this, I think
it's very important for you to

486
00:33:15,496 --> 00:33:21,456
be mindful of typical, issues and
ensure that you are ready for that.

487
00:33:21,706 --> 00:33:26,186
And one of the key issue is whatever we
do these days, we had to ensure that we

488
00:33:26,196 --> 00:33:31,046
have a way to measure progress and how,
whether what we have done is actually

489
00:33:31,046 --> 00:33:33,456
allowing business to see some benefits.

490
00:33:33,716 --> 00:33:37,366
So we had to look at your mean time for
detection, mean time for resolution,

491
00:33:37,626 --> 00:33:39,236
mean time for between failures.

492
00:33:39,446 --> 00:33:42,636
So we had to ensure that there
is a way for we can extract these

493
00:33:42,666 --> 00:33:46,226
metrics so that we can measure
this when we are going through our

494
00:33:46,466 --> 00:33:48,856
observability as called journey in AWS.

495
00:33:49,326 --> 00:33:53,956
And we had look at how, whether this
is helping us to improve reliability,

496
00:33:53,956 --> 00:33:58,476
availability and how this is, helping
us to enhance the customer experience.

497
00:33:58,496 --> 00:34:03,706
So this can be tagged into your service
level objectives, can improve your service

498
00:34:03,706 --> 00:34:06,666
level objectives, in a periodic fashion.

499
00:34:06,866 --> 00:34:10,196
So those are some of these
values we have to bring in part

500
00:34:10,196 --> 00:34:11,486
of these kinds of solutions.

501
00:34:11,776 --> 00:34:14,876
And also, can you improve
your developer velocity?

502
00:34:15,026 --> 00:34:19,146
Can this have more, positive impact
on your DORA metrics, which is like

503
00:34:19,526 --> 00:34:23,916
lead time for change and reduce
increasing the change, Frequency, make

504
00:34:24,136 --> 00:34:28,376
your production volatile while you
manage your customer experience using

505
00:34:28,376 --> 00:34:33,516
service level objectives and reduce the
deployment failure rate and those things.

506
00:34:33,516 --> 00:34:38,866
So you had to think about those things
and capturing those metrics and some

507
00:34:38,866 --> 00:34:44,206
aspects of this, you can of course use
observability as code solutions as well.

508
00:34:44,206 --> 00:34:49,836
So this, you can, instead of letting
teams is coming up, up with Their own

509
00:34:49,836 --> 00:34:54,306
solutions you can make this standard make
it also observability as code solution.

510
00:34:54,596 --> 00:35:01,196
So That way this can be tracked properly
as well And finally before we wrap up

511
00:35:01,446 --> 00:35:06,086
so observability as code has a lot of
advantages, but there are some best

512
00:35:06,096 --> 00:35:07,806
practices You have to be mindful.

513
00:35:08,166 --> 00:35:13,551
So number one I would suggest is managing
your secure api keys So when it comes to

514
00:35:13,611 --> 00:35:18,321
Datadog integration using AWS, you will
have to look at, there can be your Datadog

515
00:35:18,391 --> 00:35:22,111
API keys and AWS based credentials.

516
00:35:22,371 --> 00:35:28,091
So those you will have to leverage,
and access in a very, secure way.

517
00:35:28,691 --> 00:35:31,841
And you will have to definitely use
version control because that's one

518
00:35:31,841 --> 00:35:36,481
of the key advantage, key elements
bringing in observability as code.

519
00:35:36,701 --> 00:35:40,141
So think about ensure you don't miss
out and you do the version control.

520
00:35:40,621 --> 00:35:45,551
Keep your cord in the gig and those are
best practices and you obviously will

521
00:35:45,561 --> 00:35:49,011
have to do a modularization instead
of you know going a big band way.

522
00:35:49,571 --> 00:35:55,661
Modularize it to your agent data
dog integrations, APM enable, Real

523
00:35:55,661 --> 00:35:59,881
User Monitoring enables, Metric
enablement, Dashboard creation,

524
00:35:59,891 --> 00:36:05,921
Monitors, Synthetic monitors, Log
pipelines, Governance, Access controls.

525
00:36:06,221 --> 00:36:09,751
So that way there's modularization
so that you can take those advantage.

526
00:36:10,271 --> 00:36:13,851
And this observability as code
solution has to be plugging

527
00:36:13,851 --> 00:36:15,321
with your deployment pipelines.

528
00:36:15,511 --> 00:36:20,751
It has to go through multiple environments
and until you move into production.

529
00:36:21,221 --> 00:36:26,051
So that this way you can take the
True potential of this observability

530
00:36:26,071 --> 00:36:28,501
being written as code for AWS.

531
00:36:29,071 --> 00:36:31,931
And you'll have to look at, role
based access controls, enable

532
00:36:31,951 --> 00:36:35,751
them, based on your user community.

533
00:36:35,771 --> 00:36:38,531
You'll have to look at
how you do that as well.

534
00:36:39,051 --> 00:36:41,551
And this has to be a centralized solution.

535
00:36:41,831 --> 00:36:45,091
So it has, this should provide
centralized output, centralized

536
00:36:45,091 --> 00:36:46,445
dashboard, centralized architecture.

537
00:36:46,666 --> 00:36:49,736
the alerting mechanisms,
centralized logging systems,

538
00:36:49,916 --> 00:36:52,516
standardization across everything.

539
00:36:52,876 --> 00:36:54,126
That is very important.

540
00:36:54,136 --> 00:36:56,626
So this has to reside in standardization.

541
00:36:56,906 --> 00:37:01,186
So every engagement, every line of
business, every team in your organizations

542
00:37:01,226 --> 00:37:05,866
are pretty much following a defined
and standardization with quality

543
00:37:05,936 --> 00:37:08,556
gates and with, the ability to review.

544
00:37:08,556 --> 00:37:08,616
Thank you.

545
00:37:08,751 --> 00:37:13,991
So this should come up with a lot
of documentations, reviews, so

546
00:37:13,991 --> 00:37:15,971
that will enable collaboration.

547
00:37:16,541 --> 00:37:20,891
And Datadog has a lot of integrations,
sometimes leveraging those direct

548
00:37:20,941 --> 00:37:25,371
integrations will save you time
when it comes to AWS like serverless

549
00:37:25,411 --> 00:37:30,041
integration, container integration,
and with other different AWS

550
00:37:30,041 --> 00:37:31,531
service integrations as well.

551
00:37:32,221 --> 00:37:35,181
So all of this is driving collaboration.

552
00:37:35,381 --> 00:37:40,031
So you have to ensure that these,
taken and taken into your, multiple

553
00:37:40,051 --> 00:37:45,201
teams and work with them to enable this
collaboration so that you can get this

554
00:37:45,201 --> 00:37:50,340
value out of this, enabling observability
as code for your AWS ecosystems.

555
00:37:52,121 --> 00:37:55,201
With that, I would like to
take a close my presentation.

556
00:37:55,231 --> 00:38:01,831
I hope you enjoy it and we'll see
you in another future presentation.

557
00:38:02,391 --> 00:38:04,321
So thank you very much
for taking your time.

558
00:38:04,811 --> 00:38:05,761
And there are great.

559
00:38:06,236 --> 00:38:11,136
amount of presentations done by different
presenters, part of platform engineering

560
00:38:11,166 --> 00:38:15,166
2022 and 24 by organized by con 42.

561
00:38:15,466 --> 00:38:19,436
I'm requesting everyone to look
at these presentations as well.

562
00:38:20,026 --> 00:38:21,806
So thanks for taking time.

563
00:38:21,966 --> 00:38:22,606
Take care.

564
00:38:22,696 --> 00:38:23,076
Bye.

