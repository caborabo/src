1
00:00:14,340 --> 00:00:15,920
Hi everyone, Amir here.

2
00:00:15,920 --> 00:00:18,740
I'm the CEO and co founder at Senser.

3
00:00:19,430 --> 00:00:23,759
It's a pleasure to be here as part
of the Conf42 Kube Native conference.

4
00:00:23,850 --> 00:00:28,139
What we're going to speak is about
the deficiencies and the problems

5
00:00:28,460 --> 00:00:33,730
with working solely with logs when
trying to solve Kubernetes incidents.

6
00:00:34,260 --> 00:00:37,050
In terms of what we're going to
cover, we're going to cover the

7
00:00:37,050 --> 00:00:39,660
trouble with logs in isolation.

8
00:00:39,730 --> 00:00:41,140
What's missing in them.

9
00:00:41,599 --> 00:00:43,610
A lot of these elements
are probably a lot.

10
00:00:43,730 --> 00:00:47,739
A lot of you are familiar with
what additional context look

11
00:00:47,739 --> 00:00:49,530
like and why it is important.

12
00:00:49,889 --> 00:00:53,590
We're going to go through a
short story or a short real life

13
00:00:53,590 --> 00:00:55,190
example of an investigation.

14
00:00:55,739 --> 00:00:59,579
And eventually we'll wrap it all up
and trying to explain the pitfalls

15
00:00:59,579 --> 00:01:03,299
and explain how to get started with
a more with more advanced techniques.

16
00:01:04,030 --> 00:01:08,640
If we'll start and speak about logs,
Kubernetes in particular, but in

17
00:01:08,640 --> 00:01:14,049
general, of course, they're one of the
most helpful tools in troubleshooting.

18
00:01:14,130 --> 00:01:17,409
But as we all know, they're not ideal,
and most of the time they're not enough.

19
00:01:17,840 --> 00:01:23,299
A good way to think about it is that,
as any of us know, the problem with logs

20
00:01:23,609 --> 00:01:25,560
is that usually they require more logs.

21
00:01:25,560 --> 00:01:29,870
And the problem, especially with
regard to Kubernetes or any distributed

22
00:01:29,870 --> 00:01:32,910
system, is that the rest of the
logs which are needed are not.

23
00:01:33,350 --> 00:01:35,280
usually placed in the same location.

24
00:01:35,289 --> 00:01:38,880
You need to look at another node,
another pode and another element.

25
00:01:39,650 --> 00:01:43,789
And individual logs lack a lack of
context because of a few reasons.

26
00:01:44,049 --> 00:01:49,229
One, which is probably clear, a
human wrote them, and humans are not

27
00:01:49,229 --> 00:01:51,159
very good at predicting the future.

28
00:01:51,159 --> 00:01:55,139
So essentially a log, if you think
about it very similarly to a line

29
00:01:55,139 --> 00:01:59,199
of code, because it is the line of
code, but it has more to it, they

30
00:01:59,199 --> 00:02:02,030
exist on the basis of experience.

31
00:02:02,250 --> 00:02:03,579
What have I seen?

32
00:02:04,150 --> 00:02:09,310
In the past or assumption, what type of
corner case am I anticipating that my

33
00:02:09,570 --> 00:02:15,510
code flow is going to go through and that
would represent and we're looking at it

34
00:02:15,510 --> 00:02:22,899
at the process level, even though we're
sometimes very good at reviewing code.

35
00:02:23,040 --> 00:02:27,340
Changes or reviewing any type of
code edition, we're not very good at

36
00:02:27,580 --> 00:02:32,380
accompanying that with reviewing the
logs and what context do they bring in?

37
00:02:32,680 --> 00:02:36,610
What is their meaning and different
path different passes that the

38
00:02:36,610 --> 00:02:38,440
code or the program could take.

39
00:02:39,750 --> 00:02:43,650
Another aspect is that other issues are
happening at the same time where log

40
00:02:43,650 --> 00:02:46,110
is a encapsulation of a single moment.

41
00:02:46,445 --> 00:02:51,035
Most likely at a single time of a
single event, but other things are

42
00:02:51,045 --> 00:02:55,675
happening in tandem, and they have a
lot of importance when we're trying

43
00:02:55,695 --> 00:02:59,765
to we're trying to analyze the
issue on similar prior incidents.

44
00:03:00,345 --> 00:03:05,085
If we have the ability to correlate,
or we have the ability to look at

45
00:03:05,094 --> 00:03:09,095
past incidents and capture this
knowledge with regards to a specific

46
00:03:09,095 --> 00:03:10,935
log, that would be very beneficial.

47
00:03:11,485 --> 00:03:13,615
And, of course, the
connection to topology.

48
00:03:14,010 --> 00:03:19,460
If I have some way or some technique to
know something about the environment,

49
00:03:19,490 --> 00:03:23,780
about both the infrastructure layer,
the application layer, what elements are

50
00:03:23,780 --> 00:03:28,500
interconnected, that, of course, is not
something which appears inside of the log.

51
00:03:28,820 --> 00:03:34,200
But it's a very common aspect or a very
important aspect in doing the analysis.

52
00:03:34,220 --> 00:03:38,040
If I know where something happened
and how it is connected to the other

53
00:03:38,040 --> 00:03:42,519
elements in the system, I can start
and build the flow of analysis.

54
00:03:43,195 --> 00:03:49,725
Essentially, so my goal is to to give you
a little bit of inspiration or a little

55
00:03:49,725 --> 00:03:55,464
bit of a methodical way of thinking of
how to do it, how to do it in real life.

56
00:03:55,705 --> 00:03:58,154
We're going to take a real
example in this example.

57
00:03:58,165 --> 00:04:01,345
We're looking at part of our system,
but that could be done in any

58
00:04:01,345 --> 00:04:05,825
other observability systems or from
technique perspective to the line

59
00:04:05,825 --> 00:04:07,175
with things you're familiar with.

60
00:04:07,555 --> 00:04:10,145
What we're starting with is
a customer affecting issue.

61
00:04:10,475 --> 00:04:14,495
In this case, the front end, the
element which is responding or

62
00:04:14,495 --> 00:04:20,345
interacting with the user is essentially
returning a server error to the user.

63
00:04:20,885 --> 00:04:24,965
Of course, it is bad because we're not
fulfilling some sort of a business flow,

64
00:04:25,534 --> 00:04:27,624
but that is where we are starting with.

65
00:04:28,195 --> 00:04:31,715
And the first thing that we will
do if we're relying on logs is

66
00:04:31,745 --> 00:04:35,955
to try and find errors, which has
some sort of correlation into that.

67
00:04:36,485 --> 00:04:42,705
We'll deep dive into the log soon, but
from customer perspective, we've impacted

68
00:04:42,725 --> 00:04:45,184
our meantime to meantime to detect.

69
00:04:45,184 --> 00:04:47,025
We've impacted our meantime to recover.

70
00:04:47,515 --> 00:04:51,605
There's going to be a long investigation
time if we're relying solely on logs.

71
00:04:51,965 --> 00:04:54,414
And eventually even SREs.

72
00:04:54,704 --> 00:04:58,745
Our people, even though they're sometimes
required to do a lot of crazy things.

73
00:04:58,895 --> 00:05:01,735
So their sanity is of course
in of course in danger.

74
00:05:02,034 --> 00:05:05,525
Not only because the logs are not
written by them but this entire

75
00:05:05,525 --> 00:05:07,284
process is pressuring to begin with.

76
00:05:07,585 --> 00:05:09,414
But now there's a lot of other element.

77
00:05:09,640 --> 00:05:10,120
within it.

78
00:05:10,940 --> 00:05:13,020
So what do when I say context?

79
00:05:13,590 --> 00:05:17,020
A context would be how do I
take the essence of a log,

80
00:05:17,070 --> 00:05:21,570
which is a single moment, single
element, single point in time.

81
00:05:21,900 --> 00:05:26,030
And how do we tie that in with the
fact that the system is much larger.

82
00:05:26,560 --> 00:05:29,309
And when we're trying to
put this into context, we're

83
00:05:29,310 --> 00:05:31,600
essentially enriching the log.

84
00:05:31,930 --> 00:05:33,430
The log by itself is not enough.

85
00:05:33,894 --> 00:05:37,454
What other element, what
other views of the system are

86
00:05:37,454 --> 00:05:39,734
important for that analysis.

87
00:05:40,424 --> 00:05:42,414
So we brought three examples here.

88
00:05:42,504 --> 00:05:45,024
Each and every one of them is important.

89
00:05:45,044 --> 00:05:49,584
Each and every one of them is working
together as part of the analysis.

90
00:05:49,834 --> 00:05:51,184
But first of all, topology.

91
00:05:51,775 --> 00:05:53,875
If I'm a subject matter expert.

92
00:05:54,250 --> 00:05:54,970
Which is hard.

93
00:05:54,970 --> 00:05:59,560
I have a mental view, if you will, of
how the system is really deployed, how

94
00:05:59,580 --> 00:06:01,400
the system look like very hard to do it.

95
00:06:01,400 --> 00:06:05,110
In reality, we're speaking about
auto scaling type of system.

96
00:06:05,110 --> 00:06:10,079
We're speaking about a system, which has
a ephemeral type of type of behavior.

97
00:06:10,079 --> 00:06:12,439
So it's hard to do it
in in real life or as a.

98
00:06:12,794 --> 00:06:15,934
Thought experience, but topology
is a very important part.

99
00:06:15,954 --> 00:06:21,264
If I have a concrete and up to date,
real time, high level overview of how the

100
00:06:21,264 --> 00:06:25,964
system is structured, which infrastructure
elements are being used, like the type

101
00:06:25,964 --> 00:06:30,144
of nodes, where the nodes are located,
what infrastructure is being used, what

102
00:06:30,155 --> 00:06:34,504
type of services are being used, and how
they're interconnect, I start to have a

103
00:06:34,674 --> 00:06:36,859
picture, which allows me to understand it.

104
00:06:37,459 --> 00:06:42,919
Essentially, the technical flow and from
that try to move on to the next step.

105
00:06:43,279 --> 00:06:47,449
Another important part is
incorporating into this process.

106
00:06:48,014 --> 00:06:48,704
Matrices.

107
00:06:49,174 --> 00:06:51,374
Essentially, I have a log.

108
00:06:51,724 --> 00:06:53,204
Something could go wrong.

109
00:06:53,284 --> 00:06:57,574
I know we'll speak about an example,
but what happened on the metric level?

110
00:06:57,834 --> 00:07:04,454
Was there a performance issue in tandem to
that log appearing research being consumed

111
00:07:04,454 --> 00:07:07,954
or are or lacking like a CPU or memory?

112
00:07:08,174 --> 00:07:09,034
Was there a network?

113
00:07:09,294 --> 00:07:13,234
Latency issue or an error rate that
stems from a specific session or

114
00:07:13,234 --> 00:07:17,894
specific API, which can give me
some insight to how to move forward

115
00:07:17,894 --> 00:07:20,404
in my decision tree or my path.

116
00:07:20,454 --> 00:07:24,014
The word where the root cause
is another important element

117
00:07:24,024 --> 00:07:25,514
is the deployment history.

118
00:07:25,699 --> 00:07:28,879
We all know it, but one of the most
important part to enrich log with

119
00:07:29,209 --> 00:07:34,009
is what happened from deployment
perspective, what elements which were

120
00:07:34,539 --> 00:07:37,549
lately deployed by the CI CD pipeline.

121
00:07:37,849 --> 00:07:41,489
A lot of the time, there is a strong
correlation between an error in

122
00:07:41,499 --> 00:07:43,379
the system and a recent deployment.

123
00:07:43,609 --> 00:07:46,579
It could be a deployment
in the form of a new image.

124
00:07:47,114 --> 00:07:51,024
Coming into the production environment,
meaning like a new piece of software,

125
00:07:51,044 --> 00:07:54,444
which makes sense, it could be
a configuration change, which is

126
00:07:54,444 --> 00:07:56,424
also deployed by the pipeline.

127
00:07:56,764 --> 00:08:02,894
All of this are elements which we want
to enrich our logs or our log view with.

128
00:08:03,624 --> 00:08:11,144
Why is it hard to get this kind of context
the way to look at it the way I've decided

129
00:08:11,144 --> 00:08:17,244
to look at it is to look at maybe the
two common ways of observing the system.

130
00:08:18,214 --> 00:08:21,124
There's a lot of overlapping between
them, but just for the benefit of the

131
00:08:21,124 --> 00:08:26,174
debate, the commercial observability
tech type of solution and the

132
00:08:26,174 --> 00:08:28,284
open source observability stack.

133
00:08:28,284 --> 00:08:29,184
So it could be.

134
00:08:29,794 --> 00:08:34,324
Anyone of the incumbent solution,
it involves being able to deploy the

135
00:08:34,324 --> 00:08:40,784
observability engines to take the logs and
retained logs within the analysis system.

136
00:08:41,164 --> 00:08:43,864
There's a lot of common challenges
with it doing it in scale.

137
00:08:43,864 --> 00:08:48,614
Of course, the cost, or more specifically,
the cost to get good coverage.

138
00:08:48,934 --> 00:08:53,284
Sometimes you would see people that
are employing only infrastructure

139
00:08:53,284 --> 00:08:55,244
monitoring part of the logs.

140
00:08:55,674 --> 00:08:58,294
Employing ATM only in case of need.

141
00:08:58,574 --> 00:09:01,534
So since you don't have
all these verticals all at

142
00:09:01,564 --> 00:09:03,594
the same times, it's hard.

143
00:09:04,244 --> 00:09:05,384
It's hard to get to the solution.

144
00:09:05,724 --> 00:09:08,254
And of course, configuring
and maintaining dashboard.

145
00:09:08,284 --> 00:09:09,394
How am I building?

146
00:09:10,584 --> 00:09:14,254
I'm building to begin with
dashboards, which are good enough.

147
00:09:14,494 --> 00:09:17,724
So they essentially encapsulate
enough data and enough.

148
00:09:17,999 --> 00:09:23,529
valuable data for me to go from
a behavior aspect like a user

149
00:09:23,529 --> 00:09:27,479
error to a complete analysis and
being able to solve the issue.

150
00:09:28,079 --> 00:09:33,099
Open source observability stacks, we
gave a few examples here, but they could

151
00:09:33,099 --> 00:09:37,629
involve The equivalent of deploying
an agent or sometimes even manually

152
00:09:37,679 --> 00:09:41,459
instrumenting the production environment,
which is hard, not only at scale, but

153
00:09:41,459 --> 00:09:47,769
especially if you have various versions of
software in your production environment,

154
00:09:47,779 --> 00:09:49,729
legacies environment, so on and so forth.

155
00:09:50,069 --> 00:09:54,129
And again, the challenges here would
be the coverage gaps, the blind spot

156
00:09:54,219 --> 00:09:59,169
places, which you weren't able to
completely cover the instrumentation.

157
00:09:59,219 --> 00:10:04,769
Overhead, both from declining or covering
everything on the production impact.

158
00:10:07,509 --> 00:10:11,649
So spoiler, what type of
things could help you here?

159
00:10:11,929 --> 00:10:16,299
So we are, of course working a
lot around and automated topology.

160
00:10:17,929 --> 00:10:19,659
Not only in our context, but.

161
00:10:20,425 --> 00:10:24,515
It's a very important part in order
to to enrich the analysis environment.

162
00:10:25,375 --> 00:10:30,335
So let's take a look, for example, in the
system that I saw you, I shown you in the

163
00:10:30,335 --> 00:10:32,384
beginning, we had a front end service.

164
00:10:32,384 --> 00:10:36,365
That front end service exposes
a lot of services to the user.

165
00:10:36,575 --> 00:10:40,155
What we saw in the example to
begin with is that we're returning

166
00:10:40,245 --> 00:10:42,055
an error, a server error.

167
00:10:42,365 --> 00:10:43,675
If we're looking into the log.

168
00:10:44,460 --> 00:10:47,900
And logs are always tend
to be tend to be messy.

169
00:10:47,900 --> 00:10:48,780
They tend to be big.

170
00:10:48,990 --> 00:10:53,600
What we'll essentially see here
is that the API that was exposed

171
00:10:53,610 --> 00:10:57,590
to the user and returning an error
is working with the cart service

172
00:10:57,590 --> 00:10:59,250
in this e commerce environment.

173
00:10:59,580 --> 00:11:02,600
What the log is essentially telling
us here is that there is a connection

174
00:11:02,600 --> 00:11:07,660
failure between the front end service
and the service that represent the cart.

175
00:11:08,995 --> 00:11:14,015
We can go and deep dive into it and
get some clues about where it could be.

176
00:11:14,715 --> 00:11:18,415
But it's but it's not very
straightforward as it always it's most

177
00:11:18,415 --> 00:11:20,395
likely it's always not very clear.

178
00:11:21,695 --> 00:11:25,795
The second element that we will do
right now is we'll try to learn a

179
00:11:25,875 --> 00:11:27,745
little bit about the environment.

180
00:11:28,084 --> 00:11:30,834
So I'm going to show it in a greater zoom.

181
00:11:31,154 --> 00:11:34,425
But essentially for opening
the environment, which we

182
00:11:34,425 --> 00:11:35,795
would see here, we would see.

183
00:11:36,250 --> 00:11:40,410
The services, including the front
end, we would see the rest of the

184
00:11:40,410 --> 00:11:42,010
services they're interacting with.

185
00:11:42,050 --> 00:11:45,620
What I'm trying to do is
1st to take or get a glance.

186
00:11:46,180 --> 00:11:51,300
The front end needs the car service, which
element are implementing the car services.

187
00:11:51,309 --> 00:11:52,840
They're an actual database.

188
00:11:53,175 --> 00:11:54,185
Which is in player.

189
00:11:54,355 --> 00:11:57,985
Is there another layer of business
logic or business service, which

190
00:11:57,985 --> 00:12:00,285
is encapsulating the card behavior.

191
00:12:00,515 --> 00:12:04,755
And if the if there is, and if I can
understand what they were doing at the

192
00:12:04,755 --> 00:12:09,525
same time, I will for sure get closer
and closer to understanding the issue.

193
00:12:10,060 --> 00:12:12,960
Relying on the log alone,
what would the troubleshooting

194
00:12:12,970 --> 00:12:14,410
look like or should look like?

195
00:12:14,670 --> 00:12:18,410
To get started, I need to look
at the log, as I just did.

196
00:12:18,830 --> 00:12:21,610
And I will need to assume
that the issue is local.

197
00:12:21,860 --> 00:12:26,350
It is happening on that
node that showed that error.

198
00:12:26,660 --> 00:12:29,370
And then I'll need to go
and scrub through the logs.

199
00:12:29,590 --> 00:12:34,400
which logs are happening just prior to
that event, which logs are happening

200
00:12:34,400 --> 00:12:36,630
just immediately after the event.

201
00:12:36,970 --> 00:12:40,300
The concept here is the
essentially proximity in time.

202
00:12:40,590 --> 00:12:44,190
Elements which happened just before
might tell me something about the reason.

203
00:12:44,610 --> 00:12:49,520
Elements which happen just immediately
after can add data for me to

204
00:12:49,850 --> 00:12:51,060
move forward with the analysis.

205
00:12:51,090 --> 00:12:53,780
There will be a chain
event that triggered.

206
00:12:54,130 --> 00:12:57,850
That were triggered just immediately
after, but they're adding information

207
00:12:57,850 --> 00:13:02,140
for me, which are valuable to
valuable for the analysis perspective

208
00:13:02,470 --> 00:13:03,790
could be an application error.

209
00:13:03,790 --> 00:13:07,000
That's coming right with it or a
resource issue or a network problem

210
00:13:07,000 --> 00:13:09,170
or whatever the challenge is.

211
00:13:09,590 --> 00:13:13,590
Now, I need to go and I need to make
sense out of it in different players.

212
00:13:13,720 --> 00:13:16,320
What happened from
infrastructure perspective?

213
00:13:16,360 --> 00:13:17,320
Was there a resource?

214
00:13:17,845 --> 00:13:20,285
Issue what happened from
an application perspective?

215
00:13:20,325 --> 00:13:24,235
Was there any sort of
authentication problem?

216
00:13:24,565 --> 00:13:27,375
Was there a network error?

217
00:13:27,385 --> 00:13:28,305
So on so forth.

218
00:13:28,515 --> 00:13:32,775
I need to essentially work my way
up from the bottom, which is the

219
00:13:32,785 --> 00:13:37,035
infrastructure and all the elements,
which I'm controlling to a certain

220
00:13:37,035 --> 00:13:39,085
extent all the way up to the application.

221
00:13:39,930 --> 00:13:45,420
Essentially, by a way of elimination,
eliminating the fact that it could be some

222
00:13:45,420 --> 00:13:50,060
sort of an infrastructure issue, hardware
infrastructure, software infrastructure,

223
00:13:50,360 --> 00:13:51,900
all the way to the application level.

224
00:13:52,200 --> 00:13:55,050
And eventually, the outcome
in that case is that type of

225
00:13:55,100 --> 00:13:58,730
troubleshooting is very cumbersome,
but it's also very time consuming.

226
00:13:59,180 --> 00:14:01,150
I need to go and test these cases.

227
00:14:01,150 --> 00:14:05,700
I need to verify my thesis, which
what I'm seeing in real life.

228
00:14:05,970 --> 00:14:09,080
And eventually, it's very similar
to a way of triangulating.

229
00:14:09,550 --> 00:14:10,050
I have.

230
00:14:10,395 --> 00:14:15,784
various points in the plane,
and I'm trying to triangulate

231
00:14:15,785 --> 00:14:17,705
to where it might start with.

232
00:14:18,625 --> 00:14:21,675
And, of course, most of the time,
especially in a Kubernetes based system,

233
00:14:21,675 --> 00:14:26,225
distributed system, the problem that
I'm seeing is just the after effect.

234
00:14:26,595 --> 00:14:31,945
The first element which I'm seeing
is not the source of the problem, but

235
00:14:31,945 --> 00:14:34,255
it's already stage two, if you will.

236
00:14:34,435 --> 00:14:38,565
I'm experiencing an issue, but there
is a neighboring node, a neighboring

237
00:14:38,565 --> 00:14:41,205
service, which is the source of all evil.

238
00:14:42,905 --> 00:14:47,895
Adding context, so what type of
contextual enrichment could be done here?

239
00:14:48,395 --> 00:14:51,715
So we said the 1st stage was
understanding the environment.

240
00:14:51,725 --> 00:14:52,845
So we understood.

241
00:14:52,845 --> 00:14:55,005
We'll look at the topology,
a real time topology.

242
00:14:55,255 --> 00:14:57,535
We understood what connected and what not.

243
00:14:57,925 --> 00:14:59,305
The 2nd stage would be.

244
00:15:00,260 --> 00:15:06,390
Starting and understanding what is
the connectivity looking what I could

245
00:15:06,390 --> 00:15:11,350
learn from that in order to move
yours, move myself move myself forward.

246
00:15:11,660 --> 00:15:16,800
What I chose to do in this case, if I'm
the front end, I'm returning an error to

247
00:15:16,800 --> 00:15:22,960
the user for a cart API, I most likely
use some sort of an internal service,

248
00:15:22,960 --> 00:15:29,155
which implement The card, so let's try and
jump forward and understand how to do it.

249
00:15:29,525 --> 00:15:29,985
Assuming.

250
00:15:30,550 --> 00:15:34,150
In this case that the issue
stems from a neighboring service.

251
00:15:34,570 --> 00:15:37,730
Let's try to understand
how we're connecting to it.

252
00:15:37,870 --> 00:15:42,010
So what I've done here, I quickly filtered
used an ability here to look at the

253
00:15:42,010 --> 00:15:47,620
APIs, which the front end is a client of,
who's the front end internally is using.

254
00:15:47,880 --> 00:15:49,810
And here is the list of API.

255
00:15:50,140 --> 00:15:52,590
I know from the log that
there was a cart issue.

256
00:15:53,000 --> 00:15:56,070
Therefore, here is the cart service.

257
00:15:56,890 --> 00:16:01,120
And if this is the cart service, It's
interesting, because I can start and

258
00:16:01,130 --> 00:16:07,060
understand what services what services
working with me, and I can now look.

259
00:16:07,450 --> 00:16:12,710
Essentially, sorry, I can look I
can look at these API's and try to

260
00:16:12,710 --> 00:16:17,710
understand if these have errors as
well, as you'll see here, which they do.

261
00:16:18,920 --> 00:16:22,500
This was a very important part
because essentially the two things

262
00:16:22,750 --> 00:16:26,290
I've cleared the front end from
being the source of the issue.

263
00:16:26,780 --> 00:16:30,700
And I've moved my, I've moved myself
to the next element in the chain.

264
00:16:31,000 --> 00:16:32,950
I know where to focus now.

265
00:16:32,950 --> 00:16:37,250
And essentially one of, once I've done
this jump, I moved to the card service.

266
00:16:38,025 --> 00:16:44,865
Another interesting aspect to incorporate
topology with is that if the topology is

267
00:16:44,895 --> 00:16:49,605
built to the point like we're seeing here,
in which we also have live feedback about

268
00:16:49,965 --> 00:16:55,625
the connectivity about the liveliness
of various layers between the element.

269
00:16:56,445 --> 00:17:00,365
I can already stop here because we
can see that the front end is going

270
00:17:00,905 --> 00:17:04,665
through that gRPC transaction that we
saw the log of to the card service.

271
00:17:05,165 --> 00:17:09,355
We can also immediately see that
the card service lost the connection

272
00:17:09,835 --> 00:17:11,975
to to the Redis card in this case.

273
00:17:12,625 --> 00:17:16,375
In that aspect, we're already
90 percent at solving the issue.

274
00:17:17,095 --> 00:17:21,405
So the important part here was how
am I incorporating various different

275
00:17:21,415 --> 00:17:26,795
views On the system in order to
not only move myself forward, but

276
00:17:26,795 --> 00:17:31,775
to also make reason around what
it's probably happening on here.

277
00:17:31,835 --> 00:17:34,885
Started from the front end
looking at the card service.

278
00:17:35,635 --> 00:17:38,105
We know that there's an error there now.

279
00:17:38,245 --> 00:17:38,535
Okay.

280
00:17:38,535 --> 00:17:39,805
It completes the picture.

281
00:17:40,140 --> 00:17:43,380
I understand where the connectivity
lost either the application

282
00:17:43,390 --> 00:17:47,710
level, networking level, or
infrastructure level have taken place.

283
00:17:48,800 --> 00:17:51,170
Common pitfalls and how to avoid them.

284
00:17:51,920 --> 00:17:55,690
We spoke about a lot of different a
lot of different strategies that we can

285
00:17:55,720 --> 00:17:59,130
take, but incomplete instrumentation.

286
00:17:59,130 --> 00:18:00,800
I want to be super clear.

287
00:18:00,970 --> 00:18:05,670
Open telemetry, distributed telemetry,
the very important part in the tool set.

288
00:18:06,030 --> 00:18:10,660
It's also a very I would say complete
strategy, or it's a very beneficial

289
00:18:10,660 --> 00:18:14,470
strategy in order to understand
problems in the level of a flow of

290
00:18:14,470 --> 00:18:19,770
a technical flow, even the message
level or the transaction level.

291
00:18:20,040 --> 00:18:25,270
But a lot of the times what I see, and I'm
most likely believe that most of you are

292
00:18:25,270 --> 00:18:27,600
seeing is that environments are partially.

293
00:18:28,460 --> 00:18:30,610
There will be element,
there will be floats.

294
00:18:30,735 --> 00:18:35,395
which are implemented or instrumented,
but there is a lot of blind spots.

295
00:18:35,595 --> 00:18:39,955
And when there is a blind spot with
instrumentation, it's very hard to

296
00:18:39,955 --> 00:18:41,875
feel, very hard to fill the gap.

297
00:18:42,305 --> 00:18:48,505
Here, eBPF will be and is a very important
element because of the ability to auto

298
00:18:48,535 --> 00:18:53,325
instrument the environment, because of the
ability to attach the existing tech stack

299
00:18:53,375 --> 00:18:59,400
and do that do that instead of going and
manually, putting putting instrumentation

300
00:18:59,410 --> 00:19:01,350
inside of the code, inside of the code.

301
00:19:01,800 --> 00:19:04,910
Another aspect, which which
is usually pitfall is the

302
00:19:04,980 --> 00:19:06,620
reliance on tribal knowledge.

303
00:19:07,130 --> 00:19:13,540
Essentially a system that has within the
code or within its history and automation

304
00:19:14,080 --> 00:19:16,530
is is is a way of blinding yourself.

305
00:19:16,790 --> 00:19:20,240
So you need to make sure that you
need to make sure that the analysis

306
00:19:20,240 --> 00:19:24,540
is taken into account previous
accounts, but that it has enough

307
00:19:24,540 --> 00:19:26,930
degree of freedom or enough new data.

308
00:19:27,550 --> 00:19:29,910
For you to to cope with new situation.

309
00:19:30,870 --> 00:19:32,980
The last one is incorrect heuristics.

310
00:19:33,220 --> 00:19:36,550
Essentially, if you're looking at a
subset of the picture, or if you're

311
00:19:36,560 --> 00:19:43,230
looking at the small, I will say through
a small hole into the system, you're

312
00:19:43,230 --> 00:19:45,701
licking the white system context.

313
00:19:46,341 --> 00:19:49,661
So troubleshooting is often
focused on a single point.

314
00:19:50,076 --> 00:19:56,446
On a single node or a single service
in which the issue was observed, but in

315
00:19:56,446 --> 00:20:00,606
most cases, that's not what's happening
in real life in distributed system.

316
00:20:01,186 --> 00:20:03,176
You will always jump to the next node.

317
00:20:03,176 --> 00:20:06,146
You will always jump to the
neighboring service and the

318
00:20:06,146 --> 00:20:08,166
root cause would most probably.

319
00:20:08,326 --> 00:20:08,806
Be there.

320
00:20:08,806 --> 00:20:11,596
It could be a node or a service
under your responsibility.

321
00:20:11,816 --> 00:20:16,036
It could be a third party or an
external service cloud service.

322
00:20:16,286 --> 00:20:20,796
So that has to be the assumption and
has to be something which is focused

323
00:20:20,806 --> 00:20:25,026
on and in mind, because that's most
likely where things are stemming

324
00:20:25,026 --> 00:20:28,966
from heaps for getting started.

325
00:20:29,466 --> 00:20:36,616
As I said, regardless of the specific
system, try and have try and have, a

326
00:20:36,616 --> 00:20:42,766
very strict process in thinking and
incorporating topology, how topology

327
00:20:42,766 --> 00:20:48,546
is coming into play, how you're
using it, not only to ramp up or to

328
00:20:48,806 --> 00:20:55,506
onboard new people or new engineers
and educate them, but also inside

329
00:20:55,506 --> 00:20:57,746
of the, or as part of the analysis.

330
00:20:58,181 --> 00:20:58,771
Process.

331
00:20:59,351 --> 00:21:00,661
How am I using topology?

332
00:21:00,681 --> 00:21:07,351
How am I gaining some sort of some sort
of reasoning or some sort of logic around

333
00:21:07,351 --> 00:21:12,991
how, what am I seeing is connected to to
the system float the use of matrix, how

334
00:21:13,021 --> 00:21:17,931
to choose the right metrics, what will be
the golden metrics, which I'm employing

335
00:21:18,011 --> 00:21:22,731
to the to the issue or to the issue
analysis and deployment, as we said, most

336
00:21:22,731 --> 00:21:27,551
likely, A lot of the time, a configuration
change or a software change is going

337
00:21:27,551 --> 00:21:31,331
to be either directly or indirectly
the reason of the reason of fault.

338
00:21:31,731 --> 00:21:36,141
So very important part in enriching
the log with context, adopting the

339
00:21:36,201 --> 00:21:39,401
layered approach, try to go bottom up.

340
00:21:40,136 --> 00:21:42,506
Is it an infrastructure node level issue?

341
00:21:43,636 --> 00:21:46,246
Is this specific service issue?

342
00:21:46,456 --> 00:21:49,976
If not using the element that
we spoke about before, what is

343
00:21:49,986 --> 00:21:51,366
the surrounding environment?

344
00:21:51,686 --> 00:21:55,956
What is the high level insight
that I could get and understand?

345
00:21:56,506 --> 00:22:00,036
Not trying to solve the issue at that
stage, but what would be the most

346
00:22:00,186 --> 00:22:04,386
logical next step to take and move
forward and continue with the analysis.

347
00:22:05,226 --> 00:22:08,026
And if, as I said, avoid
context building pitfalls.

348
00:22:08,526 --> 00:22:13,826
Considering for complete coverage or other
services that automate your topology,

349
00:22:14,126 --> 00:22:17,906
to avoid manual instrumentation and
avoid the pitfall of what's happening

350
00:22:17,906 --> 00:22:21,286
when you don't have instrumentation
end to end in the environment.

351
00:22:21,646 --> 00:22:27,716
And of course, if you've seen the elements
that we're working with, or the elements

352
00:22:27,716 --> 00:22:30,596
that we are developing, AIOps in general.

353
00:22:30,766 --> 00:22:35,916
What type of artificial pipeline or
artificial intelligence elements could

354
00:22:35,926 --> 00:22:40,086
be added to the analysis part, either
at the metric level, topology level,

355
00:22:40,096 --> 00:22:44,416
deployment level and help with the
automation of going to the root cause.

356
00:22:45,366 --> 00:22:46,736
I hope you enjoyed.

357
00:22:46,886 --> 00:22:52,186
It was a very enjoyable and a
very wonderful event for me.

358
00:22:52,646 --> 00:22:56,876
I wish you all a great day
and hopefully you'll spend.

359
00:22:57,251 --> 00:23:02,031
More time deploying new new
production environment and deploying

360
00:23:02,231 --> 00:23:06,121
new production capabilities
and spend less time analyzing.

