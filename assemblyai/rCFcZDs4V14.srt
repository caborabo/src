1
00:00:21,160 --> 00:00:24,954
Hey, everybody. My name is Zan Husson. I'm with Weaviate.

2
00:00:25,494 --> 00:00:28,918
We build an open source vector database, and I'm very excited

3
00:00:28,966 --> 00:00:32,838
for this talk. So, in this talk, I'm going to be talking about advanced retrieval,

4
00:00:32,886 --> 00:00:36,542
augmented generation techniques, advanced rack techniques,

5
00:00:36,678 --> 00:00:40,154
and the example that I'm going to be using to explain these techniques

6
00:00:40,734 --> 00:00:45,222
is a chatbot that functions as a super doctor.

7
00:00:45,358 --> 00:00:48,566
And I'll talk about what it does in just a second. But I'm

8
00:00:48,590 --> 00:00:52,134
going to be using this example to explain a lot of these advanced rag

9
00:00:52,174 --> 00:00:55,790
techniques that you could potentially use to build advanced

10
00:00:55,822 --> 00:00:59,310
chatbots for your applications as well. Okay, so let's dive right

11
00:00:59,342 --> 00:01:03,198
in. So let's talk a little bit about the average

12
00:01:03,246 --> 00:01:06,542
human doctor. The average human doctor studies for at least

13
00:01:06,598 --> 00:01:11,074
seven years after undergrad. So in North America, that's four years of studying

14
00:01:11,414 --> 00:01:14,422
during undergrad, and then seven plus years after that.

15
00:01:14,598 --> 00:01:17,966
And once they're practicing, they see about 100,000 patients in

16
00:01:17,990 --> 00:01:21,566
their entire lifetime. So if you think about what a doctor has

17
00:01:21,590 --> 00:01:24,646
to do when you go see them, you present to them some of the problems

18
00:01:24,670 --> 00:01:28,558
you're having, some of the symptoms you're having, and then they use their

19
00:01:28,606 --> 00:01:32,894
experience of similar patients they've seen, or knowledge

20
00:01:32,934 --> 00:01:36,958
that they've gained over their career or during medical school

21
00:01:37,126 --> 00:01:40,554
to present plausible diagnoses for you.

22
00:01:41,334 --> 00:01:44,830
And so what I wanted to do was I wanted to see

23
00:01:44,862 --> 00:01:48,374
if we could build a large language model or AI powered

24
00:01:48,414 --> 00:01:52,236
medical doctor or assistant to help a human doctor

25
00:01:52,380 --> 00:01:56,068
with the diagnosis that they have to perform. So if we unpack that

26
00:01:56,116 --> 00:01:59,284
statement, what would this AI powered

27
00:01:59,364 --> 00:02:01,984
super doctor have to be able to do?

28
00:02:02,404 --> 00:02:06,668
So the first thing that we need to solve this

29
00:02:06,716 --> 00:02:11,104
AI powered doctor would need to have access to a lot of patient cases.

30
00:02:11,404 --> 00:02:15,348
It would need to have access to a lot of data. Not only

31
00:02:15,396 --> 00:02:17,844
that, but it would also need to be able to search over this data.

32
00:02:17,884 --> 00:02:21,756
If you have 200, 300,000 patients worth

33
00:02:21,780 --> 00:02:25,124
of data, it's not possible for it to reason over

34
00:02:25,164 --> 00:02:28,676
all of it. You have to give it the top five or the top

35
00:02:28,740 --> 00:02:31,892
ten patients that are relevant to any new patient that you want

36
00:02:31,908 --> 00:02:35,796
to diagnose. Right? So it has to be able to search for relevant patient cases.

37
00:02:35,860 --> 00:02:39,956
And not only that, but maybe even if you give it access to medical

38
00:02:40,020 --> 00:02:43,724
literature, publications, articles, it has to be able to search over

39
00:02:43,764 --> 00:02:46,684
those and use those as well.

40
00:02:48,344 --> 00:02:51,824
Because this is a medical domain application, it has to be able to

41
00:02:51,864 --> 00:02:55,760
cite its sources. So it's not enough for it to just propose

42
00:02:55,792 --> 00:02:59,240
a diagnosis. It has to explain why it proposed that diagnosis.

43
00:02:59,352 --> 00:03:03,048
So if it's using a couple of patients to learn

44
00:03:03,096 --> 00:03:07,168
from about that disease and then diagnosing a new patient,

45
00:03:07,256 --> 00:03:10,552
it has to be able to cite that. These are the two patients that I

46
00:03:10,648 --> 00:03:14,498
read history and I saw how they were diagnosed,

47
00:03:14,546 --> 00:03:18,194
and I'm using those to propose a new diagnosis. So the system

48
00:03:18,234 --> 00:03:21,106
has to be fully explainable, otherwise it's not going to be used in the medical

49
00:03:21,170 --> 00:03:24,770
industry. Lastly,

50
00:03:24,802 --> 00:03:28,370
obviously, it has to reason over those medical technical concepts,

51
00:03:28,482 --> 00:03:31,802
so it has to be able to read over historical patient

52
00:03:31,858 --> 00:03:37,448
cases and published articles and medical writing,

53
00:03:37,546 --> 00:03:40,580
and then it has to be able to propose new or similar

54
00:03:40,652 --> 00:03:42,224
diagnoses for patients.

55
00:03:44,244 --> 00:03:47,804
And then it has to do this all in real time, right?

56
00:03:47,844 --> 00:03:50,884
So it can't. A patient comes

57
00:03:50,924 --> 00:03:53,264
to this AI powered medical doctor,

58
00:03:54,764 --> 00:03:58,836
tells it their problems, it has to propose diagnoses

59
00:03:58,900 --> 00:04:02,156
in real time, right? Or it has to propose the next step in

60
00:04:02,180 --> 00:04:05,416
real time. So we only have a few seconds

61
00:04:05,440 --> 00:04:08,744
to do all of this. So let's dive in and see

62
00:04:08,784 --> 00:04:12,704
how, how I solve this problem. So the simplest

63
00:04:12,744 --> 00:04:16,864
approach that you could potentially have is you take the patient information

64
00:04:16,984 --> 00:04:20,224
over here, and you feed it into a large language model,

65
00:04:20,264 --> 00:04:24,112
and you ask it to provide a cheat sheet

66
00:04:24,168 --> 00:04:27,504
or a list of potential diagnoses for this patient. This is literally

67
00:04:27,544 --> 00:04:30,848
the simplest thing that you could do. Literally open it, chat, GPT,

68
00:04:31,016 --> 00:04:35,044
type in patient information and say, what could potentially be wrong with this patient?

69
00:04:36,944 --> 00:04:40,136
And so here you're leaving a lot

70
00:04:40,160 --> 00:04:43,904
of things to chance, right? If the language model doesn't know anything about

71
00:04:43,944 --> 00:04:47,624
this particular patient's disease, then you're going to get irrelevant output.

72
00:04:47,784 --> 00:04:52,232
So there's definitely things that we can do to improve on this if

73
00:04:52,248 --> 00:04:55,616
we have a large language model that's fine tuned on medical data. So if we

74
00:04:55,640 --> 00:04:59,398
improve the language model for this particular domain, we'll definitely get better

75
00:04:59,446 --> 00:05:03,174
results. And also, if we

76
00:05:03,294 --> 00:05:07,086
prompt the language model properly, then we might get better results as

77
00:05:07,110 --> 00:05:11,406
well. And this has been shown in previous works where the

78
00:05:11,430 --> 00:05:14,774
difference between somebody who knows how to use a language model versus somebody

79
00:05:14,814 --> 00:05:18,758
who doesn't know how to use a language model. And by

80
00:05:18,806 --> 00:05:22,074
being able to use a language model, what I mean here is prompt engineering.

81
00:05:22,414 --> 00:05:25,470
If you know how to use a language model properly, you know how to prompt

82
00:05:25,502 --> 00:05:29,092
engineer properly, you can get these things to do really wondrous things, right?

83
00:05:29,198 --> 00:05:32,604
So that's another approach that would make this simple

84
00:05:33,064 --> 00:05:36,656
framework quite successful. But I want to see how

85
00:05:36,680 --> 00:05:38,964
we can get even better than this.

86
00:05:39,944 --> 00:05:43,520
So the next approach uses a technique called

87
00:05:43,592 --> 00:05:47,328
rag retrieval augmented generation. So I call this the rag doctor

88
00:05:47,376 --> 00:05:50,160
approach. And this works as follows.

89
00:05:50,352 --> 00:05:53,968
So what we're going to do here is when a new patient comes

90
00:05:54,016 --> 00:05:58,204
to your office, you're going to use this AI chatbot,

91
00:05:58,504 --> 00:06:02,244
and you're going to give this new patients information,

92
00:06:03,184 --> 00:06:06,600
and then you're going to retrieve relevant cases. So this vector

93
00:06:06,632 --> 00:06:09,764
database has all of the medical history

94
00:06:11,024 --> 00:06:14,392
stored inside of it. You query it with the new patient

95
00:06:14,448 --> 00:06:19,616
information, and then out comes new outcomes,

96
00:06:19,680 --> 00:06:23,050
relevant medical information over here. And then you take

97
00:06:23,082 --> 00:06:26,034
those relevant medical information along with the new patient information,

98
00:06:26,114 --> 00:06:29,774
you give it to a language model, and the language model then has to propose

99
00:06:30,114 --> 00:06:33,882
potential diagnoses. And so this is

100
00:06:33,898 --> 00:06:37,970
called a rag approach, because you're retrieving a bunch of

101
00:06:38,162 --> 00:06:41,694
historical cases that might be similar to this new patient.

102
00:06:42,154 --> 00:06:45,474
And then what you're doing is you're passing it to the language model.

103
00:06:45,514 --> 00:06:49,014
So the language model gets to read over the relevant

104
00:06:49,054 --> 00:06:53,054
cases. So this is almost a research phase where it gets to study

105
00:06:53,214 --> 00:06:56,606
previous patient cases and how they were diagnosed and what happened

106
00:06:56,630 --> 00:06:59,934
to them before. It has to reason over

107
00:06:59,974 --> 00:07:03,194
and propose a diagnosis for this new patient that we're looking at.

108
00:07:04,734 --> 00:07:07,974
And the great thing about this rag approach is that you can

109
00:07:08,014 --> 00:07:11,342
now cite sources as a result of this. Right? So the

110
00:07:11,358 --> 00:07:14,866
language model can now say, based on the information that you

111
00:07:14,890 --> 00:07:18,834
provided from this retrieval task, these are the proposed diagnoses

112
00:07:18,874 --> 00:07:22,770
for this patient that I'm providing. So it becomes an explainable

113
00:07:22,842 --> 00:07:26,434
system. So let's dive a little deeper into this rag

114
00:07:26,474 --> 00:07:30,330
doctor approach. In order to successfully

115
00:07:30,362 --> 00:07:34,306
execute this rag doctor approach, you need a lot of data. So the

116
00:07:34,330 --> 00:07:38,214
first piece of this puzzle is going to be a patient's

117
00:07:38,684 --> 00:07:41,836
data set that is open source. You can

118
00:07:41,860 --> 00:07:45,844
have a look at it here. So the PMC patients data set

119
00:07:46,004 --> 00:07:49,668
is approximately 170,000 patient summaries.

120
00:07:49,756 --> 00:07:53,052
So these have been extracted from medical literature,

121
00:07:53,188 --> 00:07:56,044
and they talk about the problem that the patient had,

122
00:07:56,164 --> 00:07:59,716
how they were diagnosed, what the solution was, so on and so forth.

123
00:07:59,900 --> 00:08:03,964
So this is a paragraph or more that's

124
00:08:04,004 --> 00:08:07,530
related to one patient, their diagnosis, and everything that they went

125
00:08:07,562 --> 00:08:11,602
through in that diagnosis. So this is a pretty complete summary

126
00:08:11,658 --> 00:08:15,414
of that patient. It also has about

127
00:08:15,754 --> 00:08:19,378
one and a half million published medical articles

128
00:08:19,506 --> 00:08:22,054
and abstracts as well.

129
00:08:23,314 --> 00:08:26,754
And so this is all taken from an external data set that's

130
00:08:26,794 --> 00:08:29,810
openly available. If you want to have a look, you can click on this link

131
00:08:29,842 --> 00:08:33,074
here. But this is all publicly released information

132
00:08:33,154 --> 00:08:37,090
that I used, and this became the

133
00:08:37,202 --> 00:08:41,410
knowledge base that my language model could retrieve from and reason over.

134
00:08:41,522 --> 00:08:44,706
So technically, all of these 1.4

135
00:08:44,770 --> 00:08:48,338
million and 170,000 patient cases the language model

136
00:08:48,386 --> 00:08:50,374
had access to to learn from.

137
00:08:51,994 --> 00:08:55,334
And so this is what that data set looks like.

138
00:08:55,754 --> 00:09:00,062
So this is going to form the basis around which we're going to build

139
00:09:00,118 --> 00:09:02,794
our AI powered super doctor.

140
00:09:03,974 --> 00:09:07,878
The next thing that we need, that's a very critical ingredient to this

141
00:09:08,006 --> 00:09:12,438
entire setup is the vector database. And vector databases essentially

142
00:09:12,486 --> 00:09:16,390
give you the search functionality over all of this data.

143
00:09:16,582 --> 00:09:20,318
We've got about 1.4 million published

144
00:09:20,366 --> 00:09:23,834
medical articles and about 170,000 patient cases.

145
00:09:24,254 --> 00:09:28,154
The large language model can't read and reason over all of these

146
00:09:28,494 --> 00:09:31,750
you have to use a search functionality to retrieve

147
00:09:31,782 --> 00:09:35,494
the most relevant articles or patient cases to

148
00:09:35,534 --> 00:09:38,974
a new patient. And then you give those limited retrieved

149
00:09:39,014 --> 00:09:41,194
articles to a language model to reason over.

150
00:09:42,014 --> 00:09:45,270
And so here the vector databases can

151
00:09:45,302 --> 00:09:49,710
potentially store billions and billions of documents, medical articles

152
00:09:49,742 --> 00:09:53,122
or patient cases. And then given when a

153
00:09:53,138 --> 00:09:57,098
new patient walks into your office, you can ask them about the problem

154
00:09:57,146 --> 00:10:00,330
that they're having and you can use their unique information as a

155
00:10:00,362 --> 00:10:03,530
query to the, to the vector database. And this vector

156
00:10:03,562 --> 00:10:06,834
database is going to perform a similarity search where you

157
00:10:06,874 --> 00:10:10,450
go in and you say that to the vector database. Here's the

158
00:10:10,482 --> 00:10:13,874
information for this new patient I have. I want you to retrieve

159
00:10:13,914 --> 00:10:18,062
for me the top five most relevant previous

160
00:10:18,158 --> 00:10:21,662
patients that you've heard of in your repository from

161
00:10:21,678 --> 00:10:25,774
the 170,000 data set that we talked about and potentially

162
00:10:25,814 --> 00:10:29,486
five medical literature articles that are related to this patient's

163
00:10:29,510 --> 00:10:33,382
case. So the vector database is now going to perform this similarity search

164
00:10:33,518 --> 00:10:36,822
for you and it's going to give you the retrieved

165
00:10:36,878 --> 00:10:40,358
articles over here. And so to serve this purpose we're going

166
00:10:40,366 --> 00:10:43,834
to use an open source vector database called Weviate

167
00:10:44,774 --> 00:10:48,274
and it's going to be able to scale up nicely for us.

168
00:10:48,814 --> 00:10:52,326
If you want to learn more about it,

169
00:10:52,350 --> 00:10:55,750
I've linked some of the docs and linked the website over here.

170
00:10:55,862 --> 00:10:59,070
You can look into that as well. So the

171
00:10:59,102 --> 00:11:02,302
usage of the vector database looks something like this in practice. Let's say

172
00:11:02,318 --> 00:11:06,094
a patient comes to you and tells you that their left shoulder hurts

173
00:11:06,134 --> 00:11:09,114
and they have numbness in their thumb and index finger.

174
00:11:09,784 --> 00:11:13,192
So you're going to go and take that query, you're going to pass it

175
00:11:13,208 --> 00:11:16,168
into the vector database and we'll talk about how this works in a second.

176
00:11:16,256 --> 00:11:19,520
But you're going to pass that into the vector database and the vector database is

177
00:11:19,552 --> 00:11:23,616
going to retrieve for you the top three other

178
00:11:23,680 --> 00:11:27,784
patient cases that it has in its knowledge base. So from that 170,000

179
00:11:27,824 --> 00:11:31,280
it's going to retrieve the top three most similar cases and it might

180
00:11:31,312 --> 00:11:35,272
even retrieve for you, if you ask it, the top three published

181
00:11:35,328 --> 00:11:39,610
medical articles that are relevant to diagnose this patient.

182
00:11:39,802 --> 00:11:43,202
So now that you have the top six relevant data points,

183
00:11:43,298 --> 00:11:46,626
these can be fed into a language model, and we'll talk about that in a

184
00:11:46,650 --> 00:11:50,178
second. Okay, so the next ingredient

185
00:11:50,226 --> 00:11:53,282
that we need here is an embedding model, right?

186
00:11:53,338 --> 00:11:57,418
So a vector database needs to be able to capture

187
00:11:57,506 --> 00:12:01,370
every single patient, case or medical article as a

188
00:12:01,402 --> 00:12:05,104
vector. And so how this works is we

189
00:12:05,144 --> 00:12:08,200
need, no matter what type of

190
00:12:08,272 --> 00:12:11,760
data you have in your vector database, it needs to be turned into a vector

191
00:12:11,792 --> 00:12:15,320
embedding over here. Right? So here I've represented a vector embedding. A vector

192
00:12:15,352 --> 00:12:19,360
embedding is just a large array of numbers, and it captures the

193
00:12:19,392 --> 00:12:22,776
meaning behind patient cases or

194
00:12:22,920 --> 00:12:25,992
articles. So in this case,

195
00:12:26,088 --> 00:12:29,664
all the 170,001.4 million articles

196
00:12:29,704 --> 00:12:34,112
are going to be turned into vectors, and you'll have 1.4

197
00:12:34,168 --> 00:12:38,136
million vectors for the articles

198
00:12:38,160 --> 00:12:41,704
and 170,000 vectors for the unique patient

199
00:12:41,744 --> 00:12:44,044
cases that you want to store in your vector database.

200
00:12:45,824 --> 00:12:49,832
And so for this, we're going to need an embedding model,

201
00:12:49,928 --> 00:12:54,364
a model that generates these vectors, that understands the medical domain.

202
00:12:56,524 --> 00:13:01,716
And so for this, we're going to use a open source medical

203
00:13:01,780 --> 00:13:05,396
domain embedding model called MedCPt. And you can access

204
00:13:05,460 --> 00:13:09,260
this at the link over here. This generates vectors for short

205
00:13:09,332 --> 00:13:13,092
texts. So we can use this to take the unique information

206
00:13:13,188 --> 00:13:17,316
for this patient. Like I showed in the other slide, I have

207
00:13:17,500 --> 00:13:21,252
pain in my left shoulder and my index and

208
00:13:21,388 --> 00:13:24,712
thumb. You can

209
00:13:24,728 --> 00:13:28,600
take that short description and you can turn that into a vector.

210
00:13:28,752 --> 00:13:32,760
Not only that, but you also have a article encoder,

211
00:13:32,872 --> 00:13:36,392
another embedding model, which can embed very large text.

212
00:13:36,448 --> 00:13:40,264
So if you have a large abstract for a medical article, or you have

213
00:13:40,424 --> 00:13:44,296
a large historical patient description, you can use this type

214
00:13:44,320 --> 00:13:48,246
of embedding model to generate vectors for your,

215
00:13:48,360 --> 00:13:51,426
for your large data set. So both

216
00:13:51,450 --> 00:13:55,226
of these are going to be very critical. And this is also from an

217
00:13:55,250 --> 00:13:59,002
open source paper, and the code is also released so you can have a look

218
00:13:59,018 --> 00:14:02,506
at that. Okay, so the next piece of the

219
00:14:02,530 --> 00:14:05,826
puzzle here. So we've talked about the vector database. We've talked about

220
00:14:05,970 --> 00:14:09,374
how the, how the data gets turned into vectors.

221
00:14:09,834 --> 00:14:13,490
We're now going to talk about the large language model.

222
00:14:13,522 --> 00:14:16,944
So for this experiments, I mainly used

223
00:14:17,324 --> 00:14:21,276
chat, GPT and GPT four as the underlying model here.

224
00:14:21,420 --> 00:14:24,900
But another open source alternative, because everything that I'm talking

225
00:14:24,932 --> 00:14:28,692
about here is open source. I wanted to present an open source alternative so that

226
00:14:28,708 --> 00:14:32,172
you could build this whole thing from scratch. And run it in a private

227
00:14:32,228 --> 00:14:35,580
environment is a biomedical domain large language model.

228
00:14:35,652 --> 00:14:39,724
So one of the more powerful biomedical large language models

229
00:14:39,884 --> 00:14:43,344
that's open source is a model called Meditron.

230
00:14:44,404 --> 00:14:48,052
So Meditron is a large language model that's fine tuned

231
00:14:48,108 --> 00:14:51,996
on a lot of medical domain data. So these can be anything

232
00:14:52,060 --> 00:14:56,148
from medical abstracts to patient, patient histories

233
00:14:56,196 --> 00:14:59,516
and things like this. So this is where the Metatron 70 billion

234
00:14:59,580 --> 00:15:03,424
comes in. Metatron 70 billion is a

235
00:15:03,724 --> 00:15:07,636
fine tuned version of Lama two from meta. And what

236
00:15:07,660 --> 00:15:10,596
they did is they basically took around 50 billion tokens,

237
00:15:10,660 --> 00:15:14,564
50 billion word pieces from the medical domain, and these come

238
00:15:14,604 --> 00:15:17,820
from published articles and patient summaries and patient doctor

239
00:15:17,852 --> 00:15:21,944
interactions. So they trained it on these 50 billion tokens

240
00:15:22,564 --> 00:15:26,972
on top of the training that Lama two got, and then

241
00:15:27,108 --> 00:15:31,356
they tried it on medical reasoning tasks. And this fine

242
00:15:31,380 --> 00:15:34,748
tuned version outperforms the base lama 270

243
00:15:34,796 --> 00:15:38,500
billion, as well as the GPT 3.5 model,

244
00:15:38,532 --> 00:15:42,668
which is significantly larger than the 70 billion parameters that this

245
00:15:42,716 --> 00:15:46,380
Meditron 70 billion has. So this is an open

246
00:15:46,412 --> 00:15:51,124
source alternative GPT four that you could potentially use to

247
00:15:51,164 --> 00:15:54,500
build this project. And not

248
00:15:54,532 --> 00:15:57,948
only was it pre trained on 50 billion tokens, it was

249
00:15:57,996 --> 00:16:01,824
also supervised fine tuned medical

250
00:16:02,484 --> 00:16:03,704
data as well.

251
00:16:05,004 --> 00:16:08,980
Okay, so that completes our entire rag stack,

252
00:16:09,052 --> 00:16:12,380
right? With this, with this type of stack,

253
00:16:12,532 --> 00:16:16,220
you now have a data set. You have a vector database that can search over

254
00:16:16,252 --> 00:16:20,104
that data set, and you have a large language model that can take those

255
00:16:21,444 --> 00:16:24,844
relevant patient cases as well as the new patient

256
00:16:24,884 --> 00:16:28,024
case and generate potential diagnoses for you.

257
00:16:28,484 --> 00:16:32,036
The question now is, can we do even better? How can we improve

258
00:16:32,100 --> 00:16:35,404
on top of this? And so the answer here is that

259
00:16:35,444 --> 00:16:38,836
we need to dive into each one of these techniques that I've talked about,

260
00:16:38,900 --> 00:16:41,504
the vector database, the retrieval, the generation,

261
00:16:41,964 --> 00:16:45,452
and we need to see if we can, if we can

262
00:16:45,468 --> 00:16:48,628
see what the problems are with them and if we can apply an advanced version

263
00:16:48,676 --> 00:16:52,556
to improve the pipeline there. So now I'll propose about three

264
00:16:52,580 --> 00:16:56,082
to four more advanced techniques, and I'll explain what the intuition

265
00:16:56,138 --> 00:16:59,706
behind all of them is. So the first thing we're

266
00:16:59,730 --> 00:17:02,974
going to talk about is a technique called query rewriting.

267
00:17:03,354 --> 00:17:07,354
And the main idea behind query rewriting is

268
00:17:07,514 --> 00:17:11,234
if a new patient comes to you and they describe for you

269
00:17:11,354 --> 00:17:14,706
all of the problems that they're having, you might not know the

270
00:17:14,730 --> 00:17:18,798
best way to search for relevant articles from a vector database,

271
00:17:18,906 --> 00:17:22,086
because you have to write the query, you might not be able to

272
00:17:22,110 --> 00:17:26,154
write the query appropriately, and you might get irrelevant results from the vector database.

273
00:17:27,014 --> 00:17:31,318
And so the idea here is we want to

274
00:17:31,446 --> 00:17:34,742
rewrite the query optimally for a

275
00:17:34,758 --> 00:17:38,134
vector database to retrieve the most relevant articles. But not only

276
00:17:38,174 --> 00:17:41,686
that, but we also want to rewrite how we prompt the language model to solve

277
00:17:41,710 --> 00:17:45,326
the problem. So we might not trust our ability

278
00:17:45,390 --> 00:17:49,162
to prompt engineer properly. So we

279
00:17:49,178 --> 00:17:52,610
want to rewrite both the query that goes to the vector database to search

280
00:17:52,682 --> 00:17:56,922
our data set, but also rewrite the prompt we give to the language model.

281
00:17:57,098 --> 00:17:59,754
And there are solutions to do both of these steps.

282
00:17:59,914 --> 00:18:03,722
The first solution here is a query rewriting

283
00:18:03,778 --> 00:18:07,410
step. So the query rewriting step allows

284
00:18:07,442 --> 00:18:11,414
you to go in and rewrite a query to the vector database.

285
00:18:11,794 --> 00:18:15,830
And the DSPY framework that's also open source allows

286
00:18:15,862 --> 00:18:19,846
you to optimally generate the prompt

287
00:18:19,910 --> 00:18:22,790
that can be given to a language model to ensure that this gives you good

288
00:18:22,822 --> 00:18:25,998
results. So the first thing that we're going to do is

289
00:18:26,046 --> 00:18:29,478
rewrite the query to the vector database. So initially

290
00:18:29,526 --> 00:18:33,054
this was our query that we sent to the vector database. My left shoulder hurts

291
00:18:33,094 --> 00:18:36,462
and I have numbness in my thumb and index finger. This is what the patient

292
00:18:36,518 --> 00:18:39,886
told you. So that's what you try to retrieve articles with. And this is what

293
00:18:39,910 --> 00:18:43,252
that framework looks like, right. We're now going to modify this and

294
00:18:43,268 --> 00:18:46,772
we're going to pass this through a language model.

295
00:18:46,868 --> 00:18:50,620
And the language model's job is to rewrite the query so

296
00:18:50,652 --> 00:18:54,444
that our vector database can understand it better. So maybe

297
00:18:54,484 --> 00:18:57,604
it rewrites this query into this version, so it

298
00:18:57,684 --> 00:19:01,572
kind of chunks it up into smaller sentences and it says

299
00:19:01,708 --> 00:19:05,184
pain, left shoulder, numbness thumb, numbness, index finger.

300
00:19:05,764 --> 00:19:09,056
And so this is less understandable to a human, but maybe this

301
00:19:09,080 --> 00:19:13,112
is more understandable to a vector search engine like we

302
00:19:13,248 --> 00:19:16,640
vector database. So it optimizes the query

303
00:19:16,752 --> 00:19:20,136
to be understood by the vector database. And this is going

304
00:19:20,160 --> 00:19:22,164
to help us retrieve more relevant cases.

305
00:19:23,184 --> 00:19:26,520
Not only that, but we're also going to rewrite the prompt that

306
00:19:26,552 --> 00:19:30,144
we give to our language model. So DSPY is

307
00:19:30,184 --> 00:19:34,304
a framework that allows you to optimize and generate

308
00:19:34,724 --> 00:19:37,972
prompts for a large language model by

309
00:19:38,028 --> 00:19:41,884
iterative search. So we can also use this open source

310
00:19:42,004 --> 00:19:45,812
framework to identify

311
00:19:45,868 --> 00:19:49,508
what the best way to prompt a language model to generate a diagnosis is

312
00:19:49,556 --> 00:19:52,748
as well. Okay, so that's our first

313
00:19:52,876 --> 00:19:56,460
technique. We admit that we don't know how to query

314
00:19:56,492 --> 00:20:00,436
a vector database properly and we don't know how to prompt a language model appropriately.

315
00:20:00,540 --> 00:20:04,344
So we use language models to solve those tasks for us as well.

316
00:20:05,884 --> 00:20:09,740
Okay, so the next technique that I'm going to talk about is called hybrid

317
00:20:09,772 --> 00:20:13,276
search. So the idea behind hybrid search is

318
00:20:13,300 --> 00:20:16,784
that if you are searching over medical data,

319
00:20:17,124 --> 00:20:20,340
medical data has a lot of very specific keywords

320
00:20:20,372 --> 00:20:23,636
that you might be interested in. They could be names

321
00:20:23,660 --> 00:20:26,744
of diseases, they could be names of medicine,

322
00:20:27,264 --> 00:20:30,816
they could be chemical compounds. There's very specific

323
00:20:30,880 --> 00:20:34,168
keywords that you want to pay respect to and use

324
00:20:34,296 --> 00:20:37,776
in the field of medicine. A lot

325
00:20:37,800 --> 00:20:41,032
of the search that we've been talking about and how a

326
00:20:41,048 --> 00:20:44,992
vector database retrieves and knows what articles out of these millions

327
00:20:45,008 --> 00:20:48,684
of articles are relevant for this patient are based on similarity.

328
00:20:49,184 --> 00:20:52,344
How similar is what you tell me about this patient to the patient

329
00:20:52,384 --> 00:20:55,564
cases I have here. But for medical domain,

330
00:20:55,604 --> 00:20:59,220
this might not be the best type of search. You might want to

331
00:20:59,252 --> 00:21:03,020
search over the words in those patient cases, right? So if a

332
00:21:03,052 --> 00:21:06,564
patient was given a particular type of drug and this

333
00:21:06,604 --> 00:21:10,544
patient says that they're also taking that type of drug, then there's a match.

334
00:21:11,324 --> 00:21:14,492
I don't necessarily need to understand exactly what that drug is.

335
00:21:14,588 --> 00:21:18,704
If I can do a simple keyword matching, that might be good enough.

336
00:21:19,004 --> 00:21:22,120
So the idea behind hybrid search is why don't

337
00:21:22,152 --> 00:21:26,284
we mix vector search and keyword search and we do a little bit of both.

338
00:21:26,824 --> 00:21:30,408
And so the idea here is we want to search

339
00:21:30,496 --> 00:21:33,840
not just over the meaning and the problems that this patient is

340
00:21:33,872 --> 00:21:37,624
having, but also the keywords that are used in their description.

341
00:21:37,744 --> 00:21:42,040
So maybe numbness or the type of medication they're on or

342
00:21:42,192 --> 00:21:46,152
index finger, things like this that match well with medical literature

343
00:21:46,208 --> 00:21:49,826
and medical lingo. And so in

344
00:21:49,850 --> 00:21:53,466
hybrid search, you perform both vector search as

345
00:21:53,490 --> 00:21:56,658
well as keyword search, and then you mix the results together

346
00:21:56,746 --> 00:21:59,774
so that you get the best of both worlds and you can re rank them.

347
00:22:00,354 --> 00:22:03,602
And so if we're talking about how to implement this in

348
00:22:03,618 --> 00:22:06,994
Weaviate, it's literally one line of code that you have to

349
00:22:07,034 --> 00:22:10,618
change. And you go from doing pure vector search to a hybrid

350
00:22:10,666 --> 00:22:14,030
search of vector and keyword. So the

351
00:22:14,102 --> 00:22:18,514
third approach that we're going to use here, the third advanced retrieval augmented generation

352
00:22:19,254 --> 00:22:23,710
technique, is called autocut. And the idea behind autocut

353
00:22:23,822 --> 00:22:27,694
is if you do a search and you get irrelevant

354
00:22:27,734 --> 00:22:31,198
results from the vector database, then what you want to do is rather

355
00:22:31,246 --> 00:22:34,502
than give that to the language model and confuse it further, you want

356
00:22:34,518 --> 00:22:37,474
to cut off those results, right? You just want to throw them away.

357
00:22:38,374 --> 00:22:42,674
And so how you can potentially do this is you retrieve

358
00:22:42,714 --> 00:22:46,722
from the vector database relevant articles, and each article has some sort

359
00:22:46,738 --> 00:22:50,234
of number of how similar this article

360
00:22:50,314 --> 00:22:51,894
is to your patient information.

361
00:22:53,674 --> 00:22:57,122
And then you look over this and you say, okay, the top three return results

362
00:22:57,178 --> 00:23:01,242
are very similar, but the fourth and fifth are very

363
00:23:01,378 --> 00:23:04,586
unsimilar. Right. They're very far away compared to the top three

364
00:23:04,610 --> 00:23:08,222
results. So then you automatically cut them out and you never pass it

365
00:23:08,338 --> 00:23:11,782
over to your language model. And so

366
00:23:11,838 --> 00:23:15,462
if you do do this, if you do this automatic cutting of irrelevant results,

367
00:23:15,638 --> 00:23:19,286
it's less likely that your language model gets irrelevant results and

368
00:23:19,390 --> 00:23:23,014
it's less likely that it hallucinates as well. And so you're giving

369
00:23:23,054 --> 00:23:26,734
it better information to set it up for successful diagnostic

370
00:23:26,774 --> 00:23:30,470
generation later on. And so I want to dive into how this actually

371
00:23:30,542 --> 00:23:34,374
works. So let's say you start off with this vector database

372
00:23:34,414 --> 00:23:37,830
query that we talked about that is now rewritten. Notice pain,

373
00:23:37,862 --> 00:23:41,862
left shoulder numbness, thumb numbness, numbness, index finger

374
00:23:41,998 --> 00:23:45,238
that goes into your vector database and the vector database.

375
00:23:45,286 --> 00:23:49,286
Now let's say it gives you these six

376
00:23:49,350 --> 00:23:52,646
patient cases and not only is it going to give

377
00:23:52,670 --> 00:23:56,598
you these six patient cases, it's also going to give you a number of how

378
00:23:56,646 --> 00:23:59,798
similar these patient cases are to your input patient

379
00:23:59,846 --> 00:24:03,270
case. And each one is going to have a score. The higher

380
00:24:03,302 --> 00:24:06,686
the score, the more similar it is, the better. But notice one thing

381
00:24:06,710 --> 00:24:10,760
about these scores. These top four returned

382
00:24:10,792 --> 00:24:15,136
patient cases are quite similar, right? They have high similarity scores.

383
00:24:15,280 --> 00:24:18,560
But the fifth and the 6th one here are, there's a big

384
00:24:18,592 --> 00:24:21,824
jump in similarity. So autocut is going to come

385
00:24:21,864 --> 00:24:25,592
in and just say I'm automatically going to cut these two cases because

386
00:24:25,648 --> 00:24:28,880
they're quite different from these other four cases. And these other

387
00:24:28,912 --> 00:24:32,328
four cases are quite similar to the thing that you're interested in. So that's why

388
00:24:32,336 --> 00:24:36,196
it's called autocutter. And again, if you want to implement this,

389
00:24:36,300 --> 00:24:39,796
this is literally just one line of code in

390
00:24:39,820 --> 00:24:43,604
your v eight vector database where you can say how many chunks of

391
00:24:43,644 --> 00:24:47,236
similar things are you interested in? If you're interested in one similar thing,

392
00:24:47,340 --> 00:24:51,524
then it's going to give you one big chunk here of four articles

393
00:24:51,644 --> 00:24:55,468
and then you only keep those, the other two are disposed of

394
00:24:55,556 --> 00:24:56,704
in this example.

395
00:24:59,984 --> 00:25:03,656
Okay? And so the, the next thing that I'm going to talk about is

396
00:25:03,680 --> 00:25:07,324
called re ranking. And the idea behind re ranking is

397
00:25:07,744 --> 00:25:11,792
you've went through this search process and you've retrieved the most

398
00:25:11,848 --> 00:25:15,976
similar other patient cases to this new patient. What you

399
00:25:16,000 --> 00:25:20,928
want to do now is have a closer look into

400
00:25:21,016 --> 00:25:24,692
all of these other patient cases that have been retrieved and

401
00:25:24,888 --> 00:25:29,144
compare them one at a time to the input patient information and say,

402
00:25:29,524 --> 00:25:32,940
does this really deserve the top spot? Should I re rank it

403
00:25:32,972 --> 00:25:35,852
to be lower or should I re rank something that's at the bottom to be

404
00:25:35,868 --> 00:25:39,504
a little higher? So this is the time where you get

405
00:25:40,044 --> 00:25:43,508
to spend more, compute more

406
00:25:43,556 --> 00:25:47,564
time comparing the new patient to all of the

407
00:25:47,644 --> 00:25:51,124
retrieved patients that the vector database spat

408
00:25:51,164 --> 00:25:54,600
out. And so what you do to make this

409
00:25:54,632 --> 00:25:57,520
successful is initially you tell the vector database,

410
00:25:57,592 --> 00:26:00,824
instead of just giving me the top three most similar matching cases,

411
00:26:00,984 --> 00:26:04,424
give me 20, 30, 40 cases that you think

412
00:26:04,464 --> 00:26:08,400
are similar. And then you

413
00:26:08,472 --> 00:26:12,352
compare this new patient to each one of those 20,

414
00:26:12,408 --> 00:26:15,472
30, 40 cases that the vector database thinks are similar.

415
00:26:15,608 --> 00:26:20,244
But now you use a much more powerful and heavier machine

416
00:26:20,284 --> 00:26:24,060
learning model to re rank them based on what it thinks

417
00:26:24,172 --> 00:26:27,412
of these 30, 40 articles compared to this patient

418
00:26:27,468 --> 00:26:32,044
information. And so this again increases

419
00:26:32,084 --> 00:26:35,556
the quality of the output that we, that we're going to eventually

420
00:26:35,620 --> 00:26:39,476
pass to our large language model. So let's have a look at how this actually

421
00:26:39,540 --> 00:26:43,188
works. We go into our vector database,

422
00:26:43,236 --> 00:26:47,180
we take that query that we've already been passing into the vector database and

423
00:26:47,212 --> 00:26:50,084
now let's say we do this over fetching.

424
00:26:50,384 --> 00:26:53,784
We ask it to retrieve for us the top ten or 15

425
00:26:53,944 --> 00:26:57,792
most similar patient cases. So it gives us this long laundry

426
00:26:57,848 --> 00:27:01,520
list of similar patient cases along with the similarity scores for

427
00:27:01,552 --> 00:27:02,764
all of these patients.

428
00:27:04,304 --> 00:27:07,888
So now what we do is we ignore these similarity

429
00:27:07,936 --> 00:27:11,680
scores and we say we're going to go

430
00:27:11,712 --> 00:27:15,196
to another more powerful model. And the job of that model

431
00:27:15,260 --> 00:27:18,604
is to see how similar each one of these patient

432
00:27:18,644 --> 00:27:21,700
cases is to the original query. And it has the

433
00:27:21,732 --> 00:27:25,668
opportunity to re rank and kind of promote or demote

434
00:27:25,716 --> 00:27:29,316
some of these patient cases if it thinks that they're more similar or

435
00:27:29,380 --> 00:27:32,988
not as similar. So less similar using

436
00:27:33,036 --> 00:27:36,756
its more advanced re

437
00:27:36,780 --> 00:27:39,624
ranking and search functionality.

438
00:27:40,724 --> 00:27:44,436
So you get this re ranking step where now maybe the third

439
00:27:44,500 --> 00:27:48,196
most similar patient case, this more powerful model thought, oh, that is

440
00:27:48,220 --> 00:27:51,148
actually a lot more similar. So it's going to re rank it to be number

441
00:27:51,196 --> 00:27:54,516
one, right. It's going to take the first one and it's going to down rank

442
00:27:54,540 --> 00:27:58,260
it to spot three over here and it's going to promote number five here

443
00:27:58,292 --> 00:28:02,036
to number two. So now the idea is that these re

444
00:28:02,060 --> 00:28:05,990
ranked patient cases are a lot more similar

445
00:28:06,062 --> 00:28:09,914
to the initial query than these initially retrieved cases.

446
00:28:10,694 --> 00:28:14,702
And so the new score is a lot more reliable because a more powerful model

447
00:28:14,758 --> 00:28:18,262
generated this score for you. And now we can take

448
00:28:18,398 --> 00:28:21,662
these results, maybe the top five or top six here and give it to a

449
00:28:21,678 --> 00:28:25,366
language model. So now it has a better quality of patient cases that are

450
00:28:25,390 --> 00:28:29,434
relevant to this new patient and so it can generate better diagnoses.

451
00:28:30,054 --> 00:28:33,344
And so to implement this in a vector database like weviate,

452
00:28:33,454 --> 00:28:36,620
this is also just one line of code where you pass in and you say,

453
00:28:36,732 --> 00:28:40,604
I want to re rank based on a particular property,

454
00:28:40,724 --> 00:28:44,348
and the query is a string, and you can pass it in,

455
00:28:44,516 --> 00:28:48,292
and it's going to take everything that was returned from this semantic

456
00:28:48,388 --> 00:28:52,388
near text search, and it's going to re rank it and then pass it

457
00:28:52,556 --> 00:28:56,796
out to the language model. Okay, so we talked

458
00:28:56,820 --> 00:29:00,452
about the retrieval augmented generation stack,

459
00:29:00,508 --> 00:29:04,020
the rag doctor approach, and then I proposed four improvements,

460
00:29:04,092 --> 00:29:07,596
more advanced retrieval augmented generation techniques that you can kind

461
00:29:07,620 --> 00:29:10,876
of use to improve the quality of the

462
00:29:10,900 --> 00:29:14,276
superdoctor that we've created here. And so let's

463
00:29:14,300 --> 00:29:17,144
do a little quick summary of everything that we've accomplished.

464
00:29:17,884 --> 00:29:21,464
We've basically created an AI based super doctor assistant.

465
00:29:22,524 --> 00:29:26,476
This super doctor assistant has access to more knowledge than

466
00:29:26,540 --> 00:29:30,532
pretty much any doctor has experience

467
00:29:30,628 --> 00:29:34,246
from, so they can retrieve from more than any

468
00:29:34,310 --> 00:29:37,478
human doctor can. It can also

469
00:29:37,526 --> 00:29:41,254
propose plausible diagnoses, and not only that, but it can also source

470
00:29:41,294 --> 00:29:44,662
citations. It can tell you why it's proposing

471
00:29:44,838 --> 00:29:48,766
somebody has a viral infection or somebody has

472
00:29:48,950 --> 00:29:52,718
heart disease based on historical patient cases that it's

473
00:29:52,766 --> 00:29:55,394
read and reasoned over.

474
00:29:56,954 --> 00:30:00,794
And so it can learn from previous patterns in

475
00:30:00,834 --> 00:30:04,346
patient health and use those patterns to propose future

476
00:30:04,410 --> 00:30:08,634
diagnoses for new patients and to

477
00:30:08,714 --> 00:30:11,818
kind of complete it all up. It does this in real time.

478
00:30:11,946 --> 00:30:15,690
So it does this in a few seconds because the vector

479
00:30:15,722 --> 00:30:19,154
database search component takes a few milliseconds, and the

480
00:30:19,194 --> 00:30:22,986
generation portion takes maybe half a

481
00:30:23,010 --> 00:30:26,324
second a second. And so this can be done in real time.

482
00:30:26,364 --> 00:30:29,944
You can literally have a patient walk into your office, the doctor

483
00:30:31,124 --> 00:30:34,700
takes their symptoms, understands them, passes them off

484
00:30:34,732 --> 00:30:38,588
into the superdoctor chatbot assistant. The super

485
00:30:38,636 --> 00:30:42,428
doctor proposes some diagnosis, the doctor thinks about some diagnosis,

486
00:30:42,516 --> 00:30:45,700
and then these diagnoses come together to

487
00:30:45,732 --> 00:30:48,996
have a much more well informed diagnosis for

488
00:30:49,020 --> 00:30:52,444
that patient. And so that comes

489
00:30:52,524 --> 00:30:55,780
complete, full circle. We've talked about the entire stack of

490
00:30:55,812 --> 00:30:59,180
how you would build this technology. And the plus point

491
00:30:59,212 --> 00:31:02,356
here is that everything that I've talked about in this entire talk

492
00:31:02,420 --> 00:31:05,980
is open source. The language model, the vector database,

493
00:31:06,092 --> 00:31:10,044
the retriever, the re ranker, the auto cut. Every single thing

494
00:31:10,204 --> 00:31:13,916
I've linked and sourced as well is fully open source.

495
00:31:13,940 --> 00:31:17,386
So if you wanted, you could build this tomorrow as well. All right,

496
00:31:17,490 --> 00:31:20,850
so I wanted to thank everybody here. I was really

497
00:31:20,882 --> 00:31:24,186
excited to give this talk. If you're interested in this, check us out.

498
00:31:24,330 --> 00:31:27,802
There's a QR code that you can use here as well. And if

499
00:31:27,818 --> 00:31:31,090
you have any questions, feel free to connect with me either on

500
00:31:31,122 --> 00:31:34,562
Twitter or LinkedIn. I would be more than happy to

501
00:31:34,618 --> 00:31:37,970
talk to all of you. I'm also active on the Wev

502
00:31:38,002 --> 00:31:41,410
eight community slack, so join us there,

503
00:31:41,482 --> 00:31:45,126
drop by. Thank you very much and I'll leave you

504
00:31:45,150 --> 00:31:49,014
guys with this last QR code here. So if you want to try

505
00:31:49,054 --> 00:31:52,422
this out, give it

506
00:31:52,438 --> 00:31:55,926
a go. Weviate is open source. We also provide free

507
00:31:56,110 --> 00:31:59,502
hosted services as well. Thanks everybody and hope you're

508
00:31:59,518 --> 00:32:00,094
enjoying the conference.

