1
00:00:21,680 --> 00:00:24,958
Hello, everyone. My name is Oper Mendeleevic, and I head

2
00:00:25,006 --> 00:00:28,758
developer relations at Viktar. Today I'm going to talk about measuring

3
00:00:28,806 --> 00:00:32,622
hallucinations in rag or retrieval augmented generation.

4
00:00:32,798 --> 00:00:36,846
A little bit about myself. I've been with Victor for about a year, and I

5
00:00:36,870 --> 00:00:40,774
had the opportunity to work on lms kind of early on, since the times

6
00:00:40,814 --> 00:00:44,318
of GPT-2 it's been an incredible journey for me to see

7
00:00:44,366 --> 00:00:47,670
how this technology evolved to become so useful and

8
00:00:47,702 --> 00:00:51,486
help us be more productive. And,

9
00:00:51,550 --> 00:00:54,526
you know, I truly believe what's kind of stated in this slide,

10
00:00:54,590 --> 00:00:58,514
which is the LLM and the generative AI revolution in

11
00:00:58,554 --> 00:01:02,626
general is really important. And within five years,

12
00:01:02,650 --> 00:01:05,626
we'll see a transformation of all applications,

13
00:01:05,810 --> 00:01:09,146
from consumer to enterprise. And every piece of knowledge we

14
00:01:09,170 --> 00:01:12,442
acquire will have the ability to be based

15
00:01:12,538 --> 00:01:15,850
in this generative AI interface. So we'll be able

16
00:01:15,882 --> 00:01:19,730
to interact with computers in a way that's very different than what we do today.

17
00:01:19,882 --> 00:01:23,398
To me, this is a little bit like the transformation we've seen

18
00:01:23,446 --> 00:01:27,638
with the iPhones when they came out, a very different user interface. You can swipe,

19
00:01:27,686 --> 00:01:31,326
you can use your hands, you can use your fingers instead of the keyboard

20
00:01:31,350 --> 00:01:35,134
and the mouse. It's that level of transformation. Now with

21
00:01:35,174 --> 00:01:38,766
that, you know, as I interact with customers

22
00:01:38,790 --> 00:01:41,558
of Vectara, I see a lot of different use cases, and I want to share

23
00:01:41,606 --> 00:01:44,734
some of those with you. We have use cases around

24
00:01:44,814 --> 00:01:48,494
chatbots, very popular. For example, for customer

25
00:01:48,574 --> 00:01:52,474
support, you can put a chatbot that's based on llms

26
00:01:52,634 --> 00:01:56,530
to answer customer questions. There's a lot of question answering

27
00:01:56,602 --> 00:02:00,218
applications that are very useful. And I'll show a couple of examples

28
00:02:00,266 --> 00:02:03,162
here today. Product recommendations. Again,

29
00:02:03,218 --> 00:02:06,922
using the latest in LM and NLP capabilities to

30
00:02:06,938 --> 00:02:11,074
do recommendation engines. Semantic search, kind of

31
00:02:11,154 --> 00:02:14,934
moving away from the traditional keyword search to do a better search experience,

32
00:02:15,324 --> 00:02:17,264
workplace search, and many others.

33
00:02:18,844 --> 00:02:21,860
Now, one of the problems with LMS, at least today,

34
00:02:21,972 --> 00:02:25,468
is that they still hallucinate. And what that means is hallucination

35
00:02:25,556 --> 00:02:29,836
is when the LLM can actually give you a good response

36
00:02:29,940 --> 00:02:33,188
that looks very authentic and looks very convincing,

37
00:02:33,316 --> 00:02:37,100
but it's actually wrong. And this is one of my favorite examples here. Did Will

38
00:02:37,132 --> 00:02:40,770
Smith ever hit anyone you ask? GPT 3.5 that,

39
00:02:40,892 --> 00:02:45,358
and it gives you this response. No, you know, Will Smith is a decent guy.

40
00:02:45,526 --> 00:02:49,038
No known assault incidents, etcetera.

41
00:02:49,166 --> 00:02:52,918
And of course, we all know that's wrong, because this is really what happened

42
00:02:53,046 --> 00:02:56,830
in the oscars about two years ago. So, you know, that's an example

43
00:02:56,862 --> 00:03:00,462
of hallucination. And there's a lot of hallucinations. And the question

44
00:03:00,518 --> 00:03:04,062
is, you know, how can we avoid, and how can we reduce

45
00:03:04,198 --> 00:03:07,562
the amount of hallucinations to make the end application

46
00:03:07,618 --> 00:03:11,258
for the user much better? So one of

47
00:03:11,266 --> 00:03:14,634
the ways you address hallucination is with Rag, and that's what made rag

48
00:03:14,674 --> 00:03:19,082
so popular. So rag stands for retrieval augmented generation.

49
00:03:19,258 --> 00:03:22,594
Let me walk you through how that works at a really high

50
00:03:22,634 --> 00:03:25,946
level. So the idea behind rag is that you actually

51
00:03:26,050 --> 00:03:30,018
augment the information that the LM has with some other

52
00:03:30,066 --> 00:03:34,440
information. So it could be other public information, but in enterprise context,

53
00:03:34,552 --> 00:03:38,704
often it is just some private information that only exists within the firewall

54
00:03:38,744 --> 00:03:42,872
of the organization or your enterprise. So if an LM regularly

55
00:03:42,928 --> 00:03:46,432
takes a user query, you know, thinks about it for a while, and gets

56
00:03:46,448 --> 00:03:49,684
you a response that's only based on its internal knowledge.

57
00:03:50,104 --> 00:03:52,444
With retrieval augmented generation,

58
00:03:53,144 --> 00:03:56,968
what you do is you, the LM, you know, holds for a second and

59
00:03:57,016 --> 00:04:00,756
asks a state of the art retrieval engine to look

60
00:04:00,780 --> 00:04:04,324
at the data you provided and come up with relevant

61
00:04:04,404 --> 00:04:07,788
pieces of text or chunks or facts that

62
00:04:07,876 --> 00:04:12,116
the ELM could use to augment its internal knowledge base and answer

63
00:04:12,220 --> 00:04:16,212
more accurately. And so, again, use cases

64
00:04:16,268 --> 00:04:19,636
for that include question answering and chatbots, like I mentioned

65
00:04:19,660 --> 00:04:23,724
earlier. And it's become a very common and very useful

66
00:04:23,764 --> 00:04:25,984
application in the enterprise setting.

67
00:04:27,624 --> 00:04:31,072
Now, I apologize for this busy slide, but I wanted to share with you

68
00:04:31,128 --> 00:04:34,968
a little bit of how Reg is built when you actually

69
00:04:35,016 --> 00:04:38,752
want to build it yourself and do all the steps on

70
00:04:38,768 --> 00:04:42,240
your own. So on the blue arrow here,

71
00:04:42,432 --> 00:04:46,368
I walk through the data ingest flow. So initially

72
00:04:46,416 --> 00:04:50,104
you have some data, that's your data described earlier. I could be in

73
00:04:50,184 --> 00:04:53,072
a database, like in Microsoft database,

74
00:04:53,128 --> 00:04:56,728
MSQL could be in AWS, redshift, or snowflake,

75
00:04:56,776 --> 00:05:00,640
or databricks. It could also come from enterprise applications

76
00:05:00,712 --> 00:05:04,576
like Jira or notion or something like that.

77
00:05:04,720 --> 00:05:07,672
And very often it's just a bunch of files. It could be PDF files,

78
00:05:07,728 --> 00:05:11,296
or PowerPoint, or documents of different kinds on

79
00:05:11,320 --> 00:05:16,200
s three, or just on a different platform, like box or Dropbox.

80
00:05:16,392 --> 00:05:21,728
And you sort of ingest the data first into the

81
00:05:21,776 --> 00:05:26,506
system. And so the first thing you need to do is to take the document

82
00:05:26,570 --> 00:05:30,490
in its original form, let's say it's a PDF, and extract the text

83
00:05:30,562 --> 00:05:34,134
part in a document. So turning it from a binary to a text,

84
00:05:34,594 --> 00:05:38,402
another text, could be really long, so very common. You chunk it into

85
00:05:38,458 --> 00:05:41,938
smaller chunks. So a chunk could be a page, or it could be

86
00:05:42,026 --> 00:05:45,618
three paragraphs, or two sentences, or a lot of different strategies

87
00:05:45,666 --> 00:05:49,346
around that. And I encourage you to read more about this. If you're

88
00:05:49,370 --> 00:05:53,606
building that, there's a lot of different ways to chunk text that actually impacts

89
00:05:54,106 --> 00:05:57,650
their performance pretty significantly. By the way, before I move

90
00:05:57,682 --> 00:06:01,138
on, I want to mention, I'm mentioning a couple of different vendors or

91
00:06:01,186 --> 00:06:05,054
product names you can use to do any of these steps. That's just

92
00:06:05,554 --> 00:06:08,770
a small list, it's not comprehensive. I just wanted to mention a couple of

93
00:06:08,802 --> 00:06:12,442
options for everybody. Once you finish with the chunking,

94
00:06:12,618 --> 00:06:15,858
you go and you embed each chunk. What does embedding mean?

95
00:06:15,906 --> 00:06:19,692
It's a model. It's a different model than your GPT four.

96
00:06:19,818 --> 00:06:23,324
It's called an embedding model. And what it is, it takes this text

97
00:06:23,784 --> 00:06:27,664
and it translates it into a vector of numbers.

98
00:06:27,704 --> 00:06:31,016
Think, you know, 1000 floats. And that

99
00:06:31,040 --> 00:06:34,568
vector of number really represents in this embedding

100
00:06:34,616 --> 00:06:37,840
vector space the semantic meaning in

101
00:06:37,872 --> 00:06:40,976
that text and which is going to be used for neural search

102
00:06:41,000 --> 00:06:44,296
later on. So you take this vector and you put it in something that's called

103
00:06:44,320 --> 00:06:47,890
a vector database or a vector store which knows how to

104
00:06:47,962 --> 00:06:51,818
handle these vectors and searches vectors really well. Again, there's many,

105
00:06:51,866 --> 00:06:54,374
many options here. I'm mentioning just a few.

106
00:06:55,034 --> 00:06:58,498
Okay, so now that you have the text here and the vector

107
00:06:58,546 --> 00:07:01,946
here, you're ready to do the actual search. So let's go through

108
00:07:01,970 --> 00:07:05,330
the user query journey. So again, there's some user

109
00:07:05,362 --> 00:07:09,002
interface, some application where user has a box

110
00:07:09,058 --> 00:07:13,250
to enter their query. You enter the query and

111
00:07:13,362 --> 00:07:17,086
again the query also gets embedded. So there's a vector representing

112
00:07:17,110 --> 00:07:20,862
what the query is and what its semantic intent is.

113
00:07:21,038 --> 00:07:24,678
And then you run this against this retrieval engine. And the

114
00:07:24,686 --> 00:07:28,550
retrieval engine looks at the vector store, retrieves the most relevant

115
00:07:28,622 --> 00:07:32,502
matches of what was indexed before, and retrieves that

116
00:07:32,598 --> 00:07:36,238
the text back into here as the facts or

117
00:07:36,246 --> 00:07:39,550
the candidates, those get integrated into a prompt

118
00:07:39,702 --> 00:07:42,968
that essentially says something like hey,

119
00:07:43,016 --> 00:07:46,960
here's a user query and here's some facts that can help you address

120
00:07:47,032 --> 00:07:50,880
this query. Please respond to this query in the best way possible.

121
00:07:51,032 --> 00:07:54,792
Given these facts, you send it to an LLM like a GPT four

122
00:07:54,848 --> 00:07:58,392
or anthropic clod or something else lama two

123
00:07:58,448 --> 00:08:02,312
or anything else, and then the response gets sent

124
00:08:02,368 --> 00:08:05,728
back to the user. There's also an option here. You can actually

125
00:08:05,856 --> 00:08:09,324
look at the response, especially in the enterprise context. And sometimes

126
00:08:09,444 --> 00:08:13,300
I use products like guardrails that essentially make

127
00:08:13,332 --> 00:08:16,796
sure inappropriate content does not get back to be shown to the

128
00:08:16,820 --> 00:08:20,692
user. Now I kind of didn't mention the red arrow that much, but the

129
00:08:20,708 --> 00:08:24,140
Red Arrow represents action. What I mean by that is sometimes

130
00:08:24,172 --> 00:08:27,308
in the application you don't just show the response to the user,

131
00:08:27,436 --> 00:08:31,260
you also do something with it. You want to open a Jira ticket with

132
00:08:31,292 --> 00:08:34,564
this information, you want to send it in an email, etcetera. So those are all

133
00:08:34,604 --> 00:08:37,960
options. You have the end of this process. All right,

134
00:08:37,992 --> 00:08:41,392
so this is how do it yourself rag

135
00:08:41,448 --> 00:08:44,688
works. And as you can see, it's quite complex and there's a

136
00:08:44,696 --> 00:08:47,872
lot of steps you have to take, a lot of systems you have to set

137
00:08:47,928 --> 00:08:51,408
up. There's a cost to each of these systems. You have to have your DevOps

138
00:08:51,456 --> 00:08:54,752
and your machine learning engineer and you have

139
00:08:54,768 --> 00:08:58,152
to maintain these systems. And especially when you go from one or

140
00:08:58,168 --> 00:09:02,088
two or ten documents to a million documents in a really enterprise

141
00:09:02,136 --> 00:09:05,446
scale application, it becomes quite difficult

142
00:09:05,550 --> 00:09:09,150
to do this. So that's why at Vektara, what we've created is

143
00:09:09,182 --> 00:09:12,606
this rag as a service. And what we mean by that is we've

144
00:09:12,630 --> 00:09:15,998
taken all the complexity and put it in a box, kind of

145
00:09:16,126 --> 00:09:19,726
behind an API. So all you have to do with Vectara is you

146
00:09:19,750 --> 00:09:22,926
essentially index the text or the documents you want.

147
00:09:23,070 --> 00:09:26,470
We'll do all the extraction and the chunking and the vector store and

148
00:09:26,502 --> 00:09:30,266
everything that I've just shown you. And then you can also have

149
00:09:30,290 --> 00:09:34,290
an application called the query API. It will do all the matching

150
00:09:34,322 --> 00:09:38,330
and retrieval and everything like this, and give you back the response. So this

151
00:09:38,362 --> 00:09:41,522
makes building reg applications very easy,

152
00:09:41,658 --> 00:09:45,018
very fast, it's robust, can scale up and down,

153
00:09:45,186 --> 00:09:49,778
it's secure, it's got all the different encryption and everything you need for enterprise,

154
00:09:49,946 --> 00:09:53,178
and so you don't have to do it yourself. And that is actually really

155
00:09:53,226 --> 00:09:56,402
helpful. You can build applications faster, more robust,

156
00:09:56,458 --> 00:10:00,046
and move them from sort of an MVP or POC

157
00:10:00,110 --> 00:10:03,942
stage into production really quickly. So that's

158
00:10:03,958 --> 00:10:07,074
what Vectora does. And again, to recap,

159
00:10:07,934 --> 00:10:10,594
why is retrieval augmented generation useful?

160
00:10:10,974 --> 00:10:14,406
Well, you augment the element with your own data. So again, if you have private

161
00:10:14,470 --> 00:10:18,006
data, which most enterprises do, then, you know, check GPT

162
00:10:18,070 --> 00:10:21,302
would not know about this data. So that's the main reason you start. But also,

163
00:10:21,358 --> 00:10:25,340
again, it reduces hallucination likelihood. It, the amount of hallucinations

164
00:10:25,372 --> 00:10:28,668
is smaller just because you give it the right facts

165
00:10:28,716 --> 00:10:32,504
to base its response on. So this retrieval step is really key.

166
00:10:32,804 --> 00:10:36,076
Reg outputs are also explainable, and what I mean by that is they come with

167
00:10:36,100 --> 00:10:40,028
citations, so you increase the user trust. We'll see that in a demo, the information

168
00:10:40,116 --> 00:10:43,996
is private, we don't need to train in rag. You haven't

169
00:10:44,020 --> 00:10:47,588
seen any training or fine tuning step there in the architecture,

170
00:10:47,636 --> 00:10:51,632
so you don't need to train. So it becomes the information is safe,

171
00:10:51,748 --> 00:10:55,160
it doesn't leak into any future LLM. And then

172
00:10:55,192 --> 00:10:58,432
lastly, and this is one of my favorite reasons to use rag, is that

173
00:10:58,448 --> 00:11:02,616
it allows you to do a per person sort of permissioning or access control.

174
00:11:02,800 --> 00:11:07,552
So, for example, if some of my documents are from the HR department and

175
00:11:07,648 --> 00:11:10,496
I still want to use them in Rag, but only for the HR people or

176
00:11:10,520 --> 00:11:14,264
people who are allowed to see the results, I can

177
00:11:14,384 --> 00:11:18,384
ask the retrieval engine in Vektara to not include

178
00:11:18,464 --> 00:11:21,698
documents in the set of facts it retrieves,

179
00:11:21,866 --> 00:11:25,050
unless the person issuing the query has permission for that.

180
00:11:25,082 --> 00:11:28,778
So that allows you to create responses that are customized to a certain

181
00:11:28,826 --> 00:11:31,362
level of permission, which is actually really, really helpful.

182
00:11:31,538 --> 00:11:35,322
Okay. Okay, so why Vectara? Again, just to recap,

183
00:11:35,458 --> 00:11:38,094
building rag is more complex than it seems.

184
00:11:38,434 --> 00:11:42,258
And so a lot of reasons I mentioned, doing retrieval in

185
00:11:42,266 --> 00:11:45,110
a robust way is usually more complex than you think.

186
00:11:45,282 --> 00:11:49,062
Supporting multiple languages is hard. Again, with Vektar, you don't have

187
00:11:49,078 --> 00:11:52,222
to worry about a lot of expertise that's very specific to

188
00:11:52,238 --> 00:11:55,678
the LLM space, like prompt engineering, machine learning,

189
00:11:55,726 --> 00:11:58,782
operations, etcetera. And then, you know,

190
00:11:58,798 --> 00:12:02,342
we handle citations very well and just, you know,

191
00:12:02,398 --> 00:12:04,354
everything is ready for enterprise scale.

192
00:12:04,894 --> 00:12:08,150
Furthermore, again, security, privacy, permissioning,

193
00:12:08,182 --> 00:12:12,046
everything is taken care of by our platform, and you get a

194
00:12:12,070 --> 00:12:15,286
lower total cost of ownership when you use our platform than if you build it

195
00:12:15,310 --> 00:12:18,822
yourself. So one other thing I wanted

196
00:12:18,838 --> 00:12:22,982
to highlight is this hem, a hallucination evaluation model.

197
00:12:23,158 --> 00:12:26,470
This is a model that is very easy to use. It's open source,

198
00:12:26,502 --> 00:12:30,766
you can download it here, and it allows you to take a set of facts

199
00:12:30,910 --> 00:12:35,182
and a response from an LLM and detect whether it was hallucinating

200
00:12:35,238 --> 00:12:38,998
or not. What we see here is the leaderboard that ranks different

201
00:12:39,126 --> 00:12:43,156
llms based on their hallucination rate. It's actually really useful

202
00:12:43,260 --> 00:12:46,716
to know that there are differences, first of all, and then what the

203
00:12:46,740 --> 00:12:50,684
differences are. So that's ham. And again,

204
00:12:50,724 --> 00:12:53,852
to summarize how you build an application with Vekta or RaG

205
00:12:53,908 --> 00:12:57,024
application, first sign up to a free account.

206
00:12:57,724 --> 00:13:00,652
Then you need to ingest some data. So there's a lot of different ways to

207
00:13:00,668 --> 00:13:03,916
do that. You can, of course, use our APIs directly.

208
00:13:03,980 --> 00:13:07,504
There's a standard indexing API, there's a file upload API,

209
00:13:08,204 --> 00:13:11,612
and then you can also upload files from our console.

210
00:13:11,668 --> 00:13:15,308
Once you have an account, you get access to the console. And there's also other

211
00:13:15,356 --> 00:13:18,476
ways you can use Vector ingest, which is an open source project

212
00:13:18,540 --> 00:13:22,524
we created to help you with ingestion of data and indexing. Of data,

213
00:13:22,644 --> 00:13:25,940
including a few cool crawlers that crawl the data for

214
00:13:25,972 --> 00:13:30,020
you. And then there's integrations we have with companies like Airbyte

215
00:13:30,052 --> 00:13:33,444
and unstructured IO that also could be used for kind of no

216
00:13:33,484 --> 00:13:36,410
code ingestion. So take a look at those tools.

217
00:13:36,442 --> 00:13:39,722
Once you have the data there again, you can build the

218
00:13:39,858 --> 00:13:43,946
UI on your own using the query API and

219
00:13:44,010 --> 00:13:47,282
point it to the corpus and run queries. Or you can use some of the

220
00:13:47,298 --> 00:13:51,010
tools we have available too. We have an open source project called Victor Answer

221
00:13:51,162 --> 00:13:54,866
that can help you build question answering apps. There is a create

222
00:13:54,930 --> 00:13:58,666
UI which allows you to build a whole application, end to end

223
00:13:58,730 --> 00:14:02,150
in node JavaScript, and then a react search

224
00:14:02,182 --> 00:14:05,846
and react chatbot, which are components that you can use in

225
00:14:05,870 --> 00:14:08,966
your react application that help you

226
00:14:09,030 --> 00:14:12,006
simplify some of this billing process. So I encourage you to take a look at

227
00:14:12,030 --> 00:14:15,902
those and build your app with that. So now let

228
00:14:15,918 --> 00:14:18,894
me go to show you some of these apps that we've built just to demonstrate

229
00:14:18,934 --> 00:14:22,822
how to use this. So this is an example called Ask News.

230
00:14:22,998 --> 00:14:26,658
Let me go click on this. So I go to the actual application. So here

231
00:14:26,706 --> 00:14:30,698
we've actually crawled using Victor ingest, a bunch of news sources from

232
00:14:30,746 --> 00:14:34,626
BBC, NPR, CNN, et cetera.

233
00:14:34,810 --> 00:14:38,650
And as you can see, this crawling happens every day,

234
00:14:38,762 --> 00:14:42,202
adds the new news articles, crawls their content

235
00:14:42,258 --> 00:14:46,154
and adds them to this corpus. Now, when I run a query,

236
00:14:46,274 --> 00:14:50,450
let's say, should AI be regulated? You can see that

237
00:14:50,482 --> 00:14:54,062
it does the retrieval really quickly and it gives you a response

238
00:14:54,118 --> 00:14:57,526
here to answer the question. Now, not only that,

239
00:14:57,630 --> 00:15:01,286
it has, as I said earlier, these citations. So you can

240
00:15:01,310 --> 00:15:04,862
click on one of these citations and see, okay, this part

241
00:15:04,878 --> 00:15:08,686
of the answer was given from this article. Based on this information, you can actually

242
00:15:08,750 --> 00:15:12,406
click on this and go to that URL and see, you know

243
00:15:12,470 --> 00:15:16,270
what, where it came from, investigate further. So this gives

244
00:15:16,382 --> 00:15:19,858
a lot of trust and that's very useful. I also

245
00:15:19,906 --> 00:15:23,538
wanted to mention that we have an option here to use different

246
00:15:23,586 --> 00:15:26,774
languages. So for example, I can try to get the answer in German.

247
00:15:27,114 --> 00:15:30,138
And of course I don't speak German, so I won't be able to tell you

248
00:15:30,146 --> 00:15:33,186
if this is correct or not. But you can see that the answer gets

249
00:15:33,210 --> 00:15:37,010
translated into German, which is really, really helpful. And again, this is

250
00:15:37,042 --> 00:15:40,794
happening even though all the text is in English, so it knows how

251
00:15:40,834 --> 00:15:43,974
to match between languages really, really well.

252
00:15:44,514 --> 00:15:48,506
So that's an example of a question answering application.

253
00:15:48,690 --> 00:15:52,426
The next one I want to show you is actually the same application,

254
00:15:52,490 --> 00:15:56,322
ask news, but now using hem. So created a

255
00:15:56,338 --> 00:16:00,586
little demo of how you could use it, although there's many other ways.

256
00:16:00,730 --> 00:16:03,814
So this is ask news. But if I ask the same question,

257
00:16:04,354 --> 00:16:08,666
what you see happening here is that the response is generated in

258
00:16:08,690 --> 00:16:12,090
the same way. But then after it's get

259
00:16:12,122 --> 00:16:15,378
generated, there's an evaluation of the confidence using

260
00:16:15,426 --> 00:16:18,784
HHM. So this, this little step runs the

261
00:16:18,944 --> 00:16:23,288
hhem. In this case, it's using the hugging face inference model,

262
00:16:23,416 --> 00:16:26,600
and it generates an evaluation of this. In this

263
00:16:26,632 --> 00:16:30,080
case, yeah, this high confidence, it means that this response

264
00:16:30,152 --> 00:16:34,096
is not a hallucination relative to the facts. So this

265
00:16:34,120 --> 00:16:37,688
is one way you can use HHm on your own in your application

266
00:16:37,776 --> 00:16:41,440
to do that. So moving on here,

267
00:16:41,592 --> 00:16:45,304
this is question answering. But I also mentioned chatbots quite a bit.

268
00:16:45,424 --> 00:16:49,128
So let's look at, oh, I didn't mean to click that. Let's look at

269
00:16:49,136 --> 00:16:52,960
a chatbot example. So here's a chatbot. This is on hugging

270
00:16:52,992 --> 00:16:56,000
face. Again, built with the Victor APIs.

271
00:16:56,192 --> 00:16:59,728
So what we did here is create another corpus,

272
00:16:59,896 --> 00:17:03,360
crawled about 100, 150 pages from

273
00:17:03,432 --> 00:17:06,880
the IR's website and put them in a corpus. And now I can ask some

274
00:17:06,912 --> 00:17:11,140
questions about this. So for example, I can go in and say,

275
00:17:11,312 --> 00:17:14,388
is my college

276
00:17:14,476 --> 00:17:18,384
tuition text deductible?

277
00:17:18,804 --> 00:17:22,980
So again, it'll go into the corpus and

278
00:17:23,092 --> 00:17:27,304
try to answer this question based on the information I crawled in the website.

279
00:17:27,644 --> 00:17:31,580
Full disclosure and warning, please don't use this website other

280
00:17:31,612 --> 00:17:35,172
than for demo purposes, and use your tax

281
00:17:35,228 --> 00:17:38,692
advisor to file your taxes. I just have to say that. But it's

282
00:17:38,708 --> 00:17:41,934
just meant to show a demo. Okay, but again, you get this answer.

283
00:17:41,974 --> 00:17:44,550
And the nice thing about the chatbot is you can then ask a follow up

284
00:17:44,582 --> 00:17:48,558
question. So for example, here it said cost tuition and related expenses

285
00:17:48,606 --> 00:17:52,558
may be tax deductible in certain conditions. So I can say what

286
00:17:52,646 --> 00:17:57,274
conditions would make it tax deductible?

287
00:17:57,574 --> 00:18:00,590
And the idea is that it'll know that make,

288
00:18:00,662 --> 00:18:03,478
it probably refers to college tuition,

289
00:18:03,566 --> 00:18:08,198
right? So it has that context of the previous question

290
00:18:08,246 --> 00:18:11,526
in the previous answer. So it really answers the chatbot.

291
00:18:11,630 --> 00:18:15,078
And you see that it can, it knows that already. So this

292
00:18:15,086 --> 00:18:18,390
is a chatbot. I also want to emphasize again, this is all open source.

293
00:18:18,422 --> 00:18:22,246
So if you go to this particular website, you can actually

294
00:18:22,310 --> 00:18:26,246
see the files and all the code here, including how we run

295
00:18:26,270 --> 00:18:30,150
the query and the whole application and everything like that. So you know,

296
00:18:30,182 --> 00:18:33,246
feel free to use that as a reference to build your own app if you

297
00:18:33,270 --> 00:18:35,774
like. And with that,

298
00:18:36,194 --> 00:18:40,346
thank you for listening. I wanted to highlight a few other

299
00:18:40,410 --> 00:18:44,338
things here on my final slide. First, again, I encourage you to sign up

300
00:18:44,466 --> 00:18:48,010
to our free account. It's actually pretty generous and

301
00:18:48,122 --> 00:18:51,546
allows you to get started with up to 50 megabytes of text

302
00:18:51,610 --> 00:18:55,442
and 15,000 queries a month, which is quite a bit to

303
00:18:55,458 --> 00:18:59,002
get started and try it out. We have a

304
00:18:59,018 --> 00:19:02,674
lot of resources for you, our documentation, which is pretty thorough.

305
00:19:02,794 --> 00:19:06,970
We have a discord channel for the community, so you can join that and

306
00:19:07,162 --> 00:19:11,138
ask questions from fellow developers who build with Vektara,

307
00:19:11,186 --> 00:19:14,338
or from a lot of us at Victor are there all the time to answer

308
00:19:14,386 --> 00:19:17,498
questions. We have a GitHub where you can see a lot of open

309
00:19:17,546 --> 00:19:20,962
source projects that you can use that I mentioned here, like react,

310
00:19:21,018 --> 00:19:24,802
search, vector, ingestar answer, etcetera. And then we have a

311
00:19:24,818 --> 00:19:28,466
set of example notebooks. This one, for example, is how to use

312
00:19:28,490 --> 00:19:31,364
Vectar with Lama index, but we have others.

313
00:19:31,524 --> 00:19:34,812
You can look at this repository and then if

314
00:19:34,828 --> 00:19:37,584
you're a startup, I encourage you to take a look at our startups program.

315
00:19:38,084 --> 00:19:41,788
It's a very good way to get started with Vectara while giving

316
00:19:41,836 --> 00:19:46,420
you additional support in forms of credit and customer

317
00:19:46,452 --> 00:19:49,980
support and other things. So really a good way to get started if

318
00:19:50,012 --> 00:19:52,864
you want to use Vectara to power your product.

319
00:19:53,564 --> 00:19:56,756
And that's it. Thanks for listening again and I hope you have a

320
00:19:56,780 --> 00:19:59,684
good rest of your conf 42 conference.

