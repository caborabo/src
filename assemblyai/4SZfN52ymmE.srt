1
00:00:25,090 --> 00:00:29,010
Everyone, thanks for joining me in my today's session

2
00:00:29,170 --> 00:00:32,390
on observability in Ci CD pipeline.

3
00:00:32,730 --> 00:00:36,534
I'm Siddhartha Khare. I'm working as a technical account manager with

4
00:00:36,572 --> 00:00:39,974
new Relic. Prior to joining new Relic, I was working with

5
00:00:40,012 --> 00:00:44,470
Citrix as a software developer. Today's agenda

6
00:00:45,130 --> 00:00:48,614
will revolve around a quick recap on

7
00:00:48,652 --> 00:00:52,202
opentelemetry. What is continuous

8
00:00:52,266 --> 00:00:55,706
integration? What is continuous delivery?

9
00:00:55,898 --> 00:00:59,690
Why we need observability in Ci CD pipelines

10
00:00:59,850 --> 00:01:03,918
what are the benefits of implementing observability

11
00:01:04,014 --> 00:01:07,362
in Ci CD pipelines? And all of this is

12
00:01:07,416 --> 00:01:10,738
followed by a short demo on how

13
00:01:10,904 --> 00:01:13,250
these things can be implemented.

14
00:01:13,830 --> 00:01:17,958
Let's discuss about opentelemetry so

15
00:01:18,044 --> 00:01:21,794
Opentelemetry is an incubating project in CNCF

16
00:01:21,842 --> 00:01:25,350
umbrella. It is formed by merging open

17
00:01:25,420 --> 00:01:29,510
tracing and so if you have used

18
00:01:29,660 --> 00:01:33,126
Eger or Zipkin, you have already experienced the taste

19
00:01:33,158 --> 00:01:37,098
of open tracing. It also provides you a certain

20
00:01:37,184 --> 00:01:40,722
set of APIs libraries

21
00:01:40,886 --> 00:01:44,254
integrations so you will be able to collect your

22
00:01:44,292 --> 00:01:48,720
data more efficiently. It also

23
00:01:49,650 --> 00:01:54,158
provides you a standardized approach of collecting

24
00:01:54,254 --> 00:01:57,986
the data from your applications, which means

25
00:01:58,088 --> 00:02:02,414
what type of data you should be collecting from your applications

26
00:02:02,462 --> 00:02:06,006
or from your systems to understand how they

27
00:02:06,028 --> 00:02:09,074
are performing. What is continuous

28
00:02:09,122 --> 00:02:11,842
integration? So as the name suggests,

29
00:02:11,986 --> 00:02:15,720
it is a practice for merging all the developer code

30
00:02:16,410 --> 00:02:20,714
into a main code several times a day and

31
00:02:20,832 --> 00:02:24,458
it will help you to reduce the risk in already

32
00:02:24,544 --> 00:02:28,534
released features. It will decrease the number of the bugs

33
00:02:28,582 --> 00:02:31,600
which can be or in your application.

34
00:02:32,370 --> 00:02:36,494
It will minimize the integration issues which anyone can

35
00:02:36,532 --> 00:02:39,310
face. What is continuous?

36
00:02:39,810 --> 00:02:44,190
So the approach where the functionalities

37
00:02:44,350 --> 00:02:46,610
are delivered frequently,

38
00:02:47,190 --> 00:02:51,214
continuous delivery and with continuous

39
00:02:51,262 --> 00:02:55,066
delivery you will be able to deliver faster

40
00:02:55,118 --> 00:02:58,214
to the market in lower cost and the

41
00:02:58,252 --> 00:03:01,750
quality will also be enhanced. One can say like

42
00:03:01,820 --> 00:03:05,542
CI CD is a combined practice for integration and

43
00:03:05,596 --> 00:03:08,874
delivery. Let's discuss about why

44
00:03:08,912 --> 00:03:13,930
you need observability in CI CD pipeline. With observability

45
00:03:14,830 --> 00:03:18,502
you will be able to monitor your CI CD pipeline

46
00:03:18,566 --> 00:03:22,506
more effectively and you will be able to resolve

47
00:03:22,538 --> 00:03:26,030
the issues before they escalate, which will save your time

48
00:03:26,100 --> 00:03:29,834
and resources. By understanding the ins and outs

49
00:03:29,882 --> 00:03:33,714
of your CI CD processes, your team can

50
00:03:33,752 --> 00:03:37,358
make more informed decisions about resource allocation,

51
00:03:37,454 --> 00:03:41,250
process change or tool consolidation.

52
00:03:41,990 --> 00:03:45,942
You can also detect anomalies if there are

53
00:03:45,996 --> 00:03:49,974
any in your system. You can detect the performance issues.

54
00:03:50,092 --> 00:03:54,214
You can identify if there are any misconfigurations which

55
00:03:54,252 --> 00:03:57,914
have occurred, or the teams which

56
00:03:57,952 --> 00:04:01,770
work in the silos in more efficient manner.

57
00:04:02,350 --> 00:04:05,866
Let's also look at some of the benefits which you

58
00:04:05,888 --> 00:04:09,686
will be getting after monitoring your CI CD

59
00:04:09,718 --> 00:04:13,520
pipeline. So first one is about

60
00:04:14,130 --> 00:04:18,014
isolating the faults where it is

61
00:04:18,052 --> 00:04:22,160
a practice of designing systems such as

62
00:04:22,470 --> 00:04:26,622
when an error occurs, the negative outcomes are limited

63
00:04:26,766 --> 00:04:29,906
in the scope. Limiting the scope of the

64
00:04:29,928 --> 00:04:33,522
problems, reduce the potential for the damage and

65
00:04:33,576 --> 00:04:37,302
make systems easier to maintain. You will get

66
00:04:37,356 --> 00:04:40,402
the faster MTTR.

67
00:04:40,546 --> 00:04:45,158
This measures the maintainability of repairs and

68
00:04:45,244 --> 00:04:48,730
set the average time to repair a broken feature.

69
00:04:49,230 --> 00:04:51,850
You will see the faster release rates.

70
00:04:52,350 --> 00:04:56,010
You will also see that within

71
00:04:56,080 --> 00:05:00,410
your team the transparency accountability will improve.

72
00:05:00,910 --> 00:05:04,666
CI CD is a great way to get the continuous feedback

73
00:05:04,778 --> 00:05:08,846
not only from your customers but also in

74
00:05:08,868 --> 00:05:12,174
the demo of how we can implement the

75
00:05:12,212 --> 00:05:15,394
CI CD pipeline monitoring and what

76
00:05:15,432 --> 00:05:19,490
are the prerequisites to achieve this and

77
00:05:19,560 --> 00:05:23,060
how this will help you in a longer run.

78
00:05:23,510 --> 00:05:27,166
So let's quickly take a look on my Jenkins server

79
00:05:27,358 --> 00:05:30,646
what all jobs I have. So there are a couple of

80
00:05:30,668 --> 00:05:34,822
jobs which I have in my server and I'm running

81
00:05:34,876 --> 00:05:38,680
them. Let's take example of this particular job.

82
00:05:39,210 --> 00:05:42,566
I'm cleaning up the workspace first, then I'm checking

83
00:05:42,598 --> 00:05:46,314
out my code. I'm building the docker image, pushing that

84
00:05:46,352 --> 00:05:50,266
docker image to my Docker hub count and

85
00:05:50,288 --> 00:05:52,540
deleting the images from the system.

86
00:05:53,490 --> 00:05:57,562
Then I'm updating the Kubernetes deployment file

87
00:05:57,706 --> 00:06:01,402
and eventually pushing it to a deployment.

88
00:06:01,546 --> 00:06:05,710
So I'll also show you the actual app

89
00:06:05,780 --> 00:06:09,826
looks like. So if I go to sage you

90
00:06:09,848 --> 00:06:12,020
can see that I have an application,

91
00:06:12,630 --> 00:06:16,040
it's a Kubernetes hosted and I've just shown the

92
00:06:16,570 --> 00:06:20,166
view. If I go to this particular

93
00:06:20,268 --> 00:06:23,702
page, you can see I have a web page

94
00:06:23,756 --> 00:06:26,870
as well, produces an error,

95
00:06:27,550 --> 00:06:31,002
it will tell you. So this is the work

96
00:06:31,056 --> 00:06:34,154
of my application. Now at any point

97
00:06:34,192 --> 00:06:38,154
of time, let's say I want to monitor what

98
00:06:38,192 --> 00:06:42,334
my Jenkins server is doing, where it is failing and

99
00:06:42,372 --> 00:06:45,498
you don't have the access to portal.

100
00:06:45,594 --> 00:06:49,774
So what you will be doing, the process is very simple

101
00:06:49,972 --> 00:06:53,606
here. What we have leveraged is opentelemetry.

102
00:06:53,738 --> 00:06:57,490
So if I go to manage Jennicins search

103
00:06:57,560 --> 00:07:01,966
for opentelemetry plugin. So in my scenario I have already installed

104
00:07:01,998 --> 00:07:05,526
it. So I'll show you here. So this is the

105
00:07:05,548 --> 00:07:08,950
plugin which we will be using. Once you install

106
00:07:09,020 --> 00:07:13,078
the plugin, go back to manage Jenkins inside

107
00:07:13,164 --> 00:07:16,146
system. You will see multiple locations,

108
00:07:16,338 --> 00:07:20,234
multiple configurations which you need to do. So just search for

109
00:07:20,272 --> 00:07:23,738
opentelemetry and you need to provide

110
00:07:23,824 --> 00:07:27,980
the opentelemetry endpoint. So this endpoint can be

111
00:07:28,910 --> 00:07:32,746
any endpoint of your back end service which you are planning

112
00:07:32,778 --> 00:07:37,114
to use. In my scenario I'm using new relic.

113
00:07:37,162 --> 00:07:40,858
So the endpoint is otlpnrdata

114
00:07:40,954 --> 00:07:43,826
net 4317 is the port.

115
00:07:44,008 --> 00:07:47,346
The authentication which I am using is the API key.

116
00:07:47,448 --> 00:07:51,006
So I have leveraged the header authentication, I have named

117
00:07:51,038 --> 00:07:54,842
that header and the value is neuralik

118
00:07:54,926 --> 00:07:58,600
ingest license key. Okay. And I click on

119
00:07:59,370 --> 00:08:04,642
save. So as soon as I save this automatically

120
00:08:04,786 --> 00:08:08,186
within my neuralik portal, if you go to ApM and

121
00:08:08,208 --> 00:08:11,526
services inside opentelemetry,

122
00:08:11,558 --> 00:08:15,274
you will start seeing the here you will get the

123
00:08:15,312 --> 00:08:18,854
information about the response time throughput,

124
00:08:18,982 --> 00:08:22,960
the error rate of the application and the instance of the application.

125
00:08:23,810 --> 00:08:26,878
Now if you want to that

126
00:08:26,964 --> 00:08:30,282
what all other components your Jenkins is communicating,

127
00:08:30,346 --> 00:08:33,838
you can go to service map. If you want to validate

128
00:08:34,014 --> 00:08:37,442
what are the different type of transactions which are happening.

129
00:08:37,576 --> 00:08:41,154
So now the catch is when you see build

130
00:08:41,272 --> 00:08:46,146
in the caps. So all these are different builds

131
00:08:46,178 --> 00:08:49,698
which I have in my jenkins. So if you see here Argo

132
00:08:49,714 --> 00:08:53,110
CD Gitops worker bench Argo CD

133
00:08:53,850 --> 00:08:57,858
Gitops Argo CDCI operation Gitops Argo

134
00:08:57,874 --> 00:09:01,514
CDCI so if I go back here, you can see

135
00:09:01,552 --> 00:09:05,274
all these names if you want to dig deeper into

136
00:09:05,312 --> 00:09:08,860
it, of what is happening. Because let's say this is the main

137
00:09:10,050 --> 00:09:13,520
section which is taking 93%.

138
00:09:13,890 --> 00:09:16,954
So if I click on this particular transaction,

139
00:09:17,082 --> 00:09:20,154
I'll see the complete percentile graph,

140
00:09:20,202 --> 00:09:24,030
the throughput, and you will see the traces which are here.

141
00:09:24,180 --> 00:09:28,210
So let's see if there is any trace which has

142
00:09:28,360 --> 00:09:31,746
error. There are no one, but let's see if I go

143
00:09:31,768 --> 00:09:35,406
to this particular trace. You will see the entity map here,

144
00:09:35,528 --> 00:09:39,062
just for this particular trace. And you will see a

145
00:09:39,116 --> 00:09:43,254
nice indicator as well. Do a

146
00:09:43,292 --> 00:09:46,306
drop down, you will see all the process pens,

147
00:09:46,338 --> 00:09:50,330
you will see when the pipeline is starting, it starts running,

148
00:09:50,400 --> 00:09:54,234
the agent got initialized, and here you will see the

149
00:09:54,272 --> 00:09:57,642
stage wise approach. So the cleanup workspace took

150
00:09:57,696 --> 00:10:02,490
this much time, the checkout took 1.65 seconds.

151
00:10:02,650 --> 00:10:05,754
Building the docker image, it took 3 seconds.

152
00:10:05,882 --> 00:10:09,514
Then here, in pushing the docker image

153
00:10:09,642 --> 00:10:13,234
while it is running some shell command, it took some time. It is

154
00:10:13,272 --> 00:10:16,978
also showing me the anomaly which says this

155
00:10:17,144 --> 00:10:20,670
span is 3.79 seconds slower

156
00:10:20,830 --> 00:10:24,180
than what an average it was.

157
00:10:24,790 --> 00:10:28,790
Then it is deleting. So all these stages are coming up here.

158
00:10:28,940 --> 00:10:32,246
Now at any point of time, let's say here things are

159
00:10:32,268 --> 00:10:37,294
working fine. If I go back to my distributed tracing directly,

160
00:10:37,442 --> 00:10:40,762
I'll show you the different type of jobs which

161
00:10:40,816 --> 00:10:44,106
are in running the post details. So let me

162
00:10:44,128 --> 00:10:47,014
just filter out with errors.

163
00:10:47,142 --> 00:10:51,006
Okay, so this is the particular build

164
00:10:51,108 --> 00:10:54,960
where the errors are coming. So if I go to this particular

165
00:10:55,890 --> 00:11:00,042
and I will click on one of the trace

166
00:11:00,106 --> 00:11:04,130
here you will see the indicator is red and orange.

167
00:11:04,470 --> 00:11:07,586
If I click on drop down you will

168
00:11:07,608 --> 00:11:11,138
see the complete process span. Here you are seeing

169
00:11:11,224 --> 00:11:15,586
one anomalous span. So this anomalous span

170
00:11:15,698 --> 00:11:19,880
is generated based upon our anomaly detection engine.

171
00:11:20,490 --> 00:11:24,166
Here are the errors, which potential errors due to

172
00:11:24,188 --> 00:11:27,758
which the problem has occurred. So if I go to in span,

173
00:11:27,874 --> 00:11:31,980
you will start seeing when the pipeline started.

174
00:11:32,750 --> 00:11:36,634
Here is the first error. So let's quickly check how that

175
00:11:36,672 --> 00:11:40,206
error will look like. So it is tracing to clone from a

176
00:11:40,228 --> 00:11:43,710
wrong repo. If I go to SCM,

177
00:11:44,210 --> 00:11:47,742
you will start seeing this data. If I go to, let's say

178
00:11:47,876 --> 00:11:52,174
build docker image will start giving this. So now

179
00:11:52,212 --> 00:11:55,986
we know that this is the problem here and there was

180
00:11:56,168 --> 00:12:00,350
also an exception. So if I click on this particular exception,

181
00:12:00,430 --> 00:12:03,860
it will show me the complete stack trace of

182
00:12:04,230 --> 00:12:08,710
what is happening, which will help me to dig deeper

183
00:12:09,450 --> 00:12:13,062
how you can fix this problem. These are the

184
00:12:13,116 --> 00:12:16,662
information which you will start getting once

185
00:12:16,716 --> 00:12:20,474
you instrument it right. Even you will see

186
00:12:20,512 --> 00:12:24,774
the logs as well. So if you go to logs, you will see the details

187
00:12:24,822 --> 00:12:28,074
about that. There is some change which got detected in

188
00:12:28,112 --> 00:12:31,966
argocd Githubs workbench build,

189
00:12:32,068 --> 00:12:36,218
right? So it will tell you which particular build has changed.

190
00:12:36,314 --> 00:12:40,030
It will give you the details about the Jenkins URL.

191
00:12:40,690 --> 00:12:43,886
Once you start seeing this data, there are

192
00:12:43,908 --> 00:12:47,794
certain scenarios where every time you just don't want

193
00:12:47,832 --> 00:12:51,266
to go inside this and see what the problem is or how

194
00:12:51,288 --> 00:12:55,230
your Jenkins server is performing. So for that we have

195
00:12:55,320 --> 00:12:59,510
the out of the box dashboards. So if

196
00:12:59,580 --> 00:13:03,238
you go to any of the dashboard, you can see how your

197
00:13:03,324 --> 00:13:06,870
application is, how your CI CD

198
00:13:07,390 --> 00:13:11,354
pipeline is performing. So you can see the dashboard details like

199
00:13:11,392 --> 00:13:15,222
number of builds, 40, 20 failed.

200
00:13:15,366 --> 00:13:18,646
You will see the executed jobs,

201
00:13:18,758 --> 00:13:22,938
you will see the average job duration, you will see the job failures

202
00:13:23,114 --> 00:13:26,718
which step took the longer time,

203
00:13:26,804 --> 00:13:30,814
longer duration. You will see the number of the steps, you will see

204
00:13:30,932 --> 00:13:34,710
all those steps, the count, you will see the max

205
00:13:34,810 --> 00:13:38,482
error, like what type of errors are occurring most,

206
00:13:38,616 --> 00:13:42,322
and if there are any failed steps, you will start seeing those.

207
00:13:42,376 --> 00:13:46,034
So let me just increase the time frame to 3 hours and

208
00:13:46,072 --> 00:13:50,054
let's see. Yeah, so if you go to 3 hours, you will start

209
00:13:50,092 --> 00:13:53,894
seeing the steps which failed. You will start seeing the

210
00:13:53,932 --> 00:13:57,462
longer steps and you will see the number of builds and

211
00:13:57,516 --> 00:14:01,174
the failure builds and you will see if there are

212
00:14:01,292 --> 00:14:04,870
what is the queue time? You will see all these details

213
00:14:05,690 --> 00:14:09,494
coming up out of the box. I'll end

214
00:14:09,532 --> 00:14:13,566
my session in for observability in

215
00:14:13,668 --> 00:14:17,194
Ci CD pipeline and I hope you have enjoyed

216
00:14:17,242 --> 00:14:20,526
this session and please give it a

217
00:14:20,548 --> 00:14:23,966
try. If you face any problems. Feel free to reach out

218
00:14:23,988 --> 00:14:27,854
to me on my LinkedIn. Thank you. Have a nice day.

219
00:14:27,972 --> 00:14:28,460
Happy learning.

