1
00:00:27,320 --> 00:00:31,486
Hello everyone. Today we're diving into the fascinating world of data

2
00:00:31,550 --> 00:00:34,874
storytelling, leveraging the magic of

3
00:00:35,294 --> 00:00:37,834
oracle analytics to make it happen.

4
00:00:38,494 --> 00:00:42,714
So before we move on with our topic today,

5
00:00:43,334 --> 00:00:46,902
a quick introduction about me Uncle Aze

6
00:00:46,958 --> 00:00:50,834
and analytics principal consultant with Ritman Mead.

7
00:00:51,254 --> 00:00:54,710
I've been in the industry for almost two decades now.

8
00:00:54,822 --> 00:00:58,502
Almost been quite fortunate throughout my

9
00:00:58,558 --> 00:01:02,470
technical journey to have gained exposure to various technologies

10
00:01:02,542 --> 00:01:06,094
starting with mainframes and

11
00:01:06,174 --> 00:01:10,314
when came a time to choose my path, I chose Oracle

12
00:01:10,934 --> 00:01:15,434
and have been having an exciting ride ever since, starting with data engineering

13
00:01:16,214 --> 00:01:19,670
and switching to Oracle analytics as my major focus

14
00:01:19,742 --> 00:01:23,284
area since 2019,

15
00:01:24,144 --> 00:01:27,664
when I'm not working or speaking in conferences, I would be busy

16
00:01:27,704 --> 00:01:31,800
in my full time passion as a mother of my eleven

17
00:01:31,872 --> 00:01:35,856
year old daughter, also finding time alongside to explore

18
00:01:35,920 --> 00:01:39,456
my journey as an artist, which kind

19
00:01:39,480 --> 00:01:43,136
of works wonders to keep me recharged. So I'd

20
00:01:43,160 --> 00:01:46,912
be happy to connect with you all through any of my social handles

21
00:01:46,968 --> 00:01:51,346
which you can access via the QR code here to discuss anything

22
00:01:51,410 --> 00:01:55,334
analytics and also art if you are interested.

23
00:01:55,994 --> 00:02:00,294
Alright then, a bit about my organization

24
00:02:00,794 --> 00:02:04,114
Ritman Mead is a global oracle data and

25
00:02:04,154 --> 00:02:07,674
analytics consultancy. We are oracle partners

26
00:02:07,834 --> 00:02:11,826
and have been thought leaders in the industry for more than 16 years.

27
00:02:12,010 --> 00:02:15,058
In addition to our reputation as core

28
00:02:15,106 --> 00:02:19,160
experts in anything data covering data

29
00:02:19,272 --> 00:02:22,204
integration, engineering, data management,

30
00:02:22,824 --> 00:02:26,520
data visualization, reporting and also data science,

31
00:02:26,712 --> 00:02:30,424
we are also quite popular with our technical content with over

32
00:02:30,504 --> 00:02:33,624
2000 technical blogs published related

33
00:02:33,704 --> 00:02:37,448
to all these fields. Happy to be here.

34
00:02:37,576 --> 00:02:41,104
My topic storytelling. Now why

35
00:02:41,144 --> 00:02:45,306
do we need storytelling? Imagine for a moment that

36
00:02:45,490 --> 00:02:49,494
data is not just a collection of numbers and charts,

37
00:02:49,794 --> 00:02:53,738
but a vivid narrative that captures your

38
00:02:53,786 --> 00:02:56,654
imagination and holds our attention.

39
00:02:57,114 --> 00:03:00,746
Now that is the essence of data storytelling. It is

40
00:03:00,770 --> 00:03:04,530
an approach that transforms abstract data

41
00:03:04,682 --> 00:03:08,734
into meaningful narrative. In today's world,

42
00:03:09,504 --> 00:03:13,160
we are bombarded with information

43
00:03:13,272 --> 00:03:16,616
from all directions, right? Each day we

44
00:03:16,640 --> 00:03:20,080
create an immense amount of data. But how do we

45
00:03:20,112 --> 00:03:23,960
make sense of this avalanche of information? How can we extract

46
00:03:24,072 --> 00:03:27,604
value from it rather than feeling overwhelmed?

47
00:03:28,384 --> 00:03:31,840
Storytelling is the most powerful way to put

48
00:03:31,912 --> 00:03:35,356
ideas into the world today as we all know

49
00:03:35,380 --> 00:03:38,836
it. For thousands of years, it has been an integral

50
00:03:38,900 --> 00:03:42,824
part of our humanity. Data storytelling

51
00:03:43,244 --> 00:03:46,572
is our solution to this issue.

52
00:03:46,708 --> 00:03:50,564
It's a method of turning dry statistics into engaging

53
00:03:50,644 --> 00:03:54,476
stories which resonate with people in the current

54
00:03:54,540 --> 00:03:57,612
business world, with exponential growth in data,

55
00:03:57,668 --> 00:04:00,676
volume, variety and velocity.

56
00:04:00,780 --> 00:04:04,244
All these collected and combined data may hold tremendous amount of

57
00:04:04,284 --> 00:04:07,500
potential value, but not an ounce of

58
00:04:07,532 --> 00:04:11,892
value can be created unless the insights are uncovered

59
00:04:12,068 --> 00:04:16,264
and also translated into actions or business outcomes.

60
00:04:16,964 --> 00:04:20,956
So you can all imagine how in the current

61
00:04:21,060 --> 00:04:24,628
world and with all these technical advancements happening around,

62
00:04:24,796 --> 00:04:28,604
there's been a huge shift towards more self service

63
00:04:28,684 --> 00:04:32,488
capabilities in analytics and also bi. The pool of

64
00:04:32,536 --> 00:04:36,656
people who are generating insights has expanded

65
00:04:36,720 --> 00:04:39,992
beyond just analysts and data scientists now, which is a

66
00:04:40,008 --> 00:04:43,216
good thing. But the new breed of data tools

67
00:04:43,240 --> 00:04:47,244
which are available is actually making it easier for people across

68
00:04:48,304 --> 00:04:51,536
business functions to access and explore the data of

69
00:04:51,680 --> 00:04:54,904
their own. So that is definitely a good thing. But what is

70
00:04:54,944 --> 00:04:58,154
happening in the other end is that this is also

71
00:04:58,234 --> 00:05:02,370
leading to an unprecedented number of insights in

72
00:05:02,402 --> 00:05:05,482
which are going unutilized. Unless we

73
00:05:05,498 --> 00:05:09,426
can improve the communication, the way we communicate these

74
00:05:09,490 --> 00:05:12,754
insights to our stakeholders,

75
00:05:12,874 --> 00:05:16,578
we'll also see a poorer insight to

76
00:05:16,626 --> 00:05:20,066
value conversion rate, which is a

77
00:05:20,090 --> 00:05:23,354
key issue. By framing data

78
00:05:23,474 --> 00:05:27,062
within a narrative structure, we not only

79
00:05:27,118 --> 00:05:30,954
make it more interesting, but also more impactful.

80
00:05:31,734 --> 00:05:36,590
A well crafted story just communicate

81
00:05:36,662 --> 00:05:40,230
the information properly or impactfully,

82
00:05:40,342 --> 00:05:44,022
but it can also evoke emotions, spark curiosity.

83
00:05:44,198 --> 00:05:47,758
It can hold audiences attention far better than

84
00:05:47,806 --> 00:05:51,750
raw data ever could. So that is why I have brought this

85
00:05:51,782 --> 00:05:56,344
data story from history here to discuss, because 1855,

86
00:05:56,424 --> 00:05:59,656
the Crimea war time, Britain was fighting a

87
00:05:59,680 --> 00:06:02,804
battle with both Russia and deseasis.

88
00:06:03,104 --> 00:06:07,024
As a nurse, how do you think Florence

89
00:06:07,064 --> 00:06:10,488
Nightingale can convince an army to invest in

90
00:06:10,536 --> 00:06:14,324
hospitals and healthcare instead of guns and ammunition?

91
00:06:15,104 --> 00:06:18,912
What she did was telling her story with data

92
00:06:19,088 --> 00:06:22,656
in her most famous visualization, as you can see it on screen,

93
00:06:22,760 --> 00:06:26,150
the rose chart of deaths. It demonstrated

94
00:06:26,182 --> 00:06:29,398
through the color scheme and patterns that

95
00:06:29,446 --> 00:06:33,566
a reduction in hospital deaths would lead to thousands of lives

96
00:06:33,670 --> 00:06:37,434
saved. This collection and process of visualizing

97
00:06:37,814 --> 00:06:41,634
the underlying data was also a revelation to Nightingale,

98
00:06:42,334 --> 00:06:46,670
and when she communicated this to the army, the visualization

99
00:06:46,782 --> 00:06:50,754
helped convince the british army to make sanitation a priority,

100
00:06:51,054 --> 00:06:54,942
which saved lives in the process. Soldiers death had fallen

101
00:06:54,998 --> 00:06:58,798
sharply after the government sent out a sanitation committee in

102
00:06:58,846 --> 00:07:02,214
March 1855, which cleaned up the hospitals drinking

103
00:07:02,254 --> 00:07:06,354
water and ventilation. So what does this tell you?

104
00:07:06,974 --> 00:07:11,634
Data helps find opportunities and resolve misunderstandings.

105
00:07:12,454 --> 00:07:16,274
A well crafted story can evoke emotions,

106
00:07:16,714 --> 00:07:20,562
spark curiosity, and hold audiences

107
00:07:20,618 --> 00:07:24,174
attention far better than raw data ever could.

108
00:07:24,914 --> 00:07:28,986
Being a navigator who charts a course through the vast

109
00:07:29,050 --> 00:07:33,010
sea of information, identifying hidden patterns

110
00:07:33,202 --> 00:07:36,426
and connections, or insights that might otherwise

111
00:07:36,490 --> 00:07:40,014
go unnoticed when effectively done.

112
00:07:40,434 --> 00:07:43,854
This enables informed decision making.

113
00:07:44,574 --> 00:07:47,394
And by integrating storytelling with data,

114
00:07:48,054 --> 00:07:51,934
what we are actually doing is bridging

115
00:07:51,974 --> 00:07:56,114
the gap between data experts and everyone else.

116
00:07:56,814 --> 00:08:00,782
Data stories influence people's thoughts and actions at critical

117
00:08:00,838 --> 00:08:04,154
points in history. There's been so many other examples too,

118
00:08:04,494 --> 00:08:07,678
if you look back, which has made an impact on the world

119
00:08:07,726 --> 00:08:11,164
around us, and that is the true power

120
00:08:11,284 --> 00:08:15,012
of data storytelling. If you don't communicate

121
00:08:15,068 --> 00:08:19,068
your data clearly, your audience might be like those blind

122
00:08:19,116 --> 00:08:22,344
men here in the story, in this old story parable,

123
00:08:23,324 --> 00:08:27,476
if I can call it so, each person is touching a different part of

124
00:08:27,620 --> 00:08:31,076
an elephant and coming up with their own ideas about what it

125
00:08:31,100 --> 00:08:34,660
is. The sky feels the trunk, it's touching

126
00:08:34,692 --> 00:08:36,954
the trunk. It's a snake tail.

127
00:08:37,694 --> 00:08:41,870
Seems like rope for this linemen. And the body

128
00:08:42,022 --> 00:08:45,118
is felt like a wall, right? So they basically, they are

129
00:08:45,126 --> 00:08:48,806
all guessing based on their limited view and experiences.

130
00:08:48,950 --> 00:08:52,086
Without the right context, it is easy

131
00:08:52,150 --> 00:08:56,234
to misunderstand the full picture. Context matters.

132
00:08:56,774 --> 00:08:59,582
So here is something interesting from a study at USC.

133
00:08:59,678 --> 00:09:03,598
Researchers found that people with brain damage in a part of the brain

134
00:09:03,646 --> 00:09:07,512
that handles emotions had a really hard time making

135
00:09:07,648 --> 00:09:10,124
basic decisions when given choices.

136
00:09:10,464 --> 00:09:13,984
These folks struggle because they couldn't use their emotions

137
00:09:14,064 --> 00:09:18,008
to help them decide. Now, this shows that emotions

138
00:09:18,056 --> 00:09:22,288
are super important in making decisions quickly and effectively.

139
00:09:22,456 --> 00:09:25,960
So when we share data, it's not just about throwing out

140
00:09:26,032 --> 00:09:29,824
numbers. We need to connect with our audience emotionally

141
00:09:29,944 --> 00:09:34,048
to help them understand and make good decisions. And that's where good

142
00:09:34,096 --> 00:09:36,884
storytelling with data comes into picture.

143
00:09:37,274 --> 00:09:40,658
By making our data relatable and

144
00:09:40,706 --> 00:09:44,522
providing the right context, we help our audience really

145
00:09:44,578 --> 00:09:48,426
get it and act on it. It's also power.

146
00:09:48,570 --> 00:09:52,506
Gives you the power to influence. Let's see an example

147
00:09:52,650 --> 00:09:56,178
just to prove my point. Now, imagine you're trying to convince

148
00:09:56,266 --> 00:09:59,714
your team to invest in a new project. You could just show

149
00:09:59,754 --> 00:10:03,382
them a boring spreadsheet or some data,

150
00:10:03,478 --> 00:10:07,150
or numbers, like how you can see in here we have the schedule

151
00:10:07,182 --> 00:10:11,774
type, productivity score, and satisfaction rate for

152
00:10:11,814 --> 00:10:15,382
two kinds of two schedule types, which are compared

153
00:10:15,438 --> 00:10:18,034
against the traditional and flexible schedule.

154
00:10:18,414 --> 00:10:22,382
Now, this is one option or one way of sharing

155
00:10:22,478 --> 00:10:25,854
your information with your audience. But instead,

156
00:10:25,894 --> 00:10:29,186
you could also craft a narrative. Now, you start with

157
00:10:29,210 --> 00:10:33,002
a relatable problem, add some compelling data points

158
00:10:33,058 --> 00:10:36,482
that highlight the issue, then show how your project

159
00:10:36,618 --> 00:10:39,890
is the perfect solution. Now that is a

160
00:10:39,922 --> 00:10:43,458
good way of building your narrative,

161
00:10:43,586 --> 00:10:46,978
an effective narrative. So by the end, your team isn't just

162
00:10:47,026 --> 00:10:50,654
nodding along, they're excited and also ready to take action.

163
00:10:51,034 --> 00:10:54,936
Now, that's where the power of influence through data storing

164
00:10:55,000 --> 00:10:58,320
telling comes into picture. It's all about connecting the dots in a way

165
00:10:58,352 --> 00:11:01,640
that resonates with people. You're not just presenting

166
00:11:01,672 --> 00:11:05,776
the information, you're guiding your audience to a conclusion, making the

167
00:11:05,800 --> 00:11:09,192
data meaningful and memorable. When you tell a story

168
00:11:09,288 --> 00:11:13,040
with your data, you're not just informing, you're inspiring. And that's

169
00:11:13,072 --> 00:11:16,724
how real change happens. So here in this visual,

170
00:11:18,064 --> 00:11:21,410
as I said, it's just a plain table showing

171
00:11:21,442 --> 00:11:25,258
raw numbers for productivity scores and satisfaction rates.

172
00:11:25,426 --> 00:11:29,370
And probably a narrative that can go along with

173
00:11:29,442 --> 00:11:33,226
this data which is shared, is that the study shows

174
00:11:33,330 --> 00:11:37,266
the flexible schedules have higher productivity scores and employee

175
00:11:37,290 --> 00:11:40,922
satisfaction rates compared to traditional schedules.

176
00:11:41,098 --> 00:11:45,122
Now, this approach is lacking what engaging

177
00:11:45,178 --> 00:11:48,810
visuals, and also there's no storytelling element in it which,

178
00:11:48,842 --> 00:11:52,122
which makes the data come to life.

179
00:11:52,218 --> 00:11:55,466
So this simply presents a raw data without context,

180
00:11:55,530 --> 00:11:58,618
without emotional appeal or even a narrative

181
00:11:58,666 --> 00:12:01,970
structure, making it harder for the audience to grasp the

182
00:12:02,002 --> 00:12:04,014
significance and connect with the information.

183
00:12:04,874 --> 00:12:08,562
Now how does this look? Now this is a more visual

184
00:12:08,698 --> 00:12:12,094
narrative which also has

185
00:12:13,014 --> 00:12:16,598
given or highlighted the key points or key

186
00:12:16,646 --> 00:12:19,726
message behind the visual that we have in here.

187
00:12:19,910 --> 00:12:23,750
Stressing on the key points, also using the color coding

188
00:12:23,822 --> 00:12:27,934
to bring, to give the audience extra understanding.

189
00:12:27,974 --> 00:12:32,118
With just one look here, we are able to understand what

190
00:12:32,206 --> 00:12:35,750
the numbers, which are important, and also the

191
00:12:35,782 --> 00:12:39,358
positive and negative aspects of the comparison with red and

192
00:12:39,406 --> 00:12:42,350
green color coding, which is, which are bolded,

193
00:12:42,422 --> 00:12:45,686
right? So it's just the way you present the

194
00:12:45,710 --> 00:12:49,518
data, which kind of makes it very easy

195
00:12:49,566 --> 00:12:53,102
for your audience to grasp it all at just one

196
00:12:53,158 --> 00:12:56,406
glance rather than, you know,

197
00:12:56,470 --> 00:13:01,054
giving them the plain numbers and letting them guess the

198
00:13:01,174 --> 00:13:05,446
understanding behind based on their own perception that actually

199
00:13:05,510 --> 00:13:08,886
underlies a lot of risk. They may not really get the

200
00:13:08,910 --> 00:13:11,514
point that you're even wanting to communicate.

201
00:13:12,114 --> 00:13:15,634
So your weapon, that's where Oracle analytics comes into

202
00:13:15,674 --> 00:13:19,454
picture. So Oracle analytics is your comprehensive solution,

203
00:13:20,074 --> 00:13:23,914
offering a robust suit of features that cover

204
00:13:24,034 --> 00:13:27,802
every step of the analytics journey, from connecting to data

205
00:13:27,978 --> 00:13:31,414
modeling, preparation of your data exploration,

206
00:13:31,834 --> 00:13:35,538
visualization, even storytelling and collaboration

207
00:13:35,626 --> 00:13:38,982
with other counterparts. It's all here in

208
00:13:39,038 --> 00:13:42,582
one integrated platform. But what sets Oracle

209
00:13:42,638 --> 00:13:46,790
analytics apart? Let's take a look. Firstly, it caters

210
00:13:46,822 --> 00:13:50,358
to everyone in your organization, from it and data

211
00:13:50,406 --> 00:13:52,622
engineers to citizen data scientists,

212
00:13:52,718 --> 00:13:56,078
executors, business users. No matter your

213
00:13:56,126 --> 00:14:00,294
role, Oracle analytics has something for you now. The embedded

214
00:14:00,334 --> 00:14:03,902
machine learning brings advanced analytics capabilities to

215
00:14:03,958 --> 00:14:07,264
every user, whether you are a novice or an expert.

216
00:14:07,644 --> 00:14:11,540
And with both centralized and governed reporting and

217
00:14:11,572 --> 00:14:15,676
self service options, you can trust that your data is consistent

218
00:14:15,740 --> 00:14:18,664
and reliable, no matter who is accessing it.

219
00:14:19,244 --> 00:14:22,364
So basically, Oracle analytics abstracts the complexities

220
00:14:22,444 --> 00:14:25,788
of your data sources, the query languages, making it

221
00:14:25,836 --> 00:14:29,020
easy for even business users to dive into

222
00:14:29,092 --> 00:14:32,818
analysis without getting bogged down in technical details.

223
00:14:32,956 --> 00:14:35,474
And let's not forget about data security.

224
00:14:35,894 --> 00:14:39,774
With built in trackable data preparation and enrichment,

225
00:14:39,854 --> 00:14:43,246
there's no need for risky data exports or reliance

226
00:14:43,270 --> 00:14:46,870
on Excel spreadsheets. Now, when it comes to

227
00:14:47,062 --> 00:14:50,246
deployment options, Oracle has you covered for

228
00:14:50,270 --> 00:14:54,182
those migrating to the cloud. Oracle Analytics Cloud OAC is

229
00:14:54,198 --> 00:14:57,950
a solution and built on OCI Oracle

230
00:14:57,982 --> 00:15:01,882
cloud infrastructure OIC offers the benefits of

231
00:15:01,978 --> 00:15:06,474
cloud native analytics without the need for on premises infrastructure.

232
00:15:06,634 --> 00:15:10,154
But if you prefer to keep your data on prem, then Oracle analytics

233
00:15:10,194 --> 00:15:13,682
server is the answer. When studying about the

234
00:15:13,698 --> 00:15:17,082
importance of context, it is crucial to develop

235
00:15:17,138 --> 00:15:21,174
your understanding of exploratory and explanatory analysis.

236
00:15:21,514 --> 00:15:25,182
When we do exploratory analysis, we may need to test

237
00:15:25,338 --> 00:15:28,734
hundred different hypotheses or look at the data in hundred different

238
00:15:28,814 --> 00:15:32,486
ways to find the core message that you want to

239
00:15:32,510 --> 00:15:36,462
communicate. There's a specific story you

240
00:15:36,478 --> 00:15:40,454
may want to tell. So on a high level exploratory

241
00:15:40,534 --> 00:15:45,034
analysis which kind of marks the first starting point of your

242
00:15:45,974 --> 00:15:49,430
of creating a good data story, it involves

243
00:15:49,502 --> 00:15:52,852
understanding your data well, highlighting interest,

244
00:15:53,038 --> 00:15:56,924
testing different hypotheses which could be underlined

245
00:15:57,504 --> 00:16:01,512
will be to connect to the right data sources of your choice from

246
00:16:01,608 --> 00:16:04,928
cloud or on Prem Oracle analytics

247
00:16:04,976 --> 00:16:08,528
applications. When you use them OAC or OAS,

248
00:16:08,616 --> 00:16:12,120
it allows seamless connectivity to all major data sources,

249
00:16:12,192 --> 00:16:15,920
be it in cloud or on premises

250
00:16:15,992 --> 00:16:19,756
or PAAS application. You can also connect to data sources with

251
00:16:19,920 --> 00:16:23,064
rest endpoints and analyze the data.

252
00:16:23,524 --> 00:16:26,996
For example, connect to SAS or PAAS applications or government

253
00:16:27,100 --> 00:16:31,060
data such as weather, spatial or census data without

254
00:16:31,132 --> 00:16:34,532
compromising on data governance. The connecting to data

255
00:16:34,628 --> 00:16:38,020
via rest endpoints enables you to analyze data

256
00:16:38,092 --> 00:16:41,572
from many transactional SAS or PaaS

257
00:16:41,628 --> 00:16:45,124
applications without having to understand the internal

258
00:16:45,164 --> 00:16:48,686
format or structure of the data. So that's the advantage of

259
00:16:48,710 --> 00:16:52,238
it. You can see on screen the Oracle analytics

260
00:16:52,286 --> 00:16:55,814
cloud interface, the application home page

261
00:16:55,854 --> 00:16:59,358
in here. So I'm going to quickly show

262
00:16:59,406 --> 00:17:03,230
you how easily you'll be able to start with

263
00:17:03,262 --> 00:17:07,526
your data exploration with the help of Oracle analytics cloud

264
00:17:07,670 --> 00:17:11,270
for creating your data story. So to

265
00:17:11,302 --> 00:17:15,221
create a new data source or connection, it is as easy as

266
00:17:15,397 --> 00:17:18,953
accessing these options and

267
00:17:19,293 --> 00:17:23,037
create connection gives you create

268
00:17:23,085 --> 00:17:26,885
a connection on top of any any data source that you can think of.

269
00:17:26,989 --> 00:17:30,513
As you can see in here, even the rest API connection

270
00:17:31,333 --> 00:17:34,405
is possible and what you just need is

271
00:17:34,429 --> 00:17:37,793
the connection credentials when you map it, the wallet.

272
00:17:38,733 --> 00:17:42,674
So whatever connection credentials, if it is handy

273
00:17:42,794 --> 00:17:46,290
then feed it and it's just a

274
00:17:46,322 --> 00:17:49,706
quick way to connect to all your data sources.

275
00:17:49,770 --> 00:17:53,178
So once you create a connection, you will be able to create

276
00:17:53,226 --> 00:17:57,330
a data set on top of it. Therein. We have to choose the

277
00:17:57,362 --> 00:18:01,514
connection which is established and then

278
00:18:01,674 --> 00:18:04,978
select the table or the schema, the tables or

279
00:18:05,026 --> 00:18:08,666
even say if you have a spreadsheet, data that you want to analyze on

280
00:18:08,690 --> 00:18:12,682
top of. Just need to drag and drop the file in here so that

281
00:18:12,738 --> 00:18:15,866
you'll be able to access it into the interface.

282
00:18:16,010 --> 00:18:19,002
So for our analysis,

283
00:18:19,098 --> 00:18:23,314
which I want to quickly demonstrate, I am going to access an existing

284
00:18:23,354 --> 00:18:27,134
data set which is having the sales

285
00:18:27,434 --> 00:18:31,082
data. I thought this would be interesting

286
00:18:31,178 --> 00:18:34,374
to access. Sales super stole.

287
00:18:34,894 --> 00:18:38,518
Let me go back to the home page and take it from

288
00:18:38,566 --> 00:18:42,918
there. Sales this way I'm searching could be different.

289
00:18:43,046 --> 00:18:46,406
Yeah, we do have the sales superstore. So I

290
00:18:46,430 --> 00:18:50,342
click on the sales superstore data set and you can see that it

291
00:18:50,358 --> 00:18:53,494
has taken me to the

292
00:18:53,534 --> 00:18:57,398
workbook. So a new workbook is created on top of it and you

293
00:18:57,406 --> 00:19:00,526
can see on the right hand side it is already giving you,

294
00:19:00,550 --> 00:19:03,932
even if you, even if say I didn't have any understanding about the

295
00:19:03,948 --> 00:19:07,756
data set as a user and I'm trying to find a

296
00:19:07,780 --> 00:19:10,980
grip on what exactly is the information stored

297
00:19:11,012 --> 00:19:14,508
in there. You can see the auto insights which are

298
00:19:14,556 --> 00:19:18,444
loaded in the right hand side which is generated based out of the machine

299
00:19:18,484 --> 00:19:21,140
learning algorithms running in the background.

300
00:19:21,292 --> 00:19:25,508
So we are getting a good start of understanding

301
00:19:25,676 --> 00:19:28,972
of the data which is residing and

302
00:19:28,988 --> 00:19:32,490
there could be a lot of visual analysis which is readily available

303
00:19:32,602 --> 00:19:35,850
for you, which you could directly use for

304
00:19:35,882 --> 00:19:39,170
your data story. So if I just click on plus

305
00:19:39,282 --> 00:19:42,974
you can see automatically the canvas is loaded with the visualization.

306
00:19:43,354 --> 00:19:46,174
Let me try to bring this heat map as well.

307
00:19:46,474 --> 00:19:50,298
And likewise I'm just randomly adding

308
00:19:50,346 --> 00:19:53,946
some of the analysis which I thought we could include

309
00:19:54,010 --> 00:19:57,430
in the story. So I'm just pulling few

310
00:19:57,542 --> 00:20:01,246
ones in here and you can see that automatically.

311
00:20:01,270 --> 00:20:04,646
It is all adjusting the position, the layout,

312
00:20:04,830 --> 00:20:08,230
and so the interface is by

313
00:20:08,262 --> 00:20:11,782
default capable enough to do that. And if you

314
00:20:11,798 --> 00:20:15,662
want to do any data preparation for your data, now what? How do

315
00:20:15,678 --> 00:20:19,270
we access the data editor? So you click

316
00:20:19,302 --> 00:20:23,194
on data, you click on the edit button there

317
00:20:23,894 --> 00:20:27,590
and you can soon see that the data is loaded in

318
00:20:27,622 --> 00:20:31,294
here. So once we import our data sets or create

319
00:20:31,374 --> 00:20:34,862
connections and access our data sources, we'll be cleaning the data

320
00:20:34,918 --> 00:20:38,806
by removing say duplicates or handling any missing values to

321
00:20:38,950 --> 00:20:42,462
ensure accuracy, even we can do any

322
00:20:42,558 --> 00:20:46,630
transformations on the data as relevant. So Oracle analytics also gives

323
00:20:46,662 --> 00:20:50,406
you the power of machine learning algorithms, recommending possible

324
00:20:50,510 --> 00:20:53,928
data enrichments that can be applied in just one

325
00:20:53,976 --> 00:20:58,184
click. So you can see the recommendations are listed in the right hand side.

326
00:20:58,344 --> 00:21:02,536
And so currently the

327
00:21:02,560 --> 00:21:06,544
data set which is loaded, you can see the preview pane in here,

328
00:21:06,584 --> 00:21:09,936
gives you an all full on high level understanding of the data,

329
00:21:10,000 --> 00:21:14,376
how exactly it is varied, and if

330
00:21:14,400 --> 00:21:17,752
at all there was any missing value or null values, we would actually be

331
00:21:17,768 --> 00:21:21,726
intimated or notified by red color code.

332
00:21:21,870 --> 00:21:25,830
And if you want to do any sort of data transformation

333
00:21:25,982 --> 00:21:29,542
for any of the columns, like for example the sales. Let's see.

334
00:21:29,598 --> 00:21:33,526
So all these transformation options are readily available

335
00:21:33,630 --> 00:21:37,054
for you, which will be if when applied, it will be added

336
00:21:37,094 --> 00:21:40,166
as a step in the left hand side. You can keep a track of the

337
00:21:40,190 --> 00:21:44,194
steps that you're adding as your transformation steps.

338
00:21:44,934 --> 00:21:48,180
Just to give a quick demo, if I

339
00:21:48,212 --> 00:21:51,380
say rename the sales column in here.

340
00:21:51,492 --> 00:21:57,384
So if I say it is sales sales

341
00:21:58,404 --> 00:22:02,164
test. So I'm just testing the renaming option

342
00:22:02,204 --> 00:22:05,300
to show you how the steps are added in the left hand side you can

343
00:22:05,332 --> 00:22:08,772
see if you don't want that step to be applied,

344
00:22:08,828 --> 00:22:11,988
you can even decide to remove it at later point

345
00:22:12,036 --> 00:22:15,212
in time and it will be reverted back. So likewise any sort

346
00:22:15,228 --> 00:22:19,068
of transformation you will be able to work

347
00:22:19,116 --> 00:22:22,812
on in this transform editor and the recommendations

348
00:22:22,908 --> 00:22:27,516
is another interesting or very, very useful feature

349
00:22:27,700 --> 00:22:31,516
which is powered by machine learning. Now say if I click

350
00:22:31,540 --> 00:22:34,908
on any of these fields which I'm interested in

351
00:22:35,036 --> 00:22:39,344
now, this is a location field. Now see the enrichment, the data enrichment

352
00:22:39,724 --> 00:22:43,600
refers to. If you know, it gives you the capability to add

353
00:22:43,672 --> 00:22:47,608
information based on existing data which is not already there.

354
00:22:47,736 --> 00:22:50,896
If it is meaningful for your analysis,

355
00:22:51,080 --> 00:22:54,536
it is just one click away in here. Like for example,

356
00:22:54,680 --> 00:22:57,484
now what we have in here is the city information,

357
00:22:58,304 --> 00:23:02,000
the country, state, province, I think we already have

358
00:23:02,032 --> 00:23:05,720
it in here. But say, if we were also interested in

359
00:23:05,792 --> 00:23:09,756
understanding the population of that city to see,

360
00:23:09,900 --> 00:23:14,104
you know, how much is our range in terms of sales already

361
00:23:14,444 --> 00:23:18,132
and how much more scope. If you want to evaluate that or get that sort

362
00:23:18,148 --> 00:23:21,676
of an insight, then I just clicked on

363
00:23:21,740 --> 00:23:25,348
the recommendation wherein it asks to populate or

364
00:23:25,396 --> 00:23:28,868
enrich the data with the population and you can see that it wants

365
00:23:28,916 --> 00:23:32,224
in just one click, a new column has been created,

366
00:23:33,044 --> 00:23:36,416
named accordingly, and all the population

367
00:23:36,520 --> 00:23:40,120
information is also loaded. So this is how

368
00:23:40,312 --> 00:23:43,764
for each of the kind of data that you have in here,

369
00:23:44,344 --> 00:23:46,880
suitable recommendations,

370
00:23:47,032 --> 00:23:51,040
if it is valid, it will definitely be available

371
00:23:51,152 --> 00:23:54,560
for you. And as a user say, with less technical know

372
00:23:54,592 --> 00:23:56,964
how, this is really going to be handy to,

373
00:23:57,944 --> 00:24:01,372
you know, add more relevant

374
00:24:01,428 --> 00:24:05,484
features to your data, data set that you're analyzing

375
00:24:05,524 --> 00:24:09,012
upon. So once you're happy with your data and all

376
00:24:09,028 --> 00:24:12,644
the transformations and cleansing is done, you can create a

377
00:24:12,684 --> 00:24:16,024
workbook out of it. So I'm going to save

378
00:24:16,404 --> 00:24:20,300
all the steps which has been added, primarily the column

379
00:24:20,332 --> 00:24:23,636
addition. And now you can see that that new column

380
00:24:23,660 --> 00:24:26,504
is also loaded in here in.

381
00:24:26,934 --> 00:24:30,518
So if you go back to the initial workbook that we had created and

382
00:24:30,606 --> 00:24:33,830
go to the visualize bar, we already had the auto

383
00:24:33,862 --> 00:24:37,662
insights in the initial when it was initially loaded.

384
00:24:37,798 --> 00:24:40,654
That is our starting point of analysis, for example.

385
00:24:40,774 --> 00:24:44,374
This is likewise if at all you want to make any change in here,

386
00:24:44,534 --> 00:24:48,414
it is as easy as removing or

387
00:24:48,454 --> 00:24:52,226
dragging and dropping the see the

388
00:24:52,250 --> 00:24:55,762
corresponding fields and you will be able to see

389
00:24:55,938 --> 00:24:59,570
how the data is immediately. The changes are reflected in

390
00:24:59,602 --> 00:25:02,854
here. Now just, you know, randomly showing you,

391
00:25:03,554 --> 00:25:07,250
if you're not sure like where, which exact position to drop it,

392
00:25:07,282 --> 00:25:10,562
you can even just drop it into the visualization area

393
00:25:10,738 --> 00:25:14,770
and it is smart enough to group it accordingly

394
00:25:14,802 --> 00:25:18,162
for the given visualization style and for

395
00:25:18,178 --> 00:25:22,226
your data stories. Suppose say you only know some key

396
00:25:22,330 --> 00:25:25,914
fields which you are interested in. Like for example in

397
00:25:25,954 --> 00:25:29,306
here we have, we are interested in understanding more about

398
00:25:29,370 --> 00:25:33,134
profit and sales

399
00:25:33,554 --> 00:25:37,050
and discount and quantities are some of the key information I have

400
00:25:37,082 --> 00:25:40,506
picked up here. And you're not very sure what kind of visualization

401
00:25:40,610 --> 00:25:44,186
will really serve me good here to get a good understanding of

402
00:25:44,210 --> 00:25:47,482
the data or the patterns or insights. So what I'm doing is I'm

403
00:25:47,498 --> 00:25:51,166
just selecting it and bringing it to the

404
00:25:51,190 --> 00:25:54,806
canvas area. So you can see this green bar kind

405
00:25:54,830 --> 00:25:58,902
of guides me, the positioning of the new visualization

406
00:25:59,038 --> 00:26:03,714
which will be created out of it. So I'm just in selecting

407
00:26:04,094 --> 00:26:06,910
a smaller portion in here in the middle of both.

408
00:26:07,062 --> 00:26:10,494
So you can see that automatically a pivot is

409
00:26:10,534 --> 00:26:14,006
created out of this information. And if

410
00:26:14,030 --> 00:26:17,630
you want to change the visualization into any

411
00:26:17,662 --> 00:26:21,654
other kind which you think could help you better,

412
00:26:21,814 --> 00:26:25,766
you will also be able to just select it

413
00:26:25,790 --> 00:26:29,606
accordingly and all those information will be available or

414
00:26:29,630 --> 00:26:33,014
the changes will be reflecting right away.

415
00:26:33,134 --> 00:26:36,294
Also, for your visualization or analysis,

416
00:26:36,334 --> 00:26:39,726
the exploratory analysis that you're doing, if you want to add any

417
00:26:39,830 --> 00:26:43,246
filters, you will be able to drop in the

418
00:26:43,350 --> 00:26:46,314
filter fields, the filter bar in here,

419
00:26:46,394 --> 00:26:49,970
or if even, you know, visualization in itself

420
00:26:50,042 --> 00:26:53,514
can be acting as a filter, you have use this

421
00:26:53,554 --> 00:26:58,378
filter option to create or use visualization

422
00:26:58,546 --> 00:27:01,930
to be a filter for all the other visualization that you already created

423
00:27:01,962 --> 00:27:05,962
so that you, you're doing your analysis on the basis of all the

424
00:27:06,098 --> 00:27:09,254
factors. Like for example, if I'm creating,

425
00:27:10,214 --> 00:27:13,834
if I used or apply the user's filter for this visualization,

426
00:27:14,254 --> 00:27:17,790
which I did, I can see the tick mark in here. So if I click

427
00:27:17,822 --> 00:27:22,142
on any of these data points, or you

428
00:27:22,158 --> 00:27:25,674
can see how the visualization

429
00:27:26,014 --> 00:27:29,750
is loaded, which changes accordingly based

430
00:27:29,782 --> 00:27:33,838
on the selection made in one visualization. So many such options

431
00:27:34,006 --> 00:27:37,610
are available for you. Oracle analytics includes more than

432
00:27:37,642 --> 00:27:41,642
45 different built in visualization types. And for any cases

433
00:27:41,698 --> 00:27:44,174
that require unique or specialized visualization,

434
00:27:44,954 --> 00:27:48,814
you will also be able to map

435
00:27:49,834 --> 00:27:53,374
new visualizer custom visualizations from the extensions

436
00:27:55,234 --> 00:27:58,546
visualization extension that is available for you. So these are all like

437
00:27:58,570 --> 00:28:02,218
custom visualization which are in addition

438
00:28:02,306 --> 00:28:05,510
to the inbuilt visualization types which you

439
00:28:05,542 --> 00:28:09,334
have. So creating visualization helps you represent and

440
00:28:09,374 --> 00:28:12,638
analyze your data patterns, find insights,

441
00:28:12,686 --> 00:28:16,766
show trends, display distribution across timelines

442
00:28:16,830 --> 00:28:20,394
or geographic region. So this is the advantage of it.

443
00:28:20,774 --> 00:28:24,454
So automatically the interactive elements we had

444
00:28:24,574 --> 00:28:28,606
a quick look at. We also saw the built in visualizations

445
00:28:28,710 --> 00:28:32,646
extensions I was just showing you here. The custom visualizations are nothing

446
00:28:32,670 --> 00:28:35,832
but the extensions, extensions which we have embedded

447
00:28:35,968 --> 00:28:39,072
and also one click machine learning power.

448
00:28:39,128 --> 00:28:42,424
Now if you want to show say a trend analysis, now this is a time

449
00:28:42,464 --> 00:28:46,200
series data. We have the timelines compared against.

450
00:28:46,352 --> 00:28:50,312
If you want to add some statistics, you know

451
00:28:50,328 --> 00:28:53,656
which, which is created with the help of the

452
00:28:53,680 --> 00:28:57,024
machine learning algorithms, it is just again one click

453
00:28:57,064 --> 00:29:01,110
away. Say if you want to add a trend line for

454
00:29:01,142 --> 00:29:04,654
this visualization for each of the

455
00:29:04,694 --> 00:29:08,030
index value, what, how exactly the trend line or the

456
00:29:08,062 --> 00:29:11,510
trend has been is established with the corresponding

457
00:29:11,542 --> 00:29:15,110
color code. Also now say

458
00:29:15,262 --> 00:29:18,966
if I am taking the trend line out and say if

459
00:29:18,990 --> 00:29:23,154
I want to add some other statistics like outliers.

460
00:29:24,134 --> 00:29:27,838
The outliers did not work because it needs additional

461
00:29:27,886 --> 00:29:31,414
information. So let's go back in the interest of

462
00:29:31,454 --> 00:29:35,302
time. I'm just quickly showing you some

463
00:29:35,438 --> 00:29:39,354
option which we can definitely apply on top of the line chart here.

464
00:29:40,054 --> 00:29:44,414
Let's take a look at a data story which is built out of Oracle analytics

465
00:29:44,574 --> 00:29:48,846
taking the same data set that we have seen so far, the sales superstore.

466
00:29:49,030 --> 00:29:52,478
So in here you can see that what I'm trying to do

467
00:29:52,566 --> 00:29:56,676
is check out complete analysis

468
00:29:56,790 --> 00:30:00,560
of different dimensions of the sales data for the superstore.

469
00:30:00,752 --> 00:30:04,360
And starting with the sales overview, I have given

470
00:30:04,432 --> 00:30:08,120
a map view which is always quite attractive with respect

471
00:30:08,192 --> 00:30:11,992
to visually full attention of the audience and

472
00:30:12,048 --> 00:30:15,848
give it one glance understanding

473
00:30:15,896 --> 00:30:19,152
of which specific stage

474
00:30:19,208 --> 00:30:22,588
the sales has been higher and where it has

475
00:30:22,736 --> 00:30:26,444
lower or minimal, and which region there has been

476
00:30:26,484 --> 00:30:29,676
good business. So all these understanding, you are able to

477
00:30:29,700 --> 00:30:33,932
see that with a quick glance in this map view.

478
00:30:34,068 --> 00:30:37,876
Also to support if you want to filter out any

479
00:30:37,940 --> 00:30:41,860
particular info sales information

480
00:30:42,052 --> 00:30:45,388
I have given the filters for city category, order date,

481
00:30:45,436 --> 00:30:48,384
product name and ship date.

482
00:30:48,994 --> 00:30:52,770
Additionally have included the tiles

483
00:30:52,882 --> 00:30:56,554
in here with the major sales profit quantity

484
00:30:56,634 --> 00:30:59,754
and discount figures for bringing

485
00:30:59,794 --> 00:31:03,386
the attention. So I also added

486
00:31:03,450 --> 00:31:07,094
some conditional formatting in here. If you look at

487
00:31:07,394 --> 00:31:10,654
manage rooms, if you want to say

488
00:31:12,114 --> 00:31:15,458
you want to conditionally display

489
00:31:15,506 --> 00:31:19,162
some icons to show whether the sales has been positive

490
00:31:19,258 --> 00:31:22,538
or negative, let's say if you are going

491
00:31:22,586 --> 00:31:27,414
to have a sales of 500,000,

492
00:31:27,914 --> 00:31:31,290
then if your organization it

493
00:31:31,322 --> 00:31:35,666
can be considered as a positive state,

494
00:31:35,730 --> 00:31:39,450
then we could just conditionally format it

495
00:31:39,482 --> 00:31:42,864
further. So I have added the conditional formatting

496
00:31:42,904 --> 00:31:46,560
and you can see that the icon is also giving the user

497
00:31:46,592 --> 00:31:50,272
an additional assurance that it is all as

498
00:31:50,328 --> 00:31:53,384
expected and in green. So likewise,

499
00:31:53,504 --> 00:31:57,400
conditional formatting can also be effectively utilized to

500
00:31:57,552 --> 00:32:01,968
pass on a data message. Going further sales

501
00:32:02,016 --> 00:32:05,900
performance across time so I try to ask

502
00:32:06,072 --> 00:32:09,340
the question about how the sales performance has

503
00:32:09,372 --> 00:32:13,652
been across time period and visually analyzing the answer

504
00:32:13,708 --> 00:32:14,664
to the question.

505
00:32:16,724 --> 00:32:20,972
As you can see here, we have taken the timeline

506
00:32:21,068 --> 00:32:25,704
between February 2017 to December 2020

507
00:32:26,004 --> 00:32:29,516
and try to understand how sales has been varied

508
00:32:29,580 --> 00:32:32,676
across this timeline. Also added a reference

509
00:32:32,740 --> 00:32:36,600
line to show you and average sales

510
00:32:36,712 --> 00:32:40,480
performance. Additionally have included

511
00:32:40,512 --> 00:32:43,648
the trend line in here, the gray colors

512
00:32:43,696 --> 00:32:47,072
you can see it will give an understanding to the audience whether

513
00:32:47,208 --> 00:32:50,400
the trend has been positive or negative. So these are all

514
00:32:50,432 --> 00:32:53,880
ways to visually understand how exactly

515
00:32:53,992 --> 00:32:57,616
the sales performance has been. I want

516
00:32:57,640 --> 00:33:01,808
to further ask a question about per product sales

517
00:33:01,856 --> 00:33:05,560
performance. So that is why this visual analysis is

518
00:33:05,592 --> 00:33:08,864
brought in here. And as you can see,

519
00:33:08,984 --> 00:33:12,296
then we add the product name and the sales

520
00:33:12,400 --> 00:33:15,536
to the bar chart, the horizontal stack bar chart

521
00:33:15,560 --> 00:33:19,352
which I used here, which is quite ideal when you have

522
00:33:19,528 --> 00:33:22,984
a long label for

523
00:33:23,024 --> 00:33:26,616
the x axis. So because all the product names has been in here, this,

524
00:33:26,640 --> 00:33:30,350
this really gives a very clear visual view of the

525
00:33:30,382 --> 00:33:34,222
entire data. And also the sorting is applied

526
00:33:34,398 --> 00:33:38,514
based on the sales figures from high to low. So that is also giving

527
00:33:39,894 --> 00:33:43,366
one quick glance understanding of

528
00:33:43,510 --> 00:33:47,374
how this shear speakers have been performing

529
00:33:47,414 --> 00:33:50,734
for each of the product. So the filters in

530
00:33:50,774 --> 00:33:54,330
here is handy for doing manual analysis

531
00:33:54,422 --> 00:33:58,378
because for each of the product type, we have

532
00:33:58,426 --> 00:34:01,682
all product category and subcategory separately we have

533
00:34:01,738 --> 00:34:05,066
separate performance data. So what I've

534
00:34:05,090 --> 00:34:08,458
done is manually analyzed based on my categories

535
00:34:08,506 --> 00:34:12,202
of category selections. And I

536
00:34:12,218 --> 00:34:15,930
have demarcated all the sales

537
00:34:16,042 --> 00:34:19,970
highlights for each category so that I'll be able

538
00:34:20,002 --> 00:34:23,182
to report it to the management easily.

539
00:34:23,238 --> 00:34:27,394
So these are nothing but annotations which we have seen, how we created

540
00:34:28,294 --> 00:34:32,118
and further. So this basically

541
00:34:32,286 --> 00:34:36,366
I have, what I have given here is all the positive data in which exact

542
00:34:36,550 --> 00:34:40,198
category and subcategory products have got the best

543
00:34:40,246 --> 00:34:44,234
sales. So that's, that's what we have in the notes there.

544
00:34:44,654 --> 00:34:48,230
Now I am also trying to study the

545
00:34:48,262 --> 00:34:51,263
profit for each product category.

546
00:34:51,563 --> 00:34:55,035
So at this point in this visual analysis, I could

547
00:34:55,059 --> 00:34:59,227
say that there were some losses incurred specifically under

548
00:34:59,395 --> 00:35:02,907
the category of office supplies and

549
00:35:03,035 --> 00:35:06,903
also furnitures. So that's color coded

550
00:35:07,363 --> 00:35:11,243
as you can see in the label here, and the maximum loss

551
00:35:11,323 --> 00:35:14,896
has been incurred under the category of furniture and

552
00:35:14,920 --> 00:35:19,056
subcategory of tables of around eighteen

553
00:35:19,240 --> 00:35:22,784
k dollars. So I

554
00:35:22,824 --> 00:35:26,440
am now trying to go in depth to understand

555
00:35:26,552 --> 00:35:29,568
the figures around, you know, these categories

556
00:35:29,656 --> 00:35:33,944
and subcategories, as you can see here. So if

557
00:35:33,984 --> 00:35:37,840
I go to furnitures, you can

558
00:35:37,872 --> 00:35:41,304
see that the tables, the loss

559
00:35:41,384 --> 00:35:44,952
incurred numbers have been set in here and I can match it

560
00:35:44,968 --> 00:35:49,744
against the quantity and sales figures compared

561
00:35:49,784 --> 00:35:54,784
to the other subcategories as well. So specifically

562
00:35:54,944 --> 00:35:58,004
for the tables,

563
00:35:58,464 --> 00:36:01,928
we are trying to understand why or what

564
00:36:01,976 --> 00:36:06,940
exactly has happened in here. So I need to just

565
00:36:07,012 --> 00:36:11,196
rename it to tables and furnitures.

566
00:36:11,300 --> 00:36:14,380
So you can see how quickly we

567
00:36:14,412 --> 00:36:17,784
can able to do all these.

568
00:36:18,364 --> 00:36:21,980
So furniture stables is the loss allowances. What I'm

569
00:36:22,012 --> 00:36:25,660
specifically doing here, and based on the comparison

570
00:36:25,732 --> 00:36:29,864
between the quantity, sales and discount data for furnitures

571
00:36:30,444 --> 00:36:33,832
subcategories, I want inference. I have finally

572
00:36:33,888 --> 00:36:36,768
decided is that for tables,

573
00:36:36,936 --> 00:36:40,784
as you can see, the quantity sold and as well as

574
00:36:40,824 --> 00:36:44,644
the sales figures are not really

575
00:36:45,304 --> 00:36:47,644
that less comparatively,

576
00:36:49,744 --> 00:36:52,992
however. So yeah, the table is coming here. So when

577
00:36:53,008 --> 00:36:56,176
I'm selecting the table in one visualization, you can see that

578
00:36:56,200 --> 00:36:59,728
it has been highlighted in the other visualization. So this is a brushing

579
00:36:59,776 --> 00:37:02,824
concept that is playing out here.

580
00:37:02,944 --> 00:37:06,240
So what inference I have from

581
00:37:06,312 --> 00:37:10,416
this data is that probably the higher discounts for

582
00:37:10,440 --> 00:37:13,880
tables, which is leading to the loss scenario, even if

583
00:37:13,912 --> 00:37:17,504
the sales figures and the quantity sold are

584
00:37:17,544 --> 00:37:21,704
comparatively higher than many other subcategory of

585
00:37:21,744 --> 00:37:25,272
products. So, discount figures compared to

586
00:37:25,288 --> 00:37:28,756
its price pricing are marked as higher than approval limits and needs to be

587
00:37:28,780 --> 00:37:32,844
controlled in future. So this is my final inference or

588
00:37:32,924 --> 00:37:36,116
the main tagline for the data story,

589
00:37:36,260 --> 00:37:39,572
which I have to take to my management now

590
00:37:39,628 --> 00:37:44,852
if I'm going to present the understanding

591
00:37:44,908 --> 00:37:48,908
or all these visual analysis, I'm pulling it out to the present

592
00:37:48,996 --> 00:37:52,494
layer for final refinements before my store

593
00:37:52,524 --> 00:37:56,058
story is presented or shared across.

594
00:37:56,226 --> 00:38:00,554
So you can see that all the canvases are pulled out

595
00:38:00,714 --> 00:38:04,418
into our presentation layer. It is being

596
00:38:04,466 --> 00:38:08,138
loaded one after one. And right now I'm happy

597
00:38:08,266 --> 00:38:11,586
with the order which has been given

598
00:38:11,690 --> 00:38:15,930
for the initial four

599
00:38:16,002 --> 00:38:19,396
canvases. So I want it to be intact along with

600
00:38:19,420 --> 00:38:22,980
the notes which I have added now, just if at all. I didn't

601
00:38:23,052 --> 00:38:26,356
want the notes to be in there. I always

602
00:38:26,540 --> 00:38:29,972
could, you know, turn it on or off with the

603
00:38:29,988 --> 00:38:33,108
property adjustments in here, the raw and allisons

604
00:38:33,196 --> 00:38:36,956
for the longs I am trying, I don't want it

605
00:38:36,980 --> 00:38:40,324
to be shared across with the manager. It was just for my

606
00:38:40,364 --> 00:38:43,660
understanding, which I had done so I'm going to hide that in here

607
00:38:43,812 --> 00:38:48,198
and going to settle with these canvases

608
00:38:48,286 --> 00:38:51,910
as active. So just to test it out if

609
00:38:51,942 --> 00:38:55,294
I'm going to play it. You can see how exactly

610
00:38:55,334 --> 00:38:59,514
this data story is going to be

611
00:38:59,974 --> 00:39:02,822
presented to the external stakeholders.

612
00:39:02,878 --> 00:39:08,030
So all the selected five active canvases

613
00:39:08,142 --> 00:39:11,662
are in, you can see in here in

614
00:39:11,678 --> 00:39:14,876
the bottom bar. So the audio has been

615
00:39:14,940 --> 00:39:18,500
intact and also it has taken

616
00:39:18,572 --> 00:39:22,084
out the loss analysis

617
00:39:22,204 --> 00:39:25,596
canvas, which I did not want. And interactivity

618
00:39:25,740 --> 00:39:29,556
of your data storyboard

619
00:39:29,620 --> 00:39:32,900
is also quite the same

620
00:39:32,972 --> 00:39:36,972
as how we saw in the visualization layers. Data points and tooltips

621
00:39:36,988 --> 00:39:40,484
are giving all the information about each of the data points

622
00:39:41,544 --> 00:39:45,724
as you hover your cursor around it and

623
00:39:46,064 --> 00:39:49,456
even we can see all the nodes. We wanted it

624
00:39:49,480 --> 00:39:52,952
to be there for the management to know and visually the

625
00:39:52,968 --> 00:39:56,632
color coding and the sorting orders. Everything is looking

626
00:39:56,688 --> 00:40:00,640
intact with respect to giving a clear messaging to,

627
00:40:00,832 --> 00:40:04,680
as to what is the exact scenario

628
00:40:04,752 --> 00:40:09,082
in our sales analysis and where our

629
00:40:09,218 --> 00:40:12,778
focus area should be to avoid the losses.

630
00:40:12,906 --> 00:40:16,974
So that is the data story which I have shared

631
00:40:17,314 --> 00:40:21,134
as an example here with the help of Oracle analytics.

632
00:40:21,714 --> 00:40:25,250
So this gives you a good understanding of in what all

633
00:40:25,282 --> 00:40:29,426
ways you will be able to use the application.

634
00:40:29,610 --> 00:40:33,354
So not in scope for this discussion

635
00:40:33,694 --> 00:40:37,206
in today's presentation. However, it would be

636
00:40:37,350 --> 00:40:41,078
good to highlight that there's lots more that you can do

637
00:40:41,166 --> 00:40:44,406
with the help of Oracle analytics in

638
00:40:44,430 --> 00:40:47,878
terms of analysis or predictions

639
00:40:48,006 --> 00:40:51,702
or sentiments, you know, sentiment analysis,

640
00:40:51,838 --> 00:40:55,318
specifically about any product feedback, etcetera.

641
00:40:55,366 --> 00:40:58,926
So there are ways in which we can create

642
00:40:58,990 --> 00:41:03,286
the data pipelines, what exactly we call it in our client.

643
00:41:03,470 --> 00:41:07,030
It's a creation of data flows, which is quite powerful

644
00:41:07,102 --> 00:41:10,834
if you want to do even more complex data transformations.

645
00:41:11,254 --> 00:41:15,006
And also, as I said, the sentiment analysis,

646
00:41:15,070 --> 00:41:19,142
it's just a matter of creating or pulling out the right

647
00:41:19,278 --> 00:41:20,874
steps and,

648
00:41:22,294 --> 00:41:25,622
you know, just save the data flow and execute it and it will give you

649
00:41:25,638 --> 00:41:28,374
the final output in the form of data set,

650
00:41:28,454 --> 00:41:32,222
or even you can save it into the database if

651
00:41:32,318 --> 00:41:36,446
that is what is preferred. The same capability

652
00:41:36,590 --> 00:41:39,750
can also give you the power to create,

653
00:41:39,862 --> 00:41:42,634
train models, evaluate models performance,

654
00:41:43,014 --> 00:41:46,630
and finally apply it to live data for

655
00:41:46,662 --> 00:41:50,214
doing predictions or classifications or,

656
00:41:50,334 --> 00:41:54,144
you know, anything which, which requires further

657
00:41:54,924 --> 00:41:57,824
more complex and sophisticated handling.

658
00:41:58,244 --> 00:42:01,744
With machine learning algorithms and models also

659
00:42:02,124 --> 00:42:05,276
playing part. So, so much can be done.

660
00:42:05,420 --> 00:42:09,064
And in the interest of time, we just try to

661
00:42:09,724 --> 00:42:13,252
give an overall understanding of some of the

662
00:42:13,268 --> 00:42:17,580
capabilities, some of the major capabilities, which are quite

663
00:42:17,732 --> 00:42:20,704
important in terms of data storytelling.

664
00:42:21,064 --> 00:42:24,592
And that is where we

665
00:42:24,648 --> 00:42:26,884
stop with the demo for today.

666
00:42:27,584 --> 00:42:31,724
So that was just a quick demonstration to just give you a feel of

667
00:42:32,144 --> 00:42:35,464
the application and the ease with which you will be able to

668
00:42:35,504 --> 00:42:39,488
interact and use all the sophisticated options

669
00:42:39,536 --> 00:42:43,240
that you have. So based on your requirement, you will be able to pick

670
00:42:43,272 --> 00:42:47,400
and choose and get here your data

671
00:42:47,472 --> 00:42:51,520
speaking to you and your audience so what makes a

672
00:42:51,592 --> 00:42:55,672
great data story? Once you have done all your exploration on your data.

673
00:42:55,848 --> 00:42:59,480
So the first thing that you have

674
00:42:59,512 --> 00:43:03,648
to take into account is identifying

675
00:43:03,696 --> 00:43:07,480
your audience. So once you have a clear understanding of who

676
00:43:07,592 --> 00:43:10,856
specifically your audience is, then you can talk to them and perhaps do

677
00:43:10,880 --> 00:43:14,316
additional research, find out what they most care about,

678
00:43:14,380 --> 00:43:18,084
what their goals are, what they currently know, what decisions

679
00:43:18,124 --> 00:43:21,724
need to be made, and what additional knowledge might help

680
00:43:21,764 --> 00:43:24,940
them make the decisions that will help reach

681
00:43:24,972 --> 00:43:28,860
their goals. So knowing your audience will always help you know what

682
00:43:28,932 --> 00:43:31,924
data to look for and include in your analysis.

683
00:43:32,044 --> 00:43:36,244
You might use quantitative data such as about revenue change over time

684
00:43:36,324 --> 00:43:40,170
or number of people impacting. Or you might use qualitative

685
00:43:40,242 --> 00:43:43,522
data such as processes, systems, additional related data.

686
00:43:43,578 --> 00:43:47,522
So all these data sources can be very easily blended

687
00:43:47,618 --> 00:43:51,426
into your analysis workbook when it comes to Oracle

688
00:43:51,450 --> 00:43:54,682
analytics cloud or oracle analytics applications.

689
00:43:54,778 --> 00:43:57,214
So what is relevant?

690
00:43:58,714 --> 00:44:02,226
So audience, once is taken care of, the relevance is the

691
00:44:02,250 --> 00:44:05,660
next feature which we need to be careful of.

692
00:44:05,692 --> 00:44:09,028
So this means that content needs to fit with the audience's

693
00:44:09,076 --> 00:44:12,756
current level of knowledge and it needs to help them reach a goal

694
00:44:12,780 --> 00:44:16,380
of some kind. So maybe your audience is internal,

695
00:44:16,412 --> 00:44:20,588
like a presentation to leadership about the need to invest in a specific

696
00:44:20,716 --> 00:44:24,396
strategy or tactics. Or maybe they're external, like a campaign

697
00:44:24,500 --> 00:44:27,956
to persuade customers to try out your solution. So either way,

698
00:44:28,100 --> 00:44:31,584
think about what matters to them. And the best stories speak to

699
00:44:31,624 --> 00:44:35,684
people, and the more specific the person or the audience is, the better

700
00:44:36,464 --> 00:44:39,404
outlining the story arc.

701
00:44:40,104 --> 00:44:44,644
Once I have my data, I explore some possibilities and

702
00:44:45,544 --> 00:44:48,808
with my story arc in hand, I can think about what sort of design,

703
00:44:48,896 --> 00:44:52,576
layouts or compositions might work best. I want to get a better

704
00:44:52,680 --> 00:44:56,280
idea of what will work visually so that I often sketch out

705
00:44:56,312 --> 00:45:00,258
by hand some layouts and compositions. So this gives you

706
00:45:00,306 --> 00:45:04,218
also an understanding of the

707
00:45:04,266 --> 00:45:08,058
narrative that you want to stick to, since traditional story

708
00:45:08,146 --> 00:45:11,450
art with a beginning, middle and end.

709
00:45:11,522 --> 00:45:15,274
So that is what we are all used to doing. So for data stories,

710
00:45:15,314 --> 00:45:18,690
this usually means you need an introduction to the topic

711
00:45:18,762 --> 00:45:22,730
before you dive into the data. You also need to conclude

712
00:45:22,762 --> 00:45:26,442
with a specific call to action. Now this is another thing that makes a

713
00:45:26,458 --> 00:45:29,934
data story distinctly different from a straightforward report.

714
00:45:30,234 --> 00:45:33,874
Also, if your audience is not an expert, it's important to use

715
00:45:33,954 --> 00:45:37,370
plain language when you call out your

716
00:45:37,442 --> 00:45:41,314
final inferences. Right, and intentional

717
00:45:41,354 --> 00:45:45,298
visuals. What does that mean? It means whether to use

718
00:45:45,346 --> 00:45:49,330
photos, graphs or charts. The visuals you use should help your

719
00:45:49,402 --> 00:45:53,054
audience easily to understand what the data means above.

720
00:45:53,094 --> 00:45:56,446
All, the visuals you include should be appropriate for the

721
00:45:56,470 --> 00:45:58,474
data well labeled,

722
00:45:59,614 --> 00:46:03,206
and the labeling options or formatic

723
00:46:03,270 --> 00:46:07,286
options are definitely easily possible with oracle analytics.

724
00:46:07,430 --> 00:46:10,398
And you also saw how we can add further notes,

725
00:46:10,446 --> 00:46:13,606
annotations and even descriptions which I not show you. But it's

726
00:46:13,630 --> 00:46:16,846
all easily possible.

727
00:46:17,030 --> 00:46:20,898
It should be legible, whatever. Your visuals

728
00:46:21,006 --> 00:46:24,962
should be legible and also not misleading. So great data

729
00:46:25,018 --> 00:46:28,410
stories pay attention to details like use of color and

730
00:46:28,442 --> 00:46:32,826
imagery, including considerations related to accessibility

731
00:46:32,930 --> 00:46:36,914
and diversity. So it is possible with oracle

732
00:46:36,954 --> 00:46:40,378
analytics that you can transform data into compelling

733
00:46:40,426 --> 00:46:43,738
stories that not only inform but inspire action,

734
00:46:43,866 --> 00:46:47,734
leveraging the full potential of the capabilities with them.

735
00:46:48,414 --> 00:46:51,590
If you want to learn more with written and maid

736
00:46:51,702 --> 00:46:55,190
so you can access our technical blog which is

737
00:46:55,222 --> 00:46:57,846
quite popular among the community,

738
00:46:58,030 --> 00:47:01,550
wherein also we have options for you to

739
00:47:01,582 --> 00:47:05,710
learn from us through our bootcamps, which comes in

740
00:47:05,902 --> 00:47:09,838
quite frequently, and a new course.

741
00:47:09,926 --> 00:47:13,124
So whatever we discussed today were all like high level concepts

742
00:47:13,214 --> 00:47:17,272
about data storytelling. Just a quick glance or

743
00:47:17,328 --> 00:47:20,964
peek that I gave you

744
00:47:21,504 --> 00:47:24,600
about the interface as well. But if you want to learn in detail,

745
00:47:24,752 --> 00:47:28,120
we have a new course coming up which is data visualization for

746
00:47:28,152 --> 00:47:29,444
data storytelling,

747
00:47:31,264 --> 00:47:33,364
wherein we will be in detail,

748
00:47:33,784 --> 00:47:37,032
taking you through different processes,

749
00:47:37,088 --> 00:47:41,508
different techniques that you can adopt to formulate

750
00:47:41,556 --> 00:47:44,476
your data story in the right and effective,

751
00:47:44,580 --> 00:47:48,260
impactful manner. With that, we have

752
00:47:48,292 --> 00:47:51,744
come to an end of this quick session.

753
00:47:52,124 --> 00:47:54,584
Hope you learned something out of it,

754
00:47:54,924 --> 00:47:56,604
and thank you very much for listening.

