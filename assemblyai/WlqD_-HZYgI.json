{"language_code": "en_us", "audio_url": "https://cdn.assemblyai.com/upload/d761ab54-2ace-4246-830c-ff449d95e978", "punctuate": true, "format_text": true, "dual_channel": null, "webhook_url": null, "webhook_auth_header_name": null, "webhook_auth_header_value": null, "audio_start_from": null, "audio_end_at": null, "word_boost": ["ambili t", "best", "bestinclass", "bi", "by", "capabilities", "combine", "conf fourty two", "features", "integrated", "ml", "platforms", "principal consultant analytics", "rittman mead", "sets", "takes", "wondered"], "boost_param": "high", "filter_profanity": false, "redact_pii": false, "redact_pii_audio": false, "redact_pii_audio_quality": null, "redact_pii_policies": null, "redact_pii_sub": null, "speaker_labels": false, "speakers_expected": null, "content_safety": false, "content_safety_confidence": null, "iab_categories": false, "custom_spelling": null, "disfluencies": false, "sentiment_analysis": false, "auto_chapters": false, "entity_detection": false, "summarization": true, "summary_model": "informative", "summary_type": "bullets_verbose", "auto_highlights": true, "language_detection": false, "speech_threshold": null, "speech_model": null, "id": "d94f48c3-8068-44ed-b74d-6f2b74090c04", "status": "completed", "error": null, "text": "Hello everyone. Today we're diving into the fascinating world of data storytelling, leveraging the magic of oracle analytics to make it happen. So before we move on with our topic today, a quick introduction about me Uncle Aze and analytics principal consultant with Ritman Mead. I've been in the industry for almost two decades now. Almost been quite fortunate throughout my technical journey to have gained exposure to various technologies starting with mainframes and when came a time to choose my path, I chose Oracle and have been having an exciting ride ever since, starting with data engineering and switching to Oracle analytics as my major focus area since 2019, when I'm not working or speaking in conferences, I would be busy in my full time passion as a mother of my eleven year old daughter, also finding time alongside to explore my journey as an artist, which kind of works wonders to keep me recharged. So I'd be happy to connect with you all through any of my social handles which you can access via the QR code here to discuss anything analytics and also art if you are interested. Alright then, a bit about my organization Ritman Mead is a global oracle data and analytics consultancy. We are oracle partners and have been thought leaders in the industry for more than 16 years. In addition to our reputation as core experts in anything data covering data integration, engineering, data management, data visualization, reporting and also data science, we are also quite popular with our technical content with over 2000 technical blogs published related to all these fields. Happy to be here. My topic storytelling. Now why do we need storytelling? Imagine for a moment that data is not just a collection of numbers and charts, but a vivid narrative that captures your imagination and holds our attention. Now that is the essence of data storytelling. It is an approach that transforms abstract data into meaningful narrative. In today's world, we are bombarded with information from all directions, right? Each day we create an immense amount of data. But how do we make sense of this avalanche of information? How can we extract value from it rather than feeling overwhelmed? Storytelling is the most powerful way to put ideas into the world today as we all know it. For thousands of years, it has been an integral part of our humanity. Data storytelling is our solution to this issue. It's a method of turning dry statistics into engaging stories which resonate with people in the current business world, with exponential growth in data, volume, variety and velocity. All these collected and combined data may hold tremendous amount of potential value, but not an ounce of value can be created unless the insights are uncovered and also translated into actions or business outcomes. So you can all imagine how in the current world and with all these technical advancements happening around, there's been a huge shift towards more self service capabilities in analytics and also bi. The pool of people who are generating insights has expanded beyond just analysts and data scientists now, which is a good thing. But the new breed of data tools which are available is actually making it easier for people across business functions to access and explore the data of their own. So that is definitely a good thing. But what is happening in the other end is that this is also leading to an unprecedented number of insights in which are going unutilized. Unless we can improve the communication, the way we communicate these insights to our stakeholders, we'll also see a poorer insight to value conversion rate, which is a key issue. By framing data within a narrative structure, we not only make it more interesting, but also more impactful. A well crafted story just communicate the information properly or impactfully, but it can also evoke emotions, spark curiosity. It can hold audiences attention far better than raw data ever could. So that is why I have brought this data story from history here to discuss, because 1855, the Crimea war time, Britain was fighting a battle with both Russia and deseasis. As a nurse, how do you think Florence Nightingale can convince an army to invest in hospitals and healthcare instead of guns and ammunition? What she did was telling her story with data in her most famous visualization, as you can see it on screen, the rose chart of deaths. It demonstrated through the color scheme and patterns that a reduction in hospital deaths would lead to thousands of lives saved. This collection and process of visualizing the underlying data was also a revelation to Nightingale, and when she communicated this to the army, the visualization helped convince the british army to make sanitation a priority, which saved lives in the process. Soldiers death had fallen sharply after the government sent out a sanitation committee in March 1855, which cleaned up the hospitals drinking water and ventilation. So what does this tell you? Data helps find opportunities and resolve misunderstandings. A well crafted story can evoke emotions, spark curiosity, and hold audiences attention far better than raw data ever could. Being a navigator who charts a course through the vast sea of information, identifying hidden patterns and connections, or insights that might otherwise go unnoticed when effectively done. This enables informed decision making. And by integrating storytelling with data, what we are actually doing is bridging the gap between data experts and everyone else. Data stories influence people's thoughts and actions at critical points in history. There's been so many other examples too, if you look back, which has made an impact on the world around us, and that is the true power of data storytelling. If you don't communicate your data clearly, your audience might be like those blind men here in the story, in this old story parable, if I can call it so, each person is touching a different part of an elephant and coming up with their own ideas about what it is. The sky feels the trunk, it's touching the trunk. It's a snake tail. Seems like rope for this linemen. And the body is felt like a wall, right? So they basically, they are all guessing based on their limited view and experiences. Without the right context, it is easy to misunderstand the full picture. Context matters. So here is something interesting from a study at USC. Researchers found that people with brain damage in a part of the brain that handles emotions had a really hard time making basic decisions when given choices. These folks struggle because they couldn't use their emotions to help them decide. Now, this shows that emotions are super important in making decisions quickly and effectively. So when we share data, it's not just about throwing out numbers. We need to connect with our audience emotionally to help them understand and make good decisions. And that's where good storytelling with data comes into picture. By making our data relatable and providing the right context, we help our audience really get it and act on it. It's also power. Gives you the power to influence. Let's see an example just to prove my point. Now, imagine you're trying to convince your team to invest in a new project. You could just show them a boring spreadsheet or some data, or numbers, like how you can see in here we have the schedule type, productivity score, and satisfaction rate for two kinds of two schedule types, which are compared against the traditional and flexible schedule. Now, this is one option or one way of sharing your information with your audience. But instead, you could also craft a narrative. Now, you start with a relatable problem, add some compelling data points that highlight the issue, then show how your project is the perfect solution. Now that is a good way of building your narrative, an effective narrative. So by the end, your team isn't just nodding along, they're excited and also ready to take action. Now, that's where the power of influence through data storing telling comes into picture. It's all about connecting the dots in a way that resonates with people. You're not just presenting the information, you're guiding your audience to a conclusion, making the data meaningful and memorable. When you tell a story with your data, you're not just informing, you're inspiring. And that's how real change happens. So here in this visual, as I said, it's just a plain table showing raw numbers for productivity scores and satisfaction rates. And probably a narrative that can go along with this data which is shared, is that the study shows the flexible schedules have higher productivity scores and employee satisfaction rates compared to traditional schedules. Now, this approach is lacking what engaging visuals, and also there's no storytelling element in it which, which makes the data come to life. So this simply presents a raw data without context, without emotional appeal or even a narrative structure, making it harder for the audience to grasp the significance and connect with the information. Now how does this look? Now this is a more visual narrative which also has given or highlighted the key points or key message behind the visual that we have in here. Stressing on the key points, also using the color coding to bring, to give the audience extra understanding. With just one look here, we are able to understand what the numbers, which are important, and also the positive and negative aspects of the comparison with red and green color coding, which is, which are bolded, right? So it's just the way you present the data, which kind of makes it very easy for your audience to grasp it all at just one glance rather than, you know, giving them the plain numbers and letting them guess the understanding behind based on their own perception that actually underlies a lot of risk. They may not really get the point that you're even wanting to communicate. So your weapon, that's where Oracle analytics comes into picture. So Oracle analytics is your comprehensive solution, offering a robust suit of features that cover every step of the analytics journey, from connecting to data modeling, preparation of your data exploration, visualization, even storytelling and collaboration with other counterparts. It's all here in one integrated platform. But what sets Oracle analytics apart? Let's take a look. Firstly, it caters to everyone in your organization, from it and data engineers to citizen data scientists, executors, business users. No matter your role, Oracle analytics has something for you now. The embedded machine learning brings advanced analytics capabilities to every user, whether you are a novice or an expert. And with both centralized and governed reporting and self service options, you can trust that your data is consistent and reliable, no matter who is accessing it. So basically, Oracle analytics abstracts the complexities of your data sources, the query languages, making it easy for even business users to dive into analysis without getting bogged down in technical details. And let's not forget about data security. With built in trackable data preparation and enrichment, there's no need for risky data exports or reliance on Excel spreadsheets. Now, when it comes to deployment options, Oracle has you covered for those migrating to the cloud. Oracle Analytics Cloud OAC is a solution and built on OCI Oracle cloud infrastructure OIC offers the benefits of cloud native analytics without the need for on premises infrastructure. But if you prefer to keep your data on prem, then Oracle analytics server is the answer. When studying about the importance of context, it is crucial to develop your understanding of exploratory and explanatory analysis. When we do exploratory analysis, we may need to test hundred different hypotheses or look at the data in hundred different ways to find the core message that you want to communicate. There's a specific story you may want to tell. So on a high level exploratory analysis which kind of marks the first starting point of your of creating a good data story, it involves understanding your data well, highlighting interest, testing different hypotheses which could be underlined will be to connect to the right data sources of your choice from cloud or on Prem Oracle analytics applications. When you use them OAC or OAS, it allows seamless connectivity to all major data sources, be it in cloud or on premises or PAAS application. You can also connect to data sources with rest endpoints and analyze the data. For example, connect to SAS or PAAS applications or government data such as weather, spatial or census data without compromising on data governance. The connecting to data via rest endpoints enables you to analyze data from many transactional SAS or PaaS applications without having to understand the internal format or structure of the data. So that's the advantage of it. You can see on screen the Oracle analytics cloud interface, the application home page in here. So I'm going to quickly show you how easily you'll be able to start with your data exploration with the help of Oracle analytics cloud for creating your data story. So to create a new data source or connection, it is as easy as accessing these options and create connection gives you create a connection on top of any any data source that you can think of. As you can see in here, even the rest API connection is possible and what you just need is the connection credentials when you map it, the wallet. So whatever connection credentials, if it is handy then feed it and it's just a quick way to connect to all your data sources. So once you create a connection, you will be able to create a data set on top of it. Therein. We have to choose the connection which is established and then select the table or the schema, the tables or even say if you have a spreadsheet, data that you want to analyze on top of. Just need to drag and drop the file in here so that you'll be able to access it into the interface. So for our analysis, which I want to quickly demonstrate, I am going to access an existing data set which is having the sales data. I thought this would be interesting to access. Sales super stole. Let me go back to the home page and take it from there. Sales this way I'm searching could be different. Yeah, we do have the sales superstore. So I click on the sales superstore data set and you can see that it has taken me to the workbook. So a new workbook is created on top of it and you can see on the right hand side it is already giving you, even if you, even if say I didn't have any understanding about the data set as a user and I'm trying to find a grip on what exactly is the information stored in there. You can see the auto insights which are loaded in the right hand side which is generated based out of the machine learning algorithms running in the background. So we are getting a good start of understanding of the data which is residing and there could be a lot of visual analysis which is readily available for you, which you could directly use for your data story. So if I just click on plus you can see automatically the canvas is loaded with the visualization. Let me try to bring this heat map as well. And likewise I'm just randomly adding some of the analysis which I thought we could include in the story. So I'm just pulling few ones in here and you can see that automatically. It is all adjusting the position, the layout, and so the interface is by default capable enough to do that. And if you want to do any data preparation for your data, now what? How do we access the data editor? So you click on data, you click on the edit button there and you can soon see that the data is loaded in here. So once we import our data sets or create connections and access our data sources, we'll be cleaning the data by removing say duplicates or handling any missing values to ensure accuracy, even we can do any transformations on the data as relevant. So Oracle analytics also gives you the power of machine learning algorithms, recommending possible data enrichments that can be applied in just one click. So you can see the recommendations are listed in the right hand side. And so currently the data set which is loaded, you can see the preview pane in here, gives you an all full on high level understanding of the data, how exactly it is varied, and if at all there was any missing value or null values, we would actually be intimated or notified by red color code. And if you want to do any sort of data transformation for any of the columns, like for example the sales. Let's see. So all these transformation options are readily available for you, which will be if when applied, it will be added as a step in the left hand side. You can keep a track of the steps that you're adding as your transformation steps. Just to give a quick demo, if I say rename the sales column in here. So if I say it is sales sales test. So I'm just testing the renaming option to show you how the steps are added in the left hand side you can see if you don't want that step to be applied, you can even decide to remove it at later point in time and it will be reverted back. So likewise any sort of transformation you will be able to work on in this transform editor and the recommendations is another interesting or very, very useful feature which is powered by machine learning. Now say if I click on any of these fields which I'm interested in now, this is a location field. Now see the enrichment, the data enrichment refers to. If you know, it gives you the capability to add information based on existing data which is not already there. If it is meaningful for your analysis, it is just one click away in here. Like for example, now what we have in here is the city information, the country, state, province, I think we already have it in here. But say, if we were also interested in understanding the population of that city to see, you know, how much is our range in terms of sales already and how much more scope. If you want to evaluate that or get that sort of an insight, then I just clicked on the recommendation wherein it asks to populate or enrich the data with the population and you can see that it wants in just one click, a new column has been created, named accordingly, and all the population information is also loaded. So this is how for each of the kind of data that you have in here, suitable recommendations, if it is valid, it will definitely be available for you. And as a user say, with less technical know how, this is really going to be handy to, you know, add more relevant features to your data, data set that you're analyzing upon. So once you're happy with your data and all the transformations and cleansing is done, you can create a workbook out of it. So I'm going to save all the steps which has been added, primarily the column addition. And now you can see that that new column is also loaded in here in. So if you go back to the initial workbook that we had created and go to the visualize bar, we already had the auto insights in the initial when it was initially loaded. That is our starting point of analysis, for example. This is likewise if at all you want to make any change in here, it is as easy as removing or dragging and dropping the see the corresponding fields and you will be able to see how the data is immediately. The changes are reflected in here. Now just, you know, randomly showing you, if you're not sure like where, which exact position to drop it, you can even just drop it into the visualization area and it is smart enough to group it accordingly for the given visualization style and for your data stories. Suppose say you only know some key fields which you are interested in. Like for example in here we have, we are interested in understanding more about profit and sales and discount and quantities are some of the key information I have picked up here. And you're not very sure what kind of visualization will really serve me good here to get a good understanding of the data or the patterns or insights. So what I'm doing is I'm just selecting it and bringing it to the canvas area. So you can see this green bar kind of guides me, the positioning of the new visualization which will be created out of it. So I'm just in selecting a smaller portion in here in the middle of both. So you can see that automatically a pivot is created out of this information. And if you want to change the visualization into any other kind which you think could help you better, you will also be able to just select it accordingly and all those information will be available or the changes will be reflecting right away. Also, for your visualization or analysis, the exploratory analysis that you're doing, if you want to add any filters, you will be able to drop in the filter fields, the filter bar in here, or if even, you know, visualization in itself can be acting as a filter, you have use this filter option to create or use visualization to be a filter for all the other visualization that you already created so that you, you're doing your analysis on the basis of all the factors. Like for example, if I'm creating, if I used or apply the user's filter for this visualization, which I did, I can see the tick mark in here. So if I click on any of these data points, or you can see how the visualization is loaded, which changes accordingly based on the selection made in one visualization. So many such options are available for you. Oracle analytics includes more than 45 different built in visualization types. And for any cases that require unique or specialized visualization, you will also be able to map new visualizer custom visualizations from the extensions visualization extension that is available for you. So these are all like custom visualization which are in addition to the inbuilt visualization types which you have. So creating visualization helps you represent and analyze your data patterns, find insights, show trends, display distribution across timelines or geographic region. So this is the advantage of it. So automatically the interactive elements we had a quick look at. We also saw the built in visualizations extensions I was just showing you here. The custom visualizations are nothing but the extensions, extensions which we have embedded and also one click machine learning power. Now if you want to show say a trend analysis, now this is a time series data. We have the timelines compared against. If you want to add some statistics, you know which, which is created with the help of the machine learning algorithms, it is just again one click away. Say if you want to add a trend line for this visualization for each of the index value, what, how exactly the trend line or the trend has been is established with the corresponding color code. Also now say if I am taking the trend line out and say if I want to add some other statistics like outliers. The outliers did not work because it needs additional information. So let's go back in the interest of time. I'm just quickly showing you some option which we can definitely apply on top of the line chart here. Let's take a look at a data story which is built out of Oracle analytics taking the same data set that we have seen so far, the sales superstore. So in here you can see that what I'm trying to do is check out complete analysis of different dimensions of the sales data for the superstore. And starting with the sales overview, I have given a map view which is always quite attractive with respect to visually full attention of the audience and give it one glance understanding of which specific stage the sales has been higher and where it has lower or minimal, and which region there has been good business. So all these understanding, you are able to see that with a quick glance in this map view. Also to support if you want to filter out any particular info sales information I have given the filters for city category, order date, product name and ship date. Additionally have included the tiles in here with the major sales profit quantity and discount figures for bringing the attention. So I also added some conditional formatting in here. If you look at manage rooms, if you want to say you want to conditionally display some icons to show whether the sales has been positive or negative, let's say if you are going to have a sales of 500,000, then if your organization it can be considered as a positive state, then we could just conditionally format it further. So I have added the conditional formatting and you can see that the icon is also giving the user an additional assurance that it is all as expected and in green. So likewise, conditional formatting can also be effectively utilized to pass on a data message. Going further sales performance across time so I try to ask the question about how the sales performance has been across time period and visually analyzing the answer to the question. As you can see here, we have taken the timeline between February 2017 to December 2020 and try to understand how sales has been varied across this timeline. Also added a reference line to show you and average sales performance. Additionally have included the trend line in here, the gray colors you can see it will give an understanding to the audience whether the trend has been positive or negative. So these are all ways to visually understand how exactly the sales performance has been. I want to further ask a question about per product sales performance. So that is why this visual analysis is brought in here. And as you can see, then we add the product name and the sales to the bar chart, the horizontal stack bar chart which I used here, which is quite ideal when you have a long label for the x axis. So because all the product names has been in here, this, this really gives a very clear visual view of the entire data. And also the sorting is applied based on the sales figures from high to low. So that is also giving one quick glance understanding of how this shear speakers have been performing for each of the product. So the filters in here is handy for doing manual analysis because for each of the product type, we have all product category and subcategory separately we have separate performance data. So what I've done is manually analyzed based on my categories of category selections. And I have demarcated all the sales highlights for each category so that I'll be able to report it to the management easily. So these are nothing but annotations which we have seen, how we created and further. So this basically I have, what I have given here is all the positive data in which exact category and subcategory products have got the best sales. So that's, that's what we have in the notes there. Now I am also trying to study the profit for each product category. So at this point in this visual analysis, I could say that there were some losses incurred specifically under the category of office supplies and also furnitures. So that's color coded as you can see in the label here, and the maximum loss has been incurred under the category of furniture and subcategory of tables of around eighteen k dollars. So I am now trying to go in depth to understand the figures around, you know, these categories and subcategories, as you can see here. So if I go to furnitures, you can see that the tables, the loss incurred numbers have been set in here and I can match it against the quantity and sales figures compared to the other subcategories as well. So specifically for the tables, we are trying to understand why or what exactly has happened in here. So I need to just rename it to tables and furnitures. So you can see how quickly we can able to do all these. So furniture stables is the loss allowances. What I'm specifically doing here, and based on the comparison between the quantity, sales and discount data for furnitures subcategories, I want inference. I have finally decided is that for tables, as you can see, the quantity sold and as well as the sales figures are not really that less comparatively, however. So yeah, the table is coming here. So when I'm selecting the table in one visualization, you can see that it has been highlighted in the other visualization. So this is a brushing concept that is playing out here. So what inference I have from this data is that probably the higher discounts for tables, which is leading to the loss scenario, even if the sales figures and the quantity sold are comparatively higher than many other subcategory of products. So, discount figures compared to its price pricing are marked as higher than approval limits and needs to be controlled in future. So this is my final inference or the main tagline for the data story, which I have to take to my management now if I'm going to present the understanding or all these visual analysis, I'm pulling it out to the present layer for final refinements before my store story is presented or shared across. So you can see that all the canvases are pulled out into our presentation layer. It is being loaded one after one. And right now I'm happy with the order which has been given for the initial four canvases. So I want it to be intact along with the notes which I have added now, just if at all. I didn't want the notes to be in there. I always could, you know, turn it on or off with the property adjustments in here, the raw and allisons for the longs I am trying, I don't want it to be shared across with the manager. It was just for my understanding, which I had done so I'm going to hide that in here and going to settle with these canvases as active. So just to test it out if I'm going to play it. You can see how exactly this data story is going to be presented to the external stakeholders. So all the selected five active canvases are in, you can see in here in the bottom bar. So the audio has been intact and also it has taken out the loss analysis canvas, which I did not want. And interactivity of your data storyboard is also quite the same as how we saw in the visualization layers. Data points and tooltips are giving all the information about each of the data points as you hover your cursor around it and even we can see all the nodes. We wanted it to be there for the management to know and visually the color coding and the sorting orders. Everything is looking intact with respect to giving a clear messaging to, as to what is the exact scenario in our sales analysis and where our focus area should be to avoid the losses. So that is the data story which I have shared as an example here with the help of Oracle analytics. So this gives you a good understanding of in what all ways you will be able to use the application. So not in scope for this discussion in today's presentation. However, it would be good to highlight that there's lots more that you can do with the help of Oracle analytics in terms of analysis or predictions or sentiments, you know, sentiment analysis, specifically about any product feedback, etcetera. So there are ways in which we can create the data pipelines, what exactly we call it in our client. It's a creation of data flows, which is quite powerful if you want to do even more complex data transformations. And also, as I said, the sentiment analysis, it's just a matter of creating or pulling out the right steps and, you know, just save the data flow and execute it and it will give you the final output in the form of data set, or even you can save it into the database if that is what is preferred. The same capability can also give you the power to create, train models, evaluate models performance, and finally apply it to live data for doing predictions or classifications or, you know, anything which, which requires further more complex and sophisticated handling. With machine learning algorithms and models also playing part. So, so much can be done. And in the interest of time, we just try to give an overall understanding of some of the capabilities, some of the major capabilities, which are quite important in terms of data storytelling. And that is where we stop with the demo for today. So that was just a quick demonstration to just give you a feel of the application and the ease with which you will be able to interact and use all the sophisticated options that you have. So based on your requirement, you will be able to pick and choose and get here your data speaking to you and your audience so what makes a great data story? Once you have done all your exploration on your data. So the first thing that you have to take into account is identifying your audience. So once you have a clear understanding of who specifically your audience is, then you can talk to them and perhaps do additional research, find out what they most care about, what their goals are, what they currently know, what decisions need to be made, and what additional knowledge might help them make the decisions that will help reach their goals. So knowing your audience will always help you know what data to look for and include in your analysis. You might use quantitative data such as about revenue change over time or number of people impacting. Or you might use qualitative data such as processes, systems, additional related data. So all these data sources can be very easily blended into your analysis workbook when it comes to Oracle analytics cloud or oracle analytics applications. So what is relevant? So audience, once is taken care of, the relevance is the next feature which we need to be careful of. So this means that content needs to fit with the audience's current level of knowledge and it needs to help them reach a goal of some kind. So maybe your audience is internal, like a presentation to leadership about the need to invest in a specific strategy or tactics. Or maybe they're external, like a campaign to persuade customers to try out your solution. So either way, think about what matters to them. And the best stories speak to people, and the more specific the person or the audience is, the better outlining the story arc. Once I have my data, I explore some possibilities and with my story arc in hand, I can think about what sort of design, layouts or compositions might work best. I want to get a better idea of what will work visually so that I often sketch out by hand some layouts and compositions. So this gives you also an understanding of the narrative that you want to stick to, since traditional story art with a beginning, middle and end. So that is what we are all used to doing. So for data stories, this usually means you need an introduction to the topic before you dive into the data. You also need to conclude with a specific call to action. Now this is another thing that makes a data story distinctly different from a straightforward report. Also, if your audience is not an expert, it's important to use plain language when you call out your final inferences. Right, and intentional visuals. What does that mean? It means whether to use photos, graphs or charts. The visuals you use should help your audience easily to understand what the data means above. All, the visuals you include should be appropriate for the data well labeled, and the labeling options or formatic options are definitely easily possible with oracle analytics. And you also saw how we can add further notes, annotations and even descriptions which I not show you. But it's all easily possible. It should be legible, whatever. Your visuals should be legible and also not misleading. So great data stories pay attention to details like use of color and imagery, including considerations related to accessibility and diversity. So it is possible with oracle analytics that you can transform data into compelling stories that not only inform but inspire action, leveraging the full potential of the capabilities with them. If you want to learn more with written and maid so you can access our technical blog which is quite popular among the community, wherein also we have options for you to learn from us through our bootcamps, which comes in quite frequently, and a new course. So whatever we discussed today were all like high level concepts about data storytelling. Just a quick glance or peek that I gave you about the interface as well. But if you want to learn in detail, we have a new course coming up which is data visualization for data storytelling, wherein we will be in detail, taking you through different processes, different techniques that you can adopt to formulate your data story in the right and effective, impactful manner. With that, we have come to an end of this quick session. Hope you learned something out of it, and thank you very much for listening.", "words": [], "utterances": null, "confidence": 0.928902697489277, "audio_duration": 2877.0, "webhook_status_code": null, "webhook_auth": false, "summary": "- Uncle Aze is a principal consultant with Ritman Mead, a global oracle data and analytics consultancy. When not working or speaking in conferences, he finds time to explore his passion as an artist. Join him for a chat about anything analytics and also art if you are interested.\n- Data storytelling is an approach that transforms abstract data into meaningful narrative. By framing data within a narrative structure, we not only make it more interesting, but also more impactful. Unless we can improve the communication, we'll also see a poorer insight to value conversion rate.\n- A well crafted story can evoke emotions, spark curiosity, and hold audiences attention far better than raw data. Data stories influence people's thoughts and actions at critical points in history. By making our data relatable and providing the right context, we help our audience really get it and act on it.\n- Oracle analytics is a comprehensive solution that covers every step of the analytics journey. The embedded machine learning brings advanced analytics capabilities to every user. With both centralized and governed reporting and self service options, you can trust that your data is consistent and reliable.\n- The transform editor and the recommendations is another interesting or very, very useful feature which is powered by machine learning. It gives you the capability to add information based on existing data which is not already there. Once you're happy with your data, you can create a workbook out of it.\n- We have taken the timeline between February 2017 to December 2020 and try to understand how sales has been varied across this timeline. These are all ways to visually understand how exactly the sales performance has been. I want to further ask a question about per product sales performance.\n- So you can see how exactly this data story is going to be presented to the external stakeholders. There's lots more that you can do with the help of Oracle analytics in terms of analysis or predictions or sentiments. So, so much can be done.\n- What makes a great data story? The first thing that you have to take into account is identifying your audience. It is possible with oracle analytics that you can transform data into compelling stories. We have a new course coming up which is data data storytelling.", "auto_highlights_result": {"status": "success", "results": [{"count": 4, "rank": 0.09, "text": "Data stories", "timestamps": [{"start": 476814, "end": 477782}, {"start": 1518330, "end": 1518954}, {"start": 2714610, "end": 2715274}, {"start": 2784698, "end": 2785362}]}, {"count": 4, "rank": 0.08, "text": "Data points", "timestamps": [{"start": 632426, "end": 633002}, {"start": 1639614, "end": 1640502}, {"start": 2375684, "end": 2376292}, {"start": 2379600, "end": 2380484}]}, {"count": 7, "rank": 0.08, "text": "data storytelling", "timestamps": [{"start": 31222, "end": 32542}, {"start": 178882, "end": 180162}, {"start": 221364, "end": 222824}, {"start": 491604, "end": 492944}, {"start": 2539324, "end": 2540704}, {"start": 2833536, "end": 2834928}, {"start": 2848152, "end": 2849444}]}, {"count": 7, "rank": 0.08, "text": "data sources", "timestamps": [{"start": 863132, "end": 863892}, {"start": 959448, "end": 960128}, {"start": 971400, "end": 972120}, {"start": 978528, "end": 979128}, {"start": 1068738, "end": 1069706}, {"start": 1232846, "end": 1233462}, {"start": 2624954, "end": 2625690}]}, {"count": 3, "rank": 0.08, "text": "raw data", "timestamps": [{"start": 347806, "end": 348286}, {"start": 442674, "end": 443250}, {"start": 713850, "end": 714386}]}, {"count": 8, "rank": 0.08, "text": "data set", "timestamps": [{"start": 1073410, "end": 1073874}, {"start": 1103354, "end": 1104254}, {"start": 1128118, "end": 1128854}, {"start": 1143948, "end": 1144356}, {"start": 1262560, "end": 1263104}, {"start": 1443948, "end": 1444556}, {"start": 1785550, "end": 1786070}, {"start": 2487694, "end": 2488374}]}, {"count": 1, "rank": 0.08, "text": "data transformation", "timestamps": [{"start": 1284086, "end": 1285830}]}, {"count": 1, "rank": 0.08, "text": "data experts", "timestamps": [{"start": 473382, "end": 474422}]}, {"count": 1, "rank": 0.08, "text": "data engineering", "timestamps": [{"start": 74342, "end": 75434}]}, {"count": 1, "rank": 0.08, "text": "data flows", "timestamps": [{"start": 2464382, "end": 2465414}]}, {"count": 1, "rank": 0.08, "text": "government data", "timestamps": [{"start": 986604, "end": 987460}]}, {"count": 2, "rank": 0.08, "text": "existing data", "timestamps": [{"start": 1102778, "end": 1103602}, {"start": 1364760, "end": 1365792}]}, {"count": 1, "rank": 0.08, "text": "data management", "timestamps": [{"start": 141208, "end": 142204}]}, {"count": 2, "rank": 0.08, "text": "data scientists", "timestamps": [{"start": 278296, "end": 279048}, {"start": 831702, "end": 832622}]}, {"count": 1, "rank": 0.08, "text": "abstract data", "timestamps": [{"start": 183274, "end": 184530}]}]}, "content_safety_labels": null, "iab_categories_result": null, "chapters": null, "sentiment_analysis_results": null, "entities": null}