1
00:00:27,280 --> 00:00:30,866
Good morning, good afternoon, good evening. From wherever you're watching,

2
00:00:31,050 --> 00:00:34,562
I welcome you to my talk. I'm jibind Thomas.

3
00:00:34,618 --> 00:00:38,058
I work as a technical architect at Signet Jewelers and I have

4
00:00:38,106 --> 00:00:41,134
14 years of experience with supply chain and retail.

5
00:00:41,474 --> 00:00:45,522
I'm also a senior member of Ieee. First of all, I want to thank

6
00:00:45,578 --> 00:00:49,170
all of you to join my talk today, and I want to thank

7
00:00:49,202 --> 00:00:53,402
Mark to invite me to this wonderful Machine Learning conference of CON

8
00:00:53,458 --> 00:00:57,012
42. Today I want to discuss about optimizing

9
00:00:57,068 --> 00:01:00,544
omni channel order fulfillment with AI and advanced analytics.

10
00:01:01,084 --> 00:01:04,892
And before I delve into the machine learning side of things, I want to talk

11
00:01:04,988 --> 00:01:08,356
something about the ecommerce industry. As you all know,

12
00:01:08,460 --> 00:01:11,956
that ecommerce industry encompasses businesses that

13
00:01:12,020 --> 00:01:15,540
operate on the Internet to sell goods. And according to

14
00:01:15,612 --> 00:01:19,548
expertmarketresearch.com, the current value

15
00:01:19,676 --> 00:01:23,156
is USD $1.1 trillion, which is

16
00:01:23,180 --> 00:01:27,964
expected to grow to $3.85 trillion by 2032,

17
00:01:28,084 --> 00:01:30,984
which is like a 14.8 percentage increase.

18
00:01:31,644 --> 00:01:35,092
And I believe that artificial intelligence and machine learning is going to

19
00:01:35,108 --> 00:01:39,500
take a lot of role in this growth. Coming to omnichannel

20
00:01:39,532 --> 00:01:43,180
retailing omnichannel retailing, or in other words,

21
00:01:43,292 --> 00:01:47,540
order management system, is basically a system which

22
00:01:47,692 --> 00:01:52,124
takes the customer order and delivers it to multiple

23
00:01:52,284 --> 00:01:56,156
choices based on the customer choice. Like it could be a store,

24
00:01:56,260 --> 00:02:00,340
customer preferred store, or it could be the customer's address

25
00:02:00,452 --> 00:02:03,628
or to the collection point. And as the name

26
00:02:03,756 --> 00:02:07,388
Omni, it basically means that it is actually connected with

27
00:02:07,436 --> 00:02:11,148
multiple channels. And in this case, we have different sales

28
00:02:11,196 --> 00:02:14,764
channels like store online, mobile kiosk and call center.

29
00:02:14,884 --> 00:02:19,044
And the system is basically having a lot of fulfillment rules,

30
00:02:19,164 --> 00:02:22,908
orchestration rules, and processing and monitoring rules, because of which it

31
00:02:22,916 --> 00:02:26,100
is able to deliver the customer order. Now,

32
00:02:26,132 --> 00:02:29,636
though, there are many vendors who

33
00:02:29,660 --> 00:02:33,372
are implementing this software, but there

34
00:02:33,388 --> 00:02:37,316
are two major vendors, IBM Sterling Commerce and Manhattan. My experience

35
00:02:37,420 --> 00:02:41,108
is with IBM Sterling commerce, and though the system

36
00:02:41,156 --> 00:02:44,522
is a big giant and has a lot of benefits, and it gives a

37
00:02:44,538 --> 00:02:48,418
lot of benefits to the retailers. But there is a problem

38
00:02:48,506 --> 00:02:52,098
statement, and this is one of the things which I would like to highlight over

39
00:02:52,146 --> 00:02:55,690
here. And the thing which I have mentioned over here is

40
00:02:55,722 --> 00:02:59,094
real time inventory visibility. For example,

41
00:02:59,554 --> 00:03:03,386
you walk into a Walmart or a target store and you look onto

42
00:03:03,490 --> 00:03:07,482
an aisle and see that a product is lying over there, say for

43
00:03:07,538 --> 00:03:11,508
weeks or months. That means that that product is actually overstocked

44
00:03:11,596 --> 00:03:15,108
at that store. But at the same time, if you go to

45
00:03:15,156 --> 00:03:18,892
another Walmart or a Target store and you see that the same product is

46
00:03:18,948 --> 00:03:22,756
missing from there, that means that the store is under

47
00:03:22,820 --> 00:03:26,868
stocking. Now, in a non AI world,

48
00:03:26,956 --> 00:03:30,732
it is very hard for a retailer to have

49
00:03:30,868 --> 00:03:33,976
that kind of inventory visibility in picture.

50
00:03:34,100 --> 00:03:37,992
And this is where machine learning and artificial intelligence can

51
00:03:38,048 --> 00:03:41,440
help retailers to boost up the way

52
00:03:41,512 --> 00:03:45,324
how they display the inventory in the current world.

53
00:03:45,944 --> 00:03:49,760
And the second problem is the suboptimal sourcing, which basically

54
00:03:49,832 --> 00:03:53,728
causes a lot of high shipping costs to the customers,

55
00:03:53,776 --> 00:03:56,680
and it has a lot of impact on sustainability,

56
00:03:56,872 --> 00:04:01,444
supplier and stock management issues, lost sales and customer dissatisfaction.

57
00:04:01,994 --> 00:04:05,810
Today, I want to talk about four topics. Building a

58
00:04:05,842 --> 00:04:09,898
central inventory visibility system using AI and predictive algorithms.

59
00:04:10,066 --> 00:04:13,746
Then I would move on to talk about using

60
00:04:13,810 --> 00:04:17,026
machine learning to optimize order sourcing and routing.

61
00:04:17,210 --> 00:04:21,074
Then I will talk about predictive analytics to allocate omni channel

62
00:04:21,114 --> 00:04:24,730
inventory dynamically. And finally, I will move on to talk about

63
00:04:24,802 --> 00:04:28,604
reinforcement learning to optimize allocation across fulfillment

64
00:04:28,644 --> 00:04:32,412
centers. Moving on to the first topic, which is building a central

65
00:04:32,468 --> 00:04:35,596
inventory visibility system using AI and predictive algorithms.

66
00:04:35,740 --> 00:04:39,044
Now, to have this system in place, there are two

67
00:04:39,124 --> 00:04:42,500
major forecasting systems which a retailer should have.

68
00:04:42,612 --> 00:04:46,316
One is called as demand forecasting, which is basically a

69
00:04:46,340 --> 00:04:49,700
forecasting system which has the

70
00:04:49,732 --> 00:04:52,584
forecast done between a store and an item combination.

71
00:04:53,004 --> 00:04:56,436
On the other hand, the sales forecasting is a system which forecasts the

72
00:04:56,460 --> 00:05:00,084
future sales. Now, for all these

73
00:05:00,164 --> 00:05:03,548
use cases, which I'm going to talk about, all those

74
00:05:03,636 --> 00:05:07,820
four points which I was talking about, I'm going to display a

75
00:05:07,852 --> 00:05:11,492
small use case. This is not a real time use case for

76
00:05:11,508 --> 00:05:14,756
a retailer, because the real time machine learning data

77
00:05:14,860 --> 00:05:18,522
for retailers could be in millions, which the retailer has to train.

78
00:05:18,668 --> 00:05:21,902
But in this case, we are going to see a small use case

79
00:05:21,998 --> 00:05:26,102
with 10,000 records for all these four scenarios,

80
00:05:26,238 --> 00:05:30,230
which I was talking about. And we will see how we can use

81
00:05:30,342 --> 00:05:34,694
some of the machine learning algorithms to identify

82
00:05:34,854 --> 00:05:38,230
and predict and do the forecasting in this case.

83
00:05:38,262 --> 00:05:42,406
So here I have actually put a use case to

84
00:05:42,550 --> 00:05:46,958
do a sales forecasting system, or basically to build a sales forecasting

85
00:05:47,006 --> 00:05:50,734
system. Now, let us imagine we have a retailer

86
00:05:50,774 --> 00:05:54,046
named company a. Now, company a wants to implement

87
00:05:54,110 --> 00:05:57,742
a sales forecasting system. And the data, what you see on

88
00:05:57,758 --> 00:06:00,654
your right is basically the transaction data.

89
00:06:00,734 --> 00:06:03,670
And it is also known as the sales data.

90
00:06:03,822 --> 00:06:07,594
And company a wants to implement the

91
00:06:08,294 --> 00:06:11,846
sales forecasting system. Over here. There are some of the key columns

92
00:06:11,870 --> 00:06:15,252
here, which is transaction date, sales quantity and price.

93
00:06:15,428 --> 00:06:19,076
And based on this, we are going to implement the

94
00:06:19,100 --> 00:06:22,876
sales forecasting system, which basically means that it is going to forecast the future

95
00:06:22,940 --> 00:06:25,748
sales for company a. Now,

96
00:06:25,796 --> 00:06:29,820
to implement this, I have used three different models.

97
00:06:29,972 --> 00:06:33,372
They are also known as time series models. They are provided by

98
00:06:33,548 --> 00:06:37,460
the Python framework. And these are Arima Sarimax

99
00:06:37,532 --> 00:06:40,960
exponential smoothing. And these are three models which I've used

100
00:06:40,992 --> 00:06:44,864
for this use case. Now, regardless, whichever model we are trying

101
00:06:44,904 --> 00:06:49,096
to build, whichever machine learning algorithm we are trying to build, the steps

102
00:06:49,160 --> 00:06:52,608
pretty much remains the same. What I mean by that

103
00:06:52,656 --> 00:06:56,656
is that first step is always to

104
00:06:56,800 --> 00:07:00,424
gather the data. And in this case we are trying to

105
00:07:00,464 --> 00:07:03,448
gather the historical data set of company a.

106
00:07:03,496 --> 00:07:07,324
And once we have that done, the second step

107
00:07:07,364 --> 00:07:11,468
is basically to analyze the data, which is also known as EDA or

108
00:07:11,596 --> 00:07:15,148
exploratory data analysis. So as part of the exploratory data

109
00:07:15,196 --> 00:07:19,140
analysis, we try to analyze the data, and finally

110
00:07:19,212 --> 00:07:22,420
we try to push the data to the machine learning algorithms.

111
00:07:22,572 --> 00:07:26,500
So once we have this in place, the models

112
00:07:26,572 --> 00:07:30,904
will actually produce the output which is forecasting.

113
00:07:31,524 --> 00:07:35,222
So as you see on the right side, the flow diagram over here,

114
00:07:35,398 --> 00:07:39,142
Arima model works on the concept of p,

115
00:07:39,238 --> 00:07:43,094
d and q. P stands for autoregressive,

116
00:07:43,254 --> 00:07:47,198
d is the differentiation and q is the moving average.

117
00:07:47,326 --> 00:07:50,834
I'm going to talk about how we identify these parameters.

118
00:07:51,294 --> 00:07:54,366
So once we identify the parameters, we try to build the model,

119
00:07:54,470 --> 00:07:58,254
and then there is a diagnostic

120
00:07:58,294 --> 00:08:01,750
checks where we try to fit the model. And finally the model, it does

121
00:08:01,782 --> 00:08:05,194
the forecasting. And if you see there,

122
00:08:05,534 --> 00:08:09,014
there is a continuous improvement cycle over here,

123
00:08:09,054 --> 00:08:12,278
which is basically in loop. That means once

124
00:08:12,406 --> 00:08:16,374
the forecasting results are out, we try to adjust the model

125
00:08:16,414 --> 00:08:19,534
parameters based on the results, what we get,

126
00:08:19,654 --> 00:08:22,886
and then we try to again fit it. So this is basically a constant

127
00:08:22,950 --> 00:08:27,038
loop, which basically means that we are always

128
00:08:27,126 --> 00:08:30,914
training our model. And this also requires that we

129
00:08:30,954 --> 00:08:34,530
feed the model with the daily sales

130
00:08:34,682 --> 00:08:38,210
data, and based on that daily data, the model

131
00:08:38,242 --> 00:08:41,134
is getting better day by day.

132
00:08:41,594 --> 00:08:44,874
Now you can ask me, Jubin, how do you identify this

133
00:08:44,914 --> 00:08:48,418
PD and q parameters? So, to answer that

134
00:08:48,466 --> 00:08:51,770
question, Python frameworks actually provides

135
00:08:51,802 --> 00:08:55,256
an option of PD and Q to provide

136
00:08:55,320 --> 00:08:59,968
the value of PD and q. And the way how it works is it

137
00:09:00,016 --> 00:09:03,400
basically sets the default value of

138
00:09:03,432 --> 00:09:06,736
PDQ. So this process is also known as auto Arima process.

139
00:09:06,880 --> 00:09:10,424
So what I have done here is basically I have run my training

140
00:09:10,504 --> 00:09:14,040
and test data using the auto ArIMA

141
00:09:14,072 --> 00:09:17,208
process, and the auto Arima process determined based on my training

142
00:09:17,256 --> 00:09:20,714
and test data, that the best value for the PD

143
00:09:20,754 --> 00:09:24,802
and q in this case is zero and one.

144
00:09:24,978 --> 00:09:28,938
The screen is kind of big

145
00:09:28,986 --> 00:09:32,706
right now, but I think you should be able to see right

146
00:09:32,730 --> 00:09:36,226
now. So it identified 501 as the best parameters

147
00:09:36,330 --> 00:09:40,058
and it gave me a mean absolute error of 2.6

148
00:09:40,226 --> 00:09:43,482
which is, which is the best, which I

149
00:09:43,498 --> 00:09:46,454
could get from this test and training data.

150
00:09:47,034 --> 00:09:48,774
Now let me talk about.

151
00:09:50,114 --> 00:09:53,386
We can plot Eda. Now, EDA,

152
00:09:53,410 --> 00:09:57,538
as I said, is exploratory data analysis, which basically gives

153
00:09:57,586 --> 00:10:00,890
us time series plot and correlation metrics,

154
00:10:00,922 --> 00:10:05,066
which we can use these kind of metrics to understand

155
00:10:05,170 --> 00:10:08,810
our data much clearer. So once we have

156
00:10:08,842 --> 00:10:12,494
this in place, the next step is

157
00:10:12,794 --> 00:10:16,234
writing the code. And this is where I want to show you that,

158
00:10:16,274 --> 00:10:19,642
how we can write a code for

159
00:10:19,658 --> 00:10:23,522
the sales forecasting system. So I try to load the training data and

160
00:10:23,538 --> 00:10:27,010
the test data once I had it. Then if you

161
00:10:27,042 --> 00:10:30,258
see that the index frequency is set to d,

162
00:10:30,306 --> 00:10:33,194
which basically means that it is a daily sales data.

163
00:10:33,354 --> 00:10:36,898
And then we have the EDA, which is exploratory data analysis

164
00:10:36,946 --> 00:10:40,070
where we try to analyze the data. And this is where we try

165
00:10:40,102 --> 00:10:43,358
to. And if you can see Arima,

166
00:10:43,406 --> 00:10:46,794
I have passed 501, which is what we got from

167
00:10:47,094 --> 00:10:51,094
the auto AriMA process. Once we have this in place, we try to

168
00:10:51,214 --> 00:10:54,974
do a model dot fit, which will basically fit the model,

169
00:10:55,094 --> 00:10:58,422
and we call the forecast method of

170
00:10:58,438 --> 00:11:02,542
the model which will try to forecast the results for us. And at the

171
00:11:02,678 --> 00:11:06,350
end we basically do the forecasting.

172
00:11:06,382 --> 00:11:10,766
We print the forecast results and we also print the different metrics

173
00:11:10,950 --> 00:11:14,422
which Python framework generates. Now,

174
00:11:14,478 --> 00:11:18,646
coming back to the results, so as

175
00:11:18,670 --> 00:11:21,894
you see that the forecasting results are

176
00:11:21,934 --> 00:11:25,406
displayed over here, and all three different models are EMA,

177
00:11:25,430 --> 00:11:30,118
Sarimax and exponential smoothing. They gave me 20

178
00:11:30,166 --> 00:11:33,670
records, and these 20 records are basically the number of

179
00:11:33,702 --> 00:11:36,734
records what I have in the training data, sorry,

180
00:11:36,774 --> 00:11:40,598
the test data. So it basically generated the results based on

181
00:11:40,646 --> 00:11:44,022
my test data, because I had 20 records in my test data, it also

182
00:11:44,078 --> 00:11:47,878
generated 20 records over here. And if you see that the mean

183
00:11:47,926 --> 00:11:51,390
absolute error is 1.8 for Arima,

184
00:11:51,502 --> 00:11:54,742
where in the other models are kind of higher on

185
00:11:54,758 --> 00:11:58,934
the higher side. So mean absolute error is

186
00:11:59,054 --> 00:12:03,130
basically a parameter which is used to

187
00:12:03,322 --> 00:12:06,778
understand whether the model performance was good or bad.

188
00:12:06,866 --> 00:12:10,490
So in this case, I see that the Arima model has

189
00:12:10,522 --> 00:12:15,290
actually given me 1.8, which is basically 1.8

190
00:12:15,402 --> 00:12:19,834
units of the actual test values in the test CSV

191
00:12:19,874 --> 00:12:23,650
or the test file, and which basically tells

192
00:12:23,682 --> 00:12:27,402
us that Arima model

193
00:12:27,498 --> 00:12:31,534
in this use case has performed better compared to the other models.

194
00:12:32,194 --> 00:12:36,250
Now moving on to my next slide, which is using

195
00:12:36,322 --> 00:12:39,922
machine learning to optimize order sourcing and routing. As part

196
00:12:39,938 --> 00:12:43,562
of this, I want to talk about two different topics. One is

197
00:12:43,618 --> 00:12:47,786
predictive delivery date, and the second one is sourcing and routing.

198
00:12:47,970 --> 00:12:51,658
Before I talk about predictive delivery date, I want to talk about something

199
00:12:51,706 --> 00:12:55,010
called as estimated delivery date? An estimated

200
00:12:55,042 --> 00:12:59,112
delivery date is a date which is displayed at the retailer's

201
00:12:59,168 --> 00:13:02,784
website or the storefront. It is

202
00:13:02,824 --> 00:13:06,232
basically to show when the

203
00:13:06,288 --> 00:13:10,200
customer's order would be delivered or when an item can

204
00:13:10,232 --> 00:13:14,088
be delivered. And in a non AI

205
00:13:14,136 --> 00:13:18,368
world, the way how estimated delivery date is calculated is

206
00:13:18,416 --> 00:13:22,288
based on a lot of factors. These factors are calculating

207
00:13:22,336 --> 00:13:26,384
the lead time between the store and

208
00:13:27,324 --> 00:13:30,852
the carrier, and the carrier would have its own lead time.

209
00:13:30,948 --> 00:13:35,436
So adding up all these lead times, the retailer displays

210
00:13:35,620 --> 00:13:39,236
a buffer date or a lead days on

211
00:13:39,260 --> 00:13:42,660
the website, which is also known as the estimated

212
00:13:42,692 --> 00:13:46,404
delivery date. Now the problem with these dates are

213
00:13:46,564 --> 00:13:50,140
the estimated delivery date could be way higher than

214
00:13:50,172 --> 00:13:53,274
the actual delivery date. And that is why

215
00:13:53,444 --> 00:13:58,678
machine learning can actually help us to reduce

216
00:13:58,806 --> 00:14:02,634
this lead days so that we can have

217
00:14:03,854 --> 00:14:06,942
near to accurate delivery date displayed on

218
00:14:06,958 --> 00:14:09,434
the storefront or on the web page.

219
00:14:09,814 --> 00:14:13,766
On the other hand, the sourcing and routing is basically a concept

220
00:14:13,870 --> 00:14:17,238
where the order management system tried

221
00:14:17,286 --> 00:14:20,750
to source and route the customer order to

222
00:14:20,902 --> 00:14:25,198
the customer's address or the customer's provided zip code.

223
00:14:25,286 --> 00:14:28,774
So this is another concept where machine learning

224
00:14:28,814 --> 00:14:32,934
can actually help to understand which node

225
00:14:32,974 --> 00:14:37,006
or which store is basically near to customer's address,

226
00:14:37,150 --> 00:14:40,194
and it can provide lesser shipping costs.

227
00:14:40,694 --> 00:14:43,998
Now, to build this use case, I have used

228
00:14:44,086 --> 00:14:48,016
two different models. One is the random forest regressor and

229
00:14:48,040 --> 00:14:51,736
the second one is kneighbors classifier.

230
00:14:51,920 --> 00:14:55,416
So, random forest model, as the name says, it is

231
00:14:55,440 --> 00:14:59,152
a forest model and it requires two different parameters.

232
00:14:59,208 --> 00:15:02,720
Like in the previous use case I was talking about the Arima

233
00:15:02,752 --> 00:15:06,200
model and it requires PD and q. Here in the

234
00:15:06,232 --> 00:15:09,440
random forest it requires two different parameters, which is n

235
00:15:09,472 --> 00:15:12,560
estimators and random states. Here I

236
00:15:12,592 --> 00:15:15,896
passed the n estimators as 100 and

237
00:15:16,040 --> 00:15:21,420
random state as 42. So an

238
00:15:21,452 --> 00:15:24,812
estimators is basically it creates

239
00:15:24,948 --> 00:15:28,980
hundred different decision trees based on the input provided

240
00:15:29,012 --> 00:15:32,612
to the model, and it tries to create this decision tree

241
00:15:32,788 --> 00:15:36,228
to identify what is the

242
00:15:36,276 --> 00:15:39,988
best predicted value. And at the same

243
00:15:40,036 --> 00:15:44,000
time, random state 42 is basically a parameter which

244
00:15:44,032 --> 00:15:48,564
would help the model to always produce similar result regardless

245
00:15:48,984 --> 00:15:51,964
how many times we are passing the same input.

246
00:15:52,504 --> 00:15:56,432
And on the other hand, the knee RS model is basically a

247
00:15:56,448 --> 00:15:59,784
model which works on the concept of neighbors.

248
00:15:59,824 --> 00:16:03,016
That means based on the input, what we provide to the model,

249
00:16:03,160 --> 00:16:06,808
it will try to fetch the

250
00:16:06,856 --> 00:16:10,788
five nearest neighbors which are matching to that input,

251
00:16:10,896 --> 00:16:14,236
and it basically displays that. So these

252
00:16:14,260 --> 00:16:17,804
are two different models. And on the right side of the screen you

253
00:16:17,844 --> 00:16:21,836
can see an Amazon screen over here. And if you

254
00:16:21,860 --> 00:16:25,236
see that there is a date displayed over here, which is

255
00:16:25,380 --> 00:16:28,844
Saturday, April 27. And this is the

256
00:16:28,884 --> 00:16:32,988
date which is also known as the estimated delivery date. And according to

257
00:16:33,156 --> 00:16:37,274
one of the e commerce article where I read

258
00:16:37,404 --> 00:16:41,070
that 47% of customers, they abandon their

259
00:16:41,102 --> 00:16:44,798
cards because this date, which you can see over here,

260
00:16:44,886 --> 00:16:48,502
estimated delivery date is not matching with their expectations.

261
00:16:48,558 --> 00:16:52,994
So it is that important for a retailer to have this date displayed correctly.

262
00:16:53,574 --> 00:16:57,342
Now, in this use case, we are going to build a predictive

263
00:16:57,398 --> 00:17:01,062
system. The first one was the forecasting system. Here we are trying to build a

264
00:17:01,158 --> 00:17:04,510
predictive system. And the first data set, what you saw

265
00:17:04,582 --> 00:17:09,009
was the transactional sales data for the customers and

266
00:17:09,121 --> 00:17:12,401
for the retailers. And in this use case we are going

267
00:17:12,417 --> 00:17:15,561
to see it is basically the

268
00:17:15,617 --> 00:17:18,713
delivery data of the retailer. And here we

269
00:17:18,753 --> 00:17:22,393
have the delivery data of company a. And the key

270
00:17:22,433 --> 00:17:25,289
fields here is customer zip code, store zip code,

271
00:17:25,361 --> 00:17:29,201
shipping option fulfillment success. And this

272
00:17:29,217 --> 00:17:32,585
is a small code snippet which will help us to understand how

273
00:17:32,609 --> 00:17:36,046
this works. And first we try

274
00:17:36,070 --> 00:17:39,358
to load the data and we load the us

275
00:17:39,406 --> 00:17:43,350
zip code. And as you see, there are three key fields

276
00:17:43,382 --> 00:17:46,782
which I dropped from the data frame. Customer zip code,

277
00:17:46,878 --> 00:17:50,270
store zip code and fulfillment success. And I'm going to talk about why

278
00:17:50,302 --> 00:17:54,134
I did this. And there are two variables

279
00:17:54,294 --> 00:17:59,022
which are pretty important over here. One is x test or

280
00:17:59,118 --> 00:18:02,674
one is the x variable and the other one is the y variable.

281
00:18:03,354 --> 00:18:06,574
Now in the concept of machine learning,

282
00:18:07,314 --> 00:18:11,138
the y variable is basically the

283
00:18:11,266 --> 00:18:14,794
target variable. So the columns which we

284
00:18:14,834 --> 00:18:18,386
want to, we want our model to understand

285
00:18:18,570 --> 00:18:21,962
that we need to train our model based on

286
00:18:22,058 --> 00:18:25,242
these target variables. Then we need to drop that from

287
00:18:25,298 --> 00:18:28,666
our data frame and add that as part

288
00:18:28,690 --> 00:18:31,792
of our y variable. So that's what I'm doing over here. I dropped

289
00:18:31,808 --> 00:18:35,992
the customer zip code, store zip code, and fulfillment success because I

290
00:18:36,048 --> 00:18:40,152
wanted these three key attributes as

291
00:18:40,248 --> 00:18:42,924
part of my training. And I'm telling my model that,

292
00:18:43,424 --> 00:18:47,080
you know, these are the target variables and you have to get

293
00:18:47,112 --> 00:18:50,488
trained based on these three target variables.

294
00:18:50,576 --> 00:18:54,884
And on the other hand, all other things, all other columns

295
00:18:55,184 --> 00:19:00,580
are as part of the x variable for

296
00:19:00,612 --> 00:19:04,308
this training. Now, you can ask me that. There is no test

297
00:19:04,356 --> 00:19:07,164
data over here. That's a valid question.

298
00:19:07,244 --> 00:19:10,780
And what I am telling my model here is that the

299
00:19:10,812 --> 00:19:14,236
test size is 0.2, which basically says that

300
00:19:14,380 --> 00:19:17,948
the model is smart enough to understand that

301
00:19:17,996 --> 00:19:21,628
it will take 20 percentage of

302
00:19:21,796 --> 00:19:24,464
the training data as the test data.

303
00:19:25,014 --> 00:19:28,582
Now, as I was explaining before the end estimators, I passed it

304
00:19:28,598 --> 00:19:32,158
as 100, random state as 42, and for

305
00:19:32,206 --> 00:19:35,994
k neighbors, it is neighbors as five. So once

306
00:19:36,374 --> 00:19:40,918
I fit the model based on these three inputs,

307
00:19:41,046 --> 00:19:45,446
which is the shipping option standard and customer

308
00:19:45,470 --> 00:19:49,354
Zip code 19063 and customer

309
00:19:50,834 --> 00:19:54,458
location, which is 1963. And for the item

310
00:19:54,626 --> 00:19:58,842
two, I wanted my model to predict

311
00:19:58,898 --> 00:20:03,146
me the nearest store which can deliver the customers

312
00:20:03,250 --> 00:20:06,330
order, and it should also give me a predicted

313
00:20:06,362 --> 00:20:10,842
delivery date. So once I run this model

314
00:20:11,018 --> 00:20:14,690
or once I ran my script, this is what the model

315
00:20:14,722 --> 00:20:18,564
generated for the shipping option standard and

316
00:20:18,604 --> 00:20:22,356
for the customer Zip code 19,063. It was

317
00:20:22,380 --> 00:20:27,756
able to figure out that the store, ZIP 89402

318
00:20:27,860 --> 00:20:32,252
has an available quantity of one 10, which means that it

319
00:20:32,268 --> 00:20:35,584
is able to fulfill my order because my requested quantity is 100.

320
00:20:36,484 --> 00:20:39,104
Based on the training which model received,

321
00:20:39,404 --> 00:20:43,488
it was able to predict a delivery date as 2024

322
00:20:43,536 --> 00:20:47,360
526, which is like around six days off from today's

323
00:20:47,392 --> 00:20:50,952
date. And at the same time, if it

324
00:20:50,968 --> 00:20:54,632
is overnight, it gave me a very early

325
00:20:54,688 --> 00:20:58,244
date, which is the next date. It is tomorrow's date over here.

326
00:20:58,624 --> 00:21:01,564
521 and this is again based on the training.

327
00:21:01,904 --> 00:21:05,336
The training data has a lot of overnight records and it

328
00:21:05,360 --> 00:21:07,856
was able to understand based on the training which it received,

329
00:21:07,920 --> 00:21:11,086
that okay, if the shipping option is overnight,

330
00:21:11,190 --> 00:21:14,662
the delivery date is 521. At the same time,

331
00:21:14,798 --> 00:21:18,398
if I reduce the quantity to ten, it was able

332
00:21:18,446 --> 00:21:22,334
to find me a store, 19052, which is

333
00:21:22,374 --> 00:21:25,486
like 2.4 miles away from my place.

334
00:21:25,630 --> 00:21:29,798
And that is pretty close. So model is able to understand that

335
00:21:29,846 --> 00:21:33,230
it has to fetch a store which is pretty near

336
00:21:33,262 --> 00:21:37,440
to the customer's address. And at the same time, if I pass the

337
00:21:37,472 --> 00:21:41,416
requested quantity more than what I have in my

338
00:21:41,440 --> 00:21:45,296
training data, it gives me a message saying no available inventory for item two

339
00:21:45,320 --> 00:21:48,568
at the nearby store. Let me come to my third topic,

340
00:21:48,656 --> 00:21:51,976
predictive analytics to allocate omnichannel inventory dynamically.

341
00:21:52,120 --> 00:21:55,528
If you remember, in one of the initial slides, I was talking about the problem

342
00:21:55,616 --> 00:21:59,168
statement, the statement of having a

343
00:21:59,216 --> 00:22:01,204
real time inventory visibility issue.

344
00:22:01,784 --> 00:22:05,534
Now, in a non AI world, it is completely impossible to

345
00:22:05,574 --> 00:22:08,734
have such systems in place, but with the help of machine learning,

346
00:22:08,854 --> 00:22:12,638
we can have this. And in this use case, I will talk about how

347
00:22:12,766 --> 00:22:16,790
we can build a real time inventory visibility dashboard which

348
00:22:16,822 --> 00:22:20,874
will help to understand what kind of inventory status we have to maintain.

349
00:22:21,294 --> 00:22:24,470
So without further ado, let us help

350
00:22:24,662 --> 00:22:28,054
poor fella who is worried about the overstocking and understocking issue,

351
00:22:28,174 --> 00:22:31,664
and let us help him to to build a system in place.

352
00:22:31,964 --> 00:22:35,444
So the first use case we saw was the sales forecasting use case,

353
00:22:35,484 --> 00:22:38,580
where in the transactional data was a sales data,

354
00:22:38,692 --> 00:22:41,956
in the second use case it was the delivery data.

355
00:22:42,020 --> 00:22:45,684
And now in this use case we have product data. So company

356
00:22:45,764 --> 00:22:49,516
a has various products and this

357
00:22:49,540 --> 00:22:53,132
is the product data. What we have, this is the product id and

358
00:22:53,148 --> 00:22:57,044
then the cost per unit. And like this we have

359
00:22:57,124 --> 00:23:00,506
different other columns. And based on this data, we are

360
00:23:00,530 --> 00:23:04,614
going to create a model which will help us to predict

361
00:23:05,074 --> 00:23:08,974
what inventory status we have to maintain for a particular item.

362
00:23:09,514 --> 00:23:12,818
Here I am going to give a demo, I am not going

363
00:23:12,826 --> 00:23:16,034
to show the code. So the way

364
00:23:16,154 --> 00:23:20,314
I build this use case is using Python and flask. Flask is a microservice

365
00:23:20,354 --> 00:23:23,650
framework within Python. And the model I used to

366
00:23:23,682 --> 00:23:26,554
train was the random forest regressor.

367
00:23:26,674 --> 00:23:30,236
And I'm not going to explain the random forest regressor once again because

368
00:23:30,370 --> 00:23:32,724
I explained in one of my previous use case.

369
00:23:34,184 --> 00:23:37,960
So the way how this application works is the user accesses the application via

370
00:23:37,992 --> 00:23:41,608
web browser and the user inputs the data using the form fields.

371
00:23:41,736 --> 00:23:45,288
There is a data validation in place. If the data is incorrect,

372
00:23:45,336 --> 00:23:49,524
it displays the error message and it comes out. And if the data is successful

373
00:23:50,344 --> 00:23:53,792
or if there is no errors in the data,

374
00:23:53,928 --> 00:23:58,060
then the model basically predicts the inventory levels and it also calculates

375
00:23:58,092 --> 00:24:01,504
the mean absolute error and displays that on the screen.

376
00:24:01,924 --> 00:24:05,892
Now moving on to the demo. So this is the

377
00:24:06,028 --> 00:24:09,628
real time inventory dashboard for company a. And it has various

378
00:24:09,676 --> 00:24:13,732
fields, as you can see on the screen right now. And to

379
00:24:13,868 --> 00:24:17,412
show this demo, I would quickly like to switch my screen to show

380
00:24:17,468 --> 00:24:20,908
you one of the records of the training data,

381
00:24:20,956 --> 00:24:24,904
what we have. So we're going to use the same set of data to understand

382
00:24:25,084 --> 00:24:28,928
whether we were able to have our model predict the data correctly.

383
00:24:29,016 --> 00:24:32,336
So let's take the first record, which is product id 30. Let's put it

384
00:24:32,360 --> 00:24:36,080
over here. And we have the product cost

385
00:24:36,272 --> 00:24:39,844
as 275 and

386
00:24:41,184 --> 00:24:44,904
the revenue is 5784. And the

387
00:24:44,944 --> 00:24:48,192
days of the week two is for Tuesday, one is for Monday,

388
00:24:48,248 --> 00:24:51,456
so on and so forth. So here in this case we

389
00:24:51,480 --> 00:24:54,560
have Tuesday. If you look into the data,

390
00:24:54,752 --> 00:24:58,136
the generic holiday is zero, which is basically, it's not a

391
00:24:58,160 --> 00:25:01,952
holiday. And then the expected time, delivery days

392
00:25:02,008 --> 00:25:05,360
was actually seven. So based on

393
00:25:05,392 --> 00:25:09,584
this, when I click on predict status, it said that the product inventory

394
00:25:09,624 --> 00:25:13,464
to be maintained is 23, which is pretty close to what I

395
00:25:13,504 --> 00:25:17,560
have in my actual test data. So, which means that

396
00:25:17,672 --> 00:25:21,280
my model is able to predict a value which is near

397
00:25:21,312 --> 00:25:23,444
to accurate to the actual,

398
00:25:24,944 --> 00:25:28,272
the training data. Now, if I want

399
00:25:28,288 --> 00:25:31,520
to increase this revenue,

400
00:25:31,592 --> 00:25:34,912
so the product cost is 275 and the product revenue, if I

401
00:25:34,928 --> 00:25:38,864
want to increase it to 9999 for a particular store.

402
00:25:39,024 --> 00:25:42,604
And let's keep all of the fields as is.

403
00:25:43,104 --> 00:25:47,190
My model said that you know the inventory has to be maintained

404
00:25:47,302 --> 00:25:50,726
is 41. One last thing I want to show over here is if I

405
00:25:50,750 --> 00:25:54,270
pass the same product id here and give the same price and

406
00:25:54,302 --> 00:25:57,886
let's keep the same combination what we have. When I click

407
00:25:57,910 --> 00:26:01,614
on predict status, it gave me exactly 24 over

408
00:26:01,654 --> 00:26:04,982
here. That means regardless how many times I pass the same

409
00:26:05,038 --> 00:26:08,914
input, the model is able to give me the same value. And this is

410
00:26:09,414 --> 00:26:12,958
what we has in the random forest

411
00:26:13,006 --> 00:26:16,430
regressor, which is random state. And in this case

412
00:26:16,462 --> 00:26:19,854
we passed as 42, which helps the model to understand,

413
00:26:19,934 --> 00:26:23,822
okay, it has to give the same result regardless

414
00:26:23,998 --> 00:26:26,754
whatever time I pass the same input.

415
00:26:27,214 --> 00:26:30,918
Let me move to the last topic, which is reinforcement learning to optimize the location

416
00:26:30,966 --> 00:26:34,446
across fulfillment centers. Reinforcement learning is a branch

417
00:26:34,470 --> 00:26:37,730
of machine learning algorithm which

418
00:26:37,882 --> 00:26:41,442
does sequential decisions in environment to maximize cumulative

419
00:26:41,498 --> 00:26:44,882
rewards. Here. In this case, I've used q learning. Q learning is one of the

420
00:26:44,898 --> 00:26:49,282
simplest reinforcement learning algorithm. It learns

421
00:26:49,298 --> 00:26:53,498
the optimal action selection policy for MDP by iteratively

422
00:26:53,666 --> 00:26:56,654
updating the q values of state action pairs.

423
00:26:57,354 --> 00:27:00,874
Now, for q learning, it basically works on

424
00:27:00,914 --> 00:27:04,330
certain parameters and they are gamma, alpha and epsilon and

425
00:27:04,362 --> 00:27:07,976
having a states in place. And it basically

426
00:27:08,080 --> 00:27:11,856
calculates the actions and does the decision making. So while it

427
00:27:11,880 --> 00:27:15,616
does the decision making, there are certain factors in place, which is

428
00:27:15,720 --> 00:27:19,680
calculating the reward metrics and calculating the q values. And based on the

429
00:27:19,712 --> 00:27:23,328
learning, it again updates the q values. And this iteration keeps on going

430
00:27:23,376 --> 00:27:26,944
until it reaches its final decision. So here,

431
00:27:26,984 --> 00:27:30,336
in this case, I try to build a route

432
00:27:30,440 --> 00:27:33,476
calculation using q learning.

433
00:27:33,620 --> 00:27:36,852
And as I said that Q learning has these parameters,

434
00:27:36,908 --> 00:27:40,504
agent environment, actions, rewards and learning.

435
00:27:41,564 --> 00:27:44,504
So this is a code snippet, as you see over here.

436
00:27:45,004 --> 00:27:48,876
I passed various east

437
00:27:48,900 --> 00:27:52,260
coast states here. And what I'm asking the Q learning

438
00:27:52,292 --> 00:27:56,028
algorithm is to find me the best route between North

439
00:27:56,076 --> 00:27:59,384
Carolina to New York. And the Q

440
00:27:59,424 --> 00:28:03,384
learning algorithm was able to find this based on

441
00:28:03,464 --> 00:28:06,096
certain rewards metrics and Q learning,

442
00:28:06,240 --> 00:28:10,008
or queue values, which got updated. It was able to

443
00:28:10,176 --> 00:28:13,784
figure out the best route. So if you look into this,

444
00:28:13,904 --> 00:28:17,432
it gave me North Carolina to Virginia, to Washington

445
00:28:17,488 --> 00:28:20,624
DC, to Baltimore, to Maryland, to Delaware, to Pennsylvania,

446
00:28:20,664 --> 00:28:23,888
to New Jersey to New York. And in the real time map, if you see

447
00:28:24,016 --> 00:28:27,528
this is looking pretty accurate. So this is how reinforcement

448
00:28:27,576 --> 00:28:30,864
learning can actually help, you know, to find

449
00:28:30,904 --> 00:28:35,056
the best route or best, you know, fulfillment centers

450
00:28:35,120 --> 00:28:38,444
locations. And using this learning,

451
00:28:38,784 --> 00:28:42,880
it will definitely help supply chain to find

452
00:28:42,952 --> 00:28:46,416
out the best routes for the warehouse. That is pretty much which

453
00:28:46,440 --> 00:28:49,392
I have to share today. Thank you so much for having me, and thank you

454
00:28:49,408 --> 00:28:53,240
so much for listening to me and this is my email address,

455
00:28:53,392 --> 00:28:57,144
Jubin Thomas.org. and that's my LinkedIn

456
00:28:57,184 --> 00:29:00,880
and GitHub ids. And please reach

457
00:29:00,912 --> 00:29:04,096
out to me if you have any questions or if you want to have

458
00:29:04,120 --> 00:29:06,864
a connect, please do reach out to me. Thank you so much.

