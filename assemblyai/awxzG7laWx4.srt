1
00:00:20,810 --> 00:00:24,014
Hi, Tim Spann here. I'm going to be

2
00:00:24,052 --> 00:00:28,166
talking today, be building Apache 9520

3
00:00:28,348 --> 00:00:31,654
Python processors. Welcome to my talk here

4
00:00:31,692 --> 00:00:36,018
at Comp 42 for Python. I am a developer advocate

5
00:00:36,114 --> 00:00:40,618
covering all types of things around streaming, big data,

6
00:00:40,704 --> 00:00:44,474
LLM, gen AI, all that fun stuff.

7
00:00:44,672 --> 00:00:47,638
And you can get in touch with me through medium,

8
00:00:47,734 --> 00:00:51,534
GitHub, whatever Twitter's called now my

9
00:00:51,572 --> 00:00:55,086
blog, all over the place. Every week I

10
00:00:55,108 --> 00:00:58,330
have a newsletter that comes out. You can get it on GitHub,

11
00:00:58,410 --> 00:01:00,720
LinkedIn, it's all over the place,

12
00:01:01,330 --> 00:01:04,382
all the streaming, mLai, open source tools,

13
00:01:04,446 --> 00:01:08,018
lots of fun stuff. I also do meetups around

14
00:01:08,104 --> 00:01:12,530
the New Jersey, New York and Philly area, plus virtual plus.

15
00:01:12,600 --> 00:01:16,574
All the content gets put on GitHub and YouTube and Slideshare.

16
00:01:16,622 --> 00:01:19,334
So you'll be able to get it out there if you can't make it to

17
00:01:19,372 --> 00:01:23,526
an event. And I've got one coming up soon in New York

18
00:01:23,708 --> 00:01:27,446
and in Princeton in Boston. One of

19
00:01:27,468 --> 00:01:31,834
the main purposes of us needing to

20
00:01:31,872 --> 00:01:35,578
support Python in the streaming tool Apache Nifi is to

21
00:01:35,584 --> 00:01:39,610
be able to interface with the new machine learning and

22
00:01:39,680 --> 00:01:42,990
AI and Gen AI. They have a ton of awesome

23
00:01:43,060 --> 00:01:46,910
Python libraries, as you probably already know. And to do that

24
00:01:46,980 --> 00:01:50,206
with Nifi before was difficult with

25
00:01:50,228 --> 00:01:54,142
Java. So with the addition of Python,

26
00:01:54,206 --> 00:01:57,714
we could do a lot of cool stuff, integrate with a lot of different

27
00:01:57,752 --> 00:02:00,580
libraries. So that's pretty awesome.

28
00:02:01,430 --> 00:02:05,814
Generally we use Python to do

29
00:02:05,852 --> 00:02:09,826
some of our processing on unstructured file types,

30
00:02:09,858 --> 00:02:15,122
which Cloudera dataflow can ingest structured

31
00:02:15,186 --> 00:02:18,646
sources. We're handling those with Nifi to

32
00:02:18,668 --> 00:02:21,878
the box. Same with a bunch of enterprise data APIs,

33
00:02:21,974 --> 00:02:25,626
application streams, all that data, we get it

34
00:02:25,648 --> 00:02:29,274
in, and then when we want to push it to an

35
00:02:29,312 --> 00:02:33,098
AI model or different vector stores.

36
00:02:33,274 --> 00:02:37,962
The best way to do that is with Python

37
00:02:38,026 --> 00:02:41,470
processors, and we'll show you some of those features.

38
00:02:42,130 --> 00:02:46,034
Not going to go into generative AI, but generally we

39
00:02:46,072 --> 00:02:48,660
work with it around text to text,

40
00:02:49,430 --> 00:02:52,962
text to image, text to speech. And getting

41
00:02:53,016 --> 00:02:57,874
that data processors chunked

42
00:02:57,922 --> 00:03:01,174
up, vectorized and ready to go is usually done with

43
00:03:01,212 --> 00:03:04,754
Python, some of it in standard Nifi. But Python

44
00:03:04,802 --> 00:03:07,560
is a real game changer for us.

45
00:03:08,110 --> 00:03:12,922
Within Cloudera we're dealing with a lot within know

46
00:03:12,976 --> 00:03:16,918
the major llms out there, whether they're closed like OpenAI

47
00:03:17,094 --> 00:03:21,210
or they're open models like Mistrial or Metai,

48
00:03:21,550 --> 00:03:25,520
and a bunch more in hugging face, as well as some through Google

49
00:03:26,050 --> 00:03:29,150
work with all the major vector databases.

50
00:03:29,810 --> 00:03:34,214
I'll show you a little bit with pine code and Chroma, but Milvis

51
00:03:34,282 --> 00:03:37,746
and solar and all the other ones are out there we

52
00:03:37,768 --> 00:03:41,298
do a lot through hugging face because of their open community

53
00:03:41,384 --> 00:03:45,122
and open model really gels well with our

54
00:03:45,256 --> 00:03:49,030
open source and our open community model

55
00:03:49,100 --> 00:03:52,678
there. We work with Langchain and that's in some of our

56
00:03:52,764 --> 00:03:56,326
pre built python processors and we're doing some

57
00:03:56,348 --> 00:04:00,234
things with llama index. Lots of cool frameworks out there

58
00:04:00,352 --> 00:04:04,170
every couple of hours I think there's a new one. There's a new Google

59
00:04:04,240 --> 00:04:08,362
model just came out which looks pretty awesome. That's pretty

60
00:04:08,496 --> 00:04:13,370
standard. Up top we have generative AI applications

61
00:04:13,530 --> 00:04:17,434
and we make these prototypes available for you in GitHub

62
00:04:17,482 --> 00:04:21,434
so you could try them out. And we work with different closed source

63
00:04:21,482 --> 00:04:24,798
foundation models, whether that's through OpenAI,

64
00:04:24,974 --> 00:04:28,226
Amazon, Breadrock, IBM, Watson, lots of different

65
00:04:28,328 --> 00:04:31,390
ways to do that. We have model hubs,

66
00:04:31,550 --> 00:04:34,802
we can find two models and we work with the major open

67
00:04:34,856 --> 00:04:39,334
source foundation models like Metal, llama. Two we

68
00:04:39,372 --> 00:04:43,186
could work with the managed vector stores. Pine cone

69
00:04:43,218 --> 00:04:46,306
right now is the main one, private vector stores

70
00:04:46,338 --> 00:04:50,082
like Solar or Milvis. Underneath that we provide a massive

71
00:04:50,146 --> 00:04:53,622
open data lake house that does the real time data ingest

72
00:04:53,686 --> 00:04:57,386
and routing of this data. The data wrangling which you can imagine has a lot

73
00:04:57,408 --> 00:05:00,262
of python Spark, flink,

74
00:05:00,326 --> 00:05:03,790
Nifi, all those fun tools. We store the data,

75
00:05:03,860 --> 00:05:08,186
help you visualize it, have the training and serving of the models

76
00:05:08,298 --> 00:05:11,790
and we run this where you need to be, whether that's public

77
00:05:11,860 --> 00:05:15,522
cloud, private cloud, hybrid, multi cloud

78
00:05:15,656 --> 00:05:18,798
from AWS, Azure, Google, red hat,

79
00:05:18,894 --> 00:05:22,660
wherever you need to run. And we work with all the

80
00:05:23,030 --> 00:05:26,290
cool fast hardware out there, whether it's Nvidia's Google

81
00:05:26,360 --> 00:05:29,746
stuffs, AMDS, IBM, Intel, Dell,

82
00:05:29,858 --> 00:05:33,494
all those are partners and friends and we're know

83
00:05:33,532 --> 00:05:37,042
really cool stuff with lots of open source and Python

84
00:05:37,106 --> 00:05:40,614
everywhere. And obviously model hub's like hugging

85
00:05:40,662 --> 00:05:43,962
face. Now Nifi is a great tool

86
00:05:44,016 --> 00:05:48,070
for working with Genai and having that support for Python

87
00:05:48,230 --> 00:05:51,518
just brings us to that next level. We could do a

88
00:05:51,524 --> 00:05:54,942
lot through rest and through Java, but being able to

89
00:05:54,996 --> 00:05:58,714
add that next step now of Python

90
00:05:58,842 --> 00:06:02,382
as part of our pipelines makes it very easy

91
00:06:02,436 --> 00:06:05,842
for us to do a lot of stuff with lots of different data

92
00:06:05,896 --> 00:06:09,554
sources. And I've got a ton of articles out there working with

93
00:06:09,592 --> 00:06:13,070
things like live question and answers, travel advisories,

94
00:06:13,150 --> 00:06:17,090
weather, tons of different formats, ingest that real

95
00:06:17,160 --> 00:06:20,454
fast, enrich it, do real time

96
00:06:20,492 --> 00:06:24,422
alerts if necessary, push things to vector databases using

97
00:06:24,476 --> 00:06:28,146
Python, get things into prompts for LLM

98
00:06:28,178 --> 00:06:31,446
wherever they have to run, push real time alerts

99
00:06:31,478 --> 00:06:35,034
and data into Kafka and also write

100
00:06:35,072 --> 00:06:39,066
into your data warehouse so you'll have petabytes worth of data to

101
00:06:39,088 --> 00:06:42,366
train your models or to act as additions to

102
00:06:42,388 --> 00:06:46,800
that. As we've seen, some of the models out there will

103
00:06:47,570 --> 00:06:51,134
not always give you back the perfect answer. And the best way to

104
00:06:51,172 --> 00:06:54,686
augment that is with rag. And we

105
00:06:54,708 --> 00:06:58,066
could support that by having data in our data warehouse, in our

106
00:06:58,088 --> 00:07:01,554
vector database. And we can cache things and we could pre

107
00:07:01,592 --> 00:07:04,834
compute things. A lot of advantages of having a lot

108
00:07:04,872 --> 00:07:08,614
of data, all of it connected real time together.

109
00:07:08,812 --> 00:07:12,646
Build out real time reports and visualizations and

110
00:07:12,668 --> 00:07:16,754
alerts and aggregation with lots of the latest open source

111
00:07:16,802 --> 00:07:20,438
tools that run in this very mixed environment,

112
00:07:20,614 --> 00:07:24,540
regardless of what you need there. And if we're working

113
00:07:25,630 --> 00:07:29,258
with data flowed in the public cloud, we make it really easy.

114
00:07:29,424 --> 00:07:33,002
Go to our ready flow gallery, press a couple of buttons,

115
00:07:33,146 --> 00:07:37,040
boom, deploy a flow and get ready to start

116
00:07:37,650 --> 00:07:41,342
taking data from a database. Pushing it to s three,

117
00:07:41,476 --> 00:07:45,294
that might be the first step in your real time

118
00:07:45,492 --> 00:07:48,482
gen AI pipeline. Again,

119
00:07:48,536 --> 00:07:52,574
we mentioned before lots of ways we work with LMS, help serving

120
00:07:52,622 --> 00:07:56,150
them, fine tune them, get data

121
00:07:56,220 --> 00:07:59,266
into and query the vector data stores.

122
00:07:59,458 --> 00:08:03,234
But the main place I work is within data preparation

123
00:08:03,282 --> 00:08:07,074
and data engineering. We make sure all this data gets processed

124
00:08:07,122 --> 00:08:10,506
in whatever size cluster it needs to be, all the way

125
00:08:10,528 --> 00:08:14,262
to the edge from wherever it needs to be, whether it's on cpus

126
00:08:14,326 --> 00:08:18,070
or gpus. All that with a lot of open source.

127
00:08:18,230 --> 00:08:22,122
Keep that knowledge in a secure repository

128
00:08:22,186 --> 00:08:25,626
that can span multiple public and private clouds,

129
00:08:25,658 --> 00:08:29,214
and make sure you have everything you expect to have with that

130
00:08:29,252 --> 00:08:33,074
data storage. Nifi 20 is

131
00:08:33,112 --> 00:08:36,546
the latest and greatest version of Apache Nifi. This has

132
00:08:36,568 --> 00:08:41,294
brought us the magic of really supreme

133
00:08:41,342 --> 00:08:44,894
Python integration. Before this we could work with Python,

134
00:08:44,942 --> 00:08:48,598
but it was a little kludy. We'd execute it and

135
00:08:48,604 --> 00:08:52,070
it would kind of run on its own. Not the best way to do that.

136
00:08:52,220 --> 00:08:55,654
We now added support for the JDK 21,

137
00:08:55,692 --> 00:08:59,162
which is a lot faster, leaner, and better

138
00:08:59,216 --> 00:09:02,394
use of threads. And we've added some

139
00:09:02,432 --> 00:09:06,086
other enhancements along with that process. But let's

140
00:09:06,118 --> 00:09:10,140
look into some Python processors and

141
00:09:10,990 --> 00:09:14,990
pretty easy to write your own. Basically, take any

142
00:09:15,140 --> 00:09:19,034
if you have a library you want to wrap and you can see my examples

143
00:09:19,082 --> 00:09:22,346
is pretty much what I did. It's a pretty base plate.

144
00:09:22,378 --> 00:09:25,794
Here you have a Python class. You import these things

145
00:09:25,832 --> 00:09:28,962
you see at the top that you need for building this type

146
00:09:29,016 --> 00:09:32,786
of class. We point to the Java that

147
00:09:32,808 --> 00:09:36,870
we need to point to that connects Java and Python together.

148
00:09:37,020 --> 00:09:40,722
We give ourselves processor details.

149
00:09:40,866 --> 00:09:44,818
This tells me what version I work with, a description.

150
00:09:44,994 --> 00:09:48,634
You'll see that when we go into the tool where that pops up some

151
00:09:48,672 --> 00:09:52,522
tags there to say what this is related to, and more

152
00:09:52,576 --> 00:09:56,682
importantly our property descriptors. These are

153
00:09:56,736 --> 00:10:00,846
the properties that we want to have inside

154
00:10:01,028 --> 00:10:04,430
of our application, and these are important

155
00:10:04,500 --> 00:10:07,566
ones, as you can see here. I want the prompt that

156
00:10:07,588 --> 00:10:11,434
I'm going to send to for this case Watson

157
00:10:11,482 --> 00:10:15,234
x AI API, and I'm going to need the

158
00:10:15,272 --> 00:10:19,954
key and I'm going to need the project ID for this particular project

159
00:10:20,152 --> 00:10:22,770
that I have rights to execute.

160
00:10:23,430 --> 00:10:26,534
And this is the main body of the

161
00:10:26,572 --> 00:10:29,510
Python code. Pretty straightforward.

162
00:10:30,090 --> 00:10:33,126
This doesn't change much. You start off with

163
00:10:33,148 --> 00:10:36,518
the definition name is transform self,

164
00:10:36,604 --> 00:10:40,714
context and flow file. Those are important. Context gives

165
00:10:40,752 --> 00:10:44,154
me access to lots of

166
00:10:44,192 --> 00:10:47,130
things in the environment. Like you see the properties.

167
00:10:47,470 --> 00:10:50,974
The flow file is any file that's coming into

168
00:10:51,012 --> 00:10:54,894
the system. If I want to change it, remove it,

169
00:10:54,932 --> 00:10:58,078
make my own. It's important to get that in.

170
00:10:58,164 --> 00:11:00,320
So I get those properties in,

171
00:11:01,170 --> 00:11:04,846
set my credentials. I have some libraries from IBM

172
00:11:04,878 --> 00:11:08,366
to use. I call it convert the response

173
00:11:08,398 --> 00:11:11,986
to JSON and just return it here

174
00:11:12,168 --> 00:11:15,634
with the success. If we had a failure, we can have a relationship

175
00:11:15,752 --> 00:11:18,406
of failure. A couple different options on those.

176
00:11:18,588 --> 00:11:21,862
Our contents are what we're outputting, which in this case

177
00:11:21,916 --> 00:11:25,222
is the output of this call.

178
00:11:25,356 --> 00:11:29,350
And we could send any attributes we want. Here I just set the mime type.

179
00:11:29,500 --> 00:11:33,354
You could also, and you'll see in some other examples, I don't change the

180
00:11:33,392 --> 00:11:37,274
contents. I give you whatever flow file you gave me. Just pass that

181
00:11:37,312 --> 00:11:41,340
along, give you some attributes. That way you don't have to change

182
00:11:41,710 --> 00:11:45,566
whatever data was coming in your pipelines. You're just going to

183
00:11:45,588 --> 00:11:49,146
add some metadata around it. It's a great way to pass a file

184
00:11:49,178 --> 00:11:52,730
along without changing it too substantially,

185
00:11:52,810 --> 00:11:56,210
which is fast and just putting things you might need around it.

186
00:11:56,280 --> 00:12:00,066
If it's small data or something that augments it, you could

187
00:12:00,088 --> 00:12:02,660
decide later if you want to rewrite everything.

188
00:12:03,270 --> 00:12:07,062
So an example of one that doesn't change what's coming

189
00:12:07,116 --> 00:12:11,094
in is processor I wrote for this one

190
00:12:11,132 --> 00:12:15,542
you need and for everything with Nifi. Two, Python 310

191
00:12:15,596 --> 00:12:19,238
is the minimum, which you're probably at, but I know some

192
00:12:19,244 --> 00:12:22,742
of the older machines don't have it. We really need you to have Python

193
00:12:22,806 --> 00:12:26,534
310 and again JDK 21 on your machine.

194
00:12:26,662 --> 00:12:29,990
This uses libraries from hugging face, NLP,

195
00:12:30,070 --> 00:12:33,582
Spacey and Pytorch. This is based on an example

196
00:12:33,636 --> 00:12:37,390
I found in stack overflow and it's pretty cool.

197
00:12:37,540 --> 00:12:41,040
What it basically does is you pass in some text

198
00:12:41,490 --> 00:12:45,138
and you get back one or more companies and I've got a

199
00:12:45,144 --> 00:12:48,866
couple of attributes get returned. One is a list of all the

200
00:12:48,888 --> 00:12:52,674
companies that might be listed in your data you passed in.

201
00:12:52,872 --> 00:12:56,486
And the first company I put in

202
00:12:56,508 --> 00:13:00,630
a separate attribute. Pretty straightforward source code

203
00:13:00,700 --> 00:13:04,466
is listed at the bottom and we'll run through some examples.

204
00:13:04,498 --> 00:13:07,906
So you see it running, but it's a nice little processor

205
00:13:07,938 --> 00:13:12,234
to get you company names. I use this in some

206
00:13:12,272 --> 00:13:15,514
flows where I want the company name, and then I'm going to call

207
00:13:15,552 --> 00:13:19,114
a rest endpoint that gives me the stock symbol based

208
00:13:19,152 --> 00:13:22,814
on that company name. And then I could use that stock symbol to get

209
00:13:22,852 --> 00:13:25,758
stock values. Cool stuff to have.

210
00:13:25,924 --> 00:13:29,662
Also, sometimes when you're doing something

211
00:13:29,716 --> 00:13:32,974
in slack, someone gives you a question. Maybe it doesn't need

212
00:13:33,092 --> 00:13:36,450
to go to a large language model every time. Maybe sometimes

213
00:13:36,520 --> 00:13:40,002
it's a lookup from a databases or it's a call

214
00:13:40,056 --> 00:13:43,458
to a rest endpoint to get the current stock. You got

215
00:13:43,464 --> 00:13:47,174
to be smart about how you use these models. Don't use them for

216
00:13:47,212 --> 00:13:50,998
things they're not designed for. Another cool one.

217
00:13:51,084 --> 00:13:55,320
If you're doing any kind of transit data, and if you've been

218
00:13:55,770 --> 00:13:59,386
watching my blog, you'll see I've been doing a lot of transit data.

219
00:13:59,488 --> 00:14:02,598
They have a lot of data. It's always in motion.

220
00:14:02,694 --> 00:14:06,634
Lots of interesting stuff. Real data, real world and all over

221
00:14:06,672 --> 00:14:10,686
the world. Well, some of these return

222
00:14:10,788 --> 00:14:14,830
more than one type of data, which I found out and

223
00:14:14,980 --> 00:14:17,982
that can be problematic. So for me,

224
00:14:18,116 --> 00:14:21,422
I wrote this compound gtfs data

225
00:14:21,476 --> 00:14:24,626
reader takes a URL header and a

226
00:14:24,648 --> 00:14:28,206
key if you need it and you tell me what kind of feed

227
00:14:28,238 --> 00:14:32,210
you want here. There's three types in the GTFS spec.

228
00:14:32,360 --> 00:14:36,454
GTFS is a transit spec out

229
00:14:36,492 --> 00:14:40,374
there, trip updates, say when the bus or

230
00:14:40,572 --> 00:14:44,274
subway or whatever it is has an update vehicle tracks

231
00:14:44,322 --> 00:14:48,714
the vehicles and alerts or something happens which

232
00:14:48,752 --> 00:14:52,300
happens again. The links are down there, could try it out.

233
00:14:52,910 --> 00:14:56,362
Someone gave me a file full of weird looking data I've never

234
00:14:56,416 --> 00:14:59,958
seen before. It's this webvtt.

235
00:15:00,134 --> 00:15:03,738
Well this is a web video text tracks format.

236
00:15:03,914 --> 00:15:07,674
Well this is for when you're doing training classes

237
00:15:07,722 --> 00:15:11,120
or you have text that go along with a video.

238
00:15:11,570 --> 00:15:16,654
Well, if I want to process this in a generative

239
00:15:16,702 --> 00:15:20,194
AI or LLM, I can extract just the

240
00:15:20,232 --> 00:15:24,014
text out there. I don't need the number or the timestamp

241
00:15:24,062 --> 00:15:27,666
in there for just grabbing that data that I may want to

242
00:15:27,688 --> 00:15:31,014
push to a vector data store or I might want to use

243
00:15:31,052 --> 00:15:34,866
in a prompt whatever I'm using there. And I've got the processor

244
00:15:34,898 --> 00:15:39,494
for that. And you can see the API there mentioned

245
00:15:39,612 --> 00:15:43,830
earlier. And I showed you that code. The Watson XSDk

246
00:15:43,910 --> 00:15:47,594
to access their foundation LLM models. This one

247
00:15:47,632 --> 00:15:51,450
does the inference, it's secure and it's the official SDK.

248
00:15:51,970 --> 00:15:55,502
Other ways to do this, and I was doing this through rest, but having

249
00:15:55,556 --> 00:15:59,454
this as Python with the standard SDK is

250
00:15:59,492 --> 00:16:03,140
nice. And this runs fast, pretty easy to do,

251
00:16:03,670 --> 00:16:06,754
and we saw those parameters before

252
00:16:06,952 --> 00:16:10,958
and it fits really nice in a streaming pipelines

253
00:16:11,134 --> 00:16:14,420
get a nice way to do that. Now another

254
00:16:15,690 --> 00:16:19,318
one that's just wrapping a library is my system

255
00:16:19,404 --> 00:16:23,218
process monitoring Python processor.

256
00:16:23,394 --> 00:16:27,074
Again, Python 310 and more. This is accessing

257
00:16:27,122 --> 00:16:30,550
PS util, which is a great python library.

258
00:16:30,710 --> 00:16:34,234
And I'm just grabbing and running as many of these that

259
00:16:34,272 --> 00:16:37,210
make sense in a context on multiple machines,

260
00:16:37,550 --> 00:16:41,210
which if you want to tweak this source code is available

261
00:16:41,280 --> 00:16:44,686
on that QR. But you see where my GitHub is,

262
00:16:44,708 --> 00:16:48,138
you'll be able to find all this stuff and this outputs

263
00:16:48,314 --> 00:16:51,870
all of these different results as

264
00:16:51,940 --> 00:16:55,586
attribute values. Again, metadata not messing up

265
00:16:55,608 --> 00:16:58,740
your data. Nothing changes for you, which is great.

266
00:16:59,350 --> 00:17:03,074
Another one. Sometimes you need to test things, sometimes maybe

267
00:17:03,112 --> 00:17:06,580
you're doing a demo or you just want synthetic data.

268
00:17:07,030 --> 00:17:10,614
Well, the faker library is pretty awesome. I have

269
00:17:10,652 --> 00:17:13,798
it so you could choose as many of these as you want.

270
00:17:13,884 --> 00:17:17,286
True false. There is a ton of them. I'll let you

271
00:17:17,308 --> 00:17:20,346
get one of each right now. It goes to attribute value.

272
00:17:20,528 --> 00:17:24,246
Maybe I'll create an output flow

273
00:17:24,278 --> 00:17:27,706
file. I'm still debating that. You let me know which

274
00:17:27,728 --> 00:17:31,286
one is better for you if returning a flow

275
00:17:31,318 --> 00:17:34,558
file. Maybe I'll create a second processor that does a

276
00:17:34,564 --> 00:17:38,014
flow file. Or maybe we'll put another parameter that

277
00:17:38,052 --> 00:17:41,710
picks. Let me know if that matters to you, how important

278
00:17:41,780 --> 00:17:44,938
that is for sometimes I need wiki

279
00:17:44,954 --> 00:17:49,134
pages. These are useful in a Genai pipeline

280
00:17:49,182 --> 00:17:53,330
if I want to train a model, add some augmentation,

281
00:17:53,830 --> 00:17:57,774
look it up, add that to the prompt as part of the rag

282
00:17:57,822 --> 00:18:01,282
or prompt engineering. I use the Wikipedia

283
00:18:01,346 --> 00:18:05,154
API in Python and it lets you choose whether you want the HTML

284
00:18:05,202 --> 00:18:08,426
back or the text. And you could

285
00:18:08,528 --> 00:18:11,770
pass in what wikipage dynamically.

286
00:18:12,430 --> 00:18:15,466
Again, just use that QR code if you want to see it.

287
00:18:15,568 --> 00:18:19,414
The example grabs, that company we parsed

288
00:18:19,462 --> 00:18:23,178
with the extract company grabs their wiki

289
00:18:23,194 --> 00:18:27,162
page. Just showing you how you could use these in multiple steps.

290
00:18:27,306 --> 00:18:30,794
Again, I'm learning to write new Python processors

291
00:18:30,842 --> 00:18:33,300
here based on things we need.

292
00:18:34,550 --> 00:18:37,762
And before I added that fancy compound one,

293
00:18:37,896 --> 00:18:41,934
I have a basic one. This is the most standard transit

294
00:18:41,982 --> 00:18:45,910
URL. They return one of these three types, and usually

295
00:18:45,980 --> 00:18:48,870
it's in the name. It's like MTA,

296
00:18:49,690 --> 00:18:51,090
blah blah blah blah blah,

297
00:18:51,170 --> 00:18:55,590
alertsgb or

298
00:18:55,660 --> 00:18:58,120
Proto or gtfs or whatever it is,

299
00:18:58,570 --> 00:19:02,250
and they just have one. So this returns the JSOn for you

300
00:19:02,320 --> 00:19:05,334
pretty easy. Takes gtfs format,

301
00:19:05,382 --> 00:19:09,206
makes it easy to format and grabs it from the URL.

302
00:19:09,398 --> 00:19:12,654
Couldn't be easier than that. Now there's a bunch that

303
00:19:12,692 --> 00:19:17,600
come prepackaged in Apache 9520.

304
00:19:18,610 --> 00:19:21,870
I've tweaked a couple of these based on some of my needs,

305
00:19:22,020 --> 00:19:25,714
but there's ones for pine cone to do queries and to

306
00:19:25,832 --> 00:19:29,134
store your data. There's a great one for chunking

307
00:19:29,182 --> 00:19:32,686
up documents to make them small enough to fit in the vectors.

308
00:19:32,718 --> 00:19:36,360
Right? There's a parse document one. This is great.

309
00:19:36,970 --> 00:19:42,310
This is for parsing your markdown,

310
00:19:42,730 --> 00:19:46,150
PowerPoint, Google Doc, Excel,

311
00:19:46,810 --> 00:19:49,910
parse that data, get the text out. Again,

312
00:19:49,980 --> 00:19:53,546
great for pushing that to a vector store using that as

313
00:19:53,568 --> 00:19:56,986
a prompt, just storing that in a database, using that part as a

314
00:19:57,008 --> 00:20:00,294
slack message, whatever. Got another one that converts

315
00:20:00,342 --> 00:20:03,934
CSVs into Excel if you need Excel, one that

316
00:20:03,972 --> 00:20:07,818
does our favorite deep learning, some object detection.

317
00:20:07,994 --> 00:20:11,198
And right now I'm working with Yolo eight, so I

318
00:20:11,204 --> 00:20:13,460
might run write a new one on that.

319
00:20:13,990 --> 00:20:17,234
The best and most useful to

320
00:20:17,272 --> 00:20:20,402
have one Python processor do all this for you.

321
00:20:20,536 --> 00:20:24,698
The prompt chat GBT you put in your text prompt,

322
00:20:24,894 --> 00:20:28,406
couple parameters your id

323
00:20:28,508 --> 00:20:32,386
because you got to have access to OpenAI and calls,

324
00:20:32,418 --> 00:20:35,320
the model gets your results back.

325
00:20:35,850 --> 00:20:39,334
Really nice. Thank you Python. And then the same thing

326
00:20:39,372 --> 00:20:43,110
for the Chroma vector DB. There's a put in a query.

327
00:20:43,270 --> 00:20:46,522
Those are great ones as well. We're still in the

328
00:20:46,576 --> 00:20:50,262
early world of python

329
00:20:50,326 --> 00:20:53,946
processors, so now's the time to start putting yours

330
00:20:53,978 --> 00:20:57,754
out there. Love to see a ton of people after this conference

331
00:20:57,802 --> 00:21:01,310
write their own. Definitely contact me if you need a little help,

332
00:21:01,460 --> 00:21:04,926
and if you have some, I'll publish them in the weekly newsletter and

333
00:21:04,948 --> 00:21:08,754
I'll tell the NiFi engineering team about them. Maybe they'll go into

334
00:21:08,792 --> 00:21:12,402
the official line or they will definitely be promoted and

335
00:21:12,456 --> 00:21:16,694
used. Example of a flow we

336
00:21:16,732 --> 00:21:19,718
get slack messages in transform and clean them.

337
00:21:19,804 --> 00:21:23,270
Query a vector store, build my prompt,

338
00:21:23,690 --> 00:21:27,286
call my model with python, transfer and clean the

339
00:21:27,308 --> 00:21:30,780
results, push them to slack in kafka. Pretty easy.

340
00:21:31,230 --> 00:21:34,940
We will show you some demos here and then

341
00:21:35,550 --> 00:21:40,258
let you get on with the many more talks

342
00:21:40,294 --> 00:21:42,960
that you're seeing today, which is a pretty awesome list.

343
00:21:43,330 --> 00:21:45,920
This is 9520.

344
00:21:46,450 --> 00:21:49,534
This is my environment running on my

345
00:21:49,572 --> 00:21:54,050
laptop, and in this example I consume

346
00:21:55,030 --> 00:21:58,914
a feed from medium, which happens to be my

347
00:21:58,952 --> 00:22:03,618
feed to get all my articles and process them,

348
00:22:03,784 --> 00:22:08,362
clean them up. I do some of this with regular nifi

349
00:22:08,526 --> 00:22:12,710
processors, nothing too fancy.

350
00:22:13,050 --> 00:22:16,374
And then when it comes out here, here we start

351
00:22:16,412 --> 00:22:20,570
getting into these fancy python ones. As you can see, Python extensions,

352
00:22:21,150 --> 00:22:25,242
this one is taking plain text in and

353
00:22:25,296 --> 00:22:28,826
extracts a couple of metadata fields along with the

354
00:22:28,848 --> 00:22:32,880
data so it parses the data out. We could do one here,

355
00:22:33,650 --> 00:22:37,040
I've got a couple sitting here. Let's just run one,

356
00:22:37,730 --> 00:22:41,550
have that come in and then we will parse that.

357
00:22:41,700 --> 00:22:44,942
Now if we needed to look at all the python processors,

358
00:22:45,086 --> 00:22:48,994
I can just type python. You can see there's a couple versions of different

359
00:22:49,032 --> 00:22:52,420
ones in there. Can see my extract company name,

360
00:22:53,270 --> 00:22:57,510
fake record a bunch of different ones in here.

361
00:22:57,660 --> 00:23:01,682
Pretty straightforward. Okay, that finished this parse

362
00:23:01,746 --> 00:23:05,874
document, finished the chunk

363
00:23:06,002 --> 00:23:09,818
chunk is also a python one, again to make things

364
00:23:09,904 --> 00:23:14,326
fit into a vector. So this processed

365
00:23:14,358 --> 00:23:18,140
them up, chunked them up, and now we could push these to

366
00:23:18,670 --> 00:23:22,720
say a chroma data store with some parameters there.

367
00:23:23,410 --> 00:23:26,798
Pretty easy to do that. Just run one there.

368
00:23:26,964 --> 00:23:30,190
Same thing here. If the chroma happens to be remote,

369
00:23:30,690 --> 00:23:34,770
same idea query, pretty straightforward,

370
00:23:35,350 --> 00:23:38,722
very easy to work with

371
00:23:38,776 --> 00:23:42,546
this without too much trouble. Down here you could see we

372
00:23:42,568 --> 00:23:45,478
have some other stuff going on, so I'm going to let one through so you

373
00:23:45,484 --> 00:23:49,062
could see the other processors. And after that

374
00:23:49,116 --> 00:23:53,014
gets pushed, this one is the extract company here.

375
00:23:53,052 --> 00:23:56,694
I parsed in the prompt. Now this is

376
00:23:56,732 --> 00:24:00,294
one way to get data into a processor. The other

377
00:24:00,332 --> 00:24:04,234
way is it could come in as a full flow file. Depends what

378
00:24:04,272 --> 00:24:07,878
makes sense for you. If you look there, you could see it ran

379
00:24:08,054 --> 00:24:11,834
right now and I could see the output

380
00:24:11,882 --> 00:24:14,894
here and the results. What came in,

381
00:24:14,932 --> 00:24:18,350
what came out pretty straightforward.

382
00:24:19,970 --> 00:24:23,538
This one didn't work because it probably didn't have a company name. Some of

383
00:24:23,544 --> 00:24:27,730
these don't have a company name, but you do have always

384
00:24:27,800 --> 00:24:33,570
have the values coming out of our utils.

385
00:24:34,070 --> 00:24:37,302
So we'll get back any of the things

386
00:24:37,356 --> 00:24:40,466
that make sense for the different util.

387
00:24:40,498 --> 00:24:45,862
They're pretty straightforward. If you're using any

388
00:24:45,916 --> 00:24:50,134
of the system processing. We get the PS

389
00:24:50,182 --> 00:24:53,418
util stuff out here, we got some output from the

390
00:24:53,424 --> 00:24:58,186
wiki, and if we see here a

391
00:24:58,208 --> 00:25:01,050
couple different attributes come back from the wiki.

392
00:25:01,710 --> 00:25:04,846
Yeah, you could see in here where we had the company name. If I

393
00:25:04,868 --> 00:25:08,846
have a company name, then I can get

394
00:25:08,868 --> 00:25:12,390
a wiki page and then just have it output.

395
00:25:12,490 --> 00:25:16,674
But as you can see, we could put a ton of parameters here,

396
00:25:16,872 --> 00:25:20,526
very easy to do. There's the pids

397
00:25:20,558 --> 00:25:24,194
on the running, there's our text, there's our

398
00:25:24,232 --> 00:25:27,842
results here, and it was an HTML page. We get back again,

399
00:25:27,896 --> 00:25:31,186
there's a couple of different formats you could pick when you're grabbing

400
00:25:31,218 --> 00:25:34,662
a wiki page. And now I could push it to something else

401
00:25:34,716 --> 00:25:38,442
if I wanted to. Depend on what makes sense for your use

402
00:25:38,496 --> 00:25:41,978
case over here, I've got another use case. If we

403
00:25:41,984 --> 00:25:45,546
didn't let this guy time out, make sure

404
00:25:45,568 --> 00:25:48,860
these guys are loaded so we get those ready.

405
00:25:49,470 --> 00:25:53,630
Okay, so this one I'm using that gtfs processor here.

406
00:25:53,780 --> 00:25:57,690
And this is calling Halifax, Canada. Their vehicle

407
00:25:57,770 --> 00:26:00,720
positions. So I'll run this once.

408
00:26:01,250 --> 00:26:05,060
And that already finished. And that gave me back

409
00:26:06,310 --> 00:26:10,980
the results here. 500 bytes in,

410
00:26:11,750 --> 00:26:15,554
can't really see that till it gets split out. And you can see

411
00:26:15,592 --> 00:26:19,894
we get a lot of rows came out of there and

412
00:26:19,932 --> 00:26:23,554
we could take a look at one and see that it got converted into JSoN.

413
00:26:23,602 --> 00:26:27,254
That tells me about that vehicle and the trip and how

414
00:26:27,292 --> 00:26:31,290
fast it's going. Different data around those

415
00:26:31,360 --> 00:26:35,034
attributes. Pretty straightforward. Now when we are

416
00:26:35,072 --> 00:26:38,298
parsing documents here, again,

417
00:26:38,384 --> 00:26:42,170
this is the Python one I'm picking PDF.

418
00:26:42,330 --> 00:26:46,080
Let it parse it the way it makes sense. There's a couple of options there.

419
00:26:46,930 --> 00:26:50,542
I like this PDF parsing model. This one works

420
00:26:50,596 --> 00:26:54,790
pretty good for me. Just English. Add a couple of metadata

421
00:26:54,810 --> 00:26:58,594
fields. Not really, I don't need them because here I'm going

422
00:26:58,632 --> 00:27:01,490
to split that data out into pieces.

423
00:27:02,230 --> 00:27:05,880
Like we could take a look at a chunk, that's a chunk of text

424
00:27:06,250 --> 00:27:10,454
in a JSON format. Then I run

425
00:27:10,492 --> 00:27:14,582
that, get a chunk, and that chunk I'm going to push to

426
00:27:14,716 --> 00:27:17,994
a vector store so it's not too big to go into

427
00:27:18,032 --> 00:27:21,514
the vector databases. And then the results of that will

428
00:27:21,552 --> 00:27:24,954
go into a slack just to

429
00:27:24,992 --> 00:27:28,540
track it. I've got one to do that.

430
00:27:29,230 --> 00:27:32,970
Translate wvtt. Don't need any parameters.

431
00:27:33,050 --> 00:27:36,254
This just takes the whole file coming in

432
00:27:36,452 --> 00:27:40,046
and converts it to just the text again. And then

433
00:27:40,068 --> 00:27:42,926
I could push it into a prompt if I wanted to.

434
00:27:43,108 --> 00:27:46,514
Pretty straightforward, whatever makes

435
00:27:46,552 --> 00:27:49,874
sense. I could parse powerpoints. Lots of

436
00:27:49,912 --> 00:27:54,338
different things you could do. There. Example is

437
00:27:54,424 --> 00:27:58,514
using the prompt chat GBT. I'm using the turbo,

438
00:27:58,642 --> 00:28:01,746
get my inputs parsed in temperature,

439
00:28:01,858 --> 00:28:05,494
API key, all that kind of fun stuff. So we could run

440
00:28:05,532 --> 00:28:09,434
one of those and get the results back. This is coming from

441
00:28:09,552 --> 00:28:13,450
slack events. Pretty straightforward on that.

442
00:28:13,600 --> 00:28:16,906
And then I push that to a slack channel and we could

443
00:28:16,928 --> 00:28:19,340
take a look and see the results of that.

444
00:28:20,110 --> 00:28:23,934
We'll go to. Here is where it got the chat here

445
00:28:23,972 --> 00:28:27,454
it posted the results and we could add

446
00:28:27,492 --> 00:28:31,102
other stuff to that. But pretty easy to use that

447
00:28:31,156 --> 00:28:34,606
Python processor there. It's just an

448
00:28:34,628 --> 00:28:38,350
easy way to be able to get your data.

449
00:28:38,500 --> 00:28:41,360
Move it really quickly. Do what you need to do.

450
00:28:42,290 --> 00:28:45,606
Thanks for listening to my talk. If you're interested

451
00:28:45,708 --> 00:28:49,266
on writing your own python code for Apache

452
00:28:49,298 --> 00:28:52,580
Nifi, definitely reach out and thank.

