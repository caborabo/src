1
00:00:21,280 --> 00:00:24,934
Hi, today I'm going to talk about a creative approach I've

2
00:00:24,974 --> 00:00:28,066
devised that harnesses multiple llms

3
00:00:28,210 --> 00:00:31,698
in order to achieve a high quality output.

4
00:00:31,866 --> 00:00:35,146
It's something I call collaborative AI, and my

5
00:00:35,170 --> 00:00:38,578
hope today is that you will be able to unlock its

6
00:00:38,626 --> 00:00:42,090
potential to really push the upper limits of what is

7
00:00:42,122 --> 00:00:45,962
possible in terms of content quality and LLM

8
00:00:46,018 --> 00:00:49,938
output. Today I'm going to use Chachi PT

9
00:00:49,986 --> 00:00:54,190
four and cloud three opus to showcase the power of

10
00:00:54,302 --> 00:00:57,854
collaborative AI. Before I do so, I wanted to talk a little

11
00:00:57,894 --> 00:01:01,310
bit about how content creation pre AI has

12
00:01:01,342 --> 00:01:05,030
typically played out in my field. Online learning. The bar for

13
00:01:05,062 --> 00:01:08,862
creating educational content is usually very, very high

14
00:01:08,998 --> 00:01:12,206
when it comes to factuality. We hire what are known

15
00:01:12,230 --> 00:01:15,558
as SME's or subject matter experts, and their job

16
00:01:15,606 --> 00:01:19,288
is to be as accurate as possible, both in writing and and in reviewing

17
00:01:19,336 --> 00:01:22,464
content. They essentially are the domain experts

18
00:01:22,504 --> 00:01:25,976
of their field, be it art history or upper

19
00:01:26,000 --> 00:01:29,360
division calculus. What they are not oftentimes

20
00:01:29,432 --> 00:01:32,736
is professionally trained writers. As a result,

21
00:01:32,880 --> 00:01:36,648
their writing, while grammatically sound, factually accurate,

22
00:01:36,776 --> 00:01:39,576
can sometimes come across as a little bit dry,

23
00:01:39,720 --> 00:01:43,272
unengaging, and a bit repetitive. But this isn't helped

24
00:01:43,288 --> 00:01:46,928
by the fact that the amount of content often needed by online providers is

25
00:01:46,976 --> 00:01:50,744
staggering, and SME's have to work under a tight deadline.

26
00:01:50,864 --> 00:01:54,776
Engaging writing with memorable examples, smooth transitions,

27
00:01:54,880 --> 00:01:58,240
and that writerly touch are oftentimes out of reach

28
00:01:58,272 --> 00:02:02,008
for SME's, even those with professional training in writing.

29
00:02:02,176 --> 00:02:05,456
With AI, we are now able to get content out much faster,

30
00:02:05,600 --> 00:02:09,152
but not without potential pitfalls, for one,

31
00:02:09,248 --> 00:02:13,408
hallucinations where the LLM generates inaccuracies

32
00:02:13,456 --> 00:02:17,646
and even outright falsehoods. There's this fear that for first time learners,

33
00:02:17,750 --> 00:02:21,394
they might end up thinking that the civil war happened only last century.

34
00:02:21,934 --> 00:02:25,430
While such glaring falsehoods aren't necessarily that

35
00:02:25,502 --> 00:02:28,758
common, smaller inaccuracies do occur.

36
00:02:28,846 --> 00:02:32,294
Then there's the question of writing do AI models

37
00:02:32,414 --> 00:02:36,678
have the ability to take otherwise potentially dry educational

38
00:02:36,726 --> 00:02:40,534
content and make it exciting and interesting while

39
00:02:40,574 --> 00:02:44,646
still being accurate and and able to convey a sense of authority? The PowerPoint

40
00:02:44,710 --> 00:02:48,614
presentation that follows I'm going to take a piece of educational

41
00:02:48,654 --> 00:02:52,222
content that I'm going to have Claude three opus and Chachi Pt

42
00:02:52,278 --> 00:02:55,478
four evaluate, and then I'm going to have them generate

43
00:02:55,526 --> 00:02:58,398
their own versions. But I'll go further than that,

44
00:02:58,526 --> 00:03:02,518
leveraging collaborative AI as I take inputs and outputs from one

45
00:03:02,566 --> 00:03:06,558
LLM and feed them into the other, using collaborative

46
00:03:06,606 --> 00:03:09,790
AI to improve upon those outputs so that the

47
00:03:09,822 --> 00:03:13,014
final product is greater, better than

48
00:03:13,054 --> 00:03:16,422
anything that either LLM could have generated by itself.

49
00:03:16,518 --> 00:03:19,950
So let's dive in and see collaborative AI in action. So here we

50
00:03:19,982 --> 00:03:23,462
are with transforming content creation with collaborative AI.

51
00:03:23,638 --> 00:03:27,030
The first thing I did was create a little experiment.

52
00:03:27,222 --> 00:03:31,118
The idea here was that we needed to take some baseline,

53
00:03:31,166 --> 00:03:35,634
some standard content that the llms could improve upon,

54
00:03:35,954 --> 00:03:40,010
and we needed to make sure that there was some scoring around that

55
00:03:40,042 --> 00:03:44,122
baseline sample. Otherwise it would be difficult to say whether and how much

56
00:03:44,258 --> 00:03:47,614
the other LLM generated outputs improved by.

57
00:03:47,954 --> 00:03:51,954
So first off, we needed a piece of education content, something that

58
00:03:51,994 --> 00:03:55,346
could serve as our baseline. And of course we needed to choose a

59
00:03:55,370 --> 00:03:59,506
topic as well. And then we needed to define the criteria

60
00:03:59,690 --> 00:04:03,338
of quality, like what made this a strong or not strong

61
00:04:03,386 --> 00:04:07,362
piece of writing, and what did we want the two llms, in this case

62
00:04:07,498 --> 00:04:10,850
chachi pt four and clot three opus, to focus

63
00:04:10,922 --> 00:04:14,694
on when generating a high quality sample.

64
00:04:15,234 --> 00:04:18,882
So that again speaks to the idea of to establish a quality

65
00:04:18,978 --> 00:04:22,546
baseline. So what I did is I had chat GPT four actually write

66
00:04:22,570 --> 00:04:25,946
a chapter, and then later clod three

67
00:04:26,050 --> 00:04:29,658
scored that chapter. Now I'm going to go through each one of these parts,

68
00:04:29,746 --> 00:04:33,826
starting with the piece of education content and then ending with more details

69
00:04:33,890 --> 00:04:36,214
about establishing that quality baseline.

70
00:04:36,784 --> 00:04:40,064
First off, the piece of content, I decided it was going

71
00:04:40,564 --> 00:04:44,128
to be a 500 to 600 word article on large language models,

72
00:04:44,256 --> 00:04:47,764
and I think that makes sense given the target audience.

73
00:04:48,664 --> 00:04:51,456
But I didn't just have it write the large language model.

74
00:04:51,560 --> 00:04:55,160
Instead, I fed Claude 33 online learning excerpts

75
00:04:55,192 --> 00:04:58,376
from different topics, different areas,

76
00:04:58,560 --> 00:05:02,040
something that it could model when it

77
00:05:02,072 --> 00:05:06,458
actually generated its own article, and I chose samples that

78
00:05:06,506 --> 00:05:09,714
were indicative of more average online

79
00:05:09,834 --> 00:05:13,498
learning content. So there's a lot of great online learning content out there,

80
00:05:13,506 --> 00:05:16,826
and I definitely don't want to cast aspersions upon the field, but I was going

81
00:05:16,850 --> 00:05:20,370
for something a little bit more average, something that if someone was

82
00:05:20,402 --> 00:05:24,162
under a deadline, they might end up creating. And so I

83
00:05:24,178 --> 00:05:28,146
fed that to Claude three and had it actually characterized

84
00:05:28,170 --> 00:05:32,052
the writing, which is a step I like to do with llms. It's a reflection,

85
00:05:32,178 --> 00:05:35,736
sort of step in between before they actually generate an

86
00:05:35,760 --> 00:05:40,504
article. Now, you don't have to do this, but it's something that I did before

87
00:05:40,624 --> 00:05:44,352
it actually generated the writing. And in doing so, it identified

88
00:05:44,408 --> 00:05:47,848
eight characteristics from these excerpts and also was a sanity

89
00:05:47,896 --> 00:05:50,936
check just to make sure that what I thought wasn't great writing, that it could

90
00:05:50,960 --> 00:05:54,288
back me up there as well. And indeed it did here.

91
00:05:54,376 --> 00:05:57,962
Came up with a total of eight. I've only posted six and

92
00:05:57,978 --> 00:06:01,170
a half here, but it gives you an idea. The point here isn't to read

93
00:06:01,202 --> 00:06:04,802
through each one of these, but that there definitely are

94
00:06:04,938 --> 00:06:08,858
lapses in quality. And now once the LLM has

95
00:06:08,906 --> 00:06:12,586
that, it can generate this piece of content here, which again is a 500

96
00:06:12,610 --> 00:06:16,234
or 600 word chapter on llms. And I actually

97
00:06:16,354 --> 00:06:19,466
used my editorial eye just a little bit and looked at those

98
00:06:19,490 --> 00:06:23,634
eight characteristics as well, courtesy of cloud three. And I changed,

99
00:06:23,674 --> 00:06:26,254
tweaked just a few things, but nothing major.

100
00:06:26,774 --> 00:06:30,390
And this is what we had, or what we ended up with.

101
00:06:30,582 --> 00:06:34,110
Again, not going to pause here too long,

102
00:06:34,182 --> 00:06:36,382
I don't think the point here is to really read this. In fact, I only

103
00:06:36,438 --> 00:06:39,478
excerpted it because this is clearly not 500 to 600 words,

104
00:06:39,526 --> 00:06:43,390
but the actual thing from which, or the text from which this is exerted

105
00:06:43,502 --> 00:06:47,166
was around the 500 mark. So usually llms aren't that great at counting,

106
00:06:47,190 --> 00:06:50,486
but they did a pretty good job here. But what is mediocre

107
00:06:50,510 --> 00:06:53,710
about this? Let's just really quickly look at that first sentence where it says llms

108
00:06:53,742 --> 00:06:56,856
are a type of AI, artificial intelligence. Then notice the

109
00:06:56,880 --> 00:07:00,456
second sentence llms use. So it repeats

110
00:07:00,560 --> 00:07:04,232
that exact same noun, and that gives rise to a repetitive,

111
00:07:04,368 --> 00:07:07,344
dry kind of writing. And if you dive in here a little bit more,

112
00:07:07,384 --> 00:07:10,928
you'll see that as well. Third paragraph starts off with llms,

113
00:07:11,096 --> 00:07:14,264
but the idea here is it's the quality of writing that we're going

114
00:07:14,304 --> 00:07:17,672
for, and it just doesn't hit the mark. Next, we wanted to

115
00:07:17,688 --> 00:07:21,472
define criteria that we were looking for in

116
00:07:21,528 --> 00:07:26,302
good writing. So when we have the llms create quality output,

117
00:07:26,438 --> 00:07:30,766
what are we defining as quality? So we marked here some criteria. The LLM,

118
00:07:30,870 --> 00:07:34,750
in this case cloud three, was able to come up with five categories

119
00:07:34,822 --> 00:07:38,190
here, engaging language and storytelling, relatable examples, thought for broken

120
00:07:38,222 --> 00:07:42,046
questions, sentence structure, clarity, et cetera. And this

121
00:07:42,070 --> 00:07:46,030
is what it identified. And what I agreed were

122
00:07:46,142 --> 00:07:49,294
hallmarks of strong, engaging educational

123
00:07:49,334 --> 00:07:53,198
content. So again, in establishing the baseline,

124
00:07:53,366 --> 00:07:56,190
we got a score out of four out of ten. But I didn't want to

125
00:07:56,222 --> 00:08:00,238
just stop there. I asked myself, what if we just asked

126
00:08:00,326 --> 00:08:04,230
the LLM in a one shot prompt to come

127
00:08:04,262 --> 00:08:08,134
up with a chapter for an education course, online learning

128
00:08:08,174 --> 00:08:11,886
course on llms, what would it come out with? And it

129
00:08:11,910 --> 00:08:15,886
came out with something, this one shot prompt, and it got a seven out of

130
00:08:15,910 --> 00:08:18,584
ten. Now, I'm not going to paste that here, but I'll say it was high

131
00:08:18,624 --> 00:08:21,856
level, generic, typical AI stuff. This was a good baseline for

132
00:08:21,880 --> 00:08:25,360
me, because if we use collaborative AI here,

133
00:08:25,552 --> 00:08:28,776
or if I use collaborative AI and it turns out I also get

134
00:08:28,800 --> 00:08:32,184
a seven, then there doesn't seem to be much point in collaborative AI

135
00:08:32,224 --> 00:08:35,328
when you can just do a one shot prompt that will get you a decent

136
00:08:35,376 --> 00:08:39,200
seven out of ten score. But let's see what actually happens when

137
00:08:39,232 --> 00:08:42,880
we use collaborative AI now. You'll notice it says

138
00:08:42,952 --> 00:08:46,144
pre step one, so we're not quite there, and sorry

139
00:08:46,184 --> 00:08:49,984
to be teasing you on this, but we're almost there in the

140
00:08:50,024 --> 00:08:53,480
next slide. For now, though, the pre step prompt I did was

141
00:08:53,512 --> 00:08:57,152
I asked cloud three and chat GPT four to identify characteristics of the

142
00:08:57,168 --> 00:09:01,208
original sample and score it. That's that reflection piece that we did earlier on.

143
00:09:01,336 --> 00:09:04,696
So this isn't an integral part of collaborative AI, but just something nice to

144
00:09:04,720 --> 00:09:08,184
do. And then the second pre step was to

145
00:09:08,224 --> 00:09:11,040
ask it to generate a sample as close to a ten out of ten as

146
00:09:11,072 --> 00:09:14,906
possible. And this is where the collaborative AI

147
00:09:15,080 --> 00:09:18,478
process and machinery now starts with step one.

148
00:09:18,526 --> 00:09:22,366
Here, what I did was I input a version one from each LLM

149
00:09:22,430 --> 00:09:26,126
into the other one, asking to evaluate it on a score from one through ten.

150
00:09:26,230 --> 00:09:30,030
So, for example, clot three created a version

151
00:09:30,102 --> 00:09:33,718
on that pre step number two just a second ago, created that version one,

152
00:09:33,806 --> 00:09:37,914
and then I fed that version into chat GPT.

153
00:09:38,374 --> 00:09:41,750
But look at that second part there, where it says other LLM

154
00:09:41,822 --> 00:09:45,348
comma. That's the second part asking to evaluate.

155
00:09:45,476 --> 00:09:49,012
So I didn't just input the version, but I actually asked it to

156
00:09:49,108 --> 00:09:53,020
rate it and score it, much the way a teacher or a professional would

157
00:09:53,052 --> 00:09:56,716
do. And so with that evaluation in hand, then go

158
00:09:56,740 --> 00:10:00,224
to the next step here, which is take the version one evaluation

159
00:10:00,764 --> 00:10:04,596
from an LLM, or from one of the llms, and put it back into the

160
00:10:04,620 --> 00:10:07,732
other LLM. I know this can get a little crisscrossy, but to give you an

161
00:10:07,748 --> 00:10:11,454
example here, the chat GPT's evaluation,

162
00:10:11,834 --> 00:10:15,770
which was on version one of cloud three. I then put it back

163
00:10:15,882 --> 00:10:19,770
into cloud three, but then there's a second part to

164
00:10:19,802 --> 00:10:23,338
step two, which is inputting it into the first LLM

165
00:10:23,386 --> 00:10:26,746
for rewrite. And that brings us to step number three, where I take the rewrite,

166
00:10:26,770 --> 00:10:29,970
which we're now calling version two, and I input it back

167
00:10:30,002 --> 00:10:33,666
into the other LLM for evaluation and scoring.

168
00:10:33,770 --> 00:10:37,074
And so the thing is, step back for a moment. We can think of it

169
00:10:37,114 --> 00:10:41,386
as I gave cloud three an opportunity to

170
00:10:41,450 --> 00:10:44,290
do a rewrite the way we would in a classroom, and then we get feedback

171
00:10:44,322 --> 00:10:48,338
from a teacher. And version two is its rewrite based on this

172
00:10:48,426 --> 00:10:51,746
evaluation and scoring. And then at

173
00:10:51,810 --> 00:10:55,530
that point, was there a difference between version one and

174
00:10:55,562 --> 00:10:59,426
two in terms of score? Now you can carry this process

175
00:10:59,610 --> 00:11:03,186
on and on. You could have a version three, a version

176
00:11:03,210 --> 00:11:06,930
four, version five. But I think at a certain point there are diminishing returns.

177
00:11:07,002 --> 00:11:10,442
And so what we're trying to see here in this little experiment is,

178
00:11:10,538 --> 00:11:14,050
was there an improvement between version one and version two?

179
00:11:14,162 --> 00:11:16,962
So let's see what happens before we get too excited.

180
00:11:17,098 --> 00:11:20,106
We have a step number for it. I think it's very important is to check

181
00:11:20,130 --> 00:11:23,754
for hallucinations by inputting version two into the other LLM.

182
00:11:23,834 --> 00:11:27,276
So essentially, we're using collaborative AI to do

183
00:11:27,370 --> 00:11:31,224
hallucination checks. I know I threw a lot of text and

184
00:11:31,264 --> 00:11:35,200
words at you, but if you pause here for a moment, you can see this

185
00:11:35,392 --> 00:11:39,320
collaborative AI structure use here, spread out here for each

186
00:11:39,352 --> 00:11:42,720
one of the steps. Again, there could be more steps if you wanted

187
00:11:42,752 --> 00:11:47,120
to do more than just two versions. But this is the bare bones,

188
00:11:47,272 --> 00:11:50,840
basic little experiment version that we are doing here. So maybe you're

189
00:11:50,872 --> 00:11:54,136
curious now, what was chat DPT in cloud three's first

190
00:11:54,200 --> 00:11:57,586
version, and how was that scored? I'm happy you asked.

191
00:11:57,650 --> 00:12:01,418
Let's dive in here. The chat GT's first version,

192
00:12:01,466 --> 00:12:05,578
we can see that it gets a seven out of ten based on

193
00:12:05,746 --> 00:12:09,282
criteria of engaging writing, etcetera, which isn't great

194
00:12:09,378 --> 00:12:12,778
given that the one shot prompt also got us a seven

195
00:12:12,826 --> 00:12:16,054
out of ten. But at least it's a starting point.

196
00:12:16,354 --> 00:12:19,134
Hopefully the second version will be better.

197
00:12:19,674 --> 00:12:23,314
And how did Claude three do? Let's see what teacher Chachi Pt

198
00:12:23,354 --> 00:12:26,840
four has to say. They give it. If you look there at the bottom

199
00:12:26,872 --> 00:12:30,008
of the first paragraph, it says, I would rate this version an eight out of

200
00:12:30,056 --> 00:12:33,280
ten. So it did a little bit better. But for

201
00:12:33,312 --> 00:12:36,232
now, this is enough to give you an idea of how this works.

202
00:12:36,328 --> 00:12:39,616
So here's the second step. We feed the evaluations from

203
00:12:39,640 --> 00:12:42,604
one LLM back into the other for a rewrite.

204
00:12:42,984 --> 00:12:46,208
Now, in this case, what I did was I actually

205
00:12:46,376 --> 00:12:50,040
exerted the entire thing, and I did that for a reason. I think it's important

206
00:12:50,112 --> 00:12:53,926
to see just how detailed these evaluations

207
00:12:53,950 --> 00:12:57,358
are. So when the LLM is getting its feedback, you can think of

208
00:12:57,366 --> 00:13:01,286
it as a prompt. Imagine writing a prompt that

209
00:13:01,310 --> 00:13:06,074
is this long and, aha. Even longer.

210
00:13:06,494 --> 00:13:10,486
So that's not necessarily bad thing, given that LLMs often thrive off

211
00:13:10,510 --> 00:13:13,990
of this level of specificity, and there

212
00:13:14,022 --> 00:13:18,462
is a lot of specificity going on, does it actually amount

213
00:13:18,558 --> 00:13:21,382
to anything in version two? Meaning,

214
00:13:21,518 --> 00:13:24,830
will the LLms write a better version of

215
00:13:24,902 --> 00:13:28,542
the chapter? I'm happy you asked, because now we're

216
00:13:28,558 --> 00:13:32,406
at the point where we can ask it, come up with a version that

217
00:13:32,430 --> 00:13:35,694
gets a perfect tense, so we've definitely raised the bar, but there's a

218
00:13:35,774 --> 00:13:39,430
lot of specificity. And that, of course, is what

219
00:13:39,462 --> 00:13:43,950
makes collaborative AI so powerful. How does

220
00:13:44,102 --> 00:13:47,628
this rate we get this is the version two from

221
00:13:47,766 --> 00:13:51,448
Claude, and this is the version two from

222
00:13:51,496 --> 00:13:55,604
ChatGpt. And Drumroll. Their scores

223
00:13:56,064 --> 00:13:59,832
a 9.5 out of ten. So you can see this

224
00:13:59,848 --> 00:14:03,352
is Claude rating chat GPT. So even though chat GPT's first attempt

225
00:14:03,408 --> 00:14:07,176
was a measly baseline seven, this one got close to

226
00:14:07,200 --> 00:14:11,016
a ten, and Claude's version got a solid

227
00:14:11,080 --> 00:14:14,456
nine, if you look at the last or the bottom of the first paragraph.

228
00:14:14,560 --> 00:14:19,208
But in both cases, the version two was much better.

229
00:14:19,376 --> 00:14:23,360
So we can see the third step scores here. Version one,

230
00:14:23,472 --> 00:14:26,944
seven for chachi, BT for claude, eight. Version two,

231
00:14:26,984 --> 00:14:31,752
9.5 and nine. So both market improvements simply

232
00:14:31,808 --> 00:14:35,604
by using just one round of collaborative AI.

233
00:14:36,184 --> 00:14:40,292
Now, you might be asking, well, what about the

234
00:14:40,308 --> 00:14:43,476
human in the loop? In this case me? Did I agree with these versions?

235
00:14:43,580 --> 00:14:47,524
And so, yes, I did read these versions, and I

236
00:14:47,564 --> 00:14:50,876
agreed with them in terms of the improvement. They were

237
00:14:50,940 --> 00:14:53,988
both much better than the first versions.

238
00:14:54,036 --> 00:14:58,244
And in fact, based on the criteria that established, I essentially agreed with these scores.

239
00:14:58,364 --> 00:15:01,924
The reason I hesitate in saying I wholeheartedly agree

240
00:15:01,964 --> 00:15:05,756
with them was I felt at times they were maybe trying to be a little

241
00:15:05,820 --> 00:15:09,244
too engaging, a little bit too fun.

242
00:15:09,364 --> 00:15:13,092
But that wasn't necessarily part of the evaluation criteria. So that's something

243
00:15:13,148 --> 00:15:16,492
that, as the human in the loop, I can ask in a version three

244
00:15:16,588 --> 00:15:20,172
just to tweak that. So it doesn't sound like you're trying to be

245
00:15:20,348 --> 00:15:23,484
someone's pal and trying to be too relatable.

246
00:15:23,644 --> 00:15:27,068
But again, everything besides that was at a much higher level,

247
00:15:27,156 --> 00:15:30,820
making it solid educational content that I think would

248
00:15:30,852 --> 00:15:34,300
really pull in audiences and make learning so much more

249
00:15:34,332 --> 00:15:37,756
fun and enjoyable. Before we go on, though, I want us

250
00:15:37,780 --> 00:15:41,388
to compare here to the baseline scores just one

251
00:15:41,436 --> 00:15:45,252
last time, just to see where we came from, you know, speaking about education content

252
00:15:45,308 --> 00:15:48,308
being more fun and enjoyable. If you're going from a four out of ten,

253
00:15:48,356 --> 00:15:51,812
again, not all education content that's human created is

254
00:15:51,828 --> 00:15:55,624
a four out of ten. But if kind of the average ish

255
00:15:55,924 --> 00:16:00,354
is, then to go from four to nine to 9.5 is a huge

256
00:16:00,654 --> 00:16:04,230
improvement. And the fact that collaborative AI, at least just with this one

257
00:16:04,262 --> 00:16:08,094
round, is something that doesn't take long at all compared to some of these editorial

258
00:16:08,134 --> 00:16:11,558
and content creation processes that involve multiple

259
00:16:11,606 --> 00:16:15,526
SME's, both creators and reviewers, several rounds,

260
00:16:15,590 --> 00:16:19,462
and someone oftentimes overseeing that entire process, you can

261
00:16:19,478 --> 00:16:23,390
see that this can be costly and again, if that

262
00:16:23,422 --> 00:16:26,682
standard is only a four, then we're also getting a huge,

263
00:16:26,738 --> 00:16:30,854
huge bump in quality. Finally, there's that hallucination check.

264
00:16:31,394 --> 00:16:34,754
Both pieces passed. I think, though, it's always

265
00:16:34,834 --> 00:16:38,762
super important to have a human in the loop, especially for something like education content,

266
00:16:38,898 --> 00:16:42,402
where you do not want to have facts that are incorrect no matter

267
00:16:42,458 --> 00:16:45,214
what. Now for the broader implications.

268
00:16:46,074 --> 00:16:49,458
Quality of content and speed is vital.

269
00:16:49,626 --> 00:16:53,040
Collaborative AI can be a huge addition to whatever AI they're

270
00:16:53,072 --> 00:16:56,784
currently using. Now, if they're not using any AI, then they enter AI or

271
00:16:56,824 --> 00:17:00,288
LLMs at a much higher level than they would with one shot,

272
00:17:00,336 --> 00:17:04,448
prompting digital marketing, PR, and corporate communications.

273
00:17:04,576 --> 00:17:08,808
These are just a few here of the areas where high

274
00:17:08,976 --> 00:17:12,360
quality and engaging content that will really help people learn

275
00:17:12,392 --> 00:17:16,325
something. For instance, the case of healthcare communication. If something is dry

276
00:17:16,439 --> 00:17:19,969
and drought, patients aren't likely to remember that, make it engaging

277
00:17:20,001 --> 00:17:23,417
at that nine 9.5 level, then suddenly it's something

278
00:17:23,465 --> 00:17:26,873
that's a lot easier for them to learn and pay attention to, something that's really

279
00:17:26,913 --> 00:17:30,585
important in health. But again, coming back to that hallucination thing,

280
00:17:30,729 --> 00:17:34,729
always a human in the loop for many of these different industries.

281
00:17:34,921 --> 00:17:38,289
So now for the closing thoughts. This is an interesting

282
00:17:38,321 --> 00:17:42,065
one. It's the idea that a 9.5 out of ten for one article

283
00:17:42,209 --> 00:17:45,860
isn't quite the same as a corpus or a body of articles.

284
00:17:46,012 --> 00:17:49,624
Why? Well, imagine that 9.5 that we saw,

285
00:17:49,964 --> 00:17:52,604
and I believe that was the one that Chachi bt outputted.

286
00:17:52,724 --> 00:17:56,772
Imagine that that was the exact same one over

287
00:17:56,828 --> 00:18:00,804
and over again. Now I just use that word imagine twice

288
00:18:00,844 --> 00:18:04,212
in a row, almost as a joke. And the reason that was a

289
00:18:04,228 --> 00:18:07,564
joke is back earlier in the presentation.

290
00:18:07,724 --> 00:18:11,168
It might not have been obvious because I didn't focus on it, but two

291
00:18:11,216 --> 00:18:14,824
of the articles use the word imagine a

292
00:18:14,864 --> 00:18:17,616
world, or imagine something to start off,

293
00:18:17,800 --> 00:18:21,160
and that alone is a little bit confusing.

294
00:18:21,232 --> 00:18:24,584
And it shows that if you had that for, say, 50 articles,

295
00:18:24,744 --> 00:18:28,184
and maybe 20 of them had that phraseology. So correcting for

296
00:18:28,224 --> 00:18:32,216
something like this at scale is something that's important to keep in mind

297
00:18:32,360 --> 00:18:36,040
early on when you are creating these pieces. And again, having that

298
00:18:36,072 --> 00:18:39,840
human in the loop, someone who can really wield the AI and wield something like

299
00:18:39,872 --> 00:18:43,850
collaborative AI, will make it less likely that you're going to see very

300
00:18:43,922 --> 00:18:47,746
common or similar opening lines or really similar writing

301
00:18:47,810 --> 00:18:51,050
throughout. But that said, civil writing is part of AI,

302
00:18:51,082 --> 00:18:54,634
and there's almost this AI speak. After all, we have the GPT

303
00:18:54,714 --> 00:18:58,650
zeros of the world that can identify AI generated language or

304
00:18:58,682 --> 00:19:02,210
text for a reason. It's because there is a certain pattern that

305
00:19:02,242 --> 00:19:05,974
makes it slightly different from human generated text.

306
00:19:06,414 --> 00:19:10,046
One way around this is to actually feed models with high caliber human

307
00:19:10,110 --> 00:19:13,206
text for inspiration. And so if you

308
00:19:13,230 --> 00:19:16,710
want to make it sound even more like a person, more relatable,

309
00:19:16,782 --> 00:19:19,846
perhaps make it so that it's not always saying, imagine a

310
00:19:19,870 --> 00:19:23,294
world where and using some of those other giveaways

311
00:19:23,374 --> 00:19:26,662
of AI speak, then using

312
00:19:26,798 --> 00:19:30,158
high caliber human pros that you want it to model is a good way around

313
00:19:30,206 --> 00:19:34,274
that. These are just a few ideas of improving the

314
00:19:34,314 --> 00:19:37,970
AI using collaborative AI, but in general, lots of

315
00:19:38,002 --> 00:19:41,594
different ways that we can use collaborative AI. Not just coming up with

316
00:19:41,634 --> 00:19:44,906
subsequent versions, one after the other, but maybe even leveraging more than

317
00:19:44,930 --> 00:19:48,594
two models, having three models, having a model judge its

318
00:19:48,634 --> 00:19:52,178
own writing in a different thread and then compare it to what the other LLM

319
00:19:52,226 --> 00:19:55,890
said. See how similar those are. There's so much

320
00:19:55,922 --> 00:19:59,362
you can do here again, and to use AI speak in

321
00:19:59,378 --> 00:20:02,370
a world where the possibilities are limitless,

322
00:20:02,482 --> 00:20:05,314
collaborative AI could be a game changer.

