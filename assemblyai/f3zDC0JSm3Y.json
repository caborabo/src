{"language_code": "en_us", "audio_url": "https://cdn.assemblyai.com/upload/f580a8d5-6b7e-408a-b787-bcfbf5ebdf2e", "punctuate": true, "format_text": true, "dual_channel": null, "webhook_url": null, "webhook_auth_header_name": null, "webhook_auth_header_value": null, "audio_start_from": null, "audio_end_at": null, "word_boost": ["aws", "beyond", "cloud", "cloudnative", "codepipeline", "conf fourty two", "deployments", "ensuring", "jenkins", "marqeta", "prithvish kovelamudi", "software", "software engineer", "traditional"], "boost_param": "high", "filter_profanity": false, "redact_pii": false, "redact_pii_audio": false, "redact_pii_policies": null, "redact_pii_sub": null, "speaker_labels": false, "speakers_expected": null, "content_safety": false, "content_safety_confidence": null, "iab_categories": false, "custom_spelling": null, "disfluencies": false, "sentiment_analysis": false, "auto_chapters": false, "entity_detection": false, "summarization": true, "summary_model": "informative", "summary_type": "bullets_verbose", "auto_highlights": true, "language_detection": false, "speech_threshold": null, "speech_model": null, "id": "319a2c95-0e9b-4d59-b1b2-a7d4c45f284b", "status": "completed", "error": null, "text": "Alright everyone, let's kick off the session with a brief introduction about what AWS code pipeline is and what are the advantages of AWS codepipeline. Some of the key components involved and how a sample pipeline looks like. And then we can jump off to our demo session, we can go to the AWS console, and then we can see how we can create a simple codepipeline. First things first, let's talk a little bit about AWS codepipeline background and why it's advantages to use it and what are some of the stages involved. So the AWS code pipeline is a fully managed, continuous integration and continuous delivery service. So it's a cloud native solution, fully managed by AWS and highly configurable by users. It helps automate release deployment pipelines for fast and reliable application and infrastructure updates. Traditionally, a large number of organizations use third party tools like Jenkins for software development. So code pipeline offers native solutions to those organizations which are already heavily invested in AWS ecosystem. Coming to the advantages of AWS codepipeline, first and foremost is obviously the integration with AWS services. It offers a native out of box integration with many of AWS services like lambda, EC, two, S three and cloud formation. Now, I'm just comparing it with one of the popular third party tool Jenkins throughout this session. So if I were to contrast it with Jenkins, the main difference would be that while the integration with the cloud services is possible, it usually requires third party plugins and additional setup, potentially introducing more points of failure or compatibility issues. Coming to the next crucial aspect is obviously scalability. Since it's part of the AWS suite, it natively scales according to the demands of the deployment pipeline, so there's no need for manual intervention, which in itself kind of like ensuring consistent performance even during peak loads. Jenkins on the other side requires some adjustments, such as like adding agent nodes or reallocating resources, which is both time consuming and resource intensive since we need some dedicated personnel taking care of that. Continuing with the other advantages of AWS code pipeline, we are going to touch upon the maintenance, security, the pricing and long term value. So maintenance wise, since AWS code pipeline is a managed service, AWS handles all the updates, patches and backups. So this ensures that the latest features and security patches are always in place without us having to do much there and us having to not manually intervene there. Jenkins, on the other hand, requires periodic manual updates, backups and patching, which can kind of introduce compatibility issues or security vulnerabilities, which kind of demand regular monitoring and adjustments. Coming to the security aspect of the deployment pipelines. So one of the advantages of using AWS solution here is the comprehensive security model, which we are able to leverage the features like IAM roles, secrets, managers and other fine brained controls like service roles. So all these can be natively tied up to the code pipeline itself, which kind of ensures robust security standards along with your other tools. So on the Jenkins side, if you were to achieve a similar security level, it requires additional configurations, plugins and tools, which in itself can again sometimes introduce more vulnerabilities and unnecessary complexities and the pricing and long term value. Since AWS operates on like a pay as you go model, you only pay for what you use. So this can be cost effective, especially if we have variable workloads. On the Jenkins side, the software itself is open source, but however, maintaining the Jenkins infrastructure, accounting for all the patching and keeping it up to date itself can add up over a long period of time when you consider the time and resources invested into it. So that kind of wraps up on the key advantages of AWS code pipelines. Now we can briefly discuss into the working of code pipeline and then we can jump off to a demo session. So the key components involved in a codepipeline are the conceptually similar to any other deployment tool where you have a source stage. You either have your application artifact or some deployment assets which are going to run and deploy the source code, and then you have a build stage, which is an optional stage, kind of like for compilation and an object generation which is eventually going to be deployed. So the example is AWS code build here, and then you have the deploy stage. It's the main deployment stage where the generated artifact that you supplied or the output of the code build stage is kind of like deployed in this main stage. Again, AWS offers multiple tools that can be plugged into this stage. So code deploy is one such tool that we are going to look at today for the demo. So code deploy ECs blue green deployments are some of these things that can be plugged into this particular stage. So this is how a sample pipeline looks like we are going to look at the demo and get a closer look of it. But the bottom part is what makes up a code pipeline code commit action. And the code repository is being pushed here to an Amazon ECS, the elastic container service, and which is eventually deployed via a code deploy ECS blue green action in this pipeline. So now let's jump on to the AWS console, and then we can see how we can create a simple pipeline. All right, this is the AWS console home. So you have a list of all these tools here. So let's go to the AWS code pipeline. So on the left side if you see it shows like multiple substages that are kind of associated with the code pipeline, like the source, the build stage, and the deploy stage. So it gives us the ability to configure those stages using these sources here. So the first thing like we discussed is setting up the source repository or the deployment artifact. So I already have an S three bucket that I created and I have an object there. So we'll be using that. For the purpose of this demo, we are going to skip the build stage since we essentially don't have any compilation or object generation, but the code deploy stage is necessary stage. So let's spend a couple of minutes on the building a code deploy stage, which then we'll later plug into the code pipeline. So for the code deploy. So we need to create an application configuration. So let's go to the applications. So right now we don't have any applications, so we can just create a sample application, say Java application and the compute platform. As an EC two, the application configuration is created and now within the application we need to create a deployment group. So the deployment group essentially kind of like configures which all EC two instances you want to deploy. So that is determined using this deployment group. You can add more settings like how many EC two instances you want to deploy at a time and what would like a failure scenario look like. Those are like more advanced settings, but you can explore this on the code deploy resource page. Let's enter a sample deployments group. So the service role essentially needs to have the code deploy access, which I already created one, but you can fine tune based upon the level of security you want for your deployments codepipeline. And all these are environment configurations. For filtering the EC two instances related to the deployment group, it's often done using the tag associated with the EC two instance, for example, like I want to deploy to all the prod hosts, like Env is prod, so it filters out all those such instances and it creates a deployment group. And at the end of the day the code pipeline deploys to that. So all these settings, you can leave the default ones if you don't have any necessary changes. And then we create the deployment group. All right, the deployment group is created for a sample application that we have now we can go and create the code pipeline. So right now we don't have anything created in this section. So we are going to create a brand new code pipeline. Say sample pipeline again, you can leave the default options here. It's going to create a service role by default. If you don't give anything, it looks like the service role already exists. Let's see if we can delete this so that there's no conflict. So if you go to the roles. So this is the IAM page where you have all your service roles and the policies. So I'm just going to remove this for now. It's probably there from a previous time. So we are just deleting an existing role. All right, we deleted that. Now I believe we should be able to create a sample pipeline. And the source is going to be s three. And the bucket is going to be this. Just need to enter the object inside this bucket. We can quickly take a look what's the object inside there. If you go to the s three, and if you pull up the s three bucket, see that there's an object. So take this and plug it into the object key here and then build. We are going to skip. And then the deploy, we just configured the code deploy right. So we are just going to plug in all those. We just created the Java application and the deployment group and that's pretty much it. So once we hit the create pipeline, it's going to take a couple of minutes here and voila, the pipeline has been created. It triggered the source and this is how the pipeline looks. So if you have a valid source artifact, it kind of triggers that and then based upon the deploy configuration, goes and deploys there. So this is how a sample pipeline looks. The scope for this article next would be for the session, would next be like exploring more on the code deploy side and what is needed there.", "words": [], "utterances": null, "confidence": 0.946030921739135, "audio_duration": 810.0, "webhook_status_code": null, "webhook_auth": false, "summary": "- AWS code pipeline is a fully managed, continuous integration and continuous delivery service. It offers a native out of box integration with many of AWS services. Since it's part of the AWS suite, it natively scales according to the demands of the deployment pipeline.\n- Since AWS code pipeline is a managed service, AWS handles all the updates, patches and backups. Jenkins, on the other hand, requires periodic manual updates, backups and patching. Since AWS operates on like a pay as you go model, you only pay for what you use.\n- The key components involved in a codepipeline are the conceptually similar to any other deployment tool. You have a source stage, a build stage, and the deploy stage. AWS offers multiple tools that can be plugged into this stage. Let's see how we can create a simple pipeline.\n- So for the code deploy. So we need to create an application configuration. And then we create the deployment group. The deployment group essentially kind of like configures which all EC two instances you want to deploy. And at the end of the day the code pipeline deploys to that.\n- All right, the deployment group is created for a sample application. Now we can go and create the code pipeline. The scope for this article next would be for the session, would next be like exploring more on the code deploy side and what is needed there.", "auto_highlights_result": {"status": "success", "results": [{"count": 5, "rank": 0.12, "text": "AWS code pipeline", "timestamps": [{"start": 30156, "end": 31394}, {"start": 67912, "end": 69182}, {"start": 195104, "end": 196950}, {"start": 206948, "end": 208266}, {"start": 469192, "end": 470850}]}, {"count": 7, "rank": 0.1, "text": "AWS code", "timestamps": [{"start": 30156, "end": 30934}, {"start": 67912, "end": 68594}, {"start": 195104, "end": 196074}, {"start": 206948, "end": 207774}, {"start": 340652, "end": 341414}, {"start": 383052, "end": 384022}, {"start": 469192, "end": 469954}]}, {"count": 14, "rank": 0.1, "text": "code pipeline", "timestamps": [{"start": 30722, "end": 31394}, {"start": 68382, "end": 69182}, {"start": 97792, "end": 98454}, {"start": 195846, "end": 196950}, {"start": 207562, "end": 208266}, {"start": 274216, "end": 275146}, {"start": 346080, "end": 347290}, {"start": 430828, "end": 431910}, {"start": 469742, "end": 470850}, {"start": 478764, "end": 479794}, {"start": 532172, "end": 533270}, {"start": 645536, "end": 646214}, {"start": 666648, "end": 667730}, {"start": 673272, "end": 674526}]}, {"count": 1, "rank": 0.1, "text": "AWS code build", "timestamps": [{"start": 383052, "end": 384342}]}, {"count": 10, "rank": 0.09, "text": "code deploy", "timestamps": [{"start": 406436, "end": 407290}, {"start": 412708, "end": 413770}, {"start": 444272, "end": 445238}, {"start": 520968, "end": 521534}, {"start": 528568, "end": 529246}, {"start": 534748, "end": 535750}, {"start": 593952, "end": 595130}, {"start": 608388, "end": 609034}, {"start": 757428, "end": 758510}, {"start": 807028, "end": 807626}]}, {"count": 2, "rank": 0.09, "text": "deployment pipelines", "timestamps": [{"start": 83202, "end": 84418}, {"start": 250484, "end": 251706}]}, {"count": 2, "rank": 0.09, "text": "AWS services", "timestamps": [{"start": 114056, "end": 115220}, {"start": 120168, "end": 121202}]}, {"count": 5, "rank": 0.08, "text": "sample pipeline", "timestamps": [{"start": 39708, "end": 40594}, {"start": 421448, "end": 422334}, {"start": 676090, "end": 677510}, {"start": 721750, "end": 723650}, {"start": 798428, "end": 799314}]}, {"count": 1, "rank": 0.08, "text": "AWS solution", "timestamps": [{"start": 255700, "end": 257082}]}, {"count": 3, "rank": 0.08, "text": "AWS codepipeline", "timestamps": [{"start": 34508, "end": 36002}, {"start": 58724, "end": 60026}, {"start": 108692, "end": 110510}]}, {"count": 1, "rank": 0.07, "text": "AWS ecosystem", "timestamps": [{"start": 104196, "end": 105710}]}, {"count": 1, "rank": 0.07, "text": "AWS codepipeline background", "timestamps": [{"start": 58724, "end": 60714}]}, {"count": 2, "rank": 0.06, "text": "service roles", "timestamps": [{"start": 268920, "end": 270130}, {"start": 703412, "end": 704510}]}, {"count": 1, "rank": 0.06, "text": "ECs blue green deployments", "timestamps": [{"start": 413930, "end": 415702}]}, {"count": 1, "rank": 0.06, "text": "brand new code pipeline", "timestamps": [{"start": 672808, "end": 674526}]}]}, "content_safety_labels": null, "iab_categories_result": null, "chapters": null, "sentiment_analysis_results": null, "entities": null}