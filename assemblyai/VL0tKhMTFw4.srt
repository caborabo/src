1
00:00:20,890 --> 00:00:24,574
Hi everyone, and let's talk about unlocking the power of

2
00:00:24,612 --> 00:00:28,200
ll them and building a huggingface agent.

3
00:00:29,050 --> 00:00:32,594
So first of all, as you might know, a huggingface

4
00:00:32,642 --> 00:00:36,502
phase transformers is a popular state of the art

5
00:00:36,636 --> 00:00:39,382
machine learning library for Pytorch,

6
00:00:39,446 --> 00:00:43,146
Tensorflow and Jax. And it provides a

7
00:00:43,168 --> 00:00:46,550
thousand of pretraining models to performed tasks

8
00:00:46,630 --> 00:00:49,946
on different modalities such as text,

9
00:00:50,128 --> 00:00:52,030
ovision and audio.

10
00:00:52,770 --> 00:00:57,230
And it was just a quick introduction,

11
00:00:57,810 --> 00:01:00,640
you might be already familiar with it.

12
00:01:01,330 --> 00:01:05,522
And let's go to our agenda. So today

13
00:01:05,656 --> 00:01:09,714
we're going to talk about what are agents, what are

14
00:01:09,752 --> 00:01:13,374
tools, how to set up and initialize

15
00:01:13,422 --> 00:01:16,770
the agent, how to use a predefined

16
00:01:16,850 --> 00:01:20,930
tools such as translation, image captioning,

17
00:01:21,090 --> 00:01:24,370
text to speech, what are other tools?

18
00:01:24,450 --> 00:01:27,030
Predefined, curated tools exist.

19
00:01:27,470 --> 00:01:30,858
And very interesting, how can we create

20
00:01:30,944 --> 00:01:34,426
our custom tool? So let's get started.

21
00:01:34,528 --> 00:01:38,620
Right. First, what are agents?

22
00:01:39,550 --> 00:01:43,502
An agent, let's just think

23
00:01:43,556 --> 00:01:47,262
about a general term, an agent. You might think

24
00:01:47,316 --> 00:01:50,622
about a person who you hire for

25
00:01:50,676 --> 00:01:54,260
performing different tasks. So for example,

26
00:01:55,110 --> 00:01:59,470
an agents can assist you in writing

27
00:01:59,550 --> 00:02:02,914
some publications or calling someone

28
00:02:03,112 --> 00:02:06,454
or publishing some post on

29
00:02:06,492 --> 00:02:09,798
social medias. So the general

30
00:02:09,884 --> 00:02:13,782
idea is that an agent is an

31
00:02:13,916 --> 00:02:17,490
assistant to simplify your life,

32
00:02:17,580 --> 00:02:22,694
right? And if we go back to the huggingface

33
00:02:22,742 --> 00:02:26,426
phase. Idea of agent. An agent

34
00:02:26,528 --> 00:02:30,910
is a large language model or LLM,

35
00:02:31,330 --> 00:02:35,360
and we are prompting it. So we are asking it to perform

36
00:02:35,730 --> 00:02:39,230
a specific set of tasks

37
00:02:39,810 --> 00:02:43,806
so the agents can be equipped by different tools.

38
00:02:43,918 --> 00:02:47,746
And we will talk just in a minute about what

39
00:02:47,848 --> 00:02:52,098
different tools are and why.

40
00:02:52,264 --> 00:02:56,082
Is it possible lecture language

41
00:02:56,146 --> 00:02:59,590
model can generate a small piece of

42
00:02:59,660 --> 00:03:02,822
text, a small piece of code in

43
00:03:02,876 --> 00:03:05,160
very good and efficient way.

44
00:03:06,010 --> 00:03:09,622
Maybe if we ask it to generate a whole

45
00:03:09,676 --> 00:03:12,778
script, it might be not so good at it,

46
00:03:12,944 --> 00:03:17,142
but generating like three lines,

47
00:03:17,206 --> 00:03:20,720
four lines of code, it can deal with it.

48
00:03:21,090 --> 00:03:24,814
If we leverage this possibility to generate a small piece

49
00:03:24,852 --> 00:03:29,306
of code, small piece of text, and equip

50
00:03:29,338 --> 00:03:32,506
the agents with different tools, we can use

51
00:03:32,548 --> 00:03:35,986
it, power how you will see it. And now

52
00:03:36,008 --> 00:03:39,922
let's talk about what are tools. So if you

53
00:03:39,976 --> 00:03:43,698
have a toolbox in your garage, you might have something

54
00:03:43,784 --> 00:03:47,654
like this and this and this and

55
00:03:47,692 --> 00:03:51,750
hammers. And all these tools

56
00:03:53,450 --> 00:03:57,538
are for specific tasks. Each tool does

57
00:03:57,644 --> 00:04:01,766
specific job. And you might know I'm

58
00:04:01,798 --> 00:04:05,642
not very good at it, but you might know how to

59
00:04:05,696 --> 00:04:08,970
use each tool for which task.

60
00:04:09,970 --> 00:04:14,270
So the same idea if we think about tools

61
00:04:16,130 --> 00:04:19,630
for llms. So a tool

62
00:04:19,780 --> 00:04:23,714
is something simple which

63
00:04:23,832 --> 00:04:27,474
represents a single function with

64
00:04:27,512 --> 00:04:31,282
a name and a description, right? Because each tool has its

65
00:04:31,336 --> 00:04:35,162
own name and we have a description

66
00:04:35,326 --> 00:04:39,414
of this tool, how can we use it? And each tool,

67
00:04:39,612 --> 00:04:43,718
each function is dedicated to one

68
00:04:43,884 --> 00:04:47,834
very simple task. And if we put

69
00:04:47,872 --> 00:04:51,750
this together, this picture is from the official

70
00:04:51,830 --> 00:04:55,322
hanging face agents tutorial. We might

71
00:04:55,376 --> 00:04:59,242
have the following structure. So we have

72
00:04:59,296 --> 00:05:02,846
an extraction which we

73
00:05:02,868 --> 00:05:06,478
can tasks or what we can prompt the agent

74
00:05:06,564 --> 00:05:10,474
for and it is translated to the prompt.

75
00:05:10,602 --> 00:05:14,146
So in this particular example, we ask the agents to

76
00:05:14,168 --> 00:05:17,966
read out loud the content of the image.

77
00:05:18,158 --> 00:05:22,306
So if we think in concept of it,

78
00:05:22,328 --> 00:05:26,482
might want to first understand what's on the image.

79
00:05:26,626 --> 00:05:30,182
And then to generate text is

80
00:05:30,236 --> 00:05:34,262
the first step. And the second step is to read out loud this

81
00:05:34,316 --> 00:05:37,990
text. So this creates a prompt

82
00:05:38,830 --> 00:05:42,150
and our agents literally language

83
00:05:42,230 --> 00:05:46,550
model understand. It has a toolbox

84
00:05:46,710 --> 00:05:50,210
right here, different tools,

85
00:05:50,390 --> 00:05:55,310
the toolbox and the agent understands

86
00:05:55,810 --> 00:06:00,058
that it can use image captioner to caption the image

87
00:06:00,234 --> 00:06:03,330
and the text to speech tools to read

88
00:06:03,400 --> 00:06:07,342
the text out loud. And it generates

89
00:06:07,406 --> 00:06:11,010
a code run a Python interpreter,

90
00:06:11,990 --> 00:06:14,930
a text being voiced.

91
00:06:15,450 --> 00:06:18,886
So this is how it works. But if

92
00:06:18,908 --> 00:06:22,742
we think in general, why should we care why it

93
00:06:22,796 --> 00:06:26,822
might be interesting for us. I would

94
00:06:26,876 --> 00:06:30,470
say that this is a great interaction

95
00:06:30,550 --> 00:06:35,546
experience, so we

96
00:06:35,568 --> 00:06:39,178
don't need to even know how to code. We can

97
00:06:39,264 --> 00:06:43,050
leverage the conception prompting versus

98
00:06:43,130 --> 00:06:47,134
coding so we can prompt and have the code out of our

99
00:06:47,172 --> 00:06:50,958
prompt. And this is a great

100
00:06:51,044 --> 00:06:54,740
instrument to have a

101
00:06:55,590 --> 00:06:59,234
chained output. So if you think about it, we can

102
00:06:59,272 --> 00:07:02,290
for example generate an image,

103
00:07:02,630 --> 00:07:06,626
then add some elements to the image,

104
00:07:06,818 --> 00:07:10,834
then maybe resize the image or generate

105
00:07:10,882 --> 00:07:14,774
image captioner, translate it, get the

106
00:07:14,812 --> 00:07:19,354
voicing of it. Because there are very different

107
00:07:19,472 --> 00:07:23,750
tools and we can add our custom tools,

108
00:07:23,910 --> 00:07:27,834
it is very flexible and we will learn

109
00:07:28,032 --> 00:07:30,970
how to add our custom tools.

110
00:07:31,470 --> 00:07:34,634
And now let's talk about, let's go a little

111
00:07:34,672 --> 00:07:38,682
bit hands on and learn how to set up and initialize

112
00:07:38,746 --> 00:07:42,062
the agent. As a prerequisite, we need

113
00:07:42,116 --> 00:07:45,726
a huggingface phase token. And depending

114
00:07:45,758 --> 00:07:48,914
on the agent we are going to use,

115
00:07:49,112 --> 00:07:52,900
in our case we're going to use OpenAI agent.

116
00:07:53,270 --> 00:07:57,094
We need an OpenAI API key and

117
00:07:57,132 --> 00:08:00,786
we need a bit of code. So let's

118
00:08:00,818 --> 00:08:04,438
see how it looks like and let me

119
00:08:04,524 --> 00:08:08,220
open the collab here

120
00:08:09,070 --> 00:08:13,242
and run a simple setup. I use the

121
00:08:13,296 --> 00:08:17,340
latest version of transformers here and

122
00:08:19,150 --> 00:08:23,600
I will need to pass my huggingface phase token which

123
00:08:24,930 --> 00:08:28,238
you can have it for free. You can go to

124
00:08:28,324 --> 00:08:31,950
huggingface phase hub and you can create

125
00:08:32,020 --> 00:08:35,700
your token there, read or write token. For this particular

126
00:08:36,550 --> 00:08:41,460
activity we can have read token and

127
00:08:42,150 --> 00:08:45,542
while it's running, I should also add

128
00:08:45,596 --> 00:08:49,442
that I will upload this code to GitHub

129
00:08:49,506 --> 00:08:53,046
repository and you will have this notebook in

130
00:08:53,068 --> 00:08:56,518
a Jupyter notebook format and

131
00:08:56,684 --> 00:08:59,260
you can use it and play with it.

132
00:08:59,790 --> 00:09:03,322
Let me just grab my token and tasks

133
00:09:03,376 --> 00:09:08,154
it here. I'm logged in and

134
00:09:08,272 --> 00:09:12,666
I will pip install OpenAI library

135
00:09:12,778 --> 00:09:16,480
here and I'm going to the

136
00:09:18,530 --> 00:09:20,910
agents initialization.

137
00:09:22,390 --> 00:09:26,740
I will use OpenAI agent

138
00:09:27,190 --> 00:09:30,580
and I need my OpenAI token here,

139
00:09:31,350 --> 00:09:34,878
let me grab it, let me tasks

140
00:09:34,984 --> 00:09:38,120
it. Voila, we have it.

141
00:09:38,490 --> 00:09:43,094
Now let's go back to the presentation and

142
00:09:43,212 --> 00:09:46,482
see what are predefined tools.

143
00:09:46,626 --> 00:09:50,746
The first tool we are going to look at is

144
00:09:50,848 --> 00:09:55,260
image capturing tool. It's very simple so

145
00:09:56,670 --> 00:09:59,922
we can have pretty much everything as an image

146
00:10:00,086 --> 00:10:03,914
and we can generate a caption

147
00:10:03,962 --> 00:10:08,222
for it. So as you can see we

148
00:10:08,276 --> 00:10:12,320
just call in the comment as agent

149
00:10:12,710 --> 00:10:17,170
run and a natural language prompt

150
00:10:17,750 --> 00:10:21,330
and we are passing an image as a

151
00:10:21,400 --> 00:10:25,102
variable here. Let's go and

152
00:10:25,176 --> 00:10:28,280
look how it would look like.

153
00:10:28,970 --> 00:10:33,126
So first I will just quickly choose

154
00:10:33,228 --> 00:10:36,838
a picture and I will use

155
00:10:36,924 --> 00:10:41,370
foot some foot as a picture and

156
00:10:41,520 --> 00:10:44,906
I will generate a description for

157
00:10:44,928 --> 00:10:48,714
my picture in English. And as

158
00:10:48,752 --> 00:10:53,294
you can see here, while agent is running my

159
00:10:53,412 --> 00:10:56,910
code, it is generating an explanation.

160
00:10:57,410 --> 00:11:00,542
So you can see the explanation. I will

161
00:11:00,596 --> 00:11:03,842
use the following tool and it chooses the

162
00:11:03,896 --> 00:11:08,260
image captioner tool and then it generates code

163
00:11:09,350 --> 00:11:13,682
and then it runs code and we can see

164
00:11:13,816 --> 00:11:17,762
an output here, a plate of food with eggs,

165
00:11:17,826 --> 00:11:21,814
bread and a cup of coffee, which is

166
00:11:21,852 --> 00:11:25,750
true. And now let's go back to the presentation

167
00:11:26,730 --> 00:11:30,694
and let's have a look at translation and audio

168
00:11:30,742 --> 00:11:33,882
generation tools. So it can

169
00:11:33,936 --> 00:11:37,814
translate to and from over 80

170
00:11:37,862 --> 00:11:41,646
languages and it can voice the

171
00:11:41,668 --> 00:11:46,014
text easily. So I'm not going to spend

172
00:11:46,212 --> 00:11:50,240
much time on this slide, I'm going to show it to you.

173
00:11:51,330 --> 00:11:55,330
So a little side note about the translation.

174
00:11:56,790 --> 00:12:00,562
Under the hood, the translation is being curated by

175
00:12:00,616 --> 00:12:04,718
the meta. No language left behind

176
00:12:04,904 --> 00:12:07,318
an LLB model.

177
00:12:07,484 --> 00:12:10,680
And they claim that they have over

178
00:12:12,250 --> 00:12:15,830
approximate number of 200 of languages.

179
00:12:16,250 --> 00:12:19,850
But when I checked last time, not all

180
00:12:19,920 --> 00:12:24,074
of languages were available for translation. Some of them,

181
00:12:24,192 --> 00:12:27,322
at least with agents, some of them were

182
00:12:27,376 --> 00:12:31,006
generating errors. So I just passed a

183
00:12:31,108 --> 00:12:35,086
list of languages that worked for me and if you

184
00:12:35,108 --> 00:12:38,910
want to use a specific language you might want to check

185
00:12:38,980 --> 00:12:39,920
it before.

186
00:12:41,970 --> 00:12:45,682
But in my list you can see that there are

187
00:12:45,816 --> 00:12:49,234
approximately 80, 80 of languages, which is

188
00:12:49,272 --> 00:12:52,340
also, I believe that it is also good.

189
00:12:53,030 --> 00:12:55,910
So going back to our tools,

190
00:12:57,850 --> 00:13:02,230
we can run it together, so we can translate

191
00:13:02,570 --> 00:13:06,438
text and read it out loud just in one go,

192
00:13:06,604 --> 00:13:10,634
or we can run it separately. So first let's run it

193
00:13:10,672 --> 00:13:13,900
together just in one go.

194
00:13:14,590 --> 00:13:18,538
And you can see again, you can see an explanation, you can see

195
00:13:18,624 --> 00:13:21,360
a code generated by the agent.

196
00:13:21,890 --> 00:13:25,486
And you can see

197
00:13:25,588 --> 00:13:29,520
what's happening under the hood. And also

198
00:13:30,130 --> 00:13:33,598
if you want to build a chain

199
00:13:33,694 --> 00:13:37,074
of inputs, outputs. Don't forget to

200
00:13:37,112 --> 00:13:40,334
save your outputs as a variable

201
00:13:40,462 --> 00:13:43,682
so you can hand it as an input to next

202
00:13:43,816 --> 00:13:47,778
comment. And we can see the translated

203
00:13:47,954 --> 00:13:51,654
text here. I'm not going to read

204
00:13:51,692 --> 00:13:55,670
it out loud because it is in Spanish.

205
00:13:56,010 --> 00:13:59,718
Yes, but I have a tool that can read it out loud.

206
00:13:59,814 --> 00:14:02,860
And let's hear, how does it sound?

207
00:14:03,470 --> 00:14:07,850
Unplodo de kameta con huevos paniunataza de cafa.

208
00:14:09,390 --> 00:14:12,490
I'm not very proficient in Spanish,

209
00:14:12,570 --> 00:14:16,874
but to my mind it doesn't sound like Spanish.

210
00:14:17,002 --> 00:14:20,894
It sounds like an english version of

211
00:14:20,932 --> 00:14:22,800
Spanish or something like this.

212
00:14:23,830 --> 00:14:27,634
So maybe we can try to have it

213
00:14:27,672 --> 00:14:31,540
separately. So first doing translation and then doing

214
00:14:32,390 --> 00:14:36,054
voicing. So I will try to have my

215
00:14:36,092 --> 00:14:39,240
translated text as a variable here.

216
00:14:40,010 --> 00:14:42,790
And I'm trying to have audio.

217
00:14:43,450 --> 00:14:47,058
And let's try Plato de Komeda

218
00:14:47,074 --> 00:14:49,990
conjuevos panionitaza de cafa.

219
00:14:50,830 --> 00:14:54,826
No, I believe it's not very Spanish, but we

220
00:14:54,848 --> 00:14:59,402
will see what can we do here? And I

221
00:14:59,456 --> 00:15:03,722
promised you that we are going to talk about other predefined

222
00:15:03,866 --> 00:15:07,482
created set of tools. And Hagenphase

223
00:15:07,546 --> 00:15:12,010
provides you with several

224
00:15:12,090 --> 00:15:16,462
tools based on transformers, based on transformers

225
00:15:16,526 --> 00:15:20,034
models. And we can have

226
00:15:20,232 --> 00:15:23,554
different tools. Let's take

227
00:15:23,592 --> 00:15:27,682
a look at them. So the first it's document

228
00:15:27,746 --> 00:15:31,846
question answering tool. You can have a document in

229
00:15:31,868 --> 00:15:35,494
an image format and you can ask a question based on

230
00:15:35,532 --> 00:15:37,830
it. And under the hood,

231
00:15:39,630 --> 00:15:43,690
the transformers model which is used for it is donut.

232
00:15:44,350 --> 00:15:47,958
The next is text question answering.

233
00:15:48,054 --> 00:15:51,374
So you can have a long text paste in

234
00:15:51,412 --> 00:15:57,102
a text format, in a string format. And you

235
00:15:57,156 --> 00:16:01,870
can ask the question based on it. And the transformers

236
00:16:02,550 --> 00:16:06,098
model used for this task is

237
00:16:06,184 --> 00:16:11,314
flinty five. The next is

238
00:16:11,432 --> 00:16:14,722
image question answering. So you can pass an

239
00:16:14,776 --> 00:16:19,010
image and ask a question what's on this image?

240
00:16:19,170 --> 00:16:22,934
Or specific question on the

241
00:16:22,972 --> 00:16:26,102
image itself. And the

242
00:16:26,236 --> 00:16:29,526
transformer model operating by

243
00:16:29,548 --> 00:16:32,630
the hood is build.

244
00:16:33,950 --> 00:16:37,642
It's just for

245
00:16:37,696 --> 00:16:41,200
understanding what's going on. Next.

246
00:16:41,570 --> 00:16:44,510
We can have an image segmentation.

247
00:16:47,810 --> 00:16:50,990
We can output the segmentation tasks

248
00:16:52,210 --> 00:16:55,986
of the image. For example,

249
00:16:56,088 --> 00:16:59,810
detect animals or detect

250
00:17:00,470 --> 00:17:04,226
nature on the image. And the model

251
00:17:04,328 --> 00:17:06,950
is clip sag.

252
00:17:07,690 --> 00:17:11,510
Also we can have. In our example we had text

253
00:17:11,580 --> 00:17:14,950
to speech and we can have a reverse task.

254
00:17:16,410 --> 00:17:20,186
We can have speech and then translate it to text.

255
00:17:20,368 --> 00:17:24,362
And this model is transformer model is

256
00:17:24,416 --> 00:17:28,294
whisper. And we also can have a zero shoot

257
00:17:28,342 --> 00:17:32,510
text classification. If we don't have many labels

258
00:17:34,130 --> 00:17:37,902
for classification task, we can provide a text,

259
00:17:38,036 --> 00:17:41,534
we can provide a list of labels and

260
00:17:41,652 --> 00:17:45,202
try Bart to classify this

261
00:17:45,256 --> 00:17:49,490
text. And pretty straightforward,

262
00:17:50,070 --> 00:17:53,842
we can have text summarization so we can pass

263
00:17:53,896 --> 00:17:57,298
along text and have its summary

264
00:17:57,394 --> 00:18:00,066
in just two or three sentences.

265
00:18:00,258 --> 00:18:03,990
And this task is also apparated by Bart.

266
00:18:04,650 --> 00:18:08,522
And also we can have tools that are not based

267
00:18:08,576 --> 00:18:12,342
on transformers. That's why they are called transformers

268
00:18:12,406 --> 00:18:16,422
agnostic, because they can use different models

269
00:18:16,566 --> 00:18:20,250
or just ordinary Python script

270
00:18:20,930 --> 00:18:25,662
we might use in this text downloader tool.

271
00:18:25,796 --> 00:18:29,822
So we just can provide an URL and

272
00:18:29,876 --> 00:18:33,826
download the text. Advanced model is used

273
00:18:34,008 --> 00:18:38,082
under the hood. Yeah, just a python script which is going there

274
00:18:38,136 --> 00:18:42,130
and downloading. Pretty simple. And also

275
00:18:42,200 --> 00:18:46,050
we can have different flowers of stable diffusion

276
00:18:46,210 --> 00:18:49,926
to have text to image generation or

277
00:18:50,108 --> 00:18:53,302
image transformation like here,

278
00:18:53,436 --> 00:18:57,554
you can see an example. First we create an

279
00:18:57,612 --> 00:19:01,114
image and then we understood that we

280
00:19:01,152 --> 00:19:04,778
might want to have this image changed a

281
00:19:04,784 --> 00:19:08,410
little bit. So we ask agents to add

282
00:19:08,480 --> 00:19:10,990
a rock on this image.

283
00:19:11,490 --> 00:19:15,230
And also we can have a text

284
00:19:15,300 --> 00:19:18,814
to video generation which is also a flavor of

285
00:19:18,852 --> 00:19:22,442
stable diffusion here. So yes,

286
00:19:22,596 --> 00:19:25,842
and we can also, as I already said,

287
00:19:25,896 --> 00:19:29,954
we can also create a custom tool. And if we

288
00:19:29,992 --> 00:19:33,090
think about agent as an octopus,

289
00:19:33,910 --> 00:19:36,654
I believe it legs, yes,

290
00:19:36,792 --> 00:19:40,726
we can have an infinite octopus and we

291
00:19:40,748 --> 00:19:44,150
can add legs to this octopus.

292
00:19:44,570 --> 00:19:48,026
And these legs are our custom tools, so we

293
00:19:48,048 --> 00:19:50,998
can extend the possibility,

294
00:19:51,094 --> 00:19:54,698
the power of our agent. And also we can

295
00:19:54,864 --> 00:19:59,020
push this leg to the hub so other

296
00:19:59,630 --> 00:20:03,726
members can benefit from our

297
00:20:03,828 --> 00:20:07,790
interesting tool. And let's see

298
00:20:07,860 --> 00:20:11,840
how can it to.

299
00:20:12,210 --> 00:20:16,178
As you might remember, our voicing tool was not

300
00:20:16,264 --> 00:20:20,034
very powerful. And I'm going to

301
00:20:20,072 --> 00:20:23,860
use a Google text to speech library to

302
00:20:25,370 --> 00:20:28,898
generate audio based on text target

303
00:20:28,994 --> 00:20:31,190
tailored to specific language.

304
00:20:31,770 --> 00:20:36,950
And I already installed this library here and

305
00:20:37,020 --> 00:20:40,906
I'm importing it and I have a simple

306
00:20:41,008 --> 00:20:44,634
function using this library. I am passing a

307
00:20:44,672 --> 00:20:48,570
text as a variable here

308
00:20:48,720 --> 00:20:51,790
and also I'm passing a language as a second

309
00:20:51,860 --> 00:20:55,834
variable here. And I have an audio as the output.

310
00:20:55,962 --> 00:21:00,382
Pretty straightforward. And how

311
00:21:00,436 --> 00:21:04,242
can we wrap this function? How can we create

312
00:21:04,296 --> 00:21:09,922
a tool based on this function? So we will import class

313
00:21:10,056 --> 00:21:14,034
named tools from transformers and we

314
00:21:14,072 --> 00:21:17,350
can inherit it. And we can inherit

315
00:21:18,730 --> 00:21:22,920
our tool class from this tool parent class,

316
00:21:23,770 --> 00:21:27,222
how it will look like. So we are

317
00:21:27,276 --> 00:21:31,498
creating this class and we are passing a

318
00:21:31,584 --> 00:21:34,460
description name a name here.

319
00:21:35,870 --> 00:21:39,318
What's the name of tool like image captioner?

320
00:21:39,494 --> 00:21:45,198
Here we have Google voice in multiple languages which

321
00:21:45,284 --> 00:21:49,150
describes how it

322
00:21:49,220 --> 00:21:53,070
would work. But we have a description

323
00:21:54,530 --> 00:21:58,574
for agent to understand what

324
00:21:58,612 --> 00:22:02,414
this tool is for. So this is the name, this is

325
00:22:02,452 --> 00:22:05,782
a description, for example like hammer is

326
00:22:05,836 --> 00:22:09,334
for nails. And this is tools that

327
00:22:09,372 --> 00:22:13,602
can voice a word or a phrase in a given language

328
00:22:13,746 --> 00:22:17,758
and what does it take and what does it output.

329
00:22:17,954 --> 00:22:21,322
And here we should

330
00:22:21,376 --> 00:22:25,846
have description on our inputs format

331
00:22:26,038 --> 00:22:29,462
and description on our output format

332
00:22:29,606 --> 00:22:33,534
and we should have a call

333
00:22:33,732 --> 00:22:36,862
our function itself, how it

334
00:22:36,916 --> 00:22:41,294
would operate and we already can try it.

335
00:22:41,492 --> 00:22:44,910
So if I pass a language,

336
00:22:46,130 --> 00:22:49,174
yes, comida, comida.

337
00:22:49,322 --> 00:22:53,410
I believe it's foot in Spanish and it already

338
00:22:53,560 --> 00:22:57,126
sounds like a Spanish. And as you

339
00:22:57,148 --> 00:23:01,446
might notice, I'm not using Spanish as a

340
00:23:01,628 --> 00:23:05,030
language language name

341
00:23:05,100 --> 00:23:08,662
here, I'm using a language code and that's why

342
00:23:08,716 --> 00:23:12,582
I will be using len codes library to translate

343
00:23:12,646 --> 00:23:16,922
it from the human natural name

344
00:23:16,976 --> 00:23:19,500
of language to the language code.

345
00:23:20,370 --> 00:23:23,230
But first let's initiate,

346
00:23:24,530 --> 00:23:28,382
let's expand our octopus. Let's add this

347
00:23:28,436 --> 00:23:33,338
tool to our agent. So I'm going to reinitialize

348
00:23:33,434 --> 00:23:36,542
restartment agent and I

349
00:23:36,596 --> 00:23:40,080
will need OpenAI key once again

350
00:23:41,250 --> 00:23:45,202
and I will use len codes to translate

351
00:23:45,386 --> 00:23:49,330
to translate it from Spanish

352
00:23:49,410 --> 00:23:53,570
to sorry, target language

353
00:23:53,650 --> 00:23:57,160
will be Spanish here.

354
00:23:57,870 --> 00:24:01,078
Yes, it translates Spanish

355
00:24:01,254 --> 00:24:05,862
or some other language tool to language

356
00:24:05,926 --> 00:24:09,500
code compatible with our tool.

357
00:24:10,110 --> 00:24:14,320
And I am running, I'm going to run

358
00:24:14,930 --> 00:24:18,234
this comment as a prompt.

359
00:24:18,362 --> 00:24:23,286
Yeah, I'm going to give a prompt to our OpenAI

360
00:24:23,418 --> 00:24:27,182
agent and to ask to generate

361
00:24:27,246 --> 00:24:31,394
voicing of our text that

362
00:24:31,432 --> 00:24:34,942
we already obtained in previous

363
00:24:35,006 --> 00:24:38,370
steps to voice it to Spanish.

364
00:24:39,030 --> 00:24:42,730
Unplato de comida, congue natasa

365
00:24:42,750 --> 00:24:46,422
de casse. I would say it sounds more

366
00:24:46,476 --> 00:24:49,802
Spanish. Right. So here was

367
00:24:49,856 --> 00:24:52,090
a walkthrough,

368
00:24:52,750 --> 00:24:56,634
how to create your custom tool. And if

369
00:24:56,672 --> 00:25:00,720
you use a little bit of imagination you can think about

370
00:25:01,970 --> 00:25:05,070
expanding and using different tools,

371
00:25:05,410 --> 00:25:09,002
even funny tools like fetching

372
00:25:09,146 --> 00:25:13,090
image of cat from the Internet. So it

373
00:25:13,240 --> 00:25:16,834
can be pretty much everything that we

374
00:25:16,872 --> 00:25:20,260
can code in Python. So our agent

375
00:25:22,870 --> 00:25:26,982
can be really powerful with this. And this

376
00:25:27,036 --> 00:25:30,930
is the conclusion and final thoughts,

377
00:25:31,090 --> 00:25:34,200
a quick recap of our talk.

378
00:25:34,810 --> 00:25:37,950
Agents are still experimental,

379
00:25:38,050 --> 00:25:41,510
they still a little bit brittle for many use cases,

380
00:25:41,670 --> 00:25:45,850
especially when it comes to some complex prompting with

381
00:25:46,000 --> 00:25:49,740
different steps. So the output can be

382
00:25:50,370 --> 00:25:53,082
in some cases unexpected.

383
00:25:53,146 --> 00:25:57,578
So we need to practice

384
00:25:57,674 --> 00:26:01,470
in writing correct projects for

385
00:26:01,540 --> 00:26:05,090
using correct tools. But they

386
00:26:05,160 --> 00:26:08,930
are promising. As our agents are getting

387
00:26:09,000 --> 00:26:12,482
smarter, we can have a lot of

388
00:26:12,536 --> 00:26:16,774
tools. Agents are easily extendable and

389
00:26:16,812 --> 00:26:20,710
they are also easy to start with. As we

390
00:26:20,780 --> 00:26:24,214
saw, we can simply leverage an

391
00:26:24,252 --> 00:26:27,866
agent just in few lines of code and we

392
00:26:27,888 --> 00:26:30,454
can already use a great set of tools,

393
00:26:30,502 --> 00:26:34,662
predefined tools and they are very various

394
00:26:34,806 --> 00:26:38,730
and we can build some interesting chains

395
00:26:39,150 --> 00:26:45,614
and yeah, this what

396
00:26:45,652 --> 00:26:48,510
can make our agent really smart.

397
00:26:49,010 --> 00:26:53,058
And also some further ideas. If you

398
00:26:53,144 --> 00:26:57,140
like the idea of agent, you might want to

399
00:26:57,510 --> 00:27:01,694
experiment more with prompting, writing advanced

400
00:27:01,742 --> 00:27:05,718
prompts, and you can also bring your custom model

401
00:27:05,884 --> 00:27:10,098
as an agent. Try different OpenAI

402
00:27:10,194 --> 00:27:13,494
or just open source llms as

403
00:27:13,532 --> 00:27:17,590
an agent. Maybe they will get you better results.

404
00:27:17,950 --> 00:27:21,674
And also, if you like the overall concept of

405
00:27:21,712 --> 00:27:25,946
smart agents smart assistant, you can also check agents

406
00:27:26,048 --> 00:27:30,054
of launching or Amazon Bedrock. They also

407
00:27:30,112 --> 00:27:33,870
provide some capabilities of

408
00:27:33,940 --> 00:27:37,294
empowering an LLM to

409
00:27:37,332 --> 00:27:42,080
act on behalf of you. So yes,

410
00:27:42,450 --> 00:27:46,014
and as I already said, you can find my

411
00:27:46,052 --> 00:27:50,058
code, my slides and links used in this presentation

412
00:27:50,234 --> 00:27:54,282
in my GitHub repository huggingface underscore

413
00:27:54,346 --> 00:27:57,606
agents, and let's stay in

414
00:27:57,628 --> 00:27:58,820
touch. Thank you.

