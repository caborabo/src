1
00:00:20,680 --> 00:00:23,958
Hello everyone, welcome to the session. Large language

2
00:00:24,006 --> 00:00:28,168
models have captured the imagination for different software developers and customers

3
00:00:28,286 --> 00:00:32,624
who are interested in now integrating those models into their day to day workflows.

4
00:00:33,204 --> 00:00:37,184
Today I'll be talking about Amazon Bedrock, which is a managed service

5
00:00:37,484 --> 00:00:40,596
via which you can have access to different foundation models

6
00:00:40,660 --> 00:00:44,244
using a single API. We talk about the operational

7
00:00:44,324 --> 00:00:47,604
excellence best practices that you would like to consider when

8
00:00:47,644 --> 00:00:50,772
using Amazon bedrock. Customers are often

9
00:00:50,828 --> 00:00:54,564
looking for turnkey solution which can help integrate these llms

10
00:00:54,644 --> 00:00:57,942
into their existing applications. As part of

11
00:00:57,958 --> 00:01:01,366
the session, we will talk about an introduction to the operational

12
00:01:01,430 --> 00:01:05,206
excellence term from a well architected review perspective. We will

13
00:01:05,230 --> 00:01:09,274
talk about the llms and then we will go in depth in the bedrock.

14
00:01:09,734 --> 00:01:13,238
So let's start with operational excellence. If you look at the

15
00:01:13,286 --> 00:01:16,790
well architected review that AWS recommends,

16
00:01:16,902 --> 00:01:19,834
we have a pillar in there which says optional excellence.

17
00:01:20,334 --> 00:01:23,918
Operational excellence is basically an ability to support the development

18
00:01:24,006 --> 00:01:28,136
of your workloads, how to run your workloads, gain insight

19
00:01:28,200 --> 00:01:32,600
into your workloads, and essentially improve your process and procedures

20
00:01:32,712 --> 00:01:36,544
to deliver business value. Operational excellence is

21
00:01:36,584 --> 00:01:39,952
a practice which you develop over the course of time.

22
00:01:40,128 --> 00:01:43,784
It's not something which you will be able to get

23
00:01:43,824 --> 00:01:47,084
done overnight or just by adopting a particular solution.

24
00:01:47,624 --> 00:01:51,538
This is how your team is structured, this is how your people process and

25
00:01:51,586 --> 00:01:54,490
the technologies working together. Now,

26
00:01:54,522 --> 00:01:58,058
within operational excellence, there are different design principles

27
00:01:58,106 --> 00:02:01,426
that you should be considering. One of the key

28
00:02:01,490 --> 00:02:05,410
principles is performing operations as a code. We are all aware of infrastructure as

29
00:02:05,442 --> 00:02:08,954
code and we are aware of different tools and technologies

30
00:02:08,994 --> 00:02:12,826
which are there in the market. Try to adopt as much as possible

31
00:02:13,010 --> 00:02:17,138
from an operations perspective so that you can start executing these as code

32
00:02:17,186 --> 00:02:21,342
snippets, making frequent and small reversible changes.

33
00:02:21,478 --> 00:02:25,954
That's another key aspect of the design principle for operational excellence,

34
00:02:26,454 --> 00:02:30,582
refining your operational procedures, obviously anticipating

35
00:02:30,638 --> 00:02:33,754
failures and learning from your operational failures,

36
00:02:34,574 --> 00:02:39,034
and finally observability, which can help you get actionable insights.

37
00:02:39,654 --> 00:02:43,230
With respect to llms. Let's say you're using Amazon Bedrock,

38
00:02:43,262 --> 00:02:46,194
which is an API, access into different foundation models.

39
00:02:46,594 --> 00:02:49,842
You still have to follow all of these design principles in

40
00:02:49,858 --> 00:02:53,922
order to how to deploy the API. How do you start versioning

41
00:02:53,938 --> 00:02:57,866
the API? How do you have the different operational procedures

42
00:02:57,930 --> 00:03:01,202
working together? What kind of observability can be put in?

43
00:03:01,378 --> 00:03:04,882
So these are some of the factors that we will be talking about as we

44
00:03:04,898 --> 00:03:08,330
go more into the session. Now let's talk about some of

45
00:03:08,362 --> 00:03:12,858
the key terms that we keep hearing day in, day out DevOps,

46
00:03:12,946 --> 00:03:14,974
mlops and llmops.

47
00:03:15,834 --> 00:03:19,330
DevOps as a term has been around for a pretty long time.

48
00:03:19,522 --> 00:03:22,682
It's basically encouraging you to break down the silos,

49
00:03:22,858 --> 00:03:26,330
start having the organizational and the functional separation removed

50
00:03:26,362 --> 00:03:30,210
from the different teams, and have an ownership end to end. As to whatever

51
00:03:30,242 --> 00:03:33,414
you are building, you are also running and supporting that code.

52
00:03:33,954 --> 00:03:37,894
Mlogs is basically using the same set of processes and

53
00:03:38,534 --> 00:03:41,726
people and technology best practices within the scheme

54
00:03:41,750 --> 00:03:45,766
of machine learning solutions. So you consider DevOps

55
00:03:45,830 --> 00:03:49,278
is something which you would often use for microservices written in Java,

56
00:03:49,326 --> 00:03:52,494
Python or Golang. When you are trying to

57
00:03:52,534 --> 00:03:56,494
use the same set of technology stack, but now trying

58
00:03:56,534 --> 00:04:00,022
to solve a machine learning problem where you suddenly have a model,

59
00:04:00,158 --> 00:04:03,518
you need to train the model, you need to have the inference of the model,

60
00:04:03,566 --> 00:04:07,390
you need to have multi model endpoints.

61
00:04:07,582 --> 00:04:11,446
You want to incorporate these practices into how this model is getting trained,

62
00:04:11,510 --> 00:04:15,062
how it is getting deployed, how the approval process is going to be there,

63
00:04:15,118 --> 00:04:18,150
and ultimately how the inference is going to be there, be it a real time

64
00:04:18,182 --> 00:04:22,034
inference or a batch inference. So that's the mlops part in there.

65
00:04:22,614 --> 00:04:26,654
What about llmops? So far, mlops is

66
00:04:26,694 --> 00:04:30,454
mostly used for specific machine learning models which you have

67
00:04:30,494 --> 00:04:34,518
created to solve a single task. With large language

68
00:04:34,566 --> 00:04:37,638
models, you have a capability of using a single

69
00:04:37,686 --> 00:04:41,078
foundation model to solve different types of tasks.

70
00:04:41,166 --> 00:04:44,998
For example, a foundation model like something

71
00:04:45,046 --> 00:04:48,182
which you would be having access via

72
00:04:48,198 --> 00:04:52,078
the bedrock, you can use it for text summarization,

73
00:04:52,166 --> 00:04:55,510
you can use it as a chatbot, you can use it for

74
00:04:55,582 --> 00:04:59,510
question and answers. There are different business scenarios where

75
00:04:59,542 --> 00:05:03,314
you can use these models. Hence the llmops as a term

76
00:05:03,474 --> 00:05:06,538
is using that single model. That is

77
00:05:06,546 --> 00:05:09,254
the foundation model for different aspects of your business.

78
00:05:10,114 --> 00:05:13,890
So in all your best practices on the operational excellence which we spoke about

79
00:05:13,922 --> 00:05:16,866
in the previous slide, they remain quite consistent.

80
00:05:16,970 --> 00:05:20,122
But just the nature of these specific problems which you

81
00:05:20,138 --> 00:05:23,754
are solving would be differing depending on the machine learning solutions

82
00:05:23,834 --> 00:05:27,646
or the LLM solutions which you have. At its core,

83
00:05:27,830 --> 00:05:31,518
every solution that you are creating is going to be talking about

84
00:05:31,566 --> 00:05:33,634
people, process and technology.

85
00:05:34,614 --> 00:05:38,118
Now we say MLops is basically productionization

86
00:05:38,206 --> 00:05:41,934
of your ML solutions effectively. So let's say I deploy

87
00:05:41,974 --> 00:05:45,286
a solution into production which has the model go through its own

88
00:05:45,310 --> 00:05:48,982
set of training. Someone has provided an approval. Now it

89
00:05:48,998 --> 00:05:53,114
is an inference, be it a batch inference or a real time inference.

90
00:05:53,724 --> 00:05:58,060
There is a lot of overlap that happens with foundation model operations

91
00:05:58,252 --> 00:06:01,420
such as generative AI solutions using text, image,

92
00:06:01,532 --> 00:06:05,348
video and audio. And finally, when you talk about

93
00:06:05,436 --> 00:06:08,908
llms, these are basically large language models which are using,

94
00:06:08,996 --> 00:06:12,388
again for productionization. There are some of the attributes which would

95
00:06:12,436 --> 00:06:16,012
change in terms of the metrics that

96
00:06:16,028 --> 00:06:19,466
you're looking at, but the process more or less remains the same.

97
00:06:19,620 --> 00:06:23,414
And then there are some more additional customizations that you would incorporate

98
00:06:23,454 --> 00:06:27,326
into llms with say, rag or fine

99
00:06:27,350 --> 00:06:30,554
tuning, etcetera. We'll talk about it in a, in a few slides.

100
00:06:31,374 --> 00:06:35,114
At its core, it's still going to be people, process and technology,

101
00:06:35,614 --> 00:06:39,534
and that overlap is going to be consistent,

102
00:06:39,694 --> 00:06:42,954
irrespective of what kind of operational excellence you're going for,

103
00:06:43,614 --> 00:06:47,000
be it you using the best technology that is available in the market.

104
00:06:47,182 --> 00:06:51,260
You still need to train your people who can effectively use that technology

105
00:06:51,452 --> 00:06:54,764
to derive the business value. You need to have

106
00:06:54,804 --> 00:06:58,100
a close correlation between the team which is training your model,

107
00:06:58,212 --> 00:07:01,668
or maybe fine tuning that model, and ultimately the consumers who

108
00:07:01,676 --> 00:07:05,452
are going to be using that model. That aspect of people,

109
00:07:05,508 --> 00:07:09,652
process and technology. And obviously, Conway's law doesn't change much

110
00:07:09,788 --> 00:07:13,340
when it comes to deploying a software, whether you're deploying it using an

111
00:07:13,372 --> 00:07:16,850
LLM or you're deploying it in the traditional sense

112
00:07:16,882 --> 00:07:19,494
with microservices or even a monolith application.

113
00:07:20,194 --> 00:07:23,458
Now, let's talk about foundation models. And the first thing that we want

114
00:07:23,466 --> 00:07:27,042
to talk about is the model lifecycle. So in a

115
00:07:27,058 --> 00:07:30,690
typical machine learning use case, you will have a model

116
00:07:30,722 --> 00:07:34,106
lifecycle where you have a lot of data, and using that data now

117
00:07:34,130 --> 00:07:37,594
you're going to go into a processing stage where you're processing

118
00:07:37,634 --> 00:07:41,554
all of your information. That data has been labeled, maybe a supervised

119
00:07:41,594 --> 00:07:44,890
learning or unsupervised learning, whatever is your choice algorithm that you're

120
00:07:44,922 --> 00:07:47,878
doing. And then once the training has been done,

121
00:07:48,006 --> 00:07:52,062
now you have a hyper parameter tuning that you're doing to ultimately

122
00:07:52,198 --> 00:07:56,374
create a model. That model is going to go through the model validation,

123
00:07:56,494 --> 00:07:59,622
testing, and once that model is ready,

124
00:07:59,678 --> 00:08:02,902
you are going to be using for that specific task. That's the

125
00:08:02,918 --> 00:08:06,518
important part here. You're going to be using for this specific task because

126
00:08:06,566 --> 00:08:10,566
the model has been tuned and trained for that particular task.

127
00:08:10,750 --> 00:08:14,286
Tomorrow you have new set of data, you're going to do an iteration,

128
00:08:14,430 --> 00:08:18,374
and then you're going to do the training of the model and ultimately

129
00:08:18,414 --> 00:08:21,554
redeploy the model once the requisite approvals are available.

130
00:08:22,294 --> 00:08:26,134
So this is just one project. When it comes to

131
00:08:26,294 --> 00:08:30,158
foundation models or large language

132
00:08:30,206 --> 00:08:33,718
models, your data set is no longer just one data

133
00:08:33,766 --> 00:08:37,094
set. You're training that model using every possible

134
00:08:37,174 --> 00:08:40,724
data set. For example, the model which you

135
00:08:40,764 --> 00:08:44,596
have from meta, the Lama models you are,

136
00:08:44,660 --> 00:08:48,124
they have been trained, pre trained with large data sets,

137
00:08:48,164 --> 00:08:51,724
70 billion parameters, etcetera. Once that

138
00:08:51,764 --> 00:08:56,252
model has been made available. Now, from that foundation model,

139
00:08:56,428 --> 00:08:59,780
you can either do a fine tuning if you're interested in doing that.

140
00:08:59,812 --> 00:09:03,316
So that's the project b that you're looking at. But then from the

141
00:09:03,340 --> 00:09:06,996
same foundation model, you can directly use it for some task specific

142
00:09:07,060 --> 00:09:10,154
deployments. And then once you do a fine tuning or rag

143
00:09:10,194 --> 00:09:13,874
or something else, you can use that same model for a different

144
00:09:13,994 --> 00:09:17,890
use case. So that's the key difference here. You're using a single model

145
00:09:17,922 --> 00:09:21,234
for different projects and different scenarios with some

146
00:09:21,314 --> 00:09:24,834
alterations. And in the previous case you are having one model

147
00:09:24,874 --> 00:09:27,994
for each of it. Now, with Llmops,

148
00:09:28,034 --> 00:09:31,450
there can be different types of users that you're interacting with.

149
00:09:31,642 --> 00:09:34,970
And basically I want to talk about the generative AI user

150
00:09:35,002 --> 00:09:38,550
types and then the skills which are needed. Let's talk first about

151
00:09:38,582 --> 00:09:41,942
the providers. You have a provider, let's say someone is building an

152
00:09:41,958 --> 00:09:45,230
NLM from scratch. In this case we take a Lama model

153
00:09:45,262 --> 00:09:49,086
which has been built from scratch, and that model can

154
00:09:49,110 --> 00:09:51,154
be used for different use cases,

155
00:09:52,254 --> 00:09:55,550
NLP, data science, model deployment, inference,

156
00:09:55,582 --> 00:09:59,726
etcetera. So that's a provider. You have got a model from there internally,

157
00:09:59,830 --> 00:10:03,094
your team can decide to have a fine tuning on those

158
00:10:03,134 --> 00:10:06,412
models. So those are the people who are doing a fine tuning on the model

159
00:10:06,518 --> 00:10:09,952
to fit custom requirements. Maybe you have a business specific data

160
00:10:10,008 --> 00:10:14,096
which you want the model to be a little bit more aware of.

161
00:10:14,200 --> 00:10:17,704
So you're going to be training that model, fine tuning that model,

162
00:10:17,744 --> 00:10:21,120
using that business particular data, domain specific knowledge that you're

163
00:10:21,152 --> 00:10:24,264
having. And then the third group is basically consumers.

164
00:10:24,304 --> 00:10:27,552
They don't care about what the model has been trained

165
00:10:27,608 --> 00:10:30,352
on or how it has been fine tuned. They are more like consumers who are

166
00:10:30,368 --> 00:10:33,408
going to be just using that model. So consider someone who is using

167
00:10:33,456 --> 00:10:36,662
your chatbot, someone who has asked a question. They would like to

168
00:10:36,678 --> 00:10:40,350
get a response. They want to ensure that the response is not

169
00:10:40,462 --> 00:10:43,206
having any kind of bias, toxicity,

170
00:10:43,350 --> 00:10:47,594
or unrequired

171
00:10:48,134 --> 00:10:51,486
responses that you will be getting. So they don't really have much of the

172
00:10:51,510 --> 00:10:55,190
ML expertise, but they are basically using prompt engineering for getting

173
00:10:55,222 --> 00:10:58,534
a response from the model. Be mindful.

174
00:10:58,694 --> 00:11:02,016
These roles are transferable. So you can always have

175
00:11:02,040 --> 00:11:05,248
a provider who's also becoming a tuner, and you can always

176
00:11:05,296 --> 00:11:08,008
have a consumer who can also become a tuner.

177
00:11:08,176 --> 00:11:10,896
Essentially, this is the entire spectrum that you're having,

178
00:11:11,040 --> 00:11:14,232
where you have more on the MLov side, where the model

179
00:11:14,248 --> 00:11:17,176
is getting created, and then you have the other end of the spectrum, where people

180
00:11:17,240 --> 00:11:20,576
are directly incorporating this model into their day

181
00:11:20,600 --> 00:11:24,312
to day workflows when it comes to LLM selection,

182
00:11:24,448 --> 00:11:27,124
there are different aspects that you would want to consider.

183
00:11:27,844 --> 00:11:31,292
The three key ones that we have seen from the field is the speed,

184
00:11:31,388 --> 00:11:35,292
precision and the cost. Now, let's say you have three different llms

185
00:11:35,348 --> 00:11:39,140
and each one of them is good at one particular thing. So let's say

186
00:11:39,172 --> 00:11:42,332
we have LLM one, two and three. LLM one is

187
00:11:42,348 --> 00:11:45,540
the best when it comes to precision. Two is the best when it comes to

188
00:11:45,572 --> 00:11:48,812
cost, and we have one again

189
00:11:48,868 --> 00:11:52,236
to be the best when it comes to speed. Depending on

190
00:11:52,260 --> 00:11:56,558
the business scenario and the priority for a particular customer,

191
00:11:56,606 --> 00:12:00,590
they can choose one of those llms. Some customers are

192
00:12:00,702 --> 00:12:03,886
ready to sacrifice a bit of precision in

193
00:12:03,910 --> 00:12:07,310
order to pick up a low cost LLM

194
00:12:07,422 --> 00:12:10,854
because of the number of tokens that you'll be sending across and the large use

195
00:12:10,894 --> 00:12:15,142
that you'll be having. You always want to have a cost effective solution in

196
00:12:15,158 --> 00:12:19,118
terms of any software that you are deploying. Second is

197
00:12:19,126 --> 00:12:22,734
the response time. There are different ways in which you can surely improve the response

198
00:12:22,774 --> 00:12:25,898
times. Maybe you're using an embedded text,

199
00:12:25,946 --> 00:12:29,306
embeddings or something like that with a vector database by which you can cache it

200
00:12:29,330 --> 00:12:32,778
or you do something else. But essentially these are some of the key

201
00:12:32,826 --> 00:12:36,826
factors, the three key factors that I have seen with different customers when

202
00:12:36,850 --> 00:12:40,682
they are evaluating llms. And obviously this is a summarization of what

203
00:12:40,698 --> 00:12:43,674
I just spoke about, which is LLM one, two and three,

204
00:12:43,714 --> 00:12:47,254
how they compare. And then it's up to the customer how they want to

205
00:12:47,594 --> 00:12:50,494
pick up a particular LLM and what they want to use it against.

206
00:12:51,414 --> 00:12:55,914
Let's talk about customization. When it comes to customization of the llms,

207
00:12:56,494 --> 00:13:00,086
there are four different ways in which I have seen the customers

208
00:13:00,150 --> 00:13:04,094
to be using the llms. And one of the most common use

209
00:13:04,134 --> 00:13:07,878
cases that they have is prompt engineering. So that's when you are

210
00:13:07,966 --> 00:13:13,518
sending a request to the llms. For example, you're using an anthropic cloud

211
00:13:13,566 --> 00:13:16,798
model on Amazon Bedrock. You are going to be using one of

212
00:13:16,806 --> 00:13:19,752
the playgrounds and just send a request and ask for.

213
00:13:19,918 --> 00:13:23,364
Give me details of when was the

214
00:13:23,404 --> 00:13:27,132
last major incident which has happened in software

215
00:13:27,228 --> 00:13:30,572
engineering around the best practices or something like that. So that's

216
00:13:30,588 --> 00:13:35,316
a problem, engineering. Just asking a question. You're expecting a response from the LLC.

217
00:13:35,340 --> 00:13:39,012
A more nuanced one is a retrieval augmented generation, which is

218
00:13:39,068 --> 00:13:43,380
Rag, where you are able to use

219
00:13:43,452 --> 00:13:47,236
Rag, which as a better solution and as a better cost

220
00:13:47,300 --> 00:13:51,194
benefit, and you can use it for customizing your

221
00:13:51,274 --> 00:13:55,138
llms. Using rag then comes fine tuning,

222
00:13:55,266 --> 00:13:58,730
which is more time consuming, it is more complex.

223
00:13:58,882 --> 00:14:01,738
There is a lot of data and other things which would be needed.

224
00:14:01,866 --> 00:14:05,282
And compared to rag, fine tuning is a special

225
00:14:05,338 --> 00:14:08,882
case. I would say if you really want to have that level of

226
00:14:08,978 --> 00:14:12,906
control over the responses, then maybe you can think of fine

227
00:14:12,930 --> 00:14:16,294
tuning. And the last would be continued pre training where you

228
00:14:16,334 --> 00:14:20,134
are essentially loading the model and customizing

229
00:14:20,174 --> 00:14:24,134
it way more. And obviously the complexity increases as you go

230
00:14:24,174 --> 00:14:27,766
from prompt engineering to rack to fine tuning to

231
00:14:27,790 --> 00:14:31,398
ultimately continued pre training. One of

232
00:14:31,406 --> 00:14:35,254
the most common cases of a rush of

233
00:14:35,334 --> 00:14:38,734
LLMs that has been seen is everyone tries to

234
00:14:38,774 --> 00:14:42,666
start doing fine tuning, thinking that the LLMs can be made

235
00:14:42,730 --> 00:14:46,658
aware of specific knowledge and facts about the organization's

236
00:14:46,706 --> 00:14:50,770
code base or domain knowledge, etcetera. What has been observed

237
00:14:50,802 --> 00:14:54,574
is in majority of the cases, rag is good enough.

238
00:14:54,994 --> 00:14:58,898
It offers a better solution. It is more cost effective

239
00:14:59,026 --> 00:15:02,194
from in terms of cost benefit ratio between rag

240
00:15:02,234 --> 00:15:06,850
and fine tuning. And fine tuning requires considerably more computational

241
00:15:06,922 --> 00:15:11,176
resources and expertise. It introduces even more challenges around

242
00:15:11,240 --> 00:15:15,320
sensitivity and the proprietary data than rag.

243
00:15:15,512 --> 00:15:19,576
And there's obviously the risk of underfitting or overfitting if you

244
00:15:19,600 --> 00:15:22,896
don't have enough data which is available for fine

245
00:15:22,920 --> 00:15:28,736
tuning. So do have a very clear benchmarking

246
00:15:28,840 --> 00:15:32,696
to see how your model is performing with prompt engineering versus

247
00:15:32,880 --> 00:15:36,540
rag. And then think about whether fine tuning

248
00:15:36,572 --> 00:15:40,204
is the right solution that you want to go for without much

249
00:15:40,244 --> 00:15:43,444
evaluation. You may be jumping into a

250
00:15:43,524 --> 00:15:47,292
technology solution, but which may be a much more difficult thing to manage

251
00:15:47,348 --> 00:15:50,852
in the long term. Now customizing, now here we

252
00:15:50,868 --> 00:15:54,532
talk about customizing the business responses. So what's really going

253
00:15:54,548 --> 00:15:58,380
to help drive your business in generative AI is what's important

254
00:15:58,452 --> 00:16:01,650
for your customers, what's important for your products,

255
00:16:01,722 --> 00:16:05,474
which you're creating, and how you go about that. And you can

256
00:16:05,514 --> 00:16:09,410
leverage different mechanisms here. And this is where fine

257
00:16:09,442 --> 00:16:12,734
tuning and continued pre training comes into picture.

258
00:16:13,274 --> 00:16:16,802
You talk about the purpose, it's basically maximizing the accuracy of

259
00:16:16,858 --> 00:16:19,354
the specific tasks that you're having.

260
00:16:19,514 --> 00:16:23,074
And we have comparatively smaller number of

261
00:16:23,114 --> 00:16:26,854
label data. But then when it comes to continued pre

262
00:16:26,894 --> 00:16:30,590
training, that's where you want to maintain the model for

263
00:16:30,622 --> 00:16:33,638
a longer duration on your specific domain.

264
00:16:33,686 --> 00:16:37,534
That is hyper customizations and large number of unlabeled data

265
00:16:37,574 --> 00:16:40,954
sets that you will be using. Now, as I mentioned before,

266
00:16:41,494 --> 00:16:44,734
Amazon Bedrock can help remove the heavy lifting for these

267
00:16:44,774 --> 00:16:48,214
kind of model customization process. But be

268
00:16:48,254 --> 00:16:51,870
very clear on your use case as to

269
00:16:51,902 --> 00:16:55,398
when you would be using a rag versus a fine tuning or prompt

270
00:16:55,446 --> 00:16:59,624
engineering, and why you would want to use a more complex customization

271
00:16:59,704 --> 00:17:03,200
than the one that you're getting. So without that clarity at a business

272
00:17:03,272 --> 00:17:06,920
level, it will be quite difficult for you to just adopt the LLM

273
00:17:06,952 --> 00:17:09,684
and make sure that it is viable in the long term.

274
00:17:10,264 --> 00:17:12,444
Now let's talk about Amazon Bedrock.

275
00:17:13,224 --> 00:17:17,088
Amazon Bedrock is basically a way for simplifying

276
00:17:17,256 --> 00:17:20,832
the access to foundation models and providing an integration

277
00:17:20,888 --> 00:17:25,077
layer for you via a single API which is an invoke model API.

278
00:17:25,165 --> 00:17:29,661
You get access to different models which are available within Amazon bedrock.

279
00:17:29,797 --> 00:17:34,141
Some of the models which you have here is the

280
00:17:34,197 --> 00:17:37,621
stability AI model. You have the Amazon Titan, you have cloud,

281
00:17:37,677 --> 00:17:41,629
you have Lama models, etcetera. Customers have often told us

282
00:17:41,661 --> 00:17:45,053
that one of the most important features of bedrock is how easy it

283
00:17:45,093 --> 00:17:49,001
makes it to experiment with and select and combine different range of

284
00:17:49,157 --> 00:17:52,706
foundation models. It's still very early days and we are

285
00:17:52,730 --> 00:17:56,386
all just getting started and customers are moving extremely fast.

286
00:17:56,530 --> 00:18:00,266
And the key aspect is customers want to

287
00:18:00,410 --> 00:18:03,618
experiment, they want to deploy, they want to iterate on whatever

288
00:18:03,666 --> 00:18:07,394
they have done. And today Bedrock provides access to

289
00:18:07,434 --> 00:18:11,618
wide range of foundation models from different organizations

290
00:18:11,746 --> 00:18:15,318
and as well as the Amazon Titan models that you have. So once you have

291
00:18:15,366 --> 00:18:18,582
access to the bedrock API itself, invoking one

292
00:18:18,598 --> 00:18:21,926
of these models is extremely straightforward. I'll talk about it

293
00:18:21,950 --> 00:18:25,406
in a bit. Now let's talk about the architectural patterns

294
00:18:25,430 --> 00:18:28,274
that you have when using Amazon Bedrock.

295
00:18:29,014 --> 00:18:33,006
Obviously with Amazon Bedrock you have different knowledge bases

296
00:18:33,070 --> 00:18:37,070
for Amazon Bedrock which you will be using. And to

297
00:18:37,102 --> 00:18:40,390
equip a foundation model with an up to date proprietary

298
00:18:40,462 --> 00:18:44,310
information organization often talk about retrieval augmented

299
00:18:44,342 --> 00:18:48,710
generation. We spoke about it a little bit earlier when during

300
00:18:48,742 --> 00:18:52,446
the customization slide. It's basically a technique where

301
00:18:52,630 --> 00:18:56,310
you're fetching the data from the company's data sources,

302
00:18:56,462 --> 00:18:59,998
enriching the prompt with that particular data and delivering

303
00:19:00,046 --> 00:19:04,014
more relevant and accurate responses. We have knowledge

304
00:19:04,054 --> 00:19:07,558
bases within Amazon Bedrock which helps you

305
00:19:07,606 --> 00:19:11,336
in a fully managed rag capability and it allows

306
00:19:11,360 --> 00:19:15,312
you to customize the foundation model responses with contextual

307
00:19:15,408 --> 00:19:19,496
and relevant company data. So essentially it

308
00:19:19,520 --> 00:19:23,688
helps you securely connect to your foundation models. It's a fully managed

309
00:19:23,736 --> 00:19:27,280
rag and it's a built in session context management for

310
00:19:27,352 --> 00:19:31,272
multi tone conversations. And obviously you

311
00:19:31,288 --> 00:19:35,164
also have automated citations with retrievals to improve the transparency

312
00:19:35,544 --> 00:19:38,452
that you get. So how does it work for you?

313
00:19:38,508 --> 00:19:42,344
So let's say you have a user query someone has asked about

314
00:19:43,844 --> 00:19:47,460
how can I get the latest details about my statement or something.

315
00:19:47,652 --> 00:19:51,420
Now that information goes into Amazon Bedrock

316
00:19:51,532 --> 00:19:55,148
and it has the knowledge basis which is associated

317
00:19:55,236 --> 00:19:58,220
with that particular Amazon bedrock.

318
00:19:58,372 --> 00:20:02,458
And it's an iterative process going to look at the knowledge basis for Amazon Bedrock

319
00:20:02,556 --> 00:20:05,926
and based on that it's going to augment the prompt that

320
00:20:05,950 --> 00:20:10,034
you have received and ultimately you are going to use one of the models,

321
00:20:10,574 --> 00:20:14,222
which is the foundation models, be the Claude Llama,

322
00:20:14,358 --> 00:20:17,814
Titan or Jurassic models, and ultimately provide a response

323
00:20:17,854 --> 00:20:22,294
to your customer. All the information that you are retrieving

324
00:20:22,414 --> 00:20:25,694
as part of this process comes from the source

325
00:20:25,734 --> 00:20:29,536
citations and the source which you have within the knowledge base.

326
00:20:29,630 --> 00:20:32,820
And ultimately it gives you the citations to the knowledge base. In order to improve

327
00:20:32,852 --> 00:20:36,412
the transparency. You also have Amazon Q, which is

328
00:20:36,428 --> 00:20:40,580
an which has a similar approach when it comes to integrating with Amazon Connect.

329
00:20:40,732 --> 00:20:44,740
Not something which we are covering for this particular session, but it

330
00:20:44,772 --> 00:20:48,468
has a similar aspect of being able to use your

331
00:20:48,516 --> 00:20:51,864
knowledge bases and then give you customized responses.

332
00:20:52,644 --> 00:20:56,732
Another architectural pattern is the fine tuning. We spoke about it

333
00:20:56,908 --> 00:21:01,012
earlier. So let's say you want to have a very specific

334
00:21:01,068 --> 00:21:04,924
task for which you need to have fine tuning. Simply point

335
00:21:05,084 --> 00:21:08,764
to those examples of that particular data, which is an

336
00:21:08,804 --> 00:21:12,244
S three and they have been labeled. And then Amazon

337
00:21:12,284 --> 00:21:15,804
bedrock makes a copy of the base model,

338
00:21:15,964 --> 00:21:19,652
trains it, and creates a private fine tuned model so you

339
00:21:19,668 --> 00:21:23,244
can get tailored responses. So how does that

340
00:21:23,284 --> 00:21:26,958
work? Essentially you're making use of one of

341
00:21:26,966 --> 00:21:30,574
the foundation models, be it a Lama two model or a Titan

342
00:21:30,614 --> 00:21:34,294
model. For these specific tasks you are keeping all of

343
00:21:34,334 --> 00:21:37,742
your specific labeled data sets in Amazon

344
00:21:37,798 --> 00:21:41,014
S three, and then you are using that

345
00:21:41,054 --> 00:21:44,438
data set in order to make your model

346
00:21:44,486 --> 00:21:48,486
better to get tailored responses. So today you will have fine tuning

347
00:21:48,510 --> 00:21:51,394
available with Lama models cohere, command,

348
00:21:51,874 --> 00:21:55,666
Titan and express Titan multi model and

349
00:21:55,850 --> 00:21:59,362
Titan image generator. Fine tuning will be very soon coming

350
00:21:59,418 --> 00:22:03,534
into anthropic cloud models, but today it is not available.

351
00:22:04,554 --> 00:22:08,210
So this creates a copy. You have the label

352
00:22:08,242 --> 00:22:11,530
dataset which is in Amazon S three, and from there you are able

353
00:22:11,562 --> 00:22:14,454
to fine tune the model and get the generated responses.

354
00:22:15,034 --> 00:22:18,374
Now let's talk about how do you invoke these models.

355
00:22:18,744 --> 00:22:22,144
One of the most common patterns that you have with respect to invoking

356
00:22:22,184 --> 00:22:25,872
these models is by using API gateway. So it's

357
00:22:25,888 --> 00:22:29,760
a very well tested serverless pattern which has been there

358
00:22:29,832 --> 00:22:33,280
in existence even before Amazon bedrock instead of bedrock. You would be

359
00:22:33,312 --> 00:22:38,072
having, I don't know, ECS or EKS or

360
00:22:38,208 --> 00:22:41,408
just something running on a compute somewhere.

361
00:22:41,536 --> 00:22:45,560
And you can use Amazon Lambda AWS lambda for doing that invocation

362
00:22:45,712 --> 00:22:49,112
with bedrock as well. You are able to use the same pattern and

363
00:22:49,128 --> 00:22:52,304
it leverages the event driven architecture that you have

364
00:22:52,344 --> 00:22:55,576
been using or maybe using with Amazon API gateway.

365
00:22:55,760 --> 00:22:59,144
And it doesn't always have to be Amazon API gateway. You can use it with

366
00:22:59,184 --> 00:23:02,896
any integration layer which can support AWS Lambda to invoke

367
00:23:03,040 --> 00:23:07,440
the bedrock APIs. And finally, instead of AWS

368
00:23:07,472 --> 00:23:10,888
lambda, you can also have the same behavior which let's say if

369
00:23:10,896 --> 00:23:13,894
you're having a long running compute and EC,

370
00:23:13,934 --> 00:23:17,246
two ecs or eks, and then you can invoke bedrock API

371
00:23:17,270 --> 00:23:20,606
in the exact same way. For this particular

372
00:23:20,710 --> 00:23:24,206
example, let's consider that you are having two models which you have created

373
00:23:24,230 --> 00:23:27,390
for your request and response. Payload request is saying that

374
00:23:27,422 --> 00:23:31,254
you need to have a prompt which is going in and response is saying that

375
00:23:31,294 --> 00:23:34,542
you have a response that is coming back and a status code that is coming

376
00:23:34,598 --> 00:23:39,100
back. When you want to invoke the Amazon

377
00:23:39,132 --> 00:23:42,900
bedrock endpoint, you're going to be writing a very simple

378
00:23:43,012 --> 00:23:46,588
lambda code which is going to be using the boto three API.

379
00:23:46,716 --> 00:23:50,108
So let's walk through this API. So you guys basically

380
00:23:50,156 --> 00:23:54,076
creating a client of bedrock using the bedrock runtime.

381
00:23:54,100 --> 00:23:57,588
With boto three you are creating the body which

382
00:23:57,636 --> 00:24:01,460
is the prompt, the max tokens that you need to get

383
00:24:01,492 --> 00:24:04,742
as a sample response, the temperature, etcetera.

384
00:24:04,868 --> 00:24:08,250
And then you're selecting the model id. So here I have

385
00:24:08,282 --> 00:24:11,826
selected anthropic cloud model. You can also select any

386
00:24:11,850 --> 00:24:16,614
of the other model like a Titan model, or you can select the

387
00:24:17,714 --> 00:24:21,930
Lama model, any of the model that you want. And once

388
00:24:21,962 --> 00:24:25,194
you select the model id and you select the payload structure

389
00:24:25,234 --> 00:24:29,194
that you are sending. So be mindful that this particular payload structure can change

390
00:24:29,274 --> 00:24:33,562
depending on the model that you are invoking. And you can just use

391
00:24:33,618 --> 00:24:36,994
invoke model and give you a response. And that

392
00:24:37,034 --> 00:24:40,794
response is how you would return it back by using the same model

393
00:24:40,834 --> 00:24:44,586
structure that you have used earlier. Now this particular response

394
00:24:44,650 --> 00:24:48,946
request payload is structure would be differing based on the

395
00:24:49,090 --> 00:24:52,426
model that you are using and the model id will also change based

396
00:24:52,450 --> 00:24:55,842
on the model that you are intending to use. So that's one of

397
00:24:55,858 --> 00:24:59,322
the way of invoking it if you're using Lambda and API gateway, and even if

398
00:24:59,338 --> 00:25:03,234
you're not using API gateway, anything else which can integrate with that

399
00:25:03,274 --> 00:25:06,626
you can use. Now let's say you're not using any lambda you just

400
00:25:06,650 --> 00:25:10,370
want to use from a generic application. You can essentially use boto

401
00:25:10,402 --> 00:25:13,722
three and you can use a temporary credentials in order to gain access

402
00:25:13,818 --> 00:25:18,066
and ultimately invoke the bedrock API. And for any reason

403
00:25:18,170 --> 00:25:21,890
if the AWS SDK is not available to you.

404
00:25:22,002 --> 00:25:25,442
You can also leverage AWS SIG V four for

405
00:25:25,498 --> 00:25:29,210
constructing a valid request payload and invoking the bedrock

406
00:25:29,242 --> 00:25:33,410
API. So this is a similar example,

407
00:25:33,562 --> 00:25:37,534
quite similar to the one that has been shown earlier.

408
00:25:37,874 --> 00:25:41,986
The only difference here is we don't have the lambda handler with

409
00:25:42,010 --> 00:25:46,042
the event context and the event and the context. Here we are directly using the

410
00:25:46,058 --> 00:25:48,666
Botox reap and we are getting a response from here.

411
00:25:48,810 --> 00:25:52,162
So you can embed it in any of the applications which has

412
00:25:52,218 --> 00:25:56,254
access to the temporary credentials and you should be able to access the bedrock API.

413
00:25:57,034 --> 00:26:00,970
Talking about operational excellence, one of the things that I had spoken about earlier

414
00:26:01,082 --> 00:26:04,258
is having good insight into your application.

415
00:26:04,386 --> 00:26:08,226
So we spoke about how do you invoke the application, how do you have the

416
00:26:08,250 --> 00:26:11,610
API driven approach so that you're able to have a versioning,

417
00:26:11,642 --> 00:26:15,378
you're able to have visibility of what is invoking what,

418
00:26:15,506 --> 00:26:18,562
and you're able to have temporary credentials, best practices, etc.

419
00:26:18,618 --> 00:26:21,986
Etcetera. Now we talk about observability that you

420
00:26:22,010 --> 00:26:25,906
would be getting with Amazon bedrock and that's the invocation login.

421
00:26:26,010 --> 00:26:30,274
So customers want to know what was the invocation, what was the prompt

422
00:26:30,314 --> 00:26:33,706
which was sent and what kind of response did I get.

423
00:26:33,890 --> 00:26:37,498
You can enable it at the bedrock level and all of these

424
00:26:37,546 --> 00:26:41,042
logs can go into Amazon s three or cloudwatch or both.

425
00:26:41,178 --> 00:26:45,018
Here is a sample of a log structure where you

426
00:26:45,066 --> 00:26:49,354
have the input body which was sent by the requester

427
00:26:49,474 --> 00:26:53,814
either via lambda or any other way by which the API has been invoked.

428
00:26:53,954 --> 00:26:57,654
And you can see that this is the input someone is asking

429
00:26:57,694 --> 00:27:01,494
explain the three body problem. And here the response is coming in

430
00:27:01,654 --> 00:27:05,230
in terms of the number of tokens that has been given. So you will notice

431
00:27:05,262 --> 00:27:09,286
that because we had given a maximum token of 300, the response

432
00:27:09,310 --> 00:27:12,622
token count is 296. For the purpose of the presentation I've

433
00:27:12,638 --> 00:27:16,142
just truncated what is there in the completion response.

434
00:27:16,278 --> 00:27:19,542
But here you will have a response coming from the model. In this case it

435
00:27:19,558 --> 00:27:23,486
was a cloud model which had been used for that. So this logging will be

436
00:27:23,510 --> 00:27:26,734
available for you directly within Cloudwatch. And then from Cloudwatch

437
00:27:26,774 --> 00:27:30,398
onwards you can change it to let's say s three or

438
00:27:30,406 --> 00:27:34,582
maybe use it for any kind of future use. Talking about metrics,

439
00:27:34,758 --> 00:27:38,422
you have these metrics available out of the box for Cloudwatch

440
00:27:38,478 --> 00:27:42,310
with Amazon Bedrock, which would be your number of invocations, your latency

441
00:27:42,342 --> 00:27:46,222
that you're having, any kind of client and server side errors, any throttling that

442
00:27:46,238 --> 00:27:49,662
you're having, and obviously the token count, the input and output,

443
00:27:49,758 --> 00:27:52,702
you saw a sample of it in the previous log structure is going to be

444
00:27:52,718 --> 00:27:56,958
the same. Now, talking about the

445
00:27:57,006 --> 00:28:00,070
model evaluation bedrock currently has

446
00:28:00,142 --> 00:28:03,974
in preview, I believe a way for you to evaluate

447
00:28:04,054 --> 00:28:08,102
the models. Now the models can be evaluated for robustness,

448
00:28:08,198 --> 00:28:11,954
it can be evaluated for toxicity and accuracy.

449
00:28:12,294 --> 00:28:15,286
There is on the AWS console,

450
00:28:15,390 --> 00:28:18,670
you you can can essentially evaluate the model using recommended metrics.

451
00:28:18,702 --> 00:28:22,582
There's an automated evaluation, but you can also choose

452
00:28:22,718 --> 00:28:26,382
what kind of task you're evaluating it for. For example,

453
00:28:26,518 --> 00:28:30,054
this particular screenshot is from the AWS console, which allows you to

454
00:28:30,094 --> 00:28:34,470
evaluate for a question and answer scenario for Amazon bedrock.

455
00:28:34,582 --> 00:28:38,030
And we are using the anthropic cloud model and

456
00:28:38,062 --> 00:28:41,790
these were the responses which we received on the

457
00:28:41,822 --> 00:28:45,118
accuracy and the toxicity that was evaluated

458
00:28:45,166 --> 00:28:48,534
against. And you can also bring your own prompt data set

459
00:28:48,574 --> 00:28:52,154
or use built and curated prompt data sets for this purpose.

460
00:28:52,774 --> 00:28:56,622
So these are some of the observability and insight

461
00:28:56,678 --> 00:28:59,926
related details that you can potentially use when you

462
00:28:59,950 --> 00:29:03,574
are thinking about using bedrock as your single API for different

463
00:29:03,614 --> 00:29:06,926
foundation models. And finally, we want to talk about the

464
00:29:06,950 --> 00:29:10,866
guardrails because as we talk about generative

465
00:29:10,930 --> 00:29:14,242
AI, there are different challenges around undesirable,

466
00:29:14,418 --> 00:29:18,074
irrelevant topic responses or controversial queries or

467
00:29:18,114 --> 00:29:22,274
responses which you will be getting, toxicity of your responses,

468
00:29:22,434 --> 00:29:26,682
privacy protection bias, stereotyping propagation

469
00:29:26,778 --> 00:29:29,922
and all of those things. So as we talk about

470
00:29:29,978 --> 00:29:33,836
these new challenges, you also want to talk about what

471
00:29:33,860 --> 00:29:36,784
kind of guardrails you will be applying for your models.

472
00:29:37,244 --> 00:29:41,564
One open source solution that you have is with Nvidia Nemo

473
00:29:41,684 --> 00:29:45,628
guardrails. So this is basically for building

474
00:29:45,756 --> 00:29:49,716
trustworthy, safe and secure llms. So you can define the

475
00:29:49,740 --> 00:29:53,380
guardrails or rails and to guide and safeguard,

476
00:29:53,492 --> 00:29:56,700
guide and have a safeguarded conversation. And you can

477
00:29:56,732 --> 00:30:00,340
also choose to define the behavior of your LLM based application

478
00:30:00,452 --> 00:30:03,908
for specific topics and prevent it from engaging in any

479
00:30:03,956 --> 00:30:07,772
discussions which are in unwanted topics. You can also

480
00:30:07,908 --> 00:30:11,580
start connecting different models using LAN chain and

481
00:30:11,652 --> 00:30:15,188
other services which you can have. So it's kind of like a shim

482
00:30:15,236 --> 00:30:18,476
layer which is sitting between your application which

483
00:30:18,500 --> 00:30:22,324
is going to be invoking an LLM. So here you can define all your

484
00:30:22,364 --> 00:30:26,868
programmable guardrails and then you

485
00:30:26,876 --> 00:30:30,380
can kind of steer your llms in order to follow a predefined

486
00:30:30,452 --> 00:30:34,402
conversation path and enforce standard operating

487
00:30:34,458 --> 00:30:37,866
procedures. So these kind of standard operating procedures

488
00:30:37,970 --> 00:30:41,466
are some of the core context

489
00:30:41,530 --> 00:30:44,962
when it comes to building an operational excellence practice,

490
00:30:45,138 --> 00:30:48,482
especially when you are building out the llms. So these are some

491
00:30:48,498 --> 00:30:52,338
of the same points which I have mentioned. And you

492
00:30:52,346 --> 00:30:55,682
can have a look at GitHub and there is, I'll give you

493
00:30:55,698 --> 00:30:59,052
a link towards the end of the session as well,

494
00:30:59,178 --> 00:31:03,280
where within Amazon bedrock samples

495
00:31:03,352 --> 00:31:06,376
are available which you can take a look at it and you can see how

496
00:31:06,480 --> 00:31:09,936
the guardrails have been incorporated, is basically a config

497
00:31:10,080 --> 00:31:13,312
YAML file and you give an

498
00:31:13,368 --> 00:31:17,152
input rail and the input rails are basically applied to

499
00:31:17,168 --> 00:31:21,072
the inputs from the user and it can reject the input or

500
00:31:21,088 --> 00:31:24,520
we can stop any additional processing. Then you have the dialogue

501
00:31:24,552 --> 00:31:28,186
rails which is to influence how the LLM is prompted

502
00:31:28,320 --> 00:31:31,886
and they operate on the canonical form messages. You have the

503
00:31:31,910 --> 00:31:35,590
retrieval rails which are applied on the retrieval chunk. In the case of

504
00:31:35,622 --> 00:31:38,838
say rag scenario, a retrieval rail can reject

505
00:31:38,886 --> 00:31:42,422
a chunk or prevent it from being used to prompt the LLM. You have

506
00:31:42,438 --> 00:31:45,502
the execution rail and finally you have the output rails. So these

507
00:31:45,518 --> 00:31:49,054
are like five different levers which you can control

508
00:31:49,214 --> 00:31:52,554
and you can write your config in a config yaml.

509
00:31:53,054 --> 00:31:56,636
If you go into the GitHub for this particular guardrail,

510
00:31:56,830 --> 00:32:00,376
the Nemo guardrails, you will be able to find more details in

511
00:32:00,400 --> 00:32:03,760
there. But this is just an introduction of what kind of guardrails you can add

512
00:32:03,832 --> 00:32:07,804
into your LLM invocation. So that you are

513
00:32:08,784 --> 00:32:12,480
ensuring that it's safe and you're ensuring

514
00:32:12,552 --> 00:32:15,924
the responsible AI best practices when using llms.

515
00:32:16,704 --> 00:32:20,424
And finally, this is how it would look when you are using it with Amazon

516
00:32:20,464 --> 00:32:24,086
bedrock where you would have the central layer of all the guardrails

517
00:32:24,110 --> 00:32:28,150
that you are having. You have the invoker in here and ultimately the bedrock model

518
00:32:28,182 --> 00:32:31,526
coming in here and the Neemo guardrails would apply at the central layer.

519
00:32:31,630 --> 00:32:35,150
So that is the shim layer that is sitting between your LLM

520
00:32:35,182 --> 00:32:39,070
which is exposed via the bedrock and then the invoker who is

521
00:32:39,262 --> 00:32:42,806
giving that. And finally

522
00:32:42,830 --> 00:32:46,238
the GitHub handle where you can find the details of Amazon bedrock workshop.

523
00:32:46,286 --> 00:32:50,116
And this is a screenshot of the UI that you have that

524
00:32:50,180 --> 00:32:53,828
closes every, all the topics that I wanted to cover for this session.

525
00:32:53,996 --> 00:32:57,596
Talking all the way from what bedrock is what

526
00:32:57,620 --> 00:33:00,884
it is offering. How do you invoke bedrock, what kind

527
00:33:00,924 --> 00:33:05,292
of observability you're getting out of the box. And finally the guardrails

528
00:33:05,308 --> 00:33:08,692
which you can apply for bedrock. Hope this helps.

529
00:33:08,788 --> 00:33:10,964
Thank you so much for your time. It's been a pleasure.

