1
00:00:20,650 --> 00:00:24,110
Welcome to my presentation. Today I'm going to be talking

2
00:00:24,180 --> 00:00:28,134
about how we can use data science and machine learning

3
00:00:28,252 --> 00:00:31,442
to work with AWS DevOps.

4
00:00:31,506 --> 00:00:34,738
Right? If you manage a service deployed

5
00:00:34,754 --> 00:00:37,698
to AWS, I think this presentation is for you.

6
00:00:37,804 --> 00:00:40,714
So let me start presenting myself,

7
00:00:40,832 --> 00:00:44,650
introducing myself. My name is Gustavo Beveramigo. I'm a senior software

8
00:00:44,990 --> 00:00:48,220
engineer at Amazon Prime Video.

9
00:00:48,750 --> 00:00:52,314
Before Amazon, I was working with startups and I've

10
00:00:52,362 --> 00:00:55,726
been doing this work for quite

11
00:00:55,748 --> 00:00:59,226
a long time. And I've been introducing on my daily

12
00:00:59,258 --> 00:01:03,090
basis Python machine learning and all

13
00:01:03,160 --> 00:01:07,294
of its tooling to manage those infrastructures.

14
00:01:07,342 --> 00:01:09,858
So let's start here.

15
00:01:10,024 --> 00:01:13,874
Okay, the agenda for today we're going to be talking about how

16
00:01:13,912 --> 00:01:17,526
can we use Python and its tooling to fine tune your

17
00:01:17,548 --> 00:01:21,298
service to perfection. We're going to be using pandas for data manipulation,

18
00:01:21,394 --> 00:01:24,866
Jupyter for notebooking, locust for load

19
00:01:24,898 --> 00:01:28,214
testing. It's a python tool for load testing, and both

20
00:01:28,252 --> 00:01:31,670
of three to access our AWS account.

21
00:01:31,820 --> 00:01:35,814
Right. The target audience are software engineers, software reliability engineers,

22
00:01:35,862 --> 00:01:39,802
and DevOps. Right. And I'm assuming that you are

23
00:01:39,856 --> 00:01:43,610
familiar with pandas a little bit for data manipulation and

24
00:01:43,680 --> 00:01:47,326
also with Jupyter. But don't worry if you don't know them

25
00:01:47,428 --> 00:01:50,686
that much. If you know Python and AWS, I think this should be

26
00:01:50,708 --> 00:01:54,260
enough for you to understand this presentation. All right,

27
00:01:55,030 --> 00:01:58,626
first of all, I think the first thing that

28
00:01:58,648 --> 00:02:03,598
I want to talk about is related to scaling.

29
00:02:03,774 --> 00:02:07,718
I think the first part of scaling, scaling a service is

30
00:02:07,804 --> 00:02:12,374
really hard. I've been doing this for years and

31
00:02:12,412 --> 00:02:16,210
it's always hard. It doesn't matter if it's a small scale

32
00:02:16,290 --> 00:02:20,410
or if it's a big scale, right, as you have at Amazon or

33
00:02:20,560 --> 00:02:23,706
on big tags or if you're in startup, it's always hard.

34
00:02:23,808 --> 00:02:27,366
And the reason that it's hard is because testing

35
00:02:27,478 --> 00:02:30,220
scalability is really hard, right.

36
00:02:30,830 --> 00:02:34,366
It's really a lot of work to understand if

37
00:02:34,388 --> 00:02:37,678
your service can scale and when you have scaling issues,

38
00:02:37,764 --> 00:02:41,118
it's a lot of work to fix that. The other thing

39
00:02:41,204 --> 00:02:44,498
that makes autoscaling hard is that it's really hard to reason

40
00:02:44,584 --> 00:02:48,034
about scaling to understand what are the bottlenecks and

41
00:02:48,072 --> 00:02:52,594
how we can make your service scale is

42
00:02:52,632 --> 00:02:56,114
something that is really not easy. And the other thing

43
00:02:56,152 --> 00:03:00,366
is that infrastructure is expensive. So if

44
00:03:00,488 --> 00:03:04,322
infrastructure was cheap or cheap, you could just scale

45
00:03:04,466 --> 00:03:08,006
the number of resources you're using and that would be fine. But that

46
00:03:08,108 --> 00:03:12,154
infrastructure is really expensive. So you need to be really resourceful in

47
00:03:12,192 --> 00:03:16,086
the resources that you use so it doesn't

48
00:03:16,118 --> 00:03:19,818
get more expensive than it needs to be. So I'm going to

49
00:03:19,824 --> 00:03:23,680
be talking a little bit about this. In this talk,

50
00:03:24,450 --> 00:03:27,598
first, I'm going to present you a

51
00:03:27,684 --> 00:03:31,102
problem, a problem that I've seen multiple times

52
00:03:31,156 --> 00:03:34,786
in my career, all right? Which is you

53
00:03:34,808 --> 00:03:38,126
have a service scales dynamically.

54
00:03:38,318 --> 00:03:41,650
What I mean by that is that you have multiple hosts, right?

55
00:03:41,720 --> 00:03:45,534
You have like one host here, another host here, another host

56
00:03:45,582 --> 00:03:48,770
here, and use your cloud resources,

57
00:03:49,130 --> 00:03:53,126
depending on the traffic that you're receiving. You want

58
00:03:53,148 --> 00:03:55,320
to add more hosts, right?

59
00:03:56,010 --> 00:03:59,866
And you do like, we call that dynamically scaling or sometimes

60
00:04:00,048 --> 00:04:03,546
autoscaling, right. The problem here

61
00:04:03,648 --> 00:04:07,402
is that how we can do this outscaling, how we can set up

62
00:04:07,456 --> 00:04:14,926
our infrastructure in a way that it

63
00:04:14,948 --> 00:04:18,734
will scale at the right velocity and using

64
00:04:18,772 --> 00:04:23,460
the right resources at the right time without

65
00:04:24,150 --> 00:04:28,482
having problems. Right. What I mean by problems without

66
00:04:28,536 --> 00:04:32,034
your services being unavailable and how we can do that in

67
00:04:32,072 --> 00:04:35,374
efficient ways. So if you're too conservative,

68
00:04:35,502 --> 00:04:39,554
you're going to be adding more hosting than necessary. If you're too aggressive,

69
00:04:39,682 --> 00:04:43,830
you won't add hosts at the right time and at the right scale.

70
00:04:44,250 --> 00:04:47,682
So the way that I set up this problem here,

71
00:04:47,756 --> 00:04:51,274
I set up an infrastructure just for this talk

72
00:04:51,392 --> 00:04:55,398
where I will do a scaling experiment,

73
00:04:55,494 --> 00:04:58,998
right? And we're going to be using python

74
00:04:59,174 --> 00:05:02,814
to analyze this problem and try to come up with a

75
00:05:02,852 --> 00:05:06,826
solution. So that's my approach to this. So let's

76
00:05:06,858 --> 00:05:10,426
say we have this infrastructure here which scales

77
00:05:10,458 --> 00:05:15,760
dynamically. And let's say that we have a traffic that

78
00:05:16,450 --> 00:05:19,220
increases in this space here, right?

79
00:05:19,670 --> 00:05:22,898
It starts like after ten minutes,

80
00:05:22,984 --> 00:05:26,066
scales to 30,000 requests per minute.

81
00:05:26,178 --> 00:05:29,366
And then you have a search here that in eight minutes

82
00:05:29,468 --> 00:05:34,946
it will scale from 30,000 rpm

83
00:05:35,058 --> 00:05:39,162
to close to 150,000

84
00:05:39,296 --> 00:05:42,570
requests per minute. This is a very aggressive

85
00:05:43,310 --> 00:05:47,498
ramping up, and that does happen in real life. All right,

86
00:05:47,584 --> 00:05:50,950
so that's not something that we haven't seen

87
00:05:51,040 --> 00:05:54,910
that does happen. Right. If you work with

88
00:05:55,060 --> 00:05:58,414
retail, for example, ecommerce, we have that

89
00:05:58,452 --> 00:06:02,586
on Black Fridays or when you have promotions and

90
00:06:02,628 --> 00:06:05,010
things like that, or a marketing campaign,

91
00:06:06,710 --> 00:06:09,954
it's not uncommon to see this kind of shape. So the way

92
00:06:09,992 --> 00:06:13,262
that we usually work, we prepare

93
00:06:13,326 --> 00:06:16,626
our infrastructure and our service in order to handle

94
00:06:16,658 --> 00:06:18,440
that kind of search.

95
00:06:19,210 --> 00:06:22,450
Sometimes this search happens unexpectedly.

96
00:06:22,530 --> 00:06:26,198
Right. All the seminar, there's like a promotion that was

97
00:06:26,284 --> 00:06:30,554
sent out by the marketing team and your

98
00:06:30,592 --> 00:06:34,026
team was not prepared for that, but your

99
00:06:34,048 --> 00:06:37,914
service needs to scale to that amount of

100
00:06:37,952 --> 00:06:41,722
traffic in a way that

101
00:06:41,776 --> 00:06:45,866
you won't have any problem, so you won't have unavailability

102
00:06:45,978 --> 00:06:49,694
issues. So that's the problem that I'm presenting to you guys.

103
00:06:49,732 --> 00:06:52,894
And that's the problem that I'm going to try to solve here

104
00:06:53,012 --> 00:06:56,558
using Python machine learning data science tools

105
00:06:56,574 --> 00:07:00,082
like the tools that we use usually for

106
00:07:00,136 --> 00:07:03,394
other types of problems. I'm going to be using this for this kind of

107
00:07:03,432 --> 00:07:06,290
problem. A little bit of the context.

108
00:07:06,450 --> 00:07:10,866
I deployed application to AWS Pinstalk

109
00:07:10,978 --> 00:07:15,062
basically under the hood it uses application load balancer to

110
00:07:15,196 --> 00:07:19,862
load balance those route

111
00:07:19,926 --> 00:07:23,386
that prime to EC two hosts. The application is

112
00:07:23,408 --> 00:07:26,842
deployed against an EC two host, EC two box.

113
00:07:26,976 --> 00:07:30,714
The instance type is a three t three micro

114
00:07:30,762 --> 00:07:33,886
which is a very small instance. I created that just for

115
00:07:33,908 --> 00:07:37,120
this experiment that we are running here.

116
00:07:37,810 --> 00:07:42,430
Also we use autoscaling group to scale

117
00:07:44,450 --> 00:07:49,086
that cluster and the scaling parameters that

118
00:07:49,108 --> 00:07:52,926
I have set up. This is quite standard like this scale up

119
00:07:52,948 --> 00:07:57,046
and scale down implements is one and minus one. That means that every time

120
00:07:57,148 --> 00:08:00,726
that scaly event is triggered I'm going to

121
00:08:00,748 --> 00:08:04,642
increment that by one host or by minus one host.

122
00:08:04,786 --> 00:08:08,010
The upper thread showed is going to be 25%.

123
00:08:08,080 --> 00:08:11,766
It's 25% of cpu utilization,

124
00:08:11,878 --> 00:08:15,980
right. So when the average cpu utilization across all of your services

125
00:08:16,350 --> 00:08:19,866
is above 25% it's going

126
00:08:19,888 --> 00:08:24,190
to add one host, right. And then when it's

127
00:08:26,370 --> 00:08:29,662
the lower threshold, it's written down here, but it's the lower

128
00:08:29,716 --> 00:08:33,460
threshold here it's 15%.

129
00:08:34,150 --> 00:08:37,426
This doesn't really matter for our experiment here because we are

130
00:08:37,448 --> 00:08:40,946
testing the ramp up time, not how

131
00:08:41,128 --> 00:08:44,270
it scales down your fleet.

132
00:08:44,350 --> 00:08:47,590
And the metric that we are using is a utilization, right.

133
00:08:47,660 --> 00:08:51,222
The other parameters here, like the time that it takes

134
00:08:51,356 --> 00:08:54,440
to do this scaling, it waits for five minutes.

135
00:08:56,250 --> 00:08:59,978
The CP utilization needs to breach that limit for five minutes.

136
00:09:00,144 --> 00:09:03,754
If that happens it will scale the service. It takes like three to four

137
00:09:03,792 --> 00:09:07,382
minutes to spin up a new host.

138
00:09:07,446 --> 00:09:11,582
Right. So this is our scaling parameters, right. This is quite

139
00:09:11,636 --> 00:09:16,270
standard set up. I've seen that multiple times. Usually people use 25%,

140
00:09:16,340 --> 00:09:20,046
30%. That's quite standard. Like that's quite

141
00:09:20,068 --> 00:09:23,594
a common sense. Sometimes we change

142
00:09:23,652 --> 00:09:26,914
this scale up and scale down increment to try

143
00:09:26,952 --> 00:09:30,420
to improve things. That's how it usually works.

144
00:09:31,670 --> 00:09:35,230
The approach that I'm going to be using, I'm going to low test

145
00:09:35,320 --> 00:09:39,074
one host, right. Because I need an exact profile

146
00:09:39,202 --> 00:09:42,530
of how one host behaves when it receives

147
00:09:42,610 --> 00:09:46,402
traffic. I'm going to retrieve that data from AWS

148
00:09:46,466 --> 00:09:49,990
Cloudwatch to pandas. Right. This is the second line

149
00:09:50,060 --> 00:09:52,700
here so I can work with that data.

150
00:09:53,630 --> 00:09:57,930
Based on that I can determine what would be the capacity for one host.

151
00:09:58,270 --> 00:10:02,302
And based on that I can try to find what would

152
00:10:02,356 --> 00:10:06,222
happen when this

153
00:10:06,276 --> 00:10:10,270
cluster receives more traffic. How it will scale out,

154
00:10:10,420 --> 00:10:14,530
scale out is when you are adding more hosts to handle

155
00:10:14,950 --> 00:10:18,914
the additional traffic that you're receiving. And finally,

156
00:10:19,032 --> 00:10:23,118
I will try to test the parameters that we have figured

157
00:10:23,134 --> 00:10:26,686
out here during our experimentations. I will

158
00:10:26,728 --> 00:10:29,782
try that in production, the setup that I have done here.

159
00:10:29,836 --> 00:10:33,238
And we're going to analyze the results of that.

160
00:10:33,324 --> 00:10:37,142
All right, first of all, I load test one

161
00:10:37,196 --> 00:10:40,506
host, right? So I just use this product here.

162
00:10:40,608 --> 00:10:43,786
It's called locust. I think

163
00:10:43,808 --> 00:10:47,194
that's how it's pronounced. It's an open source tool

164
00:10:47,232 --> 00:10:50,060
for Python. It's really easy to use,

165
00:10:50,690 --> 00:10:53,850
and I use that just to send traffic to one host,

166
00:10:53,930 --> 00:10:57,630
right. And just to

167
00:10:57,700 --> 00:11:01,450
check if it can handle how much traffic it can handle.

168
00:11:01,610 --> 00:11:05,540
And all that after that, what I did

169
00:11:06,150 --> 00:11:10,802
retrieved that data from AWS to

170
00:11:10,856 --> 00:11:14,766
pandas. This is how you can do like you can use bottle

171
00:11:14,798 --> 00:11:18,310
three to get the metrics right.

172
00:11:18,460 --> 00:11:22,630
This is quite AWS. This is a query you create

173
00:11:22,700 --> 00:11:25,926
against. This part here is a

174
00:11:25,948 --> 00:11:27,640
query you create against,

175
00:11:29,450 --> 00:11:32,942
right where you're gaining the utilization.

176
00:11:33,106 --> 00:11:36,762
You point into a specific outscaling group and

177
00:11:36,816 --> 00:11:39,834
you start like a period of time.

178
00:11:39,952 --> 00:11:43,486
You get that and you transform that to

179
00:11:43,508 --> 00:11:46,942
a data frame, which is the data type here

180
00:11:46,996 --> 00:11:50,606
that we're using with. And one tip that

181
00:11:50,628 --> 00:11:54,850
I give people is that once you do that, save that to cvs,

182
00:11:55,430 --> 00:11:59,090
to a csv file, because data

183
00:11:59,160 --> 00:12:02,606
on cloud watch, they will be erased after a period

184
00:12:02,638 --> 00:12:06,162
of time, depending on the period that you're fetching here.

185
00:12:06,216 --> 00:12:10,102
If it's 10 seconds, I think it's unavailable only for 24

186
00:12:10,156 --> 00:12:13,830
hours. I think for 1 minute, it's available

187
00:12:13,900 --> 00:12:16,774
for a couple of days and so on. So it's not going to be there

188
00:12:16,812 --> 00:12:21,114
forever. So if you need that data for future work,

189
00:12:21,312 --> 00:12:24,934
do save that to a CSV so you don't lose

190
00:12:24,982 --> 00:12:28,300
that data. All right, moving forward here,

191
00:12:28,830 --> 00:12:33,520
after I do this, I can just use pandas to actually

192
00:12:35,570 --> 00:12:38,954
draw plot

193
00:12:39,082 --> 00:12:42,382
graphics here and start analyzing the data

194
00:12:42,436 --> 00:12:46,254
that you have. This is pretty much similar to what observability tools

195
00:12:46,302 --> 00:12:50,050
you would use. It's not that different. But once you're using

196
00:12:50,120 --> 00:12:54,450
pandas, you get access to all the tools

197
00:12:54,790 --> 00:12:58,370
that are available in pandas that are really sophisticated.

198
00:12:58,530 --> 00:13:02,614
So here we can see the CP utilization and

199
00:13:02,652 --> 00:13:06,258
then we see how the request per minute

200
00:13:06,354 --> 00:13:09,798
it increases according to the CP utilization.

201
00:13:09,974 --> 00:13:13,274
That's quite interesting, but I think we can do a little better than

202
00:13:13,312 --> 00:13:15,994
that. So what I did here,

203
00:13:16,112 --> 00:13:19,514
I compare the CP utilization against the

204
00:13:19,552 --> 00:13:24,254
RPM and I run a linear regression to

205
00:13:24,292 --> 00:13:28,010
find, based on the request permitted that I'm

206
00:13:28,090 --> 00:13:31,710
receiving what is going to be the CPU utilization. And also

207
00:13:31,780 --> 00:13:35,106
based on that, I can create a predictor. So I

208
00:13:35,128 --> 00:13:38,718
can predict, based on the request permitted, how much cpu

209
00:13:38,814 --> 00:13:41,220
it's going to be optimizing, right?

210
00:13:41,910 --> 00:13:45,982
And the other thing that I can find here is that, is this relation linear?

211
00:13:46,046 --> 00:13:49,902
Because sometimes if the traffic you're receiving,

212
00:13:49,966 --> 00:13:53,238
the supervisation is not linear, you might have a problem,

213
00:13:53,324 --> 00:13:57,218
right? So it should be linear, but it's

214
00:13:57,234 --> 00:14:01,094
not always linear. So we are validating a hypothesis

215
00:14:01,142 --> 00:14:05,146
here, like an assumption here, that it's linear. And now we know the

216
00:14:05,168 --> 00:14:08,778
coefficient for this, which means that

217
00:14:08,864 --> 00:14:12,462
for 40k requests per minute, you're going to be using

218
00:14:12,516 --> 00:14:16,206
about 30% of your cpu. This is

219
00:14:16,228 --> 00:14:19,854
for one host, right? That's quite interesting.

220
00:14:20,052 --> 00:14:23,554
That's better than what we have. Like now we have an idea of how many

221
00:14:23,592 --> 00:14:27,326
hosts we need in order to handle

222
00:14:27,358 --> 00:14:30,434
our traffic. There's another thing as well.

223
00:14:30,472 --> 00:14:33,858
Like I noticed that response time, the latency here,

224
00:14:34,024 --> 00:14:37,734
which is the time that you put the request, how long does

225
00:14:37,772 --> 00:14:41,014
it take to get a response? And we see

226
00:14:41,052 --> 00:14:44,790
here that while the cputilization is below

227
00:14:44,860 --> 00:14:49,078
here, 50, right, in this period, it's pretty normal.

228
00:14:49,254 --> 00:14:52,730
It does increase a little bit here, but it's not something

229
00:14:52,800 --> 00:14:56,518
that it becomes

230
00:14:56,534 --> 00:15:00,542
a worry. But after 50, we notice that things get

231
00:15:00,596 --> 00:15:03,854
out of hand, right? We see all these guys here.

232
00:15:03,892 --> 00:15:07,774
So my reasoning on here is

233
00:15:07,812 --> 00:15:11,562
that after 50% of cputonization,

234
00:15:11,706 --> 00:15:15,970
my application doesn't work. So I need to keep my application

235
00:15:16,120 --> 00:15:18,978
below 50%. So it's always available.

236
00:15:19,064 --> 00:15:22,610
If it's go above 50%, things will not work

237
00:15:22,680 --> 00:15:26,050
correctly. So that's a really nice find.

238
00:15:26,120 --> 00:15:29,446
Right? And I'm going to be using that as

239
00:15:29,468 --> 00:15:33,366
a parameter to scale my service. Right. Sometimes when

240
00:15:33,388 --> 00:15:36,774
you do that, some applications is 60%, some of them

241
00:15:36,812 --> 00:15:40,614
like 80%, but there's like a cut off percentage

242
00:15:40,662 --> 00:15:42,780
here that you need to find out.

243
00:15:47,150 --> 00:15:50,526
For this application, it's 50%. It might be related to the

244
00:15:50,548 --> 00:15:54,170
instance type, which is very small, maybe. And it's

245
00:15:54,250 --> 00:15:58,474
one of those three t three instance. If you're

246
00:15:58,522 --> 00:16:04,334
using a C instance, which is meant for CPU

247
00:16:04,382 --> 00:16:08,174
intensive application, it might behave differently. It might be related

248
00:16:08,222 --> 00:16:11,646
to the application that I've deployed here, which is the same publication

249
00:16:11,678 --> 00:16:14,050
from AWS. It's not being sophisticated.

250
00:16:14,710 --> 00:16:18,790
So this is how this application works,

251
00:16:18,860 --> 00:16:21,240
right? And I'm going to be using that.

252
00:16:23,930 --> 00:16:27,682
We haven't actually answered the question how we can scale,

253
00:16:27,826 --> 00:16:31,178
but we have some clues here. Like the

254
00:16:31,184 --> 00:16:34,380
CPU utilization should be kept below 50%,

255
00:16:35,470 --> 00:16:38,746
but we don't know how to do that. Efficiently. We don't know how

256
00:16:38,768 --> 00:16:41,610
to keep this CP utilization below 50%.

257
00:16:41,760 --> 00:16:44,846
We don't know how to use most of CPU at

258
00:16:44,868 --> 00:16:48,730
all times. We don't want a fleet that is subutilized.

259
00:16:48,810 --> 00:16:52,674
Right. Like, the average CPU utilization is very low. We want them

260
00:16:52,712 --> 00:16:56,174
to be using our resources

261
00:16:56,222 --> 00:17:00,420
efficiently. So what can we do? I think

262
00:17:01,030 --> 00:17:04,594
that's the question that we've been asking here. We have

263
00:17:04,632 --> 00:17:08,646
two options here, right? We can test multiple parameters in

264
00:17:08,668 --> 00:17:12,246
production. And the problem with that is

265
00:17:12,268 --> 00:17:15,874
that, first of all, testing, changing those parameters in production,

266
00:17:15,922 --> 00:17:19,142
it's risky. It's doable, but it's risky.

267
00:17:19,286 --> 00:17:22,602
Usually you have to do that in a very low

268
00:17:22,656 --> 00:17:26,154
traffic time during overnight, things like that. It's high

269
00:17:26,192 --> 00:17:28,140
effort because you're changing that.

270
00:17:30,510 --> 00:17:34,094
You need to do the change and wait to see if there

271
00:17:34,132 --> 00:17:37,582
were no problems. It's usually not easy

272
00:17:37,636 --> 00:17:41,230
to do that kind of test in production, and also

273
00:17:41,380 --> 00:17:44,638
you want to do that test in production, and you want to do a

274
00:17:44,644 --> 00:17:48,514
low test to check if the parameters that you have

275
00:17:48,552 --> 00:17:51,220
applied, if they actually work. Right.

276
00:17:51,590 --> 00:17:54,738
I didn't talk about this, but usually load tests is you

277
00:17:54,744 --> 00:17:58,870
want to do load testing against production environment,

278
00:17:59,370 --> 00:18:03,170
and you want to run those load tests on production environment,

279
00:18:03,250 --> 00:18:07,080
but at the same time, you don't want that load test to cause

280
00:18:08,810 --> 00:18:12,454
any outages, any issues. So it's usually a trade off.

281
00:18:12,492 --> 00:18:16,280
Like, how can you do that? So the other,

282
00:18:17,050 --> 00:18:20,266
we could do that in production, but we know it's very risk

283
00:18:20,298 --> 00:18:24,206
and it's very high effort. So what I

284
00:18:24,228 --> 00:18:27,374
decided to do here for this presentation, I'm going to do

285
00:18:27,412 --> 00:18:30,250
some local experimentation using Python.

286
00:18:30,330 --> 00:18:35,086
Right? Python is our answer, so we don't have to keep trying

287
00:18:35,188 --> 00:18:38,498
operator meters in production. And if I can do

288
00:18:38,504 --> 00:18:42,082
this in Python, and it should be

289
00:18:42,136 --> 00:18:45,538
a lot easier. So how do I solve this problem?

290
00:18:45,704 --> 00:18:49,142
First of all, I create a scaling simulator, right?

291
00:18:49,276 --> 00:18:52,726
I create a simulator. The link

292
00:18:52,908 --> 00:18:55,910
is going to be on my GitHub. The link is in the end,

293
00:18:55,980 --> 00:19:00,166
I create an autoscaling simulator, modeling how scaling

294
00:19:00,198 --> 00:19:03,820
works in AWS, one of the policies that we have there.

295
00:19:04,350 --> 00:19:07,638
It's just like a simple code where you simulate

296
00:19:07,734 --> 00:19:13,406
how it's going to work, like, based on wait for five minutes for

297
00:19:13,428 --> 00:19:14,430
the threshold,

298
00:19:16,690 --> 00:19:19,918
five minutes, breaching the threshold. If that happens,

299
00:19:20,004 --> 00:19:24,090
trigger a scale up event where you're going to spin off

300
00:19:24,260 --> 00:19:28,126
a machine, wait for like, three or four minutes to spin

301
00:19:28,158 --> 00:19:32,290
up that machine. After that, you can consider that machine to be

302
00:19:32,440 --> 00:19:36,638
healthy, and it will be able to receive traffic

303
00:19:36,734 --> 00:19:40,458
and how that balances out the cpuization

304
00:19:40,574 --> 00:19:43,190
across all of your hosts.

305
00:19:43,930 --> 00:19:47,526
It's a simulation code. It's really not hard to

306
00:19:47,548 --> 00:19:51,050
do. And based on that, what I did,

307
00:19:51,200 --> 00:19:54,554
these are like I'm applications. The parameters that we have there,

308
00:19:54,592 --> 00:19:58,010
like it's 25 minutes for the upper threshold, 15 minutes

309
00:19:58,080 --> 00:20:01,998
for the lower threshold, it scales up in one increment and it

310
00:20:02,004 --> 00:20:05,098
scales down by minus one increment,

311
00:20:05,194 --> 00:20:08,480
right. And I run that and I can see

312
00:20:09,170 --> 00:20:12,606
how my application would behave. The other thing I

313
00:20:12,628 --> 00:20:15,742
have done, I created a shares generator,

314
00:20:15,806 --> 00:20:19,266
right? Instead of doing a load, it's like our simulation of

315
00:20:19,288 --> 00:20:22,750
a load testing, right? So I have here the parameters,

316
00:20:22,830 --> 00:20:26,760
like during ten minutes, ramp up to 30k

317
00:20:28,250 --> 00:20:31,430
rpms, requests per minute.

318
00:20:32,410 --> 00:20:35,958
During eight minutes, ramp up to 150k

319
00:20:36,044 --> 00:20:40,214
rpms, and then keep that for another 30 minutes.

320
00:20:40,332 --> 00:20:43,562
And I create that, enable that in a data

321
00:20:43,616 --> 00:20:46,746
frame. And now I have here, like, this is my shape that

322
00:20:46,768 --> 00:20:50,234
I'm going to run my simulation. And what

323
00:20:50,272 --> 00:20:53,230
happens with that is that when I run that,

324
00:20:53,380 --> 00:20:57,040
like I get my new load shape, which is

325
00:20:57,730 --> 00:21:01,614
my autoscaling simulator. What I find out is that if

326
00:21:01,652 --> 00:21:05,620
I rim pump based on this graph here,

327
00:21:06,310 --> 00:21:09,966
this is how my outscaling would add hosts.

328
00:21:09,998 --> 00:21:13,506
Like it's adding one host here, adding another host here,

329
00:21:13,608 --> 00:21:16,914
adding another host here. It seems that it's adding

330
00:21:16,962 --> 00:21:19,640
at five minutes here.

331
00:21:20,010 --> 00:21:23,986
What happens is that my cpu utilization

332
00:21:24,178 --> 00:21:28,566
could be way above 50%, which is our threshold

333
00:21:28,678 --> 00:21:33,020
for quite some time here. Probably for.

334
00:21:33,950 --> 00:21:37,146
Yeah, we can leave in separate, but it seems to be like during

335
00:21:37,248 --> 00:21:40,766
15 minutes, my applications would probably out of

336
00:21:40,788 --> 00:21:44,062
service, maybe more, right. Like in real life,

337
00:21:44,116 --> 00:21:47,934
that's probably more than that. So this is pretty bad,

338
00:21:48,132 --> 00:21:51,120
this configurations that we have here.

339
00:21:51,570 --> 00:21:55,522
Based on our simulation, it doesn't seem that it would

340
00:21:55,576 --> 00:21:59,106
work. Right. So we have problems.

341
00:21:59,208 --> 00:22:02,706
Right. And let me talk a little bit more

342
00:22:02,728 --> 00:22:05,986
about that. The reason that the

343
00:22:06,008 --> 00:22:09,334
CPU station is so high is because here at

344
00:22:09,372 --> 00:22:12,726
this point here, we are already receiving a

345
00:22:12,748 --> 00:22:16,678
lot of traffic, but we don't have any hosts that are

346
00:22:16,684 --> 00:22:19,562
available. It's just one host, right. And then it's two.

347
00:22:19,696 --> 00:22:24,730
It's not enough to handle all this traffic here.

348
00:22:24,800 --> 00:22:27,690
When I have five hosts,

349
00:22:28,590 --> 00:22:32,654
things starts to get better, right. So during

350
00:22:32,692 --> 00:22:36,186
this period here, I don't have enough hosts to handle

351
00:22:36,218 --> 00:22:39,754
this track. That's why that configuration doesn't

352
00:22:39,802 --> 00:22:43,934
work, right. So basically, our arp threshold

353
00:22:43,982 --> 00:22:47,902
of 25% and increment

354
00:22:47,966 --> 00:22:51,380
in one host at a time, it doesn't work. Right.

355
00:22:51,830 --> 00:22:55,234
And as we said, the lower threshold and the scale down

356
00:22:55,272 --> 00:22:58,438
increment won't matter. For this experimentation that we

357
00:22:58,444 --> 00:23:02,006
are doing here, my first attempt. Well,

358
00:23:02,108 --> 00:23:05,846
let's try to scale up in two increments, right. Instead of

359
00:23:05,948 --> 00:23:09,386
just adding one, it has two at a time.

360
00:23:09,488 --> 00:23:13,334
Right. And what we see here is that the problem hasn't

361
00:23:13,382 --> 00:23:16,570
gone away, right. So we still have a problem

362
00:23:16,640 --> 00:23:20,166
here. It's not working. And the funny

363
00:23:20,198 --> 00:23:23,818
part is that that's usually what teams do in production.

364
00:23:23,994 --> 00:23:27,326
They see that problem, they see that it didn't work.

365
00:23:27,428 --> 00:23:31,834
What they do, oh, let's try. Their first insight

366
00:23:31,882 --> 00:23:36,110
is that it's not scaling fast enough. So let's increase the scale up increment

367
00:23:36,190 --> 00:23:39,406
from one to two. But it didn't solve

368
00:23:39,438 --> 00:23:40,660
the problem. Right.

369
00:23:45,190 --> 00:23:49,302
Sometimes they're like clueless, what should we do? And I've seen

370
00:23:49,356 --> 00:23:52,930
teams what they do, they just like, hey, just add like ten hosts

371
00:23:53,010 --> 00:23:56,978
at all time and problem solve. Let's not using autoscaling anymore.

372
00:23:57,074 --> 00:24:01,194
Some teams decide to do that to abandon the

373
00:24:01,232 --> 00:24:04,566
outscaling the dynamic scaling strategy.

374
00:24:04,678 --> 00:24:08,218
But that's really not resourceful because most of the time you are going

375
00:24:08,224 --> 00:24:12,240
to have host provision that will not be used at all.

376
00:24:13,330 --> 00:24:17,774
Continue here. What we can also like

377
00:24:17,812 --> 00:24:21,006
to solve this, we can try to find what

378
00:24:21,028 --> 00:24:24,322
would be the best parameter. So I create two loops here.

379
00:24:24,376 --> 00:24:28,222
One we're going to be testing all increments

380
00:24:28,286 --> 00:24:31,762
from one to ten and then the upper threshold from

381
00:24:31,816 --> 00:24:35,478
eleven to 35. I didn't try above that but

382
00:24:35,484 --> 00:24:39,970
I mean I could and then I run my autoscaling simulator

383
00:24:40,130 --> 00:24:43,686
and I get the maximum cpuization that

384
00:24:43,788 --> 00:24:46,934
it would be using and I do,

385
00:24:47,132 --> 00:24:51,386
hey, I just want the results that are below 50% and

386
00:24:51,408 --> 00:24:54,810
then based on that I will have all

387
00:24:54,880 --> 00:24:58,250
the simulations that were successful here, right.

388
00:24:58,320 --> 00:25:05,854
And I transform that in a data form so I can use

389
00:25:05,892 --> 00:25:10,042
that in pandas, right. What I have with that is a winner.

390
00:25:10,106 --> 00:25:12,954
Like I have a winner. Parameters,

391
00:25:13,082 --> 00:25:17,038
parameters which is basically like what my simulation is telling

392
00:25:17,054 --> 00:25:20,334
me here. It's like why don't you use two for scale

393
00:25:20,382 --> 00:25:24,434
of increment and 15 for the

394
00:25:24,472 --> 00:25:27,960
upper threshold like these two here,

395
00:25:29,050 --> 00:25:33,542
the lower threshold, it doesn't matter a lot. And what

396
00:25:33,596 --> 00:25:38,194
says like for that load

397
00:25:38,242 --> 00:25:41,802
shape that I used here the average cpu should be around

398
00:25:41,856 --> 00:25:45,834
16% and the maximum cp utilization should be 39%.

399
00:25:45,952 --> 00:25:50,038
Right. And I choose the best based on the average cp utilization

400
00:25:50,134 --> 00:25:53,930
and up threshold and scale increment. So by

401
00:25:54,000 --> 00:25:57,726
prioritizing have like a very average high cp utilization because I

402
00:25:57,748 --> 00:26:01,034
want to use the most cp utilization

403
00:26:01,082 --> 00:26:04,738
that I can from my holds and I

404
00:26:04,744 --> 00:26:08,258
think upper threshold. It seems that

405
00:26:08,424 --> 00:26:11,502
yeah, I chose like this shouldn't

406
00:26:11,566 --> 00:26:15,910
matter that much. It's just like to have a parameter

407
00:26:16,890 --> 00:26:21,110
if there's a draw here. But I think what I'm really interested

408
00:26:21,260 --> 00:26:25,714
is in average cpuization. That cpu

409
00:26:25,762 --> 00:26:29,210
from my hosts, right? And when I

410
00:26:29,280 --> 00:26:32,954
actually run the simulator against those

411
00:26:32,992 --> 00:26:36,682
parameters, things look a lot better, right? It does

412
00:26:36,736 --> 00:26:39,370
spin off hosts faster.

413
00:26:40,510 --> 00:26:44,458
They add hosts at two increments at a time, and cpu

414
00:26:44,474 --> 00:26:47,902
utilization is below here, 50%. So it seems

415
00:26:47,956 --> 00:26:51,054
that this setup is a lot better than what

416
00:26:51,092 --> 00:26:55,186
we had. So I take these parameters and

417
00:26:55,208 --> 00:26:58,798
I actually apply those parameters to production.

418
00:26:58,894 --> 00:27:02,930
And I run a real load testing using low cost

419
00:27:03,080 --> 00:27:06,834
again, right? And I try to like. There's a way

420
00:27:06,872 --> 00:27:10,786
to set up the shape in low

421
00:27:10,808 --> 00:27:14,102
cost as well. So it does create here

422
00:27:14,156 --> 00:27:17,640
like an incremental ramp up.

423
00:27:18,830 --> 00:27:21,530
It does this by adding new users.

424
00:27:21,950 --> 00:27:27,500
And I ran that for maybe

425
00:27:29,070 --> 00:27:33,040
40 minutes, about 40 minutes. And we see that things

426
00:27:33,570 --> 00:27:36,670
stabilize, right? Like from the low testing

427
00:27:37,410 --> 00:27:40,974
two perspective, right, the p 95%,

428
00:27:41,092 --> 00:27:44,686
it does have like a d two spike, but it's like 40 milliseconds

429
00:27:44,718 --> 00:27:48,450
in terms of response prime. And it's quite stable, right? Like after

430
00:27:48,520 --> 00:27:52,050
some time, my application runs very stable.

431
00:27:52,790 --> 00:27:56,118
Let's see the parameters. And then I get the

432
00:27:56,124 --> 00:27:59,686
same parameters. This is the traffic that I was

433
00:27:59,708 --> 00:28:04,534
able to generate. I wasn't able to get 150%.

434
00:28:04,652 --> 00:28:08,774
It peaked here to 120k

435
00:28:08,892 --> 00:28:12,582
rpm. But it did work.

436
00:28:12,716 --> 00:28:16,406
We see how the hosts were being created

437
00:28:16,438 --> 00:28:20,342
here. We see that in cremine it added

438
00:28:20,406 --> 00:28:23,258
two hosts at a time. And we see the cpuization,

439
00:28:23,354 --> 00:28:26,894
it didn't reach 39%. I think the peak here was

440
00:28:26,932 --> 00:28:30,942
about 26, 27%. So it's pretty good.

441
00:28:31,076 --> 00:28:34,702
And the response time here, it was quite

442
00:28:34,756 --> 00:28:36,560
stable as well. Right?

443
00:28:39,970 --> 00:28:43,950
Based on that, we can compare

444
00:28:44,370 --> 00:28:47,986
our a simulator, like our simulation,

445
00:28:48,098 --> 00:28:52,022
to what happened in real life. This is

446
00:28:52,076 --> 00:28:55,714
like my simulation. When I use the request

447
00:28:55,762 --> 00:28:59,714
per minute data from my load testing,

448
00:28:59,842 --> 00:29:03,914
this is the superiorization that it predicted it would be using.

449
00:29:04,032 --> 00:29:07,338
Like this is my simulation, this is what actually

450
00:29:07,424 --> 00:29:10,734
happened in real life. And we see here how

451
00:29:10,852 --> 00:29:14,378
I predicted that the hosts would be created. My simulation,

452
00:29:14,474 --> 00:29:18,190
it seems to be a little bit slower than what happens

453
00:29:18,260 --> 00:29:22,074
in real life. Like the AWS,

454
00:29:22,202 --> 00:29:25,662
it starts adding new hosts earlier,

455
00:29:25,726 --> 00:29:29,314
like five minutes earlier probably. My simulation can

456
00:29:29,352 --> 00:29:32,530
be changed. So it

457
00:29:32,600 --> 00:29:35,926
better represents how the actual

458
00:29:36,108 --> 00:29:40,214
dynamic scaling in AWS works to mimic this behavior. And we

459
00:29:40,252 --> 00:29:44,054
see that my missimulation, it's adding hosts a little bit

460
00:29:44,092 --> 00:29:47,914
faster than what we see on AWS. So it

461
00:29:47,952 --> 00:29:51,498
starts a little bit later, but it

462
00:29:51,584 --> 00:29:55,494
increments faster. AWS outscaling

463
00:29:55,542 --> 00:29:58,950
group with the dynamic scaling policies,

464
00:29:59,110 --> 00:30:02,634
scales a little bit slower, but it starts

465
00:30:02,682 --> 00:30:07,070
earlier, right? So that's the difference between my simulation

466
00:30:07,650 --> 00:30:11,134
and what we see in real life. But I mean, I think

467
00:30:11,172 --> 00:30:14,514
this is quite interesting because we learned a lot how

468
00:30:14,632 --> 00:30:18,226
autoscaling works, right? Like how the autoscaling group and its

469
00:30:18,248 --> 00:30:21,970
autoscaling policies, how they work, by using Python to model

470
00:30:22,040 --> 00:30:25,438
this and verify what parameters can be

471
00:30:25,464 --> 00:30:29,574
used. The other part that I find really interesting is

472
00:30:29,612 --> 00:30:32,886
that I ran the load testing in production, and it

473
00:30:32,908 --> 00:30:36,822
just worked. That was like the first attempt just

474
00:30:36,876 --> 00:30:41,050
worked. I think that's really powerful.

475
00:30:41,390 --> 00:30:45,370
Usually you don't see that when you're doing load testing.

476
00:30:45,710 --> 00:30:49,226
It's quite common to go bad, and you

477
00:30:49,248 --> 00:30:52,798
have to stop the load testing because you're having issues

478
00:30:52,884 --> 00:30:56,874
or because it's just not working, because you have the wrong parameters

479
00:30:57,002 --> 00:31:00,110
set in your scanning configuration.

480
00:31:00,530 --> 00:31:04,142
So I think that's basically the takeaways

481
00:31:04,286 --> 00:31:08,798
that I have found here, and that's how we can use Python

482
00:31:08,974 --> 00:31:12,882
to actually reason and think

483
00:31:12,936 --> 00:31:17,298
about how we can do things we can do in production,

484
00:31:17,394 --> 00:31:20,950
right, in AWS infrastructure.

485
00:31:22,250 --> 00:31:25,538
And the conclusion here from my experimentation is that when I changed

486
00:31:25,554 --> 00:31:29,382
the upper threshold to 15, from 25 to 15,

487
00:31:29,516 --> 00:31:32,858
and the upper increment, it did work, it was

488
00:31:32,944 --> 00:31:36,074
efficiently, and I didn't have

489
00:31:36,272 --> 00:31:39,926
problems. I think we

490
00:31:39,968 --> 00:31:42,720
can assert that the code,

491
00:31:44,050 --> 00:31:47,374
I uploaded the code here, right? So you

492
00:31:47,412 --> 00:31:50,990
can access that. The code that I used for this, it's very simple code.

493
00:31:51,060 --> 00:31:54,426
There's nothing sophisticated for this. I'm using pandas

494
00:31:54,458 --> 00:31:58,030
for data manipulation, Jupiter for notebooking,

495
00:31:58,110 --> 00:32:03,566
so I can mix python

496
00:32:03,598 --> 00:32:07,442
code with graphics that I created, and it's more

497
00:32:07,496 --> 00:32:10,994
dynamic to do this kind of thing. Locust for load testing,

498
00:32:11,042 --> 00:32:13,750
and both of three to get AWS client.

499
00:32:14,570 --> 00:32:18,290
This technique here you can use for other topics as well.

500
00:32:18,460 --> 00:32:22,374
For provisioning, for capacity planning, for caching,

501
00:32:22,422 --> 00:32:25,386
for example. There are some tools that you can use for that.

502
00:32:25,488 --> 00:32:28,746
You can use the same tooling to understand

503
00:32:28,848 --> 00:32:32,654
how you should be setting up your alarms. You can

504
00:32:32,692 --> 00:32:36,138
use that to troubleshoot problems you have in our infrastructure.

505
00:32:36,234 --> 00:32:40,010
I think it's a very powerful, powerful approach,

506
00:32:40,090 --> 00:32:43,700
and I think there's a trend at the park for

507
00:32:46,070 --> 00:32:50,258
DevOps senior site reliability engineers to start

508
00:32:50,344 --> 00:32:54,094
using this kind of tooling in order to make the infrastructure

509
00:32:54,142 --> 00:32:57,350
better. Just using the observability tooling,

510
00:32:58,170 --> 00:33:01,686
you hit a limit of the things that you can do quite fast.

511
00:33:01,788 --> 00:33:05,522
So, Jupiter and Python,

512
00:33:05,586 --> 00:33:09,010
I think it's a very powerful tooling.

513
00:33:09,170 --> 00:33:13,254
I hope you have enjoyed, if you were able to with

514
00:33:13,292 --> 00:33:16,690
me, I hope you have enjoyed this approach.

515
00:33:16,770 --> 00:33:21,200
You can reach me through my LinkedIn page. It's available.

516
00:33:22,290 --> 00:33:25,614
It's here, right? LinkedIn or my

517
00:33:25,652 --> 00:33:29,486
GitHub is this one or you can drop me a message on Twitter as

518
00:33:29,508 --> 00:33:33,486
well. Right? So I hope you guys have enjoyed this and thank

519
00:33:33,508 --> 00:33:35,500
you for watching this.

