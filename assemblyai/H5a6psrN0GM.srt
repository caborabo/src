1
00:00:20,640 --> 00:00:24,998
Hi everybody. Today I want to talk about techniques

2
00:00:25,086 --> 00:00:29,034
that allow you to reduce the load on the server

3
00:00:29,334 --> 00:00:32,154
and keep your service running smoothly,

4
00:00:32,694 --> 00:00:37,074
preventing server overload in case of traffic bursts.

5
00:00:37,574 --> 00:00:41,118
In particular, I will be talking about rate

6
00:00:41,166 --> 00:00:44,558
limiting and load shedding. A little

7
00:00:44,606 --> 00:00:48,470
disclaimer by service, I mean any

8
00:00:48,502 --> 00:00:52,874
backend application. It can be a monolithic application

9
00:00:53,334 --> 00:00:57,262
or an individual microservice in a large distributed

10
00:00:57,318 --> 00:01:00,634
system. But first, let me

11
00:01:01,214 --> 00:01:03,594
tell you a little bit about me.

12
00:01:04,294 --> 00:01:07,526
My name is Ivan Lemeshev. I live

13
00:01:07,550 --> 00:01:10,966
in Finland. I moved here over three years

14
00:01:10,990 --> 00:01:14,766
ago, and since then I have been working at

15
00:01:14,790 --> 00:01:17,674
Unity as a senior software engineer.

16
00:01:18,294 --> 00:01:21,934
I have been using Golang as my primary programming language

17
00:01:22,054 --> 00:01:25,714
for many years and I am interested in the development

18
00:01:26,304 --> 00:01:30,004
of large scale and distributed systems.

19
00:01:30,544 --> 00:01:34,584
You can find me on LinkedIn or GitHub

20
00:01:34,704 --> 00:01:37,936
by following the links to begin

21
00:01:38,000 --> 00:01:41,728
with, let's look at the agenda for this

22
00:01:41,776 --> 00:01:45,608
talk. First, I will discuss survey

23
00:01:45,656 --> 00:01:48,504
overload, why it occurs,

24
00:01:48,664 --> 00:01:52,436
and how it affects the performance of backend

25
00:01:52,500 --> 00:01:56,548
services. I'll give you an example of common

26
00:01:56,596 --> 00:01:59,064
causes of server overload,

27
00:01:59,364 --> 00:02:03,156
and then I'll show you what it looks like

28
00:02:03,300 --> 00:02:07,104
in the example of a simple HTTP service.

29
00:02:07,924 --> 00:02:11,884
After that, I'll consider techniques that

30
00:02:11,964 --> 00:02:14,628
help prevent server overload.

31
00:02:14,796 --> 00:02:19,186
I'll start with rate limiting and review common

32
00:02:19,380 --> 00:02:22,934
rate limiting algorithms. Then I'll

33
00:02:22,974 --> 00:02:26,174
show you a simple implementation of one

34
00:02:26,214 --> 00:02:29,774
of the algorithms, and you will see how it

35
00:02:29,814 --> 00:02:33,934
works. Next, I will discuss another technique

36
00:02:34,014 --> 00:02:37,638
called load shedding and show

37
00:02:37,686 --> 00:02:41,358
you a simple well, let's get

38
00:02:41,406 --> 00:02:45,774
started. When we develop a backend application,

39
00:02:45,934 --> 00:02:49,412
we deploy it to a server to make it available

40
00:02:49,508 --> 00:02:52,796
to users. As a server,

41
00:02:52,980 --> 00:02:56,916
both physical and virtual servers

42
00:02:56,980 --> 00:03:00,784
can be used. It doesn't matter.

43
00:03:01,484 --> 00:03:05,460
Each server always has limited computational or

44
00:03:05,532 --> 00:03:09,544
system resources, such as cpu or memory.

45
00:03:10,204 --> 00:03:14,556
The service utilizes some of these resources to

46
00:03:14,620 --> 00:03:17,224
process each incoming user request,

47
00:03:17,964 --> 00:03:21,196
including managing multiple tasks,

48
00:03:21,380 --> 00:03:25,108
switching between them, cleaning up unused memory,

49
00:03:25,276 --> 00:03:29,544
and waiting for data to come in or go out.

50
00:03:30,204 --> 00:03:34,836
The server can process only a particular

51
00:03:35,020 --> 00:03:40,424
number of concurrent user requests simultaneously

52
00:03:41,084 --> 00:03:44,388
under heavy load. When a system is given

53
00:03:44,476 --> 00:03:48,264
more work than each resources support,

54
00:03:49,004 --> 00:03:53,100
it starts experiencing a lack of resources

55
00:03:53,212 --> 00:03:55,904
and becomes slow,

56
00:03:56,644 --> 00:04:00,804
which leads to an increase in the processing time

57
00:04:00,924 --> 00:04:05,244
or latency. For each request. The service reaches

58
00:04:05,324 --> 00:04:08,652
some threshold where its

59
00:04:08,708 --> 00:04:11,144
performance degrades rapidly.

60
00:04:12,124 --> 00:04:16,256
It can keep working even when it

61
00:04:16,280 --> 00:04:20,632
is overloaded, but it spends amounts

62
00:04:20,648 --> 00:04:24,576
of time contacts switching and

63
00:04:24,760 --> 00:04:28,208
becomes too slow to be useful because

64
00:04:28,376 --> 00:04:32,248
most likely the client has some timeouts

65
00:04:32,416 --> 00:04:36,296
and can't wait for the response from the

66
00:04:36,320 --> 00:04:39,672
service too long. Therefore,

67
00:04:39,848 --> 00:04:44,092
the service performance and availability of

68
00:04:44,148 --> 00:04:47,788
your service will be declined because

69
00:04:47,916 --> 00:04:51,620
almost all requests will fail due

70
00:04:51,652 --> 00:04:55,484
to high latency and timeouts. In the

71
00:04:55,524 --> 00:04:58,652
worst case, the server may

72
00:04:58,708 --> 00:05:03,100
completely crash and stop handling requests

73
00:05:03,252 --> 00:05:06,988
due to running out of memory or other

74
00:05:07,036 --> 00:05:11,182
resources. Of course, we can use auto scaling and

75
00:05:11,238 --> 00:05:13,994
deploy additional service instances,

76
00:05:14,294 --> 00:05:18,142
but it doesn't happen instantly if

77
00:05:18,278 --> 00:05:21,798
the load grows gracefully. Auto scaling works

78
00:05:21,846 --> 00:05:25,230
well. However, deploying an appropriate

79
00:05:25,302 --> 00:05:29,262
number of additional instances requires time

80
00:05:29,358 --> 00:05:33,762
if we have a traffic burst and the load is

81
00:05:33,918 --> 00:05:35,694
exceptionally high.

82
00:05:36,434 --> 00:05:40,482
Also, there may be a situation when an

83
00:05:40,538 --> 00:05:43,874
individual user or a group of users

84
00:05:43,954 --> 00:05:47,694
may produce so many requests,

85
00:05:48,434 --> 00:05:52,374
consuming all the system resources, and other service

86
00:05:52,794 --> 00:05:55,818
users will be unable to use it.

87
00:05:55,946 --> 00:05:58,814
In this case, auto scaling will not help.

88
00:05:59,484 --> 00:06:03,076
Now let's explore situations

89
00:06:03,140 --> 00:06:06,264
where a surge of traffic can occur.

90
00:06:07,084 --> 00:06:10,892
Traffic bursts can occur due to various

91
00:06:10,988 --> 00:06:14,424
reasons, both predictable and unpredictable.

92
00:06:15,084 --> 00:06:19,188
For predictable reasons, there could be different scheduled

93
00:06:19,316 --> 00:06:22,748
events or planned events like product launches,

94
00:06:22,916 --> 00:06:26,104
sales, promotions, marketing campaigns,

95
00:06:26,574 --> 00:06:30,034
or even regular peak hours can lead

96
00:06:30,614 --> 00:06:33,894
to a surge in traffic as users try

97
00:06:33,934 --> 00:06:38,754
to access the service or website simultaneously.

98
00:06:39,454 --> 00:06:42,606
Another reason is seasonal traffic.

99
00:06:42,790 --> 00:06:47,034
Businesses in specific industries might experience

100
00:06:47,494 --> 00:06:50,438
seasonal spikes in traffic. For example,

101
00:06:50,606 --> 00:06:54,192
e commerce sites might see

102
00:06:54,248 --> 00:06:57,768
a search during holidays or

103
00:06:57,856 --> 00:07:01,632
back to school seasons. The next one is

104
00:07:01,768 --> 00:07:04,364
the time of day or week.

105
00:07:05,024 --> 00:07:09,184
Traffic patterns can change regularly depending

106
00:07:09,264 --> 00:07:13,176
on the target audience and service type.

107
00:07:13,280 --> 00:07:16,936
For example, social media platforms see

108
00:07:17,000 --> 00:07:21,294
higher traffic during evenings or weekends

109
00:07:21,874 --> 00:07:26,866
for unpredictable reasons. There could be different

110
00:07:27,050 --> 00:07:31,370
viral events like social media trends,

111
00:07:31,562 --> 00:07:36,018
news articles, or influencer mentions can

112
00:07:36,066 --> 00:07:39,610
drive sudden traffic bursts to a website

113
00:07:39,762 --> 00:07:43,894
or service. Also, there could be different

114
00:07:44,354 --> 00:07:46,674
technical issues. For instance,

115
00:07:47,014 --> 00:07:51,350
system outages on competitor platforms

116
00:07:51,462 --> 00:07:54,750
can lead to users flocking

117
00:07:54,782 --> 00:07:57,434
to a service, causing a temporary spike.

118
00:07:58,054 --> 00:08:01,926
Another very popular reason is denial of service

119
00:08:02,030 --> 00:08:06,246
attacks. It is when malicious actors might

120
00:08:06,310 --> 00:08:10,438
attempt to overwhelm a system with traffic,

121
00:08:10,566 --> 00:08:13,990
causing a spike and potentially disrupting

122
00:08:14,062 --> 00:08:17,288
functionalities. The next one is bot

123
00:08:17,336 --> 00:08:21,832
activity. Automated bots or

124
00:08:21,968 --> 00:08:25,816
scripts can cause unexpected bursts,

125
00:08:25,880 --> 00:08:29,984
especially if they are scrapping data or attempting

126
00:08:30,024 --> 00:08:34,440
to exploit vulnerabilities. There could also be

127
00:08:34,512 --> 00:08:38,784
issues with external dependencies. For instance,

128
00:08:38,944 --> 00:08:42,752
if your service relies on external

129
00:08:42,808 --> 00:08:44,604
APIs or services,

130
00:08:45,464 --> 00:08:49,040
outages or slowdowns on their end can

131
00:08:49,112 --> 00:08:53,432
lead to a cascading effect and cause traffic

132
00:08:53,488 --> 00:08:57,056
spikes for your users trying to access features

133
00:08:57,120 --> 00:09:00,204
that depend on those external services.

134
00:09:00,944 --> 00:09:04,376
By understanding these potential causes, you can

135
00:09:04,480 --> 00:09:07,830
better prepare for traffic bursts. Well,

136
00:09:07,942 --> 00:09:11,734
now let's look at the example of server

137
00:09:11,814 --> 00:09:14,874
overload. To demonstrate this,

138
00:09:15,694 --> 00:09:18,910
I implemented a simple HTTP service in

139
00:09:18,942 --> 00:09:22,534
go. The main function sets up an

140
00:09:22,574 --> 00:09:26,994
HTTP server that listens on port 8000.

141
00:09:27,574 --> 00:09:31,310
It registers a single root

142
00:09:31,502 --> 00:09:35,516
with a handler function. The handler function attempts

143
00:09:35,540 --> 00:09:39,204
to extract a path parameter length from

144
00:09:39,244 --> 00:09:44,024
the requests, convert it to an integer value

145
00:09:44,724 --> 00:09:48,452
and use it to generate a password.

146
00:09:48,628 --> 00:09:52,124
If the length parameter cannot be converted to an integer,

147
00:09:52,284 --> 00:09:55,660
for example, if it's not a number, the function

148
00:09:55,732 --> 00:09:58,744
responds with 400 status.

149
00:09:59,044 --> 00:10:02,276
If the length parameter is successfully

150
00:10:02,380 --> 00:10:06,068
converted to an integer, the function generates a password

151
00:10:06,116 --> 00:10:10,356
of that length and then generated password is sent back to

152
00:10:10,380 --> 00:10:12,664
the client with 200 status.

153
00:10:13,364 --> 00:10:17,624
I use the docker container to run this service

154
00:10:18,044 --> 00:10:21,860
because it allows us to simulate limited

155
00:10:21,932 --> 00:10:25,104
resources. You will see it in the next slide.

156
00:10:25,884 --> 00:10:29,564
I built and run the service using this

157
00:10:29,644 --> 00:10:33,492
simple dockerfile, the application using

158
00:10:33,668 --> 00:10:37,460
the Golang image in the build stage, and then it

159
00:10:37,492 --> 00:10:40,932
uses the distr less base image from

160
00:10:40,988 --> 00:10:44,584
Google's container registry to run the service.

161
00:10:46,204 --> 00:10:50,356
This image contains only the application and its

162
00:10:50,460 --> 00:10:54,126
runtime dependencies, and it is

163
00:10:54,270 --> 00:10:56,394
designed to be as small as possible.

164
00:10:57,294 --> 00:11:00,902
Then I built a docker image from

165
00:11:00,958 --> 00:11:04,438
the dockerfile. I set the

166
00:11:04,526 --> 00:11:08,198
cpu option to one to limit

167
00:11:08,246 --> 00:11:12,030
the number of cpu cores that also

168
00:11:12,142 --> 00:11:15,302
I set two options, memory and memory.

169
00:11:15,358 --> 00:11:18,862
Swap 300 megabytes to limit the

170
00:11:18,918 --> 00:11:22,728
containers memory. I have to set

171
00:11:22,776 --> 00:11:26,584
both options to the same value to prevent

172
00:11:26,704 --> 00:11:30,056
the container from using. When we

173
00:11:30,160 --> 00:11:33,404
have a running service, we need to test

174
00:11:33,984 --> 00:11:38,432
for that I use a load testing tool called Grafana

175
00:11:38,488 --> 00:11:41,664
k six. Here is a script that is

176
00:11:41,704 --> 00:11:45,724
used by this tool. It is just a simple JavaScript file

177
00:11:46,404 --> 00:11:49,984
with some configuration for the test.

178
00:11:50,564 --> 00:11:54,252
The test consists of four stages. In the

179
00:11:54,348 --> 00:11:58,076
stage one, we gracefully increase the number of virtual

180
00:11:58,140 --> 00:12:02,144
users from zero to 1000

181
00:12:02,484 --> 00:12:06,316
for two minutes, and then in stage

182
00:12:06,380 --> 00:12:10,024
two we keep the number of users at 1000

183
00:12:10,484 --> 00:12:14,538
for another two minutes. In the stage three,

184
00:12:14,706 --> 00:12:18,538
we ramp up to 2000

185
00:12:18,626 --> 00:12:22,186
virtual users for two minutes. And finally in

186
00:12:22,210 --> 00:12:27,014
stage four we keep the number of users at 2000

187
00:12:27,354 --> 00:12:29,254
for another two minutes.

188
00:12:30,234 --> 00:12:34,534
In the default function, we define the user logic.

189
00:12:35,034 --> 00:12:38,242
Each virtual user makes a get request to

190
00:12:38,258 --> 00:12:42,466
the service to generate a password. Then the user sleeps

191
00:12:42,610 --> 00:12:46,138
for 100 milliseconds that

192
00:12:46,186 --> 00:12:49,914
simulates approximately ten requests per second

193
00:12:49,994 --> 00:12:53,654
from a single user. After that,

194
00:12:54,114 --> 00:12:58,674
I just run the test using this command for

195
00:12:58,754 --> 00:13:02,858
it to end. I also use a web dashboard

196
00:13:02,946 --> 00:13:06,374
as an output to visualize the test results.

197
00:13:06,904 --> 00:13:10,544
It produces graphs showing the number

198
00:13:10,584 --> 00:13:13,888
of requests latency and other

199
00:13:13,976 --> 00:13:17,824
metrics. In the graph, we can

200
00:13:17,864 --> 00:13:21,376
see how latency changes depending on

201
00:13:21,400 --> 00:13:23,844
the number of requests per second.

202
00:13:24,304 --> 00:13:28,440
Initially, we gracefully increased the number of users and

203
00:13:28,512 --> 00:13:31,752
the service could handle that load. The latency

204
00:13:31,808 --> 00:13:35,482
was very low and then after four minutes

205
00:13:35,538 --> 00:13:39,210
we increased the number of users up to 2000

206
00:13:39,322 --> 00:13:42,498
and the service started to experience

207
00:13:42,666 --> 00:13:46,714
a lack of resources. That led to a significant increase

208
00:13:46,794 --> 00:13:51,014
in latency and the server became overloaded.

209
00:13:51,394 --> 00:13:55,694
In the following graph we can see the latency distribution

210
00:13:56,434 --> 00:14:00,494
by percentile. From these results we can understand

211
00:14:01,564 --> 00:14:06,004
that when we use system resources at maximum,

212
00:14:06,164 --> 00:14:09,824
the latency significantly increases many times.

213
00:14:10,604 --> 00:14:13,564
But this is just an artificial example.

214
00:14:13,724 --> 00:14:17,660
In the actual application the latency

215
00:14:17,732 --> 00:14:21,140
might be higher and there will

216
00:14:21,292 --> 00:14:24,604
likely be some timeout on the client side that will

217
00:14:24,644 --> 00:14:28,332
drop requests and make the service unavailable

218
00:14:28,428 --> 00:14:32,180
for users. We have discussed server overload

219
00:14:32,252 --> 00:14:36,092
and its causes. Also we saw what it looks like

220
00:14:36,188 --> 00:14:39,804
in the example. Now lets look at the first

221
00:14:39,884 --> 00:14:43,144
technique that can be used in this situation.

222
00:14:44,524 --> 00:14:47,744
First I want to discuss rate limiting.

223
00:14:48,164 --> 00:14:51,224
Sometimes it also called throttling,

224
00:14:52,044 --> 00:14:55,264
so these terms may be used interchangeably.

225
00:14:55,994 --> 00:14:59,654
Rate limiting is a technique used to control

226
00:15:00,354 --> 00:15:04,254
the flow of requests to a network,

227
00:15:04,594 --> 00:15:07,854
resource server or API.

228
00:15:08,234 --> 00:15:12,554
It essentially sets a limit on how often a user

229
00:15:12,634 --> 00:15:16,850
or application can perform a specific

230
00:15:16,922 --> 00:15:19,734
action within a given time frame.

231
00:15:20,234 --> 00:15:23,634
It protects against malicious activities like denial

232
00:15:23,674 --> 00:15:28,172
of service attacks where attackers try to overwhelm

233
00:15:28,308 --> 00:15:31,820
a system with excessive requests,

234
00:15:31,972 --> 00:15:35,012
making it unavailable to legitimate users.

235
00:15:35,148 --> 00:15:38,252
Also, it helps ensure fair access

236
00:15:38,308 --> 00:15:42,284
to resources by preventing single users

237
00:15:42,364 --> 00:15:45,540
or applications for monopolizing them.

238
00:15:45,692 --> 00:15:50,244
It is especially important when the

239
00:15:50,284 --> 00:15:54,134
service for services with limited resources

240
00:15:54,754 --> 00:15:58,810
by controlling the request rate. Rate limiting prevents

241
00:15:58,882 --> 00:16:02,314
overloading the server and helps

242
00:16:02,354 --> 00:16:06,054
maintain optimal performance for all users.

243
00:16:06,474 --> 00:16:10,506
We can limit the request rate per an IP

244
00:16:10,570 --> 00:16:13,642
address or a user identifier,

245
00:16:13,738 --> 00:16:17,874
an API key, or other criteria depending

246
00:16:17,994 --> 00:16:22,034
on a particular use case. For example,

247
00:16:22,114 --> 00:16:25,722
we can load ten requests per minute from

248
00:16:25,778 --> 00:16:29,306
a single IP address, and if the number

249
00:16:29,370 --> 00:16:32,674
of requests per minute is less or equal to

250
00:16:32,714 --> 00:16:36,450
that value, we process a request.

251
00:16:36,602 --> 00:16:40,458
Otherwise, if the limit is exceeded,

252
00:16:40,626 --> 00:16:44,234
we will drop the request. There are many

253
00:16:44,394 --> 00:16:48,114
algorithms and variations of them

254
00:16:48,274 --> 00:16:52,338
for implementing rate limiting. I'll briefly review

255
00:16:52,426 --> 00:16:54,854
just the most common of them.

256
00:16:55,554 --> 00:16:59,414
One is the fixed window counter algorithm.

257
00:17:00,034 --> 00:17:04,294
This algorithm divides time into equal sized

258
00:17:05,194 --> 00:17:09,214
time intervals or fixed windows.

259
00:17:09,554 --> 00:17:13,442
The window size can be defined in milliseconds,

260
00:17:13,578 --> 00:17:17,144
seconds, minutes, or any other irrelevant unit

261
00:17:17,184 --> 00:17:20,744
depending on the use case. Each window

262
00:17:20,864 --> 00:17:24,880
has a request counter that allows the algorithm

263
00:17:25,072 --> 00:17:29,216
to keep track of how many requests occur

264
00:17:29,400 --> 00:17:33,400
within each window. As a request arrives,

265
00:17:33,592 --> 00:17:37,204
the algorithm checks the current timestamp.

266
00:17:37,864 --> 00:17:41,256
It decides which window the timestamp falls

267
00:17:41,320 --> 00:17:44,858
into based on the window

268
00:17:44,906 --> 00:17:48,014
size and the starting point on the current window.

269
00:17:48,594 --> 00:17:51,970
If the request falls within the current window,

270
00:17:52,122 --> 00:17:56,134
the counter for that window is incremented by one.

271
00:17:56,514 --> 00:18:00,082
Otherwise, a new window starts, the counter is

272
00:18:00,138 --> 00:18:03,266
reset to zero and incremented by

273
00:18:03,330 --> 00:18:06,494
one, and the start time of the window is updated.

274
00:18:07,234 --> 00:18:10,810
Then, if the counter value is less or equal to

275
00:18:10,842 --> 00:18:14,636
the limit, the rate limiter allows the request to

276
00:18:14,660 --> 00:18:17,828
be processed. Otherwise the request

277
00:18:17,876 --> 00:18:21,864
is dropped if the counter value exceeds the limit.

278
00:18:22,364 --> 00:18:25,668
The example on the slide shows

279
00:18:25,756 --> 00:18:29,188
that we have a 1 minute window size

280
00:18:29,276 --> 00:18:32,692
and set the rate limit to five requests

281
00:18:32,788 --> 00:18:36,476
per minute in each window. The first five

282
00:18:36,540 --> 00:18:40,622
requests were processed, all other requests

283
00:18:40,718 --> 00:18:43,794
were dropped. As you can see,

284
00:18:44,414 --> 00:18:47,710
this algorithm is quite simple.

285
00:18:47,902 --> 00:18:51,950
However, it has a big drawback which

286
00:18:52,022 --> 00:18:55,154
you have probably already noticed here.

287
00:18:55,854 --> 00:18:59,734
Since the counter is reset when the new window

288
00:18:59,814 --> 00:19:03,014
is started, the rate limiter doesn't know

289
00:19:03,094 --> 00:19:06,402
how many requests were

290
00:19:06,458 --> 00:19:09,818
made in the previous window. It leads to

291
00:19:09,866 --> 00:19:13,114
some issues. For example, in this picture,

292
00:19:13,234 --> 00:19:17,218
the total number of requests per minute was more than

293
00:19:17,266 --> 00:19:21,090
five because requests burst at

294
00:19:21,122 --> 00:19:24,474
the end of the second window and the beginning

295
00:19:24,514 --> 00:19:28,418
of the third window. The fixed window counter

296
00:19:28,466 --> 00:19:31,858
algorithm is easy to understand and implement because it

297
00:19:31,906 --> 00:19:35,680
only requires keeping track of a counter for

298
00:19:35,712 --> 00:19:39,760
each window. Also, it is efficient because

299
00:19:39,952 --> 00:19:44,640
it requires only basic counter operations and

300
00:19:44,712 --> 00:19:47,960
it has low memory usage because it only needs to

301
00:19:47,992 --> 00:19:51,744
store the counter value for a window, which is typically

302
00:19:51,824 --> 00:19:54,964
a small amount of data. However,

303
00:19:55,904 --> 00:19:59,924
request bursts are possible on edgest when

304
00:20:01,044 --> 00:20:03,940
switching between windows,

305
00:20:04,012 --> 00:20:08,260
and this algorithm is not suitable for

306
00:20:08,372 --> 00:20:12,628
identifying frequent requests since the counter is set

307
00:20:12,716 --> 00:20:16,384
at each window. The following algorithm

308
00:20:17,084 --> 00:20:20,144
is sliding window lock.

309
00:20:20,604 --> 00:20:24,388
It also uses a window, but this

310
00:20:24,436 --> 00:20:28,268
window slides a long time representing the

311
00:20:28,316 --> 00:20:31,424
relevant time frame. For rate limiting,

312
00:20:32,084 --> 00:20:35,580
the window size can be also defined

313
00:20:35,692 --> 00:20:39,124
in milliseconds, seconds, minutes, or any

314
00:20:39,164 --> 00:20:42,224
other relevant unit, depending on the use case.

315
00:20:42,804 --> 00:20:46,164
Instead of request counter, this algorithm

316
00:20:46,324 --> 00:20:50,620
keeps track of for each incoming request and

317
00:20:50,692 --> 00:20:54,598
stores it in the the log can

318
00:20:54,646 --> 00:20:57,918
be stored in a data structure like

319
00:20:58,006 --> 00:21:01,622
hash table or sorted

320
00:21:01,678 --> 00:21:04,594
set for efficient retrieval.

321
00:21:05,334 --> 00:21:07,914
As the window slides forward,

322
00:21:08,494 --> 00:21:12,998
timestamps outside the current window become

323
00:21:13,126 --> 00:21:17,174
irrelevant for rate limiting purposes

324
00:21:17,254 --> 00:21:20,004
and removed from the log.

325
00:21:20,464 --> 00:21:24,536
A new request arrives. Each timestamp

326
00:21:24,680 --> 00:21:28,304
is added to the log. The algorithm

327
00:21:28,384 --> 00:21:32,320
calculates the total number of requests within the current window

328
00:21:32,472 --> 00:21:35,496
by iterating through the remaining timestamps

329
00:21:35,520 --> 00:21:39,884
in the log to decide if the request should be allowed.

330
00:21:40,504 --> 00:21:44,420
The request is processed in. The total count

331
00:21:44,532 --> 00:21:48,308
within the window is less than

332
00:21:48,476 --> 00:21:51,624
or equal to the allowed limit.

333
00:21:52,324 --> 00:21:55,540
Otherwise, it's considered a rate limit

334
00:21:55,572 --> 00:21:58,756
violation and might be rejected.

335
00:21:58,940 --> 00:22:01,264
Let's look at the example.

336
00:22:02,524 --> 00:22:07,180
In this example, we allow two requests

337
00:22:07,252 --> 00:22:11,270
per minute when the first requests when

338
00:22:11,302 --> 00:22:14,750
the first request is saved to the lock,

339
00:22:14,862 --> 00:22:18,326
there is only one request in the lock at

340
00:22:18,350 --> 00:22:22,014
that point in time, so the request is allowed

341
00:22:22,134 --> 00:22:25,478
and processed. Then the second

342
00:22:25,566 --> 00:22:29,558
request comes and each timestamp is

343
00:22:29,646 --> 00:22:33,114
saved to the lock as well. Now there are two

344
00:22:34,054 --> 00:22:37,358
requests in the lock. All of them fall within

345
00:22:37,406 --> 00:22:40,506
the current window, so the number of requests

346
00:22:40,570 --> 00:22:44,654
is equal to the limit and the request can be processed.

347
00:22:45,194 --> 00:22:49,294
Then the third request comes and each timestamp

348
00:22:49,634 --> 00:22:53,362
is saved to the lock. Now there are three requests

349
00:22:53,538 --> 00:22:56,574
that fall into the current window,

350
00:22:57,234 --> 00:23:01,442
then the limit, so the request is rejected,

351
00:23:01,578 --> 00:23:05,124
and finally the fourth request comes comes.

352
00:23:05,704 --> 00:23:09,724
Each timestamp is also saved to the lock.

353
00:23:10,144 --> 00:23:13,960
There are only two requests that fall within the

354
00:23:13,992 --> 00:23:17,320
current window at that point in time,

355
00:23:17,432 --> 00:23:21,384
and there are two all

356
00:23:21,424 --> 00:23:24,844
timestamps that do not fall into the current window.

357
00:23:25,384 --> 00:23:28,720
The old timestamps are removed from

358
00:23:28,752 --> 00:23:33,646
the lock and the new request is allowed and

359
00:23:33,710 --> 00:23:37,302
processed. Because the number of requests in

360
00:23:37,318 --> 00:23:40,154
the current window equals the limit,

361
00:23:40,494 --> 00:23:45,958
the algorithm captures recent surges in requests

362
00:23:46,046 --> 00:23:50,526
more accurately than the fixed window counter because

363
00:23:50,630 --> 00:23:54,510
it considers only relevant requests within the

364
00:23:54,542 --> 00:23:58,254
sliding window can effectively handle bursts

365
00:23:58,294 --> 00:24:02,528
of requests. However, storing timestamps

366
00:24:02,576 --> 00:24:06,144
for all requests requires

367
00:24:06,224 --> 00:24:09,664
a lot of memory and it can be memory

368
00:24:09,824 --> 00:24:13,368
intensive, especially for high requests

369
00:24:13,496 --> 00:24:17,128
volumes. Also, it's more complex because it

370
00:24:17,176 --> 00:24:20,896
requires maintenance and iteration through the request

371
00:24:20,960 --> 00:24:24,400
log following algorithm is

372
00:24:24,512 --> 00:24:28,224
called sliding window counter.

373
00:24:28,804 --> 00:24:32,636
It offers a balance between simplicity

374
00:24:32,740 --> 00:24:36,468
and accuracy compared to fixed window

375
00:24:36,516 --> 00:24:39,384
counter and sliding window log algorithms.

376
00:24:39,724 --> 00:24:43,900
The algorithm maintains a counter variable

377
00:24:44,092 --> 00:24:47,724
and fixit size window duration similar

378
00:24:47,804 --> 00:24:51,812
to the fixed window counter, but in addition,

379
00:24:51,948 --> 00:24:55,490
it uses a sliding window to represent

380
00:24:55,602 --> 00:24:59,218
the relevant time frame for

381
00:24:59,266 --> 00:25:02,642
rate limiting. Unlike the sliding window

382
00:25:02,738 --> 00:25:06,506
log algorithm, it doesn't sort for

383
00:25:06,570 --> 00:25:10,554
all requests. Instead, it keeps track of

384
00:25:10,594 --> 00:25:14,170
the counters for fixed window and calculates a

385
00:25:14,202 --> 00:25:17,014
weighted counter for the sliding window.

386
00:25:17,754 --> 00:25:21,758
When a new request arrives. The algorithm calculates

387
00:25:21,846 --> 00:25:25,702
a weighted counter using the sliding window time frame

388
00:25:25,878 --> 00:25:29,214
and request counters for the previous and current

389
00:25:29,294 --> 00:25:32,750
windows. For that, it uses a percent

390
00:25:32,822 --> 00:25:36,510
of time. The sliding window overlaps with

391
00:25:36,542 --> 00:25:40,486
the previous fixit window, the number of requests

392
00:25:40,590 --> 00:25:44,726
from the previous fixit window, and the number of requests

393
00:25:44,790 --> 00:25:47,916
from the current fixit window. You can see

394
00:25:47,980 --> 00:25:51,604
the formula on the slide. The resulting

395
00:25:51,644 --> 00:25:54,700
value of these calculations is a

396
00:25:54,732 --> 00:25:58,068
weighted counter. Then, the algorithm

397
00:25:58,196 --> 00:26:02,224
compares the weighted counter with the limit value.

398
00:26:02,924 --> 00:26:06,276
The request is allowed and processed if

399
00:26:06,300 --> 00:26:09,384
the counter is less or equal to the limit.

400
00:26:09,964 --> 00:26:12,864
Otherwise, the request is dropped.

401
00:26:13,214 --> 00:26:16,518
The old counters from previous fixed windows

402
00:26:16,566 --> 00:26:20,078
are removed from tracking when they are

403
00:26:20,126 --> 00:26:24,454
no longer relevant for a sliding window. The algorithm

404
00:26:24,574 --> 00:26:28,102
captures recent requests rate trends

405
00:26:28,158 --> 00:26:31,510
more accurately than the fixed window

406
00:26:31,542 --> 00:26:35,478
counter as it considers requests that

407
00:26:35,526 --> 00:26:39,526
fall within the sliding window. Also, it avoids

408
00:26:39,590 --> 00:26:42,930
storing timestamps for all requests,

409
00:26:42,962 --> 00:26:46,202
make it more memory efficient and

410
00:26:46,258 --> 00:26:50,314
easier to implement than sliding window log

411
00:26:50,354 --> 00:26:53,474
algorithm. However, it is

412
00:26:53,554 --> 00:26:57,254
less precise than sliding window log algorithm.

413
00:26:57,874 --> 00:27:01,706
The next algorithm is as

414
00:27:01,730 --> 00:27:05,454
you can see from the name, it uses a concept

415
00:27:06,014 --> 00:27:09,874
of a bucket that contains tokens.

416
00:27:10,174 --> 00:27:13,434
The bucket has a fixed size

417
00:27:14,134 --> 00:27:18,354
representing the maximum number of tokens it can hold.

418
00:27:19,014 --> 00:27:22,350
Each token represents a capacity to process

419
00:27:22,462 --> 00:27:25,630
a single request. In other words,

420
00:27:25,782 --> 00:27:29,566
the bucket size defines a maximum number of requests

421
00:27:29,710 --> 00:27:33,374
the system can handle at a time.

422
00:27:33,834 --> 00:27:37,574
So the bucket size represents rate limit.

423
00:27:37,994 --> 00:27:41,850
The bucket is constantly refilled with new tokens

424
00:27:41,962 --> 00:27:46,258
at a constant rate called the refill rate, which defines

425
00:27:46,346 --> 00:27:49,578
how quickly the bucket refills

426
00:27:49,626 --> 00:27:53,522
with tokens over time, ten tokens per

427
00:27:53,578 --> 00:27:57,370
second. Therefore, the refill rate controls

428
00:27:57,402 --> 00:28:01,146
the average rate at which request can be processed.

429
00:28:01,170 --> 00:28:05,546
Processed when a request arrives, the algorithm

430
00:28:05,650 --> 00:28:09,050
checks if there are enough tokens in the bucket.

431
00:28:09,242 --> 00:28:13,370
If there are tokens in the bucket, it consumes a token or removes

432
00:28:13,442 --> 00:28:17,234
it from the bucket and allows to be

433
00:28:17,314 --> 00:28:20,530
processed. Otherwise, if the bucket

434
00:28:20,562 --> 00:28:24,334
is empty, the request is dropped.

435
00:28:25,194 --> 00:28:29,130
On the one hand, this algorithm is relatively easy to implement.

436
00:28:29,242 --> 00:28:32,662
However, it is also slightly more complex

437
00:28:32,718 --> 00:28:36,034
due to the token management logic.

438
00:28:36,374 --> 00:28:39,438
It is efficient and uses low memory because

439
00:28:39,526 --> 00:28:43,022
it keeps tracks of the bucket size, which is typically just

440
00:28:43,078 --> 00:28:47,238
a number that is incremented or documented over

441
00:28:47,326 --> 00:28:50,966
time. It allows

442
00:28:51,070 --> 00:28:54,794
for a smooth distribution of requests,

443
00:28:55,094 --> 00:28:59,302
but bursts of requests up to the bucket's capacitor

444
00:28:59,398 --> 00:29:02,750
possible in cases when the bucket

445
00:29:02,782 --> 00:29:06,478
is full and a large number of requests arrive

446
00:29:06,566 --> 00:29:10,022
simultaneously. And finally, the last

447
00:29:10,078 --> 00:29:13,254
algorithm for today is leaky

448
00:29:13,294 --> 00:29:17,262
bucket algorithm. It also uses

449
00:29:17,358 --> 00:29:20,574
the concept of a bucket, but in a

450
00:29:20,614 --> 00:29:25,004
different way. It is like the analogy of

451
00:29:25,174 --> 00:29:28,816
a bucket with a hole at

452
00:29:28,840 --> 00:29:32,208
the bottom that constantly leaks at a fixed

453
00:29:32,256 --> 00:29:36,584
rate. The bucket can hold a

454
00:29:36,624 --> 00:29:40,576
specific number of requests representing its

455
00:29:40,680 --> 00:29:45,040
maximum capacity. The requests leak

456
00:29:45,232 --> 00:29:48,244
out from the bucket at a fixed rate.

457
00:29:49,584 --> 00:29:52,984
This leak rate specifies sustain

458
00:29:53,024 --> 00:29:57,004
it rate at which the system can process requests.

459
00:29:57,544 --> 00:30:01,240
When a request arrives and the bucket

460
00:30:01,312 --> 00:30:04,392
is not full, a new request is added to

461
00:30:04,408 --> 00:30:07,680
the bucket and processed. If the bucket

462
00:30:07,712 --> 00:30:10,644
is full, the request is dropped.

463
00:30:11,104 --> 00:30:14,664
The liquor bucket algorithm is good at

464
00:30:14,704 --> 00:30:18,124
smoothing out requests because the requests

465
00:30:18,434 --> 00:30:22,682
leak out and processed at a controlled

466
00:30:22,738 --> 00:30:26,802
rate, preventing surges or bursts

467
00:30:26,858 --> 00:30:30,834
of traffic. However, it doesn't

468
00:30:30,914 --> 00:30:34,250
account for the time between requests,

469
00:30:34,442 --> 00:30:38,186
which means if a user sends a

470
00:30:38,210 --> 00:30:40,374
burst of requests quickly,

471
00:30:40,954 --> 00:30:44,278
it all be dropped, even if

472
00:30:44,326 --> 00:30:47,750
they are under the overall rate

473
00:30:47,862 --> 00:30:52,542
limit. We have reviewed rate

474
00:30:52,598 --> 00:30:56,262
limiting algorithms. Each algorithm

475
00:30:56,398 --> 00:30:59,994
has pros and cons, so you should consider

476
00:31:01,094 --> 00:31:04,902
trade offs based on the particular use

477
00:31:04,958 --> 00:31:08,674
case when choosing an algorithm for rate limiting.

478
00:31:09,394 --> 00:31:13,146
Also, each algorithm may

479
00:31:13,290 --> 00:31:16,834
be implemented differently depending

480
00:31:16,954 --> 00:31:20,466
on the requirements. Now let's look

481
00:31:20,530 --> 00:31:24,618
at the simple implementation of a rate limiter based

482
00:31:24,666 --> 00:31:26,894
on the token bucket algorithm.

483
00:31:27,474 --> 00:31:31,538
For the example, I implemented the

484
00:31:31,586 --> 00:31:34,574
rate limiter logic in a separate package.

485
00:31:35,134 --> 00:31:39,862
Here I use the bucketstruct as

486
00:31:39,878 --> 00:31:43,862
a token bucket. It has two fields, current tokens,

487
00:31:43,998 --> 00:31:47,702
which is the number of tokens currently in the bucket and last refill

488
00:31:47,758 --> 00:31:52,034
time, which is the last time the bucket was refilled.

489
00:31:52,854 --> 00:31:56,878
Then I define the token bucket instruct which

490
00:31:56,926 --> 00:32:00,534
represents the rate limiter. It has a mutex

491
00:32:00,654 --> 00:32:05,294
for thread safety and map buckets

492
00:32:06,634 --> 00:32:11,370
that stores a bucket some

493
00:32:11,442 --> 00:32:14,714
key. As a key, I will use the

494
00:32:14,754 --> 00:32:16,614
client's ip addresses.

495
00:32:17,754 --> 00:32:22,106
Also, it has two fields bucket size

496
00:32:22,290 --> 00:32:26,458
which represents maximum number of tokens, a single bucket hand hold

497
00:32:26,626 --> 00:32:30,478
and refill rate, or the rate at which tokens are added

498
00:32:30,526 --> 00:32:34,590
to the bucket. Then I define new

499
00:32:34,702 --> 00:32:38,366
token bucket function that just

500
00:32:38,430 --> 00:32:42,134
creates a new rate limiter with specified bucket

501
00:32:42,174 --> 00:32:45,046
size, refill rates, and empty buckets.

502
00:32:45,110 --> 00:32:48,914
Map this rate limiter has one method

503
00:32:49,734 --> 00:32:53,718
that's called isallowed. This method

504
00:32:53,766 --> 00:32:57,834
checks if a request with the specified key is allowed.

505
00:32:59,334 --> 00:33:02,646
If there is no bucket with a

506
00:33:02,670 --> 00:33:06,254
given key, it creates a new bucket for the

507
00:33:06,294 --> 00:33:08,994
key and allows the request.

508
00:33:09,414 --> 00:33:12,994
If the key exists. It refills a bucket.

509
00:33:13,414 --> 00:33:17,238
It checks at least one token

510
00:33:17,326 --> 00:33:20,358
in the bucket. If there is a token,

511
00:33:20,446 --> 00:33:24,676
it decrements number of tokens and

512
00:33:24,860 --> 00:33:30,784
allows the request otherwise denies

513
00:33:31,804 --> 00:33:35,508
the refill. Method refills the bucket for

514
00:33:35,676 --> 00:33:39,124
the specified key. It calculates the number of

515
00:33:39,164 --> 00:33:42,988
tokens to add based on the time elapsed since the last

516
00:33:43,036 --> 00:33:46,892
refill and the refill rate after

517
00:33:46,948 --> 00:33:50,124
that. It adds them to the bucket, up to the bucket

518
00:33:50,164 --> 00:33:54,664
size, and updates the last refill time. I also use

519
00:33:55,404 --> 00:33:58,604
middleware for that example,

520
00:33:58,724 --> 00:34:02,332
I define a middleware to use for rate limiting.

521
00:34:02,508 --> 00:34:06,036
I have a simple rate limiter interface that contains only

522
00:34:06,100 --> 00:34:10,064
one method is allowed. This interface

523
00:34:10,764 --> 00:34:14,892
allows allows us to use

524
00:34:14,948 --> 00:34:18,612
different rate limiter implementations depending

525
00:34:18,708 --> 00:34:22,198
on our needs and replace them

526
00:34:22,246 --> 00:34:26,646
more easily. Then I define rate limiting middleware

527
00:34:26,710 --> 00:34:30,318
function. It checks if a request is allowed

528
00:34:30,366 --> 00:34:33,838
by calling the isallowed method of the rate

529
00:34:33,886 --> 00:34:37,022
limiter with the remote address of the request.

530
00:34:37,198 --> 00:34:42,934
If the request is not allowed, it responds with 429

531
00:34:43,094 --> 00:34:46,554
status corresponding status text.

532
00:34:46,944 --> 00:34:51,312
If the request is allowed, it calls the original handler

533
00:34:51,368 --> 00:34:54,604
function. I use the same service

534
00:34:55,184 --> 00:34:59,484
as the previous example, but with a few changes.

535
00:34:59,984 --> 00:35:03,056
Initialize the rate limiter first with a

536
00:35:03,080 --> 00:35:07,248
bucket size of one token and refill rate of one token

537
00:35:07,296 --> 00:35:10,488
per second. That means that

538
00:35:10,576 --> 00:35:14,140
we allow approximately one request

539
00:35:14,252 --> 00:35:17,584
per second from a single user,

540
00:35:18,204 --> 00:35:21,636
the handler function with the rate limiter middleware,

541
00:35:21,780 --> 00:35:25,904
and pass the rate limiting limiter there

542
00:35:28,364 --> 00:35:31,684
I use the same test configuration as previous

543
00:35:31,764 --> 00:35:35,300
example and the result test

544
00:35:35,372 --> 00:35:39,440
results show that even rate limiter allowed

545
00:35:39,572 --> 00:35:43,160
us to decrease the average load on the

546
00:35:43,192 --> 00:35:46,560
server and the latest is not as high

547
00:35:46,632 --> 00:35:50,656
as before. However, it can't improve the performance

548
00:35:50,760 --> 00:35:54,680
significantly in this case. Because rate limiter is

549
00:35:54,752 --> 00:35:58,960
integrated into the service, it also uses the same system

550
00:35:59,032 --> 00:36:02,664
resources. You should always remember about it.

551
00:36:02,784 --> 00:36:06,754
Using a rate limiter has its overhead

552
00:36:06,834 --> 00:36:10,106
and costs as well. You have to

553
00:36:10,130 --> 00:36:14,122
consider different trade offs and find

554
00:36:14,218 --> 00:36:18,074
a balance between using a rate limiter and the

555
00:36:18,114 --> 00:36:21,370
performance of the service. Moreover,

556
00:36:21,562 --> 00:36:25,218
you can't just use the rate limiter from the example

557
00:36:25,266 --> 00:36:29,522
in the real production applications because you need some shared

558
00:36:29,578 --> 00:36:33,194
state with counters that can be used in all instances

559
00:36:33,274 --> 00:36:36,612
of the application. For example, you can use

560
00:36:36,668 --> 00:36:40,364
redis to store the counters and get them from redis during rate

561
00:36:40,404 --> 00:36:43,916
limiter checks. Also, you will likely need a

562
00:36:43,940 --> 00:36:47,940
distributed rate limiter that can be implemented in a separated

563
00:36:48,012 --> 00:36:51,308
service, for example in the API,

564
00:36:51,356 --> 00:36:53,864
gateway or other solutions.

565
00:36:54,884 --> 00:36:58,452
In addition, on this slide I provided the

566
00:36:58,508 --> 00:37:02,504
list of different implementations of rate limiters in

567
00:37:02,544 --> 00:37:05,872
Golang. You can check these packages, see how

568
00:37:05,928 --> 00:37:09,208
different algorithms are implemented,

569
00:37:09,376 --> 00:37:12,936
and use one of them in your application if

570
00:37:12,960 --> 00:37:16,204
it suits your particular use case.

571
00:37:16,784 --> 00:37:20,504
We have considered server overload,

572
00:37:20,664 --> 00:37:24,544
the rate limiting technique, and common rate limiting algorithms.

573
00:37:24,624 --> 00:37:26,924
Also, we saw it in examples.

574
00:37:27,404 --> 00:37:31,340
Now let's look at another technique

575
00:37:31,412 --> 00:37:33,424
called load shedding.

576
00:37:34,684 --> 00:37:38,108
Load shedding is another technique that is used

577
00:37:38,196 --> 00:37:41,924
to prevent server overload. It is like a controlled

578
00:37:41,964 --> 00:37:46,196
shutdown to prevent a total crash during

579
00:37:46,300 --> 00:37:49,668
a traffic overload. It can be implemented

580
00:37:49,756 --> 00:37:53,824
in different ways. For example, the system can

581
00:37:54,194 --> 00:37:57,906
constantly check its resources,

582
00:37:58,090 --> 00:38:02,242
such as cpu and memory. If things

583
00:38:02,338 --> 00:38:05,174
get overloaded,

584
00:38:06,074 --> 00:38:10,042
load shedding kicks in. It might reject

585
00:38:10,178 --> 00:38:14,454
random or non critical incoming requests,

586
00:38:15,754 --> 00:38:19,802
prioritizing critical ones. Also, the system

587
00:38:19,938 --> 00:38:23,924
might slow down process processing for non critical tasks.

588
00:38:24,304 --> 00:38:28,264
The system also might redirect some requests

589
00:38:28,424 --> 00:38:32,084
to other services if possible.

590
00:38:33,024 --> 00:38:37,016
By sacrificing some requests,

591
00:38:37,120 --> 00:38:40,552
the system stays operational for

592
00:38:40,608 --> 00:38:44,472
the most important ones. Critical requests

593
00:38:44,608 --> 00:38:48,084
still get processed within a reasonable time frame.

594
00:38:48,574 --> 00:38:51,742
A controlled slowdown is better

595
00:38:51,878 --> 00:38:55,594
than a complete system breakdown in this situation.

596
00:38:55,974 --> 00:38:59,034
However, as always, there are some trade offs.

597
00:38:59,414 --> 00:39:02,590
Users might experience delays

598
00:39:02,702 --> 00:39:07,198
or errors for some requests during

599
00:39:07,366 --> 00:39:11,794
shedding. Depending on the system, some data

600
00:39:12,414 --> 00:39:15,994
processing might be delayed or even lost.

601
00:39:16,434 --> 00:39:20,094
So now let's look at an example.

602
00:39:20,674 --> 00:39:24,178
To demonstrate this technique, I implemented a simple

603
00:39:24,306 --> 00:39:28,586
algorithm to decide if the system is overloaded

604
00:39:28,730 --> 00:39:31,854
and reject random requests.

605
00:39:32,994 --> 00:39:36,094
I will use a ticker from the time package,

606
00:39:36,434 --> 00:39:40,334
and I assume that if the system is overloaded

607
00:39:40,714 --> 00:39:44,974
we will have some delays and the ticker will not work.

608
00:39:46,264 --> 00:39:50,912
I strongly do not recommend this algorithm

609
00:39:51,048 --> 00:39:54,844
for production applications is just for

610
00:39:55,544 --> 00:39:58,856
demonstration purposes. I implemented the

611
00:39:58,880 --> 00:40:02,244
logic in a separate package called overload detector.

612
00:40:02,944 --> 00:40:06,680
Here I define overload detector struct that will

613
00:40:06,832 --> 00:40:10,576
be used to detect if a system is overload

614
00:40:10,640 --> 00:40:14,544
based on a specified overload factor

615
00:40:15,284 --> 00:40:18,772
structure has three fields.

616
00:40:18,908 --> 00:40:22,716
Check interval is the duration between each check

617
00:40:22,780 --> 00:40:27,732
for overload. For overload overload

618
00:40:27,788 --> 00:40:32,364
factor is a duration that is considered as

619
00:40:32,404 --> 00:40:35,812
a threshold for overload and is

620
00:40:35,868 --> 00:40:39,360
overloaded flag indicating where

621
00:40:39,432 --> 00:40:43,488
the system is overloaded. I use bool

622
00:40:43,656 --> 00:40:47,832
from the sync atomic package for thread

623
00:40:47,888 --> 00:40:52,008
safety. Then I define the new

624
00:40:52,056 --> 00:40:55,728
function which just creates a new overload

625
00:40:55,776 --> 00:40:59,564
detector arguments and

626
00:41:00,624 --> 00:41:04,364
the overload detector check in the background

627
00:41:05,214 --> 00:41:08,534
using the run method. Also, I have

628
00:41:08,574 --> 00:41:12,182
isoverloaded method that just returns the

629
00:41:12,198 --> 00:41:13,954
value for the flag,

630
00:41:15,094 --> 00:41:19,794
and in the run method we

631
00:41:20,694 --> 00:41:24,286
do the check if the system is overloaded.

632
00:41:24,430 --> 00:41:28,038
First we initialize the ticker that if the system

633
00:41:28,086 --> 00:41:32,994
is overloaded every check interval on

634
00:41:33,034 --> 00:41:36,594
each tick, it checks. If the time since the last

635
00:41:36,634 --> 00:41:40,174
check is greater than the overload factor,

636
00:41:40,834 --> 00:41:44,490
it considers the system as overloaded and sets the

637
00:41:44,522 --> 00:41:47,866
flag to the true value. If it is not, it sets

638
00:41:47,890 --> 00:41:52,202
the flag to false I also define a middleware for

639
00:41:52,298 --> 00:41:55,490
load sharing as I have done for rate

640
00:41:55,522 --> 00:41:59,326
limit meeting. I have a simple overload detector

641
00:41:59,390 --> 00:42:03,114
interface that contains only one method is overloaded.

642
00:42:03,814 --> 00:42:07,454
Then I define the overload detecting

643
00:42:07,494 --> 00:42:11,086
middleware function. It checks if request

644
00:42:11,190 --> 00:42:15,154
is allowed by calling the isoverloaded method,

645
00:42:15,614 --> 00:42:19,462
and if the server is overloaded it responds

646
00:42:19,518 --> 00:42:23,890
with 500 and

647
00:42:23,922 --> 00:42:26,334
if the system is not overloaded,

648
00:42:27,914 --> 00:42:31,454
it calls the original handler function.

649
00:42:32,794 --> 00:42:36,170
Again, I use the same service as the previous example but

650
00:42:36,202 --> 00:42:39,914
with few changes. I initialize the overload

651
00:42:39,954 --> 00:42:43,874
detector with a check interval of ten milliseconds

652
00:42:43,954 --> 00:42:47,496
and an overload factor of eleven milliseconds.

653
00:42:47,690 --> 00:42:52,244
Then I wrap the handler function with the overload

654
00:42:52,284 --> 00:42:55,972
detecting middleware and pass the overload

655
00:42:56,028 --> 00:42:59,284
detector. There, I use the same

656
00:42:59,324 --> 00:43:02,864
test configuration as the previous examples.

657
00:43:03,284 --> 00:43:07,596
The test results shows that using the overload shedding

658
00:43:07,660 --> 00:43:11,584
allowed us to decrease the average load on the server.

659
00:43:11,924 --> 00:43:15,538
Depending on the particular case and requirements,

660
00:43:15,626 --> 00:43:19,414
load shedding can be implemented differently in the real production.

661
00:43:20,754 --> 00:43:24,954
To understand load shedding better and the

662
00:43:24,994 --> 00:43:29,162
approaches for its implementation, I recommend

663
00:43:29,218 --> 00:43:33,242
reading this article by a senior principal engineer at

664
00:43:33,298 --> 00:43:37,546
Amazon that explains load shedding in more

665
00:43:37,650 --> 00:43:41,734
detail. Well, we have explored

666
00:43:42,034 --> 00:43:45,526
server overload and how it can

667
00:43:45,670 --> 00:43:50,038
affect your services at

668
00:43:50,126 --> 00:43:53,886
common reasons for overload and how

669
00:43:53,950 --> 00:43:56,354
to identify them.

670
00:43:56,894 --> 00:44:00,670
We then reviewed two key techniques to

671
00:44:00,702 --> 00:44:04,446
make your systems more resilient, rate limiting,

672
00:44:04,590 --> 00:44:08,494
health control incoming traffic and prevent overload

673
00:44:08,574 --> 00:44:12,546
before it happens, and load shedding that

674
00:44:12,610 --> 00:44:15,374
acts as a safety valve,

675
00:44:15,874 --> 00:44:19,054
gracefully degrading service during

676
00:44:20,034 --> 00:44:23,562
extreme traffic surges to maintain

677
00:44:23,658 --> 00:44:25,574
overall system stability.

678
00:44:26,274 --> 00:44:29,826
Understanding and implementing these techniques

679
00:44:29,890 --> 00:44:33,778
ensures your services stay healthy

680
00:44:33,866 --> 00:44:38,394
and responsive even under heavy

681
00:44:38,474 --> 00:44:42,894
load. Remember, a well designed system

682
00:44:43,714 --> 00:44:47,722
anticipates traffic spikes and

683
00:44:47,818 --> 00:44:51,482
has mechanisms to handle

684
00:44:51,578 --> 00:44:54,930
them effectively. So I hope

685
00:44:55,082 --> 00:44:58,778
you found this talk helpful. Thanks for

686
00:44:58,826 --> 00:44:59,394
your time.

