1
00:00:20,760 --> 00:00:24,806
Hi everyone, thanks for joining for my talk on isolation

2
00:00:24,870 --> 00:00:28,114
levels and partial failures in distributed systems.

3
00:00:28,954 --> 00:00:32,770
So most of my talk in this particular session

4
00:00:32,802 --> 00:00:37,450
will be covering the non functional aspects of distributed

5
00:00:37,482 --> 00:00:39,014
systems like consistency,

6
00:00:40,074 --> 00:00:43,554
isolation, concurrency, performance,

7
00:00:43,674 --> 00:00:47,814
availability and reliability. Why they're important and

8
00:00:48,834 --> 00:00:53,094
what problems are we trying to solve. So to begin with,

9
00:00:54,434 --> 00:00:57,918
I would start off with the concept of isolation

10
00:00:58,106 --> 00:01:01,486
and why is it important in transactions?

11
00:01:01,590 --> 00:01:05,734
And even before that, what is a transaction?

12
00:01:05,774 --> 00:01:08,958
Right. So any event or any

13
00:01:09,006 --> 00:01:13,230
operation that we do in our day to day life, say you're purchasing

14
00:01:13,302 --> 00:01:17,278
something on an e commerce platform, or you're editing a Google document,

15
00:01:17,406 --> 00:01:20,974
or reading from a Google document, or browsing

16
00:01:21,014 --> 00:01:24,574
something on the Internet and looking at some data. Anything and

17
00:01:24,614 --> 00:01:28,332
everything involves two things. Either it is a read

18
00:01:28,428 --> 00:01:32,092
or a write operation in the distributed system. Say when you are purchasing something on

19
00:01:32,108 --> 00:01:35,500
the Internet, on the ecommerce platform, you are actually making

20
00:01:35,532 --> 00:01:39,332
a payment. And for that you need to update a database record.

21
00:01:39,388 --> 00:01:43,500
So that means you're writing something in the DB, the database, in the backend,

22
00:01:43,692 --> 00:01:46,948
or when you're viewing something on the

23
00:01:46,956 --> 00:01:50,812
ecommerce platform to purchase something, that means you are reading the data.

24
00:01:50,948 --> 00:01:54,374
So it's just read or write. What happens

25
00:01:54,414 --> 00:01:57,398
when so many of us, it's not just one person,

26
00:01:57,486 --> 00:02:00,646
millions of people across the globe trying to read and

27
00:02:00,670 --> 00:02:04,434
write the data onto these distributed systems

28
00:02:04,894 --> 00:02:08,454
concurrently, at the same time. So lot of

29
00:02:08,574 --> 00:02:11,854
things needed to be handled at the back end. What is that? Lot of things.

30
00:02:11,894 --> 00:02:15,662
So most importantly, concurrency. So the concept of

31
00:02:15,678 --> 00:02:18,754
concurrency in itself explains that it coming

32
00:02:18,794 --> 00:02:22,706
into picture as we all try to interact with these distributed systems.

33
00:02:22,810 --> 00:02:26,674
So what is important is the

34
00:02:26,714 --> 00:02:30,106
acid properties of the database. Like what is

35
00:02:30,130 --> 00:02:34,010
acid, the atomicity, consistency, isolation and

36
00:02:34,042 --> 00:02:37,434
durability. So among these four, I would be focusing

37
00:02:37,474 --> 00:02:40,818
on the isolation aspect of this

38
00:02:40,866 --> 00:02:45,006
particular data based systems in the distributed

39
00:02:45,070 --> 00:02:48,334
environment. So these properties are fundamental

40
00:02:48,374 --> 00:02:52,542
principles of these database management systems that ensure the reliability,

41
00:02:52,598 --> 00:02:56,142
integrity and correctness of transactions. Now in this,

42
00:02:56,238 --> 00:03:00,182
let's talk about the isolation and what is

43
00:03:00,238 --> 00:03:03,974
isolation? And in that, what are these isolation levels and

44
00:03:04,014 --> 00:03:08,154
why are they needed in this distributed systems environment?

45
00:03:08,654 --> 00:03:12,486
So isolation means that a transaction should take place in a system in

46
00:03:12,510 --> 00:03:17,576
such a way that that is the only transaction that

47
00:03:17,600 --> 00:03:20,896
is accessing the resources in the distributed system. So like

48
00:03:20,920 --> 00:03:24,816
I mentioned earlier, many of us are trying to access these systems.

49
00:03:24,880 --> 00:03:28,004
Say, while I took this example here, e commerce platform,

50
00:03:29,344 --> 00:03:33,416
some users are trying to, users are trying to

51
00:03:33,600 --> 00:03:36,936
say, purchase some items. Buyer one is trying to look

52
00:03:36,960 --> 00:03:40,356
at all the products and also buyer two and

53
00:03:40,380 --> 00:03:43,652
buyer three, all of them are looking at some products and as you can

54
00:03:43,668 --> 00:03:46,620
see, buyer one and buyer two are trying to purchase,

55
00:03:46,812 --> 00:03:50,956
read and write, that is, view and purchase the

56
00:03:50,980 --> 00:03:54,744
same product, which is the Jim Klaus here. And there is

57
00:03:55,244 --> 00:03:59,276
a view buyer three who is trying to also read

58
00:03:59,340 --> 00:04:03,820
and purchase, read and write a couple of products like

59
00:04:03,852 --> 00:04:07,524
motorcycle helmet and office chair at the same time while the seller is trying to

60
00:04:07,564 --> 00:04:10,828
update the price of the product. So that means a lot of concurrency.

61
00:04:10,876 --> 00:04:15,324
Lot of concurrent things are happening here. So imagine

62
00:04:15,364 --> 00:04:19,300
that you're implementing like a distributed system, an e commerce system like this.

63
00:04:19,412 --> 00:04:23,060
All these operations have to take place at the same time, right? Multiple customers

64
00:04:23,092 --> 00:04:26,596
simultaneously want to purchase the same product, prices of the product

65
00:04:26,660 --> 00:04:30,252
may change, and new products are still being delivered. So on. As you know,

66
00:04:30,268 --> 00:04:34,220
a single action done by a user is run as a transaction

67
00:04:34,252 --> 00:04:38,360
in a database, which I just explained. So we need some logic to

68
00:04:38,392 --> 00:04:42,256
maintain the consistency. And that's the role of isolation,

69
00:04:42,400 --> 00:04:46,288
because it controls whether locks

70
00:04:46,336 --> 00:04:49,632
are taken, when the data is read, and what type

71
00:04:49,648 --> 00:04:52,736
of locks are requested, how long the

72
00:04:52,760 --> 00:04:57,912
read locks are held, so that the

73
00:04:57,968 --> 00:05:01,120
viewer is able to see a proper consistent data

74
00:05:01,272 --> 00:05:04,990
before some new data gets updated. Whether a read operation

75
00:05:05,142 --> 00:05:08,950
referencing some rows modified by another transaction,

76
00:05:09,102 --> 00:05:12,822
say here, the seller updating the price of a particular

77
00:05:12,878 --> 00:05:16,422
product, which the buyer three is reading. So it blocks until

78
00:05:16,478 --> 00:05:19,670
the exclusive lock on the row is freed or

79
00:05:19,702 --> 00:05:23,742
retrieves the committed version of the row that existed at the time the

80
00:05:23,798 --> 00:05:27,518
transaction started. It's depending on the isolation

81
00:05:27,566 --> 00:05:31,306
levels. So these are the things which is controlled by

82
00:05:31,330 --> 00:05:35,034
the isolation level. And let me again go into

83
00:05:35,154 --> 00:05:38,978
what is an isolation level and what are the different types of isolation

84
00:05:39,026 --> 00:05:41,946
levels. So simple, right?

85
00:05:42,010 --> 00:05:45,626
Putting in simple terms, database isolation defines the degree

86
00:05:45,650 --> 00:05:49,894
to which a transaction must be isolated from the data modifications

87
00:05:50,194 --> 00:05:54,230
made by any other transaction. Say multiple,

88
00:05:54,402 --> 00:05:58,394
multiple transactions, or multiple people are trying to access the same record.

89
00:05:59,334 --> 00:06:02,814
How much degree of isolation, how much isolation is needed for

90
00:06:02,854 --> 00:06:06,774
either reading or writing is called this

91
00:06:06,814 --> 00:06:10,542
isolation level, and there can be a large number of concurrently

92
00:06:10,558 --> 00:06:13,926
running transactions. So that's why the goal is to prevent reads

93
00:06:13,950 --> 00:06:17,254
and writes of temporary, aborted,

94
00:06:17,374 --> 00:06:21,050
or otherwise incorrect data written by concurrent transactions,

95
00:06:21,142 --> 00:06:24,642
right? Say if someone is writing the data and hasn't committed the data,

96
00:06:24,698 --> 00:06:28,218
and someone else is reading the data, which is not committed,

97
00:06:28,306 --> 00:06:32,026
not supposed to happen, right? So you shouldn't let read happen, say when,

98
00:06:32,210 --> 00:06:35,954
until a transaction is committed, write transaction is committed. An example,

99
00:06:36,114 --> 00:06:40,154
by the way, while I'm explaining that, I already gave an example of dirty

100
00:06:40,194 --> 00:06:44,514
read. So here you can see there's a problem or a phenomena

101
00:06:44,594 --> 00:06:47,870
of concurrent transactions called dirty read,

102
00:06:48,042 --> 00:06:51,558
where a transaction reads data written by

103
00:06:51,646 --> 00:06:55,870
a concurrent uncommitted transaction. Here, the uncommitted

104
00:06:55,902 --> 00:06:59,718
data is called dirty. For example. Let's take the example on

105
00:06:59,726 --> 00:07:02,674
the right hand side. On the screen here I presented,

106
00:07:03,214 --> 00:07:06,582
let's say a transaction one updates a row in a database

107
00:07:06,678 --> 00:07:08,714
and leaves it uncommitted.

108
00:07:09,454 --> 00:07:13,602
Meanwhile, transaction two reads the updated data updated

109
00:07:13,658 --> 00:07:17,614
row. So if transaction one rolls back that change

110
00:07:18,514 --> 00:07:22,210
like it's aborted, or it rolls

111
00:07:22,242 --> 00:07:26,066
back, transaction two will have red data that is considered to

112
00:07:26,090 --> 00:07:30,294
never have existed, right? So we shouldn't let

113
00:07:30,994 --> 00:07:34,642
someone read until the data is actually

114
00:07:34,698 --> 00:07:38,842
committed. So that's what this read

115
00:07:38,898 --> 00:07:42,160
committed isolation level means. As you can see on the left

116
00:07:42,192 --> 00:07:46,440
side of the picture, not letting transaction two

117
00:07:46,592 --> 00:07:50,424
read the data. T two to read the data until the t

118
00:07:50,464 --> 00:07:54,480
one has finished writing and then updating it. So that's

119
00:07:54,512 --> 00:07:58,144
what read committed isolation level

120
00:07:58,224 --> 00:07:59,844
means. Now,

121
00:08:01,384 --> 00:08:05,096
the isolation level does not allow any other transaction

122
00:08:05,120 --> 00:08:09,022
to write or read row to which another

123
00:08:09,078 --> 00:08:12,198
transaction has written two. But dotnet committed another

124
00:08:12,246 --> 00:08:15,550
transaction. Here is t one. That's what I just explained. Thus it does not

125
00:08:15,582 --> 00:08:18,894
allow allow dirty read, right? So you're locking

126
00:08:18,974 --> 00:08:22,486
on the read, not letting read to happen. The transaction holds a

127
00:08:22,510 --> 00:08:26,326
read or a write lock on the current row, and thus prevents other transactions from

128
00:08:26,350 --> 00:08:30,270
reading, updating, or deleting it. Now, what things are guaranteed

129
00:08:30,302 --> 00:08:33,726
with this? Right? Firstly, let's talk about three aspects,

130
00:08:33,910 --> 00:08:38,238
which I was saying the non functional aspects. First is consistency. So read

131
00:08:38,286 --> 00:08:42,182
committed provides good balance between consistency and concurrency.

132
00:08:42,318 --> 00:08:46,086
It ensures that transactions only see committed data, right? So preventing

133
00:08:46,110 --> 00:08:48,834
dirty reads so consistency is good.

134
00:08:49,854 --> 00:08:53,502
You are like across different systems or different

135
00:08:53,558 --> 00:08:57,318
nodes, there won't be any wrong data or inconsistent data.

136
00:08:57,486 --> 00:09:01,198
Secondly, concurrency read committed

137
00:09:01,326 --> 00:09:05,754
allows for higher concurrency compared to other strong isolation levels

138
00:09:06,374 --> 00:09:10,126
like repeatable read, which we'll be covering later because it

139
00:09:10,150 --> 00:09:14,474
releases locks as soon as the data is read.

140
00:09:15,374 --> 00:09:19,566
So it's not like in

141
00:09:19,590 --> 00:09:22,822
this particular read committed doesn't hold the lock for a

142
00:09:22,838 --> 00:09:26,364
long time, which is good for.

143
00:09:27,304 --> 00:09:30,764
Which is good for concurrency. A lot of concurrent operations can happen

144
00:09:31,064 --> 00:09:34,824
since you're holding the lock for lesser time. However, it still suffers from

145
00:09:34,944 --> 00:09:38,352
non repeatable reads and phantom reads, which we'll

146
00:09:38,368 --> 00:09:41,680
be covering in the next sections again. Now let's move into

147
00:09:41,712 --> 00:09:45,040
the performance so performance is again, read committed tends to have

148
00:09:45,072 --> 00:09:49,000
better performance than other stronger isolation levels due to its lower

149
00:09:49,032 --> 00:09:52,324
level of locking and reduced contention. I just mentioned

150
00:09:52,824 --> 00:09:56,272
a few seconds ago it allows for more concurrent transactions,

151
00:09:56,328 --> 00:10:00,288
but may still incur some overhead due to lack of acquisition

152
00:10:00,376 --> 00:10:03,424
and releases. Now in this

153
00:10:03,504 --> 00:10:07,104
direction, let's move into the next problem, which is non

154
00:10:07,144 --> 00:10:10,604
repeatable read, which I just gave an intro about.

155
00:10:10,904 --> 00:10:14,784
So what is a non repeatable read which the read committed isolation level doesn't

156
00:10:14,824 --> 00:10:19,080
solve? Say for example, suppose transaction

157
00:10:19,112 --> 00:10:22,292
t one reads data, okay?

158
00:10:22,428 --> 00:10:26,524
Now due to concurrency, another transaction t two updates the

159
00:10:26,644 --> 00:10:30,156
same data and commit. Now, if t one rereads the

160
00:10:30,180 --> 00:10:33,732
same data, rereads like the same again repeated reads

161
00:10:33,748 --> 00:10:37,924
the data, it will retrieve a different value, right? So you're

162
00:10:37,964 --> 00:10:42,348
not rereading the same value, but a different value after

163
00:10:42,476 --> 00:10:45,308
the t two has written and committed the data,

164
00:10:45,396 --> 00:10:48,884
right? So the read committed

165
00:10:48,924 --> 00:10:51,964
doesn't guarantee this particular,

166
00:10:52,084 --> 00:10:55,984
you know, don't want to, you want to read the same data within the same

167
00:10:56,484 --> 00:10:59,144
transaction flow like read and read. Right?

168
00:11:00,444 --> 00:11:04,196
Now how is it solved by now? This can be

169
00:11:04,220 --> 00:11:08,344
solved by repeatable read isolation level.

170
00:11:09,204 --> 00:11:12,460
This isolation level makes sure any transaction that

171
00:11:12,532 --> 00:11:16,934
reads data from row blocks any

172
00:11:16,974 --> 00:11:20,382
other writing transactions from accessing the

173
00:11:20,398 --> 00:11:23,982
same row. So this is the most restrictive isolation

174
00:11:24,038 --> 00:11:27,470
level that holds read locks on all rows it

175
00:11:27,502 --> 00:11:31,702
references and write locks on all rows. It inserts,

176
00:11:31,838 --> 00:11:35,150
updates and deletes. Since other transactions cannot read,

177
00:11:35,222 --> 00:11:39,158
update, or delete these rows. Consequently, it avoids non repeatable read.

178
00:11:39,246 --> 00:11:42,560
I just demonstrated all of this using the picture

179
00:11:42,592 --> 00:11:46,352
on the left t one is trying to

180
00:11:46,368 --> 00:11:49,656
do select and select two select send.

181
00:11:49,840 --> 00:11:53,592
No other transaction can do any operation

182
00:11:53,648 --> 00:11:57,680
while you are reading. While one transaction is reading here. So two

183
00:11:57,712 --> 00:12:00,124
reads are happening and it's locked completely.

184
00:12:02,304 --> 00:12:05,712
All the locks, all rows it references

185
00:12:05,848 --> 00:12:09,554
are being locked completely. So that way non

186
00:12:09,594 --> 00:12:13,050
repeatable road non repeatable read can be

187
00:12:13,122 --> 00:12:17,130
avoided. And now let's

188
00:12:17,162 --> 00:12:20,658
talk about the consistency, concurrency and performance.

189
00:12:20,746 --> 00:12:22,934
So as you can see, firstly,

190
00:12:23,754 --> 00:12:27,186
holding lot of locks, right? Holding locks on all the

191
00:12:27,210 --> 00:12:29,414
rows. Let's talk about performance.

192
00:12:30,234 --> 00:12:33,734
Repeatable read have slightly worse

193
00:12:33,774 --> 00:12:36,878
performance as I just described, compared to late

194
00:12:36,926 --> 00:12:40,894
committed recommitted isolation level due to like increased locking

195
00:12:40,934 --> 00:12:44,782
and reduced concurrency. Its impact on

196
00:12:44,838 --> 00:12:48,914
performance depends on the workload too, and the level of contention system.

197
00:12:49,614 --> 00:12:53,126
So why reduced concurrency? Let's talk about concurrency.

198
00:12:53,270 --> 00:12:57,494
Repeatable read typically results in lower concurrency compared

199
00:12:57,534 --> 00:13:00,882
to read committed because it holds locks for the duration

200
00:13:00,938 --> 00:13:04,626
of the transaction. Because you're doing two reads, right read

201
00:13:04,690 --> 00:13:08,754
read for the entire duration of the transaction. T one

202
00:13:08,874 --> 00:13:12,450
is holding the lock entire duration

203
00:13:12,482 --> 00:13:16,698
of the transaction to prevent other transactions, say t two in this aspect to

204
00:13:16,746 --> 00:13:19,934
do any kind of updates from modifying the data.

205
00:13:20,514 --> 00:13:24,602
This can lead to increased contention and potential deadlock situations because as

206
00:13:24,618 --> 00:13:28,214
you are holding the lock for a long time, there'll be a lot of contention

207
00:13:28,254 --> 00:13:32,194
and waiting and there's bad concurrency,

208
00:13:32,614 --> 00:13:36,310
things are not happening in parallel. Well, so holding

209
00:13:36,342 --> 00:13:39,886
lock for longer and not letting other writes

210
00:13:39,910 --> 00:13:42,874
to happen in parallel is something not really good.

211
00:13:43,654 --> 00:13:47,190
But consistency, yeah, repeatable read provides

212
00:13:47,222 --> 00:13:50,830
strong consistency than read committed because you're solving that other

213
00:13:50,902 --> 00:13:54,492
problem as well by ensuring that once data

214
00:13:54,548 --> 00:13:58,020
is read by a transaction, it remains unchanged for the duration of

215
00:13:58,052 --> 00:14:01,716
the transaction. So that's good consistency. Even though someone

216
00:14:01,780 --> 00:14:05,820
updates the data and commits, you can't do that like in read committed.

217
00:14:05,932 --> 00:14:09,844
That is allowed, right? Until, if it is committed, you can

218
00:14:09,884 --> 00:14:13,036
read again after it is committed. So two reads will result in

219
00:14:13,060 --> 00:14:16,604
two different data. It's not totally consistent if it is read committed isolation

220
00:14:16,644 --> 00:14:21,214
level. But with this particular readable

221
00:14:21,754 --> 00:14:26,026
repeatable read isolation level, you're actually providing

222
00:14:26,090 --> 00:14:27,494
stronger consistency.

223
00:14:29,914 --> 00:14:33,334
But the non repeatable reads may not.

224
00:14:34,154 --> 00:14:37,586
This prevents non repeatable reads, but it may

225
00:14:37,610 --> 00:14:41,034
still allow something called phantom reads. Now, what is a phantom

226
00:14:41,074 --> 00:14:44,506
read and who solves it? Let's talk about it. Now, the next

227
00:14:44,650 --> 00:14:48,802
thing is snapshot isolation. This is another very

228
00:14:48,898 --> 00:14:52,162
very very deep or strong isolation

229
00:14:52,258 --> 00:14:55,786
level. And what it solves is something called phantom read,

230
00:14:55,890 --> 00:15:00,450
along with the dirty read and the non

231
00:15:00,482 --> 00:15:05,594
repeatable read as well. So phantom

232
00:15:05,634 --> 00:15:09,574
read a transaction, say, re executes

233
00:15:10,174 --> 00:15:14,030
a query returning a set of rows, not just one row, but a range

234
00:15:14,062 --> 00:15:17,234
query. A set of rows say greater than, say, for example,

235
00:15:18,774 --> 00:15:22,590
let's list all the players

236
00:15:22,662 --> 00:15:26,070
who earn more than say blah blah blah, certain dollars. So list

237
00:15:26,102 --> 00:15:29,454
of all, like a range query. So set of rows that satisfy

238
00:15:29,494 --> 00:15:32,822
search condition and finds that the set of rows satisfying the condition has

239
00:15:32,878 --> 00:15:36,710
changed due to another recently committed transaction,

240
00:15:36,742 --> 00:15:40,376
say new entry got added, right? So this

241
00:15:40,400 --> 00:15:44,216
is similar to a non repeatable read, except it involves

242
00:15:44,400 --> 00:15:48,764
changing collection matching predicate rather than

243
00:15:49,344 --> 00:15:53,656
a single item. So as I have given the example

244
00:15:53,720 --> 00:15:57,456
as well here, say transaction one has read something and

245
00:15:57,560 --> 00:16:01,792
now there is something written by transaction two

246
00:16:01,928 --> 00:16:05,630
appending to the list. It's just range query appending to the

247
00:16:05,662 --> 00:16:09,798
list and it's committed. And when you read the transaction

248
00:16:09,966 --> 00:16:12,634
after some time, again double read,

249
00:16:14,174 --> 00:16:17,302
it's similar to non repeatable read. Exactly the same thing. If you

250
00:16:17,318 --> 00:16:21,142
look back, it's even in

251
00:16:21,158 --> 00:16:25,094
the previous one you're reading, and then transaction two is writing committed,

252
00:16:25,134 --> 00:16:28,742
and then another read. Similarly reading, and then another

253
00:16:28,798 --> 00:16:32,462
transaction is writing, and again a second

254
00:16:32,518 --> 00:16:36,554
read. So it's similar to non repeatable read, except it involves

255
00:16:37,854 --> 00:16:41,406
changing collection matching predicate rather than single items.

256
00:16:41,430 --> 00:16:45,230
It's a range. So how is this solved? By snapshot

257
00:16:45,262 --> 00:16:48,958
isolation level. This isolation level can greatly

258
00:16:49,006 --> 00:16:53,270
increase concurrency at lower cost than transactional

259
00:16:53,302 --> 00:16:57,190
isolation. Now, when the data is modified. The committed

260
00:16:57,222 --> 00:17:01,414
versions of affected rows are copied to a temporary

261
00:17:02,314 --> 00:17:06,722
data structure or a temporary place and

262
00:17:06,738 --> 00:17:10,634
given some version numbers. So this operation is called copy on write and

263
00:17:10,674 --> 00:17:14,146
is used for all inserts updates. And I'm referring to the diagram

264
00:17:14,170 --> 00:17:18,226
on the left. And when another session reads

265
00:17:18,250 --> 00:17:22,014
the same data, the committed version of the data

266
00:17:23,154 --> 00:17:27,104
as of the time the reading transaction began, it returned.

267
00:17:27,224 --> 00:17:30,952
So when someone initiates read, it will be provided with

268
00:17:30,968 --> 00:17:35,320
a snapshot of the current data. And if

269
00:17:35,352 --> 00:17:38,112
someone is doing a write at the same time,

270
00:17:38,288 --> 00:17:42,416
the write gets its own snapshot. As you can see in

271
00:17:42,440 --> 00:17:46,408
t one and t two, two transactions are trying to write say

272
00:17:46,496 --> 00:17:50,264
odd to even and then even to odd. So the

273
00:17:50,304 --> 00:17:53,510
green, like t one, is changing from odd to even.

274
00:17:53,582 --> 00:17:57,150
All the greens, it has its own snapshot and then changed. And t

275
00:17:57,182 --> 00:18:00,878
two, it has its own snapshot and it's changed event odd.

276
00:18:01,006 --> 00:18:05,110
Ultimately, though, all are combined once the transactions

277
00:18:05,142 --> 00:18:09,326
are complete and written to the original database. So same way when

278
00:18:09,350 --> 00:18:12,286
there is a read happening, when these two t one, t two, like t three

279
00:18:12,310 --> 00:18:15,342
is doing some read, it will be provided its own snapshot,

280
00:18:15,478 --> 00:18:18,858
and so there is no one interfering with their

281
00:18:18,906 --> 00:18:21,834
own say, transactions, say read or write.

282
00:18:21,954 --> 00:18:25,554
So that way, maintaining everyone

283
00:18:25,634 --> 00:18:30,174
having their own snapshots has this high level of concurrency

284
00:18:30,874 --> 00:18:33,574
and also strong consistency maintained.

285
00:18:33,994 --> 00:18:37,442
So let's talk about consistency. Firstly,

286
00:18:37,538 --> 00:18:41,610
snapshot isolation, as I said, provides the strongest consistency guarantees

287
00:18:41,722 --> 00:18:45,358
among all the three isolation levels I just mentioned. It ensures that

288
00:18:45,446 --> 00:18:49,462
transactions see a consistent snapshot of the database. As of the transactions

289
00:18:49,518 --> 00:18:53,102
start when the read, say started. By the

290
00:18:53,118 --> 00:18:56,886
time the read is finished, like two or three reads the whole transaction,

291
00:18:57,070 --> 00:18:59,834
the data is still the same because it's using snapshot,

292
00:19:00,334 --> 00:19:03,510
preventing both non repeatable reads and phantom reads.

293
00:19:03,582 --> 00:19:07,614
There's no change. If there is a change, that's when the phantom

294
00:19:07,654 --> 00:19:10,314
reads and non repeatable reads come into picture their problems.

295
00:19:10,614 --> 00:19:14,294
Now, concurrency snapshot isolation typically allows for higher

296
00:19:14,334 --> 00:19:17,830
concurrency because it doesn't hold locks on read operations.

297
00:19:17,902 --> 00:19:21,514
Right? Just like previously we were talking about holding locks in

298
00:19:22,654 --> 00:19:26,994
what is that repeatable read isolation level.

299
00:19:27,774 --> 00:19:31,422
Now with this, instead,

300
00:19:31,478 --> 00:19:35,366
it maintains multiple versions of data items, allowing concurrent transactions to

301
00:19:35,390 --> 00:19:38,702
operate on their own constant snapshots. So concurrency is

302
00:19:38,718 --> 00:19:42,486
guaranteed. Wonderful. No performance. Snapshot isolation can

303
00:19:42,510 --> 00:19:46,390
have good performance too in read heavy workloads with

304
00:19:46,422 --> 00:19:49,934
low update contention because it allows for high concurrency.

305
00:19:50,014 --> 00:19:53,462
Like when read is happening, everyone is probably with their

306
00:19:53,478 --> 00:19:57,314
own snapshots and write can also happen in parallel and

307
00:19:58,214 --> 00:20:01,302
avoids the overhead of locking. So wonderful.

308
00:20:01,478 --> 00:20:04,844
But think about it, the performance here,

309
00:20:05,264 --> 00:20:08,560
the time complexity is ensured, like it's

310
00:20:08,592 --> 00:20:12,480
fast, there's no locking, and concurrently things are happening. It's quick.

311
00:20:12,672 --> 00:20:16,288
However, it requires like additional storage space, because where do

312
00:20:16,296 --> 00:20:20,072
you put the snapshots, right? So overhead of maintaining the multiple versions of

313
00:20:20,088 --> 00:20:23,352
the data is coming into picture. So that needs to be considered.

314
00:20:23,488 --> 00:20:27,296
The space complexity is what I'm talking about, especially in

315
00:20:27,320 --> 00:20:30,720
writes, everyone maintaining a copy of their own. So you need to account for that

316
00:20:30,752 --> 00:20:34,874
extra memory in the database when you're considering the

317
00:20:35,214 --> 00:20:39,834
snapshot isolation. So those are the three things

318
00:20:40,934 --> 00:20:44,434
about the read, committed,

319
00:20:45,054 --> 00:20:48,366
non repeatable read

320
00:20:48,550 --> 00:20:52,622
and snapshot, all three levels of isolation which guarantee

321
00:20:52,678 --> 00:20:56,606
certain degree of consistency, concurrency and performance

322
00:20:56,790 --> 00:21:01,088
aspects. Now, switching gears apart from

323
00:21:01,216 --> 00:21:03,444
the consistency,

324
00:21:04,784 --> 00:21:08,064
concurrency and performance, the two

325
00:21:08,144 --> 00:21:11,472
other non functional aspects of distributed systems, especially in

326
00:21:11,488 --> 00:21:15,328
the large language models which are very

327
00:21:15,376 --> 00:21:19,656
important to consider, are these partial failures.

328
00:21:19,840 --> 00:21:23,704
So now partial failures,

329
00:21:23,744 --> 00:21:26,864
like what are partial failures, right. These refer

330
00:21:26,904 --> 00:21:31,164
to situations where only a subset of components,

331
00:21:32,144 --> 00:21:36,208
like what is a distributed system? Like I said, lot of connected computers working in

332
00:21:36,216 --> 00:21:40,672
a network, you have lot of systems connected globally

333
00:21:40,848 --> 00:21:44,896
in a network, interacting with each other, trying to locate the data

334
00:21:45,080 --> 00:21:48,776
and processing, computing, again, merging the data,

335
00:21:48,960 --> 00:21:52,644
all that is happening, data processing in a distributed environment.

336
00:21:53,184 --> 00:21:56,504
Now a lot of communication is going on. So what

337
00:21:56,544 --> 00:22:00,504
if only a subset of components or nodes within the system experience failures

338
00:22:00,624 --> 00:22:03,776
while other parts continue to function normally? That's called

339
00:22:03,840 --> 00:22:06,808
partial failure, the name itself suggests.

340
00:22:06,896 --> 00:22:11,496
Right, this is what I'm saying. But so

341
00:22:11,520 --> 00:22:14,952
the two types of like failures I mentioned here,

342
00:22:15,008 --> 00:22:18,352
as I said all the, by the way, this distributed environment,

343
00:22:18,408 --> 00:22:21,892
again, you can consider it as an e commerce platform where a lot of

344
00:22:21,908 --> 00:22:25,660
people are trying to purchase items on the

345
00:22:25,812 --> 00:22:29,300
ecommerce website and all the transaction

346
00:22:29,332 --> 00:22:33,196
requests coming onto the back end. And that back end is this node,

347
00:22:33,220 --> 00:22:36,484
one node three, node two, node ten, node four connected over a network.

348
00:22:36,644 --> 00:22:40,164
And node failures, like I said, the partial failures can be of two types.

349
00:22:40,244 --> 00:22:43,780
Node failures, individual computers, individual systems may

350
00:22:43,812 --> 00:22:47,516
experience failures due to hardware or software, right? It's very much

351
00:22:47,540 --> 00:22:51,708
possible. Or network partitions, where these

352
00:22:51,796 --> 00:22:55,580
systems interacting with each other may be disrupted due to some

353
00:22:55,692 --> 00:22:58,996
bad network and leading to some network

354
00:22:59,060 --> 00:23:02,420
partitions, or isolated segments unable to reach or

355
00:23:02,492 --> 00:23:04,980
connectivity issues and things like that.

356
00:23:05,172 --> 00:23:08,364
And these partial failures are very unique

357
00:23:08,404 --> 00:23:11,732
feature of distributed systems, only because if you think about a

358
00:23:11,748 --> 00:23:15,476
single program, single computer, or a single system where you are just running

359
00:23:15,500 --> 00:23:19,292
a program and letting it run a standalone application, there's no

360
00:23:19,308 --> 00:23:22,984
problem why it either runs

361
00:23:23,324 --> 00:23:27,436
100%, or if it doesn't run, it's either because your

362
00:23:27,620 --> 00:23:31,284
Internet is bad, or the hardware failure,

363
00:23:31,364 --> 00:23:34,516
or blank screen, things like that. It's zero or 100. There is

364
00:23:34,540 --> 00:23:37,860
nothing in between if it is a single computer, or if there is a flaw

365
00:23:37,892 --> 00:23:40,860
in the software itself, the program you're running. But in distributed environment,

366
00:23:41,052 --> 00:23:44,640
it's not the issue with just the logic of your program or the

367
00:23:44,672 --> 00:23:48,164
code, or it's not the problem with

368
00:23:48,864 --> 00:23:53,884
the connectivity or just the

369
00:23:55,224 --> 00:23:59,096
what is that? Complete failure. But it has to be

370
00:23:59,200 --> 00:24:02,752
completely partial as well, like it's somewhere in

371
00:24:02,768 --> 00:24:06,072
between. So that is the distributed environment problem.

372
00:24:06,248 --> 00:24:09,512
Now, despite the partial failures, some parts

373
00:24:09,528 --> 00:24:13,064
of the distributed system may remain operational, while others experience

374
00:24:13,144 --> 00:24:16,580
disruptions. So this can result in inconsistencies,

375
00:24:16,772 --> 00:24:20,504
degraded performance, or temporary unavailability of services.

376
00:24:20,844 --> 00:24:23,224
Now, how can this be handled?

377
00:24:24,524 --> 00:24:27,584
Is simple, right? Like you need to have lot of replication.

378
00:24:28,564 --> 00:24:32,580
I picked replication. There are other things like building fault tolerance systems and

379
00:24:32,652 --> 00:24:35,796
reliable systems, which I covered in some of my

380
00:24:35,900 --> 00:24:39,172
previous sessions at con 42, which can be referred

381
00:24:39,188 --> 00:24:42,880
to, but here I'll be focusing a bit or giving some

382
00:24:42,912 --> 00:24:46,216
intro about the replication aspect to handle

383
00:24:46,240 --> 00:24:49,904
these partial failures. Now, various replication

384
00:24:49,944 --> 00:24:53,536
strategies are employed in distributed systems to handle these partial failures and ensure data

385
00:24:53,560 --> 00:24:56,728
availability and reliability. First is full replication.

386
00:24:56,856 --> 00:25:00,504
So in full replication, all data is replicated across multiple

387
00:25:00,544 --> 00:25:04,304
nodes or replicas. In the distributed system, each replica

388
00:25:04,344 --> 00:25:08,070
contains a complete copy copy of the dataset. So this approach ensures

389
00:25:08,102 --> 00:25:11,238
high availability and fault tolerance. And since any

390
00:25:11,286 --> 00:25:15,254
node, any single node failure can be mitigated by accessing data

391
00:25:15,294 --> 00:25:18,646
from other replicas. However, it can be costly in terms of storage

392
00:25:18,710 --> 00:25:22,006
and bandwidth requirements, especially for large data sets.

393
00:25:22,190 --> 00:25:25,806
So next is what? Partial replication? Yeah, so partial

394
00:25:25,830 --> 00:25:29,182
replication involves replicating only a subset of

395
00:25:29,198 --> 00:25:32,586
the data across multiple nodes. Different subsets

396
00:25:32,610 --> 00:25:36,562
of data can be replicated based on access patterns, data importance or

397
00:25:36,578 --> 00:25:40,146
other criteria. And this strategy

398
00:25:40,170 --> 00:25:43,634
can help reduce storage and bandwidth costs compared to the full replication, while still

399
00:25:43,674 --> 00:25:47,098
providing fault tolerance for critical data. However, it may require

400
00:25:47,146 --> 00:25:50,482
careful data partitioning and management to ensure, like you need

401
00:25:50,498 --> 00:25:55,826
to understand what is important, data that is adequately used

402
00:25:55,890 --> 00:25:59,334
and needs to be replicated next is sharding alsoness.

403
00:25:59,454 --> 00:26:03,062
It's a very common one, it's a very popular one. Horizontal partitioning

404
00:26:03,118 --> 00:26:07,270
involves partitioning the dataset into multiple subsets called shards,

405
00:26:07,302 --> 00:26:10,894
and distributing these shards across multiple nodes. Each node is responsible

406
00:26:10,934 --> 00:26:14,582
for storing and managing a subset of the data, so sharding can improve

407
00:26:14,638 --> 00:26:18,222
scalability and performance. Scalability is more important or

408
00:26:18,358 --> 00:26:21,630
is a higher, bigger problem, which sharding solves and performance,

409
00:26:21,702 --> 00:26:25,736
of course, by distributing the workload across different nodes, parallelly happening concurrent

410
00:26:25,760 --> 00:26:29,528
requests in the event of a node failure only

411
00:26:29,576 --> 00:26:32,472
the data stored on that node is affected,

412
00:26:32,648 --> 00:26:35,928
minimizing the impact on the overall system. Right. So still

413
00:26:35,976 --> 00:26:40,160
that this is still manageable. Now, replication chains replication

414
00:26:40,192 --> 00:26:43,912
chains involve replicating data from one node to another in a

415
00:26:44,048 --> 00:26:47,624
sequential chain like fashion. Each node in the chain replicates

416
00:26:47,664 --> 00:26:51,216
data to its successor node. This approach can provide

417
00:26:51,280 --> 00:26:55,318
fault tolerance by ensuring that data is replicated across multiple

418
00:26:55,496 --> 00:26:58,626
nodes in the chain. However, it may introduce latency

419
00:26:58,690 --> 00:27:02,490
and complexity, especially in the large distributed systems.

420
00:27:02,562 --> 00:27:06,170
As it's a chain of replication, you have to do, as it sounds

421
00:27:06,202 --> 00:27:10,134
obvious. Next is the primary backup replication.

422
00:27:10,834 --> 00:27:14,754
One node serves as the primary replica,

423
00:27:14,874 --> 00:27:19,690
responsible for processing client requests and updating data changes

424
00:27:19,762 --> 00:27:23,830
made to the primary replica, asynchronously replicated to one or

425
00:27:23,862 --> 00:27:27,554
more backup replicas. So asynchronously replicating is very important.

426
00:27:28,454 --> 00:27:31,950
You don't want to block other transactions while replication is

427
00:27:31,982 --> 00:27:35,550
happening. So if the primary replica fails, one of the backup

428
00:27:35,582 --> 00:27:39,110
replicas can be promoted to the primary role to continue

429
00:27:39,182 --> 00:27:42,046
serving client requests. So this approach,

430
00:27:42,110 --> 00:27:47,046
again, it's like a master slave and new leader, new master election,

431
00:27:47,110 --> 00:27:50,888
and all those things come into picture. So this approach provides fault tolerance,

432
00:27:51,016 --> 00:27:55,524
higher availability, while minimizing overhead compared to full replication.

433
00:27:55,984 --> 00:27:58,284
And the last one is quorum based replication.

434
00:27:59,104 --> 00:28:02,080
It involves replicating data to a subset of nodes,

435
00:28:02,152 --> 00:28:05,304
known as a quorum. Read and write

436
00:28:05,344 --> 00:28:09,208
operations require coordination among a quorum of nodes to

437
00:28:09,296 --> 00:28:12,160
ensure consistency and fault tolerance.

438
00:28:12,272 --> 00:28:16,056
So quorum based replication can provide strong

439
00:28:16,120 --> 00:28:19,920
consistency guarantees while tolerating failures of a subset

440
00:28:19,952 --> 00:28:23,576
of nodes within the quorum.

441
00:28:23,720 --> 00:28:27,584
So yeah, so this is all I wanted to cover

442
00:28:27,624 --> 00:28:30,968
today. Obviously there'll be more

443
00:28:31,016 --> 00:28:34,496
things to talk about, say the fault tolerance.

444
00:28:34,560 --> 00:28:39,008
And like I said, I covered in one of my previous talks.

445
00:28:39,136 --> 00:28:42,720
And for even more detailed discussions or

446
00:28:42,752 --> 00:28:46,566
furthermore problems and handling the problems in distributed systems,

447
00:28:46,590 --> 00:28:49,674
I would like to take some other session.

448
00:28:50,294 --> 00:28:53,434
This is it for now. And thank you very much for

449
00:28:54,014 --> 00:28:55,974
watching all the way through. Thank you.

