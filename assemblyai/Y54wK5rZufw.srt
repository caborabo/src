1
00:00:27,334 --> 00:00:31,390
Hello everyone and welcome to Conf 42 site Reliability

2
00:00:31,462 --> 00:00:35,326
Engineering 2024. My name is Ricardo Castro and today

3
00:00:35,390 --> 00:00:38,834
we're going to talk about slos for event driven architectures.

4
00:00:40,254 --> 00:00:44,414
In this talk, we'll examine an approach for monitoring and maintaining

5
00:00:44,454 --> 00:00:47,434
reliability of event driven systems.

6
00:00:48,014 --> 00:00:51,874
We will focus on three core availability,

7
00:00:52,174 --> 00:00:55,806
freshness and correctness, and we will learn how they impact

8
00:00:55,870 --> 00:00:59,394
our complex distributed systems. Lets dive in

9
00:00:59,974 --> 00:01:03,998
event driven architectures are transforming the way we build distributed

10
00:01:04,046 --> 00:01:06,734
systems. They offer flexibility,

11
00:01:06,894 --> 00:01:09,154
scalability and a real time focus.

12
00:01:09,974 --> 00:01:14,270
Events can power everything from user interactions in web applications

13
00:01:14,382 --> 00:01:18,354
to complex data processing in IoT or financial systems.

14
00:01:18,974 --> 00:01:22,894
Understanding how to guarantee their reliability is key to

15
00:01:22,934 --> 00:01:26,868
success. To achieve true

16
00:01:26,916 --> 00:01:30,468
reliability in event driven systems, lets concentrate on

17
00:01:30,516 --> 00:01:34,412
three fundamental freshness assures

18
00:01:34,508 --> 00:01:38,556
timely data availability ensures services

19
00:01:38,700 --> 00:01:43,052
stay responsive correctness prevents flawed decision making

20
00:01:43,148 --> 00:01:45,464
by maintaining data integrity.

21
00:01:46,044 --> 00:01:49,908
These arent just buzzwords, these are measurable metrics

22
00:01:49,956 --> 00:01:53,360
that drive user experience. Imagine a

23
00:01:53,392 --> 00:01:57,552
stock trading system where price updates are delayed or

24
00:01:57,568 --> 00:02:01,164
a self driving car getting an outdated sensor reading.

25
00:02:01,704 --> 00:02:05,400
Freshness is paramount in scenarios where the timeliness

26
00:02:05,432 --> 00:02:08,564
of data directly impacts outcomes.

27
00:02:09,144 --> 00:02:12,520
Freshness is measured by the time an event

28
00:02:12,592 --> 00:02:16,632
creation takes to be consumed. Delayed or stale

29
00:02:16,688 --> 00:02:20,204
data leads to poor decision making and user frustration.

30
00:02:21,054 --> 00:02:24,914
Real time is a relative concept depending on the use case.

31
00:02:25,414 --> 00:02:28,590
Lets look at a simple example. We have

32
00:02:28,622 --> 00:02:31,314
two services that communicate over events.

33
00:02:31,854 --> 00:02:35,134
In this context, freshness represents how long

34
00:02:35,174 --> 00:02:38,630
an event took to get from service one to service

35
00:02:38,702 --> 00:02:42,118
two, it can be implemented and self

36
00:02:42,166 --> 00:02:45,710
reported, for example at the service level by using a

37
00:02:45,742 --> 00:02:49,102
histogram. In a more complex scenario,

38
00:02:49,238 --> 00:02:53,634
one or even more events can trigger multiple other events.

39
00:02:54,254 --> 00:02:57,350
Although freshness can be measured in a similar way,

40
00:02:57,462 --> 00:03:01,414
meaning self reported at the service level by using a histogram,

41
00:03:01,574 --> 00:03:04,114
it needs to be done at different places.

42
00:03:04,774 --> 00:03:08,414
It will of course have different thresholds of acceptance

43
00:03:08,494 --> 00:03:11,914
depending on the context and on where it is measured.

44
00:03:13,034 --> 00:03:16,698
In event based systems, we have to move beyond the simple notion

45
00:03:16,746 --> 00:03:20,730
of uptime. Availability is not just about

46
00:03:20,842 --> 00:03:24,778
if a system is online or offline, it centers on

47
00:03:24,826 --> 00:03:28,514
whether core functionality is accessible within acceptable time

48
00:03:28,554 --> 00:03:32,970
frames. Components may be technically

49
00:03:33,082 --> 00:03:36,654
running, yet users could get an answer.

50
00:03:37,234 --> 00:03:40,570
Parcel outages, a consumer fails and event processing

51
00:03:40,602 --> 00:03:44,522
slows down can have real consequences. Our focus

52
00:03:44,618 --> 00:03:48,578
must be on ensuring critical event flows remain operational,

53
00:03:48,706 --> 00:03:51,834
even under stressors like component failures or load

54
00:03:51,874 --> 00:03:55,654
spikes. Focusing again on our simple scenario

55
00:03:56,354 --> 00:04:00,418
availability means that an event triggered in service one actually

56
00:04:00,506 --> 00:04:04,534
arrived at service two. For a simple system like this,

57
00:04:05,154 --> 00:04:08,466
it should be fairly straightforward to check that that event arrived at

58
00:04:08,490 --> 00:04:12,222
service two. But for a more complex scenario

59
00:04:12,278 --> 00:04:16,274
like the one were seeing here availability might not be as simple.

60
00:04:16,654 --> 00:04:20,046
One or multiple events can trigger a cascade of

61
00:04:20,110 --> 00:04:24,062
many events. Availability needs to be measured at

62
00:04:24,118 --> 00:04:27,854
different points within the system. For a complex system,

63
00:04:27,934 --> 00:04:30,354
it might not be feasible to do it online.

64
00:04:31,054 --> 00:04:34,554
A way to achieve this could be to leverage synthetic monitoring.

65
00:04:35,154 --> 00:04:38,578
Think of it as using a robot to continuously test your

66
00:04:38,626 --> 00:04:42,562
system like a real event would. Simulated checks

67
00:04:42,658 --> 00:04:46,490
run at regular intervals, allowing you to find issues

68
00:04:46,642 --> 00:04:50,194
before they affect your users. Synthetic monitoring

69
00:04:50,234 --> 00:04:53,810
provides control predictable tests, while real user

70
00:04:53,842 --> 00:04:57,466
monitoring tracks actual user behavior, which can be messier.

71
00:04:57,650 --> 00:05:00,454
These approaches work best when coupled together.

72
00:05:01,224 --> 00:05:03,960
Have you ever heard the saying garbage in,

73
00:05:04,032 --> 00:05:07,824
garbage out? It rings especially true for

74
00:05:07,864 --> 00:05:11,360
event driven systems. Event payloads must

75
00:05:11,392 --> 00:05:15,564
be valid, accurate, and align with the expected structure.

76
00:05:16,104 --> 00:05:19,844
Incorrect data can propagate through a system undetected,

77
00:05:20,544 --> 00:05:23,680
a bad sensor reading an invalid transaction.

78
00:05:23,832 --> 00:05:27,368
This can ripple through the system, leading to inaccurate reports,

79
00:05:27,496 --> 00:05:30,224
or worse, have irreversible actions.

80
00:05:30,844 --> 00:05:33,940
Validation is crucial, yet it must be

81
00:05:33,972 --> 00:05:37,428
balanced with performance. Coming back to our simple

82
00:05:37,476 --> 00:05:41,604
scenario, correctness means that an event triggered in service

83
00:05:41,684 --> 00:05:46,104
one has to arrive at service two with the right format.

84
00:05:46,964 --> 00:05:50,708
Again, just as with availability checking.

85
00:05:50,756 --> 00:05:53,984
This should be straightforward for such a simple scenario.

86
00:05:54,504 --> 00:05:58,216
But in our more complex scenario, measuring correctness

87
00:05:58,280 --> 00:06:01,288
is again not trivial. Again,

88
00:06:01,416 --> 00:06:04,912
one or multiple events can trigger a cascade of

89
00:06:05,008 --> 00:06:08,928
potentially different events. They are correlated,

90
00:06:09,016 --> 00:06:12,080
but they are not the same event. Again,

91
00:06:12,192 --> 00:06:15,084
correctness needs to be measured at different points,

92
00:06:15,784 --> 00:06:18,564
and it might not be feasible to do it online.

93
00:06:19,344 --> 00:06:23,284
Synthetic monitoring is again a very good option to achieve this.

94
00:06:23,994 --> 00:06:28,574
Synthetic tests dont just check if a system responds,

95
00:06:28,874 --> 00:06:31,014
they can examine its output.

96
00:06:32,074 --> 00:06:35,650
These tests can be designed to send specific event data

97
00:06:35,722 --> 00:06:38,614
and assert that the expected outcome occurs.

98
00:06:39,834 --> 00:06:44,114
This might mean checking if calculations are correct or if a database

99
00:06:44,154 --> 00:06:48,362
update is actually performed correctly. They can help uncover

100
00:06:48,458 --> 00:06:52,402
incorrect responses, unexpected data transformations,

101
00:06:52,538 --> 00:06:56,818
or flawed logic in your event flows. This is proactive

102
00:06:56,906 --> 00:07:00,402
error prevention through connection checks.

103
00:07:00,578 --> 00:07:04,146
Through correctness checks we can sometimes add some overhead,

104
00:07:04,250 --> 00:07:08,746
so it's essential to strike a balance between rigorous testing and

105
00:07:08,890 --> 00:07:12,306
system speed requirements. Synthetic monitoring

106
00:07:12,330 --> 00:07:16,274
for correctness can help verify that event based systems

107
00:07:16,314 --> 00:07:19,934
adhere to business rules and maintain data consistency.

108
00:07:20,674 --> 00:07:24,214
Dont think of SLOS as merely setting targets.

109
00:07:24,714 --> 00:07:28,322
This is a journey of continuous improvement for your event based

110
00:07:28,378 --> 00:07:32,098
systems. It begins with identifying the most

111
00:07:32,146 --> 00:07:36,094
impactful metrics for availability, freshness, and correctness.

112
00:07:36,914 --> 00:07:40,938
You will refine these over time to ensure that they always align with

113
00:07:40,986 --> 00:07:43,614
real user experience and business goals.

114
00:07:44,514 --> 00:07:48,662
Remember, strong slos are the result of a close dialogue between

115
00:07:48,758 --> 00:07:52,714
technical teams and those who understand the overall system goals.

116
00:07:53,574 --> 00:07:57,086
And this is all for my part in this talk. We explored a

117
00:07:57,110 --> 00:08:00,366
high level overview of how we can define reliability for event

118
00:08:00,430 --> 00:08:03,654
driven architectures. In subsequent talks,

119
00:08:03,734 --> 00:08:07,238
I will explore in much more detail how this can actually be

120
00:08:07,326 --> 00:08:11,046
implemented and measured. Thank you so much for attending my talk

121
00:08:11,110 --> 00:08:11,934
and have a great conference.

