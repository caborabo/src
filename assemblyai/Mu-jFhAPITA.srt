1
00:00:24,650 --> 00:00:28,102
Hi. View us. I'm santosh, software engineering lead

2
00:00:28,156 --> 00:00:31,686
at Bytedance, San Francisco, Bay Area. Today I'll be talking about some

3
00:00:31,708 --> 00:00:35,142
of the architectural best practices for large scale data

4
00:00:35,196 --> 00:00:38,614
systems. So what are these

5
00:00:38,812 --> 00:00:42,818
large scale data systems? They are something which we use on a daily basis,

6
00:00:42,994 --> 00:00:46,834
like Gmail, Yelp, eventbrite, booking.com, digital wallet,

7
00:00:46,962 --> 00:00:49,830
e commerce system, and Google document.

8
00:00:50,450 --> 00:00:53,982
So I'll be going

9
00:00:54,036 --> 00:00:57,630
over some trade offs which you need to consider as

10
00:00:57,700 --> 00:01:00,846
part of making choices for what you need to

11
00:01:00,868 --> 00:01:05,374
pick while architecting these large scale data systems.

12
00:01:05,502 --> 00:01:09,970
So firstly, to begin with, we'll go over the storage architecture.

13
00:01:10,630 --> 00:01:13,570
Now, what is storage architecture?

14
00:01:13,910 --> 00:01:17,286
So let's get into some introduction about

15
00:01:17,308 --> 00:01:20,840
this, right? So let's take an example. I mentioned

16
00:01:21,370 --> 00:01:24,930
a user, or a lot of users, accessing their Gmail

17
00:01:25,010 --> 00:01:28,578
or Yelp or booking.com or any of

18
00:01:28,604 --> 00:01:32,266
these services or websites. The request goes through

19
00:01:32,368 --> 00:01:35,942
load balancer and then the HTTP API call to gateway,

20
00:01:36,006 --> 00:01:39,322
then the microservices. All of these fun things happen

21
00:01:39,456 --> 00:01:42,830
in the backend system. So what is ultimately

22
00:01:43,170 --> 00:01:47,614
happening is all the data is written to some

23
00:01:47,652 --> 00:01:51,566
kind of a place where the data is written, and then

24
00:01:51,588 --> 00:01:55,842
the data is also read when you have to retrieve or

25
00:01:55,896 --> 00:01:59,314
on the get API calls. So this particular

26
00:01:59,432 --> 00:02:03,170
place where all the data is stored, like the blue box

27
00:02:03,240 --> 00:02:07,160
in this diagram I'm showing is

28
00:02:07,690 --> 00:02:11,622
the storage layer, and the storage has different

29
00:02:11,676 --> 00:02:15,314
types of databases. In the current world, we have been using lot of NoSQl

30
00:02:15,362 --> 00:02:19,398
and MySQl. And this is again data moving from MySQL

31
00:02:19,414 --> 00:02:23,798
to NoSQL or directly making an entry into the NoSQL like Cassandra

32
00:02:23,894 --> 00:02:27,542
or Redis, and databases

33
00:02:27,606 --> 00:02:31,006
like that is totally different topic, which I won't be covering here.

34
00:02:31,108 --> 00:02:35,230
And MySQL databases, MySQL, like a typical

35
00:02:35,970 --> 00:02:39,614
relational database management system. So where the data is

36
00:02:39,652 --> 00:02:43,546
written. And now in this storage system,

37
00:02:43,668 --> 00:02:47,058
we already have lot of options in

38
00:02:47,064 --> 00:02:50,260
the current world, which I just gave some examples, right,

39
00:02:51,110 --> 00:02:54,974
you don't need to implement the storage system from

40
00:02:55,032 --> 00:02:59,334
scratch. All we need to know is some

41
00:02:59,452 --> 00:03:02,806
technical details of how the data in the

42
00:03:02,828 --> 00:03:08,042
storage system being saved or

43
00:03:08,096 --> 00:03:11,562
processed, so that we as an architect or any

44
00:03:11,616 --> 00:03:15,050
software architect, will be able to make the right decisions

45
00:03:16,030 --> 00:03:19,578
when building a system. When building a data intensive system.

46
00:03:19,744 --> 00:03:23,626
So the two things, right, select the app storage

47
00:03:23,658 --> 00:03:27,262
engine based on the trade offs and then fine tune the storage engine

48
00:03:27,316 --> 00:03:30,894
to perform well for our system workload. So for these

49
00:03:30,932 --> 00:03:34,734
two needs, we need to understand the underlying implementation

50
00:03:34,862 --> 00:03:39,326
of this particular storage layer. Now let's

51
00:03:39,358 --> 00:03:43,486
look at some options. So ultimately

52
00:03:43,598 --> 00:03:47,586
the storage layer, which I just talked about has some

53
00:03:47,608 --> 00:03:51,554
way of storing the data in the form of some data structures,

54
00:03:51,602 --> 00:03:54,562
right? So ultimately the data has to be stored in the form of data structure.

55
00:03:54,626 --> 00:03:58,386
So when you say MysQL or a Cassandra or any database,

56
00:03:58,498 --> 00:04:01,770
ultimately that database is storing your

57
00:04:01,840 --> 00:04:05,526
data, say your gmail or say the restaurants in the Aihelp

58
00:04:05,558 --> 00:04:08,874
or the Google Maps data, the places and all those things are

59
00:04:08,912 --> 00:04:12,466
stored in some data structure in the backend

60
00:04:12,518 --> 00:04:15,674
of these storage systems. So that's something we'll be focusing

61
00:04:15,722 --> 00:04:19,262
on to understand the different types and then

62
00:04:19,396 --> 00:04:22,754
what storage we need to

63
00:04:22,792 --> 00:04:26,430
pick depends totally on the data structure

64
00:04:26,510 --> 00:04:30,866
or the back end implementation of

65
00:04:30,888 --> 00:04:34,194
that particular data structure. So now let's look at some

66
00:04:34,232 --> 00:04:37,494
examples. Firstly, the B

67
00:04:37,532 --> 00:04:41,222
trees. So this is a very classic data

68
00:04:41,276 --> 00:04:45,158
structure where you have the parent

69
00:04:45,244 --> 00:04:48,886
and then the children dropping off the parents,

70
00:04:49,078 --> 00:04:53,046
which I'll be going into each and every data structure in the upcoming sections.

71
00:04:53,158 --> 00:04:56,902
So most relational database management systems

72
00:04:57,046 --> 00:05:00,762
use this btrees and some examples of

73
00:05:00,816 --> 00:05:03,850
backend systems which use the database based

74
00:05:03,920 --> 00:05:07,774
off of Btree's are like Gmail, Yahoo mail or any

75
00:05:07,812 --> 00:05:11,502
mail system. And there are other services too, but I just took email because

76
00:05:11,556 --> 00:05:14,926
it's more connected to all of us. So the other

77
00:05:14,948 --> 00:05:19,540
ones are quattries. Say we have these

78
00:05:20,070 --> 00:05:23,394
services like Yelp, what are the nearby restaurants or

79
00:05:23,432 --> 00:05:27,220
nearby places on Google Map where you can just look around

80
00:05:27,910 --> 00:05:31,234
searching, or also booking.com where you select a region

81
00:05:31,282 --> 00:05:34,966
and then look for all the hotels or anything you want to

82
00:05:34,988 --> 00:05:38,822
book. So at the back end you are getting some data

83
00:05:38,876 --> 00:05:41,962
to be viewed, right? So where is that data coming from?

84
00:05:42,016 --> 00:05:45,398
That data is coming from a data structure which is called quattrics

85
00:05:45,494 --> 00:05:49,466
and why quattries are used here. And if you're building a

86
00:05:49,488 --> 00:05:53,002
new system altogether, what data structure you need to pick

87
00:05:53,056 --> 00:05:57,230
is something which should be running on your mind while I'm giving these details.

88
00:05:58,050 --> 00:06:01,658
Now these are like very interesting. The third type of data structure is the LSM

89
00:06:01,674 --> 00:06:04,590
trees. So they are write intensive.

90
00:06:05,270 --> 00:06:08,638
They're used for write intensive applications because it's

91
00:06:08,654 --> 00:06:12,034
a very unique data structure where the data is first

92
00:06:12,072 --> 00:06:15,306
written into some temporary cache and then flushed

93
00:06:15,358 --> 00:06:19,286
into the secondary storage like a disk. So like for

94
00:06:19,308 --> 00:06:22,802
example, rocksdb is a database

95
00:06:22,866 --> 00:06:26,770
which implements or uses this or implements

96
00:06:26,850 --> 00:06:30,266
the log structured merge trees in the backend and I'll be

97
00:06:30,288 --> 00:06:34,026
going into the details in the upcoming slides. And digital wallet is

98
00:06:34,048 --> 00:06:37,114
one service which uses because there is

99
00:06:37,152 --> 00:06:41,342
heavy rights. And of course the Hadoop distributed file system and Kafka also

100
00:06:41,396 --> 00:06:44,894
have write intensive operations, so they have to

101
00:06:44,932 --> 00:06:48,350
use the LSM trees in the backend storage.

102
00:06:48,850 --> 00:06:52,186
And inverted index is another, although it's

103
00:06:52,218 --> 00:06:55,666
not a data structure, but another concept which you need to consider

104
00:06:55,768 --> 00:07:00,290
when selecting the storage systems and configuring these storage systems.

105
00:07:00,870 --> 00:07:04,814
And in search engines like google.com or Amazon.com,

106
00:07:04,952 --> 00:07:08,434
when you search for certain items, you immediately

107
00:07:08,482 --> 00:07:12,246
get those things right. So in

108
00:07:12,268 --> 00:07:15,558
the back end, it is the inverted index that is doing the

109
00:07:15,564 --> 00:07:18,742
magic. And so whenever you build any search engine,

110
00:07:18,796 --> 00:07:22,614
inverted index is something which is very crucial and needs to be incorporated

111
00:07:22,662 --> 00:07:26,266
in your system design. So now let's get into the details one by

112
00:07:26,288 --> 00:07:29,094
one, like I said, firstly, the b trees.

113
00:07:29,222 --> 00:07:32,702
So as you can see in the picture, this is how the B tree is

114
00:07:32,756 --> 00:07:36,862
structured. So at the top you have some numbers,

115
00:07:36,996 --> 00:07:42,542
and anything to the left of the numbers are

116
00:07:42,596 --> 00:07:45,854
the nodes, or a node which

117
00:07:45,892 --> 00:07:49,954
contains values which are less than, say that number here 100,

118
00:07:49,992 --> 00:07:53,746
less than 100 are 48, 50 and 79. And between 100 and

119
00:07:53,768 --> 00:07:56,962
155 we have the second node at the second level,

120
00:07:57,096 --> 00:08:01,074
128 and 140. Like that, anything greater lies

121
00:08:01,122 --> 00:08:05,126
onto the right side of any node and anything less

122
00:08:05,228 --> 00:08:08,520
than that particular node value lies onto the left side

123
00:08:09,210 --> 00:08:14,040
of that node and anything in between. Of course, say here in 155,

124
00:08:15,230 --> 00:08:18,506
on the left you have lesser than 155 and on the right you

125
00:08:18,528 --> 00:08:22,350
have greater than 155. So this way the data is well

126
00:08:22,420 --> 00:08:26,030
hierarchically organized. What it means

127
00:08:26,100 --> 00:08:29,710
is it's efficient for lookups, like reading,

128
00:08:30,130 --> 00:08:34,846
say, when you have to look for when

129
00:08:34,868 --> 00:08:38,170
the data is so organized like this in btrees.

130
00:08:38,330 --> 00:08:41,598
So when you have to look for, say certain queries,

131
00:08:41,694 --> 00:08:45,666
you say, I want to look at an email from

132
00:08:45,848 --> 00:08:49,714
in a particular time range, like certain say March

133
00:08:49,762 --> 00:08:53,474
10 to March 15. And that means that data lies

134
00:08:53,522 --> 00:08:56,818
in only one side or one part of the B tree.

135
00:08:56,834 --> 00:09:00,186
So you don't have to look through or search through the entire

136
00:09:00,288 --> 00:09:03,702
database automatically when you query.

137
00:09:03,846 --> 00:09:07,466
It doesn't do lot of seeking because

138
00:09:07,648 --> 00:09:10,990
even if you think about it, the data is ultimately

139
00:09:12,130 --> 00:09:16,014
stored in some kind of a secondary storage. So this particular

140
00:09:16,212 --> 00:09:20,270
B tree data structure enables us to use something like a disk

141
00:09:20,850 --> 00:09:24,394
and disk. Why disk? Because disk based storage is always cheaper

142
00:09:24,442 --> 00:09:29,330
than the SSDs. But again, disk that

143
00:09:29,400 --> 00:09:32,610
operations like input out operations really

144
00:09:32,760 --> 00:09:37,182
adds a lot of latency to avoid that our btree

145
00:09:37,326 --> 00:09:40,886
data structure, which is where the way it is

146
00:09:40,908 --> 00:09:45,286
organizing the data in the storage when

147
00:09:45,308 --> 00:09:48,634
we are using the RDBMs, it enables us

148
00:09:48,672 --> 00:09:51,914
to search through the right trees and

149
00:09:51,952 --> 00:09:55,580
pruning the other irrelevant or not needed

150
00:09:56,430 --> 00:10:00,218
branches so that you can just go to a specific

151
00:10:00,304 --> 00:10:03,262
node and there is not much I O happening,

152
00:10:03,396 --> 00:10:06,666
which means you're already optimizing the disk

153
00:10:06,698 --> 00:10:10,174
storage. And of course you're getting the data in a very quick time.

154
00:10:10,212 --> 00:10:14,254
And the time complexity would be log n. As for any binary

155
00:10:14,302 --> 00:10:18,740
tree or a B tree, as is

156
00:10:19,830 --> 00:10:23,922
proven mathematically. And of course it supports like just

157
00:10:23,976 --> 00:10:27,074
mentioned, range queries is one important thing. So in

158
00:10:27,112 --> 00:10:30,534
Gmail or Yahoo mail, when you have to search for

159
00:10:30,572 --> 00:10:34,038
a certain, because that's a very frequently used operation to

160
00:10:34,044 --> 00:10:37,366
look for emails from a particular sender or time range. So the querying is really,

161
00:10:37,388 --> 00:10:40,970
really easy. So read heavy operations

162
00:10:41,470 --> 00:10:44,646
are really efficient with the btree,

163
00:10:44,678 --> 00:10:47,734
and cheaper as well with the disk based storage

164
00:10:47,782 --> 00:10:51,434
optimization, which I just described. Now moving on to the next data structure,

165
00:10:51,482 --> 00:10:55,054
which is quarteries. And so some

166
00:10:55,092 --> 00:10:59,358
databases use quarteries. I gave an example here,

167
00:10:59,524 --> 00:11:03,554
mongodb, PostGis. These databases use

168
00:11:03,672 --> 00:11:07,538
quarteries to represent the data. Now, what is a quarter? Right, let's look

169
00:11:07,544 --> 00:11:11,874
at an example. You can look at the

170
00:11:11,912 --> 00:11:16,026
picture in this slide. The top node represents

171
00:11:16,078 --> 00:11:19,426
the entire map, like a two dimensional map.

172
00:11:19,618 --> 00:11:23,206
That map can be the entire globe, or that map can

173
00:11:23,228 --> 00:11:26,614
be a small region. Say, let's do it simple, right?

174
00:11:26,732 --> 00:11:30,294
Let's imagine the top node is the entire globe

175
00:11:30,342 --> 00:11:34,726
2D map. And every map has four quadrants.

176
00:11:34,838 --> 00:11:38,746
On the left top it's the northwest, and the

177
00:11:38,768 --> 00:11:41,658
right top it is northeast,

178
00:11:41,834 --> 00:11:45,722
and down left is southwest,

179
00:11:45,786 --> 00:11:49,310
and down right is the southeast. That's it. So now

180
00:11:49,460 --> 00:11:52,682
if you want to go into North America in the globe,

181
00:11:52,746 --> 00:11:56,546
it's in the northwest. So it goes to node a. And in

182
00:11:56,568 --> 00:12:00,114
the node A in North America, there might be lot

183
00:12:00,152 --> 00:12:03,234
of places, lot of states. And when you have to

184
00:12:03,272 --> 00:12:06,390
go zoom into some places,

185
00:12:06,890 --> 00:12:10,434
you further go drill down from the node

186
00:12:10,482 --> 00:12:14,054
A, even down further. Just like how we have node C

187
00:12:14,092 --> 00:12:18,614
and D, I've given here in the northeast

188
00:12:18,662 --> 00:12:22,842
quadrant, which we can assume as say China or like

189
00:12:22,896 --> 00:12:26,282
Japan, where you can

190
00:12:26,336 --> 00:12:30,102
look for certain, you zoom into certain regions.

191
00:12:30,246 --> 00:12:34,122
And again, say if C and d represent certain countries,

192
00:12:34,186 --> 00:12:38,046
say for example, c represents China here and inside China, if you want to

193
00:12:38,148 --> 00:12:41,946
look for certain places, again the c drills

194
00:12:41,978 --> 00:12:45,362
down to four more nodes as a children,

195
00:12:45,496 --> 00:12:48,754
and then you look for certain whatever places you

196
00:12:48,792 --> 00:12:53,026
wanted to see. And that way the

197
00:12:53,048 --> 00:12:56,006
whole quadrant is structured in such a way that you can zoom in,

198
00:12:56,028 --> 00:12:59,814
zoom in, zoom in, or even zoom out, zoom out and look

199
00:12:59,852 --> 00:13:03,606
at the country level or just continent level

200
00:13:03,708 --> 00:13:07,174
and all those things. And one thing

201
00:13:07,212 --> 00:13:11,340
to note here is every node has a value, and each value

202
00:13:12,030 --> 00:13:15,274
represents like, the higher the value,

203
00:13:15,472 --> 00:13:17,980
the more important the place is. For example,

204
00:13:18,430 --> 00:13:22,362
if you are looking for, say, restaurants, the top

205
00:13:22,416 --> 00:13:26,014
restaurant always has a high value and is always at the top of

206
00:13:26,052 --> 00:13:29,866
the node in a particular region. Say you are zooming into North

207
00:13:29,898 --> 00:13:33,762
America A and a represents inside going down

208
00:13:33,816 --> 00:13:36,846
a, you have a one which represents California,

209
00:13:36,958 --> 00:13:40,066
and in a one you probably pick a

210
00:13:40,088 --> 00:13:43,438
top restaurants, like a brazilian steakhouse.

211
00:13:43,534 --> 00:13:47,122
And that immediately is the first child of a

212
00:13:47,176 --> 00:13:50,690
one. So when you're picking the algorithm,

213
00:13:50,770 --> 00:13:53,942
how it works is the breakfast search

214
00:13:53,996 --> 00:13:58,090
is done when an area is selected and

215
00:13:58,160 --> 00:14:02,054
all the nodes which are at the periphery of the selected map

216
00:14:02,182 --> 00:14:05,174
are picked. So, which means that the top places,

217
00:14:05,222 --> 00:14:07,420
the top things are always retrieved first.

218
00:14:09,230 --> 00:14:12,574
And the way this is working, like how the data is being

219
00:14:12,612 --> 00:14:15,738
retrieved very quickly, because this particular quad

220
00:14:15,754 --> 00:14:19,790
tree supports something called spatial indexing. It is just like a regular

221
00:14:20,130 --> 00:14:24,782
indexing, but applied on this

222
00:14:24,836 --> 00:14:28,334
particular data, the coordinates based on the applied on the coordinates

223
00:14:28,382 --> 00:14:32,254
data, like a 2D map, which I just explained. And of course the range

224
00:14:32,302 --> 00:14:36,200
queries similar to Btree, where we go through

225
00:14:36,970 --> 00:14:40,706
certain nodes, we don't have to search through the entire nodes.

226
00:14:40,738 --> 00:14:43,078
Again, login complexity, really quick.

227
00:14:43,244 --> 00:14:46,406
And what else? Oh, the important one is the

228
00:14:46,428 --> 00:14:50,006
density. So you can see in this particular picture

229
00:14:50,038 --> 00:14:53,386
itself, you just left node a as is, and there

230
00:14:53,408 --> 00:14:56,278
are no children, but node,

231
00:14:56,454 --> 00:15:00,282
the second node, which is northeast region, you have like

232
00:15:00,336 --> 00:15:04,430
again four children, and again in the southeast region, you have until

233
00:15:04,500 --> 00:15:09,726
level three, going until E and F nodes. So that means if

234
00:15:09,748 --> 00:15:13,338
a user wants to just look at superficially

235
00:15:13,434 --> 00:15:17,986
zooming onto the map, or a 2D map at

236
00:15:18,008 --> 00:15:21,634
a very high level, like a country level, you're not going to see too many

237
00:15:21,752 --> 00:15:25,638
details, right? But if you drill down all the way to certain

238
00:15:25,724 --> 00:15:30,486
pinpoint locations, then that's when the

239
00:15:30,508 --> 00:15:33,954
tree gets more dense in that particular node,

240
00:15:34,002 --> 00:15:37,494
like say southeast in this example, and you look into

241
00:15:37,532 --> 00:15:41,514
the details of it and you can get as dense as you can.

242
00:15:41,632 --> 00:15:45,654
So say, if there are a lot of things to be retrieved,

243
00:15:45,782 --> 00:15:49,322
the particular node can be very dense. And if there are

244
00:15:49,376 --> 00:15:52,202
not many places to be shown,

245
00:15:52,346 --> 00:15:56,346
then it will be low density. So it's quite adaptable

246
00:15:56,378 --> 00:16:00,478
and flexible in that aspect. So that's why you need to consider

247
00:16:00,564 --> 00:16:04,002
using quad trees for proximity service or any service

248
00:16:04,056 --> 00:16:07,346
that involves like the coordinates and spatial indexing and anything with

249
00:16:07,368 --> 00:16:08,930
maps and places.

250
00:16:09,670 --> 00:16:14,178
Now, the next one is very interesting.

251
00:16:14,264 --> 00:16:17,330
One is LSM trees, I explained.

252
00:16:17,990 --> 00:16:22,226
So what are these? So LSM

253
00:16:22,258 --> 00:16:26,642
trees are the data structure in the storage systems,

254
00:16:26,786 --> 00:16:30,758
which are used for write heavy applications,

255
00:16:30,854 --> 00:16:34,726
say Kafka, say Hadoop distributed file

256
00:16:34,758 --> 00:16:38,006
system, where there is lots and lots of data, like stream

257
00:16:38,038 --> 00:16:41,562
data coming in. And imagine if there is lot of data

258
00:16:41,616 --> 00:16:45,326
coming in, you just don't want to write all

259
00:16:45,348 --> 00:16:48,478
the data each and every. Say you've got a write request and you don't want

260
00:16:48,484 --> 00:16:52,314
to write it as secondary storage immediately, right? Because it involves

261
00:16:52,362 --> 00:16:55,854
some I o and it won't be efficient. You always go to the disk,

262
00:16:55,902 --> 00:17:00,002
write and come back. No, the more efficient way is store

263
00:17:00,056 --> 00:17:04,094
it like buffer it in a particular cache,

264
00:17:04,142 --> 00:17:07,078
like a cache thing, as it is shown here, right?

265
00:17:07,164 --> 00:17:10,694
So the incoming writes first are buffered in a

266
00:17:10,732 --> 00:17:14,134
small cache, like a mem cache, and that

267
00:17:14,172 --> 00:17:17,506
itself is implemented. The back end data structure is again a

268
00:17:17,548 --> 00:17:22,490
binary tree, and once that is full, the data is asynchronously

269
00:17:22,830 --> 00:17:26,422
flushed to the disk.

270
00:17:26,486 --> 00:17:30,118
So here, level 0123 are disks, the secondary storage.

271
00:17:30,214 --> 00:17:34,058
So when the cache is full, the data is flushed onto the disk,

272
00:17:34,154 --> 00:17:38,826
and the disk when it is flushed, the small objects

273
00:17:38,858 --> 00:17:42,222
or the small entities you see at level zero, each one is called

274
00:17:42,276 --> 00:17:45,426
sorted string table, which are called the SS tables, and they

275
00:17:45,448 --> 00:17:49,410
are immutable, they can't be changed, and the data

276
00:17:49,480 --> 00:17:53,326
is sorted whenever it is pushed.

277
00:17:53,438 --> 00:17:57,886
And when you have lot of such individual SS tables,

278
00:17:57,998 --> 00:18:01,654
imagine if someone wants to do a search like writing is good,

279
00:18:01,692 --> 00:18:05,366
right? We are just flushing into the memcache and then writing into

280
00:18:05,388 --> 00:18:09,378
the memcache and flushing into the disk. But what if someone wants

281
00:18:09,404 --> 00:18:13,146
to read? Are you going to write the logic to go over all these

282
00:18:13,168 --> 00:18:16,522
SS tables? It's not efficient, right? So to make

283
00:18:16,576 --> 00:18:19,722
the system read efficient, what happens

284
00:18:19,776 --> 00:18:23,662
is in the background, asynchronously, there's something called compaction, which happens.

285
00:18:23,716 --> 00:18:25,600
What it means is say at level zero,

286
00:18:27,330 --> 00:18:31,582
the two or two to four SS tables are

287
00:18:31,636 --> 00:18:35,002
clubbed together, like the merge sort algorithm is used.

288
00:18:35,156 --> 00:18:39,182
Since they are sorted. We use a merge sort to compact

289
00:18:39,246 --> 00:18:43,038
or club multiple SS tables together and then flushed

290
00:18:43,054 --> 00:18:46,526
to level one. So the level one, what you see is an X

291
00:18:46,568 --> 00:18:49,094
level zero which was flushed to level one.

292
00:18:49,132 --> 00:18:53,046
Similarly, level two is an X level one which

293
00:18:53,068 --> 00:18:56,610
was combined. At level one, all the data SS tables,

294
00:18:56,690 --> 00:19:00,394
the merge data is again merged. It's a classic merge sort. You can look

295
00:19:00,432 --> 00:19:04,202
up online and the merge data is

296
00:19:04,256 --> 00:19:07,642
flushed from level one to level two. So that way the data

297
00:19:07,696 --> 00:19:11,466
keeps getting built up. And so when you have all the

298
00:19:11,488 --> 00:19:15,520
sorted data clubbed together at one place, it is easy to search.

299
00:19:16,370 --> 00:19:19,806
And that way you're getting the read performance and also the

300
00:19:19,828 --> 00:19:23,214
right performance with that memcache buffer. So compaction

301
00:19:23,262 --> 00:19:26,894
is an important point here, which needs to be noted.

302
00:19:26,942 --> 00:19:30,754
And LSM trees are used for

303
00:19:30,792 --> 00:19:34,910
any write heavy application. This is the very reason. And another important

304
00:19:35,000 --> 00:19:36,950
thing here is with the LSM trees,

305
00:19:38,730 --> 00:19:42,070
the configuration is customized.

306
00:19:42,410 --> 00:19:46,680
We can provide what is the buffer size of Memcache and

307
00:19:47,710 --> 00:19:51,180
how frequently do you want to flush the data from buffer to

308
00:19:52,510 --> 00:19:55,802
the disk storage and

309
00:19:55,856 --> 00:19:58,986
what should be the size of the compaction which we

310
00:19:59,008 --> 00:20:01,740
are doing. So all those things are there.

311
00:20:03,070 --> 00:20:06,586
Now moving on to the last one. This is again not a data structure.

312
00:20:06,618 --> 00:20:10,206
But I mentioned about inverted index, right? So why inverted index in

313
00:20:10,228 --> 00:20:13,886
search engine? So what are inverted index? Right? So what

314
00:20:13,908 --> 00:20:17,682
is an index first of all? So index is again used to search in a

315
00:20:17,736 --> 00:20:21,474
DB. You create a map with a keyword and

316
00:20:21,512 --> 00:20:24,974
then having the reference like say, id of a document.

317
00:20:25,022 --> 00:20:27,910
And then with that ID you refer to some content.

318
00:20:28,060 --> 00:20:32,086
So it's more for faster search in

319
00:20:32,108 --> 00:20:35,826
the backend or in the database. That's what the indexing

320
00:20:35,858 --> 00:20:39,014
is used for. Now, what is reverse index? Say, let's take an

321
00:20:39,052 --> 00:20:42,854
example here. So we have lot of documents and you can imagine

322
00:20:42,902 --> 00:20:46,266
these documents as say the web links which

323
00:20:46,288 --> 00:20:49,500
appear when you search Google.com. When you search on google.com,

324
00:20:51,390 --> 00:20:54,798
who is the highest paid actor, you get a list of links, right?

325
00:20:54,884 --> 00:20:58,846
So you can imagine all those links as these documents say,

326
00:20:58,868 --> 00:21:02,110
document one is one web link. And like a web crawler thing, right?

327
00:21:02,180 --> 00:21:05,842
So document one is web link one, web link two, web link three.

328
00:21:05,976 --> 00:21:10,802
And now how

329
00:21:10,936 --> 00:21:14,546
we build the inverted index is you get all the

330
00:21:14,568 --> 00:21:17,682
names, right, all the searchable entities.

331
00:21:17,826 --> 00:21:21,206
Like he says this a all brown day in this

332
00:21:21,308 --> 00:21:25,254
particular black table, I picked all the words from

333
00:21:25,292 --> 00:21:28,554
these documents and put here. And then

334
00:21:28,592 --> 00:21:32,054
the key is what all the documents are referring

335
00:21:32,102 --> 00:21:32,700
to,

336
00:21:35,710 --> 00:21:39,338
these particular keywords. So it's very opposite of

337
00:21:39,424 --> 00:21:42,846
say, document one has these keywords and document two has these

338
00:21:42,868 --> 00:21:46,206
keywords. It's the reverse. The keywords have documents one, two,

339
00:21:46,228 --> 00:21:49,390
three, and keyword has document two, three, four, whatever,

340
00:21:49,460 --> 00:21:52,714
something like that. And now when someone is searching,

341
00:21:52,762 --> 00:21:55,966
right, when you search for, say with these keywords,

342
00:21:55,998 --> 00:21:59,746
say all brown day, then what is

343
00:21:59,768 --> 00:22:03,310
returned is documents three, one and two are returned.

344
00:22:03,390 --> 00:22:07,174
So that means you are actually based on the keywords you're caching the

345
00:22:07,212 --> 00:22:10,694
actual documents, just like say Google.com,

346
00:22:10,732 --> 00:22:14,006
right? You search for the

347
00:22:14,028 --> 00:22:17,946
highest paid actors, right? All the keywords are used and

348
00:22:18,048 --> 00:22:23,050
whichever documents or whichever web links have those keywords

349
00:22:23,550 --> 00:22:27,226
retrieve the particular links and are displayed. So that's what

350
00:22:27,248 --> 00:22:30,734
the reverse inverted index is about. So when you're designing or

351
00:22:30,772 --> 00:22:34,958
building a search engine or anything, one of the most important

352
00:22:35,124 --> 00:22:38,462
storage architectural considerations is building an

353
00:22:38,516 --> 00:22:42,350
inverted index. So now moving on to the second

354
00:22:42,420 --> 00:22:46,690
part is again, we're still in the storage department.

355
00:22:47,030 --> 00:22:50,286
So it is a bit tangential,

356
00:22:50,398 --> 00:22:53,746
but still in the storage part is partitioning the databases. Now,

357
00:22:53,848 --> 00:22:57,270
until now, we talked about the data structure behind

358
00:22:57,420 --> 00:23:01,474
the storage, where the data is being stored.

359
00:23:01,602 --> 00:23:06,774
Now, how the data is being like,

360
00:23:06,972 --> 00:23:10,458
you can't use one database or you can't use one storage system.

361
00:23:10,544 --> 00:23:14,202
It's always distributed with all these large scale, large data

362
00:23:14,256 --> 00:23:17,658
intensive systems, right? So we all know about

363
00:23:17,744 --> 00:23:21,230
primary indices, but I would like to focus on something called

364
00:23:21,300 --> 00:23:24,654
secondary index. Now let's understand what is

365
00:23:24,692 --> 00:23:28,014
secondary index and why we need to know, and what are the

366
00:23:28,052 --> 00:23:32,640
architectural best practices you need to consider

367
00:23:35,190 --> 00:23:38,946
to use the right secondary index. Now, let's take an

368
00:23:38,968 --> 00:23:43,042
example. I took an online book management system here and

369
00:23:43,176 --> 00:23:46,406
say a user is trying to find,

370
00:23:46,508 --> 00:23:50,566
I wrote it in red here, trying to find all books by a

371
00:23:50,588 --> 00:23:52,200
particular author called.

372
00:23:54,730 --> 00:23:58,710
So now what

373
00:23:58,780 --> 00:24:02,278
happens here is the user sends that find all books

374
00:24:02,454 --> 00:24:06,838
by David, and it goes to, obviously the microservice,

375
00:24:07,014 --> 00:24:10,502
and the request goes to the backend storage. You see, there is a primary

376
00:24:10,566 --> 00:24:13,886
index for fast retrieval of the data. Say,

377
00:24:14,068 --> 00:24:17,646
when you say find all books, there are the data. First of

378
00:24:17,668 --> 00:24:21,114
all, this is how the data is partitioned. Let's assume,

379
00:24:21,162 --> 00:24:25,920
right, you don't have one

380
00:24:26,930 --> 00:24:30,174
storage or one server or one back end storage,

381
00:24:30,222 --> 00:24:33,890
where you get all the data. It's always distributed. You have

382
00:24:34,040 --> 00:24:37,174
partition one located in, say,

383
00:24:37,212 --> 00:24:40,582
Virginia, partition two located in Seattle, partition three

384
00:24:40,636 --> 00:24:44,680
located in, say, Europe. You have data scattered all across.

385
00:24:48,350 --> 00:24:53,434
Let's assume the data is sorted or partitioned based

386
00:24:53,472 --> 00:24:57,226
on the genre, and say, now we have to find all

387
00:24:57,248 --> 00:25:01,134
the books by the author. David, you need

388
00:25:01,172 --> 00:25:04,746
to go through, like novel

389
00:25:04,938 --> 00:25:08,778
science and biography, each of the partitions. And in each partition

390
00:25:08,874 --> 00:25:12,560
there is something called secondary index. Why? Because even

391
00:25:13,810 --> 00:25:16,978
with just going into the partition won't help you, right? There might be a

392
00:25:16,984 --> 00:25:20,434
lot of other authors too, and you want to retrieve the books of

393
00:25:20,472 --> 00:25:22,926
only one but one author, which is searched.

394
00:25:22,958 --> 00:25:26,402
So going until the partition level is

395
00:25:26,456 --> 00:25:30,166
fine with the primary index, but in the primary index, in a

396
00:25:30,188 --> 00:25:34,114
partition, you actually need a secondary index to retrieve results

397
00:25:34,162 --> 00:25:37,994
faster and quick lookup. And that's why you need a secondary index. And now

398
00:25:38,032 --> 00:25:41,994
what happens here when

399
00:25:42,032 --> 00:25:46,102
you go to the secondary index and search for the author David,

400
00:25:46,246 --> 00:25:49,990
you have author David in partition one, two and three.

401
00:25:50,160 --> 00:25:53,306
So the data is retrieved from all three partitions,

402
00:25:53,418 --> 00:25:56,686
and then it is aggregated in the microservice and

403
00:25:56,708 --> 00:25:58,110
then returned to the user.

404
00:26:01,170 --> 00:26:05,214
So that's something which is a lot

405
00:26:05,252 --> 00:26:08,846
of activities happening there, right? Like aggregation.

406
00:26:08,958 --> 00:26:12,386
So it sounds fine, but let

407
00:26:12,408 --> 00:26:16,474
me explain. You this particular secondary

408
00:26:16,542 --> 00:26:19,846
index is located in each partition, right? That's why

409
00:26:19,868 --> 00:26:23,666
we call it local secondary index, or another name is partitioning secondary

410
00:26:23,698 --> 00:26:27,906
index by document. So the querying process across multiple partitions

411
00:26:27,938 --> 00:26:31,510
is known as scatter and gather. It's scattered,

412
00:26:31,590 --> 00:26:35,098
you're querying everything and you're gathering together, aggregating and sending it to the

413
00:26:35,104 --> 00:26:38,826
user. This involves parallel queries to each partition to

414
00:26:38,848 --> 00:26:42,714
collect the data needed, although parallelization can improve

415
00:26:42,762 --> 00:26:46,650
speed. Although parallelization can improve the speed,

416
00:26:46,810 --> 00:26:50,430
the scatter and gather can be resource intensive,

417
00:26:50,770 --> 00:26:53,970
especially in this kind of large databases.

418
00:26:54,790 --> 00:26:58,334
So the main costs are associated with querying each partition

419
00:26:58,382 --> 00:27:01,742
separately and then consolidating the results, which often require

420
00:27:01,886 --> 00:27:05,682
lot of computational and network resources. You're actually

421
00:27:05,736 --> 00:27:09,666
making calls over the network for fetching all the data. You can definitely optimize

422
00:27:09,698 --> 00:27:13,250
it. Consequently, while local secondary indices

423
00:27:13,330 --> 00:27:17,510
enhance partition specific query efficiently, which I just explained, they also

424
00:27:17,580 --> 00:27:21,066
necessitate a careful consideration of the overhead involved in

425
00:27:21,088 --> 00:27:24,634
scatter and gather operations in distributed data systems like this.

426
00:27:24,752 --> 00:27:28,122
So what is the solution? So what we need is

427
00:27:28,176 --> 00:27:31,726
not local for this particular use case, but we

428
00:27:31,748 --> 00:27:35,246
need a global secondary index. So here in this example,

429
00:27:35,428 --> 00:27:38,842
in this architecture, the secondary index

430
00:27:38,906 --> 00:27:40,880
is not local,

431
00:27:42,050 --> 00:27:45,150
it's not pertaining to a specific partition,

432
00:27:45,230 --> 00:27:48,354
but it is at the level of primary index itself. Now,

433
00:27:48,392 --> 00:27:52,850
when a user tries to find all the books for that particular author,

434
00:27:56,570 --> 00:27:59,926
we can directly let the microservice query through the

435
00:27:59,948 --> 00:28:02,840
secondary index. And you can see here,

436
00:28:03,690 --> 00:28:06,994
when the user asks for the books

437
00:28:07,042 --> 00:28:10,714
with author David, you can fetch it from partition one,

438
00:28:10,832 --> 00:28:13,820
two, and so,

439
00:28:14,670 --> 00:28:18,858
and there is no aggregation needed. And all

440
00:28:18,864 --> 00:28:22,814
the books data is actually returned back. And at the same time, if you want

441
00:28:22,852 --> 00:28:26,766
to retrieve all the books related to a particular genre like

442
00:28:26,788 --> 00:28:30,702
novel, it goes through primary index and say partition one,

443
00:28:30,836 --> 00:28:34,962
all the books with novel genre and

444
00:28:35,096 --> 00:28:38,942
all the authors are returned. So this is the more ideal.

445
00:28:39,006 --> 00:28:42,286
Like the partition secondary. Global secondary index

446
00:28:42,318 --> 00:28:46,038
is the most ideal in the particular

447
00:28:46,124 --> 00:28:52,418
case where you are drilling down querying

448
00:28:52,514 --> 00:28:56,454
certain authors books in a particular genre, like two levels of

449
00:28:56,492 --> 00:29:00,186
filters. So this partitioning is

450
00:29:00,208 --> 00:29:03,974
called partitioning secondary index by term. This approach

451
00:29:04,022 --> 00:29:08,230
offers a more efficient solution for queries that span multiple partitions,

452
00:29:08,310 --> 00:29:11,654
like searching by authors across all genres. It reduces

453
00:29:11,702 --> 00:29:15,226
overhead of scattered and gathered, which I described, since the index

454
00:29:15,258 --> 00:29:18,814
is global and not confined to individual partitions. However, one more

455
00:29:18,852 --> 00:29:22,794
thing, this method might introduce challenges in maintaining the global index.

456
00:29:22,842 --> 00:29:26,474
Like you're already having a primary index, right? So you have to have

457
00:29:26,532 --> 00:29:29,746
a separate data structure like a map, and where do you

458
00:29:29,768 --> 00:29:33,346
want to store it and how do you want to store it? And with

459
00:29:33,368 --> 00:29:36,478
a large data and large data intensive environment,

460
00:29:36,574 --> 00:29:40,114
it becomes a challenge. So it's a trade off between the ease of cross

461
00:29:40,162 --> 00:29:43,698
partition queries which you get with the global

462
00:29:43,794 --> 00:29:47,154
secondary index, and the complexity of maintaining a global

463
00:29:47,202 --> 00:29:50,554
index. So after all, everything in life is a trade off.

464
00:29:50,752 --> 00:29:54,362
Now let's get some differences, right? I'll give some

465
00:29:54,496 --> 00:29:57,926
real world use cases. So let's

466
00:29:57,958 --> 00:30:01,626
take an example, a couple of examples. When local secondary

467
00:30:01,658 --> 00:30:04,542
index is used and when global secondary index is used.

468
00:30:04,676 --> 00:30:09,870
So local is about partitioning.

469
00:30:10,850 --> 00:30:14,740
Querying in a particular partition, say in an ecommerce website,

470
00:30:16,390 --> 00:30:20,580
the buyer wants to look at all the products,

471
00:30:21,430 --> 00:30:25,698
say in electronic products and with

472
00:30:25,784 --> 00:30:29,350
a particular company, say Sony, he wants to look at.

473
00:30:29,420 --> 00:30:32,630
He or she wants to look at Sony electronic products.

474
00:30:32,700 --> 00:30:36,662
In Sony electronic products. So the first level is go to

475
00:30:36,716 --> 00:30:40,662
electronics partition. And then in electronics partition you want to retrieve

476
00:30:40,806 --> 00:30:44,586
all the products that

477
00:30:44,608 --> 00:30:48,214
are Sony. So for that you need secondary index right here. The Sony

478
00:30:48,262 --> 00:30:51,742
products or the company name

479
00:30:51,796 --> 00:30:54,314
is a secondary index in the electronics category.

480
00:30:54,362 --> 00:30:57,806
Electronics, what is that partition? So we

481
00:30:57,828 --> 00:31:01,360
only need the data from that partition. Now consider a use case

482
00:31:01,890 --> 00:31:05,374
which is more applicable for the global secondary index

483
00:31:05,422 --> 00:31:08,974
is say any company or any firm,

484
00:31:09,022 --> 00:31:12,514
right? A multinational firm has employees across

485
00:31:12,712 --> 00:31:16,050
different countries like US, UK, Asia.

486
00:31:16,470 --> 00:31:20,006
Now the HR department wants to view all the

487
00:31:20,028 --> 00:31:23,394
managers across the company respect

488
00:31:23,442 --> 00:31:26,920
of the country. And let's assume that

489
00:31:28,350 --> 00:31:30,970
the storage is actually partitioned.

490
00:31:33,870 --> 00:31:37,574
It is sharded as per the country like US employees

491
00:31:37,622 --> 00:31:41,374
are present. The data is present in the US data center, UK and UK data

492
00:31:41,412 --> 00:31:44,910
center, so on. And now for this particular

493
00:31:44,980 --> 00:31:48,862
query from the HR to view all the managers across the

494
00:31:48,996 --> 00:31:53,066
company, you don't need a local secondary

495
00:31:53,098 --> 00:31:56,462
index. You don't need to look into the details of one particular partition.

496
00:31:56,526 --> 00:32:00,820
Rather you want to look at all the partitions. And this is where

497
00:32:02,870 --> 00:32:06,806
the importance of global secondary index comes into picture. So data is

498
00:32:06,828 --> 00:32:10,434
obtained from all partitions. So those are the two use cases.

499
00:32:10,482 --> 00:32:13,766
And yeah, this multinational company employee database is a

500
00:32:13,788 --> 00:32:17,638
common thing for a lot of companies. So I'm

501
00:32:17,654 --> 00:32:21,100
sure many of you guys can relate to it.

502
00:32:21,470 --> 00:32:25,322
Now we'll switch gears, moving on to the next

503
00:32:25,376 --> 00:32:29,290
part, which is again, we are still in the

504
00:32:29,440 --> 00:32:33,440
storage world or a database world. Now I'll be talking about this

505
00:32:34,050 --> 00:32:37,550
conflict free replicated data types. So what are they?

506
00:32:37,620 --> 00:32:40,894
But before I talk about these data types, we should

507
00:32:40,932 --> 00:32:44,594
understand why we are even talking about this.

508
00:32:44,632 --> 00:32:48,782
Or how can the architecture be improved

509
00:32:48,926 --> 00:32:52,402
or architectural considerations should have

510
00:32:52,536 --> 00:32:55,498
something like a CRDTs.

511
00:32:55,694 --> 00:32:58,818
Now let's talk about a concept called replication.

512
00:32:58,994 --> 00:33:03,526
Now what

513
00:33:03,548 --> 00:33:07,606
is replication? Right. So as you can see,

514
00:33:07,788 --> 00:33:11,514
I directly am mentioning multilateral replication here. So that

515
00:33:11,552 --> 00:33:14,906
means the back end storage or

516
00:33:14,928 --> 00:33:18,474
the data is not present at one place, but it is copied over

517
00:33:18,512 --> 00:33:21,774
to multiple servers or multiple data

518
00:33:21,812 --> 00:33:28,400
centers or multiple places. And again,

519
00:33:29,890 --> 00:33:32,998
multileader replication is needed in distributed systems

520
00:33:33,034 --> 00:33:36,738
for several reasons. First of all, replication is needed. Several reasons. And on

521
00:33:36,744 --> 00:33:40,878
top of that, multireeader replication. Why? Like first and foremost, high availability.

522
00:33:41,054 --> 00:33:44,674
Say system availability is

523
00:33:44,712 --> 00:33:48,226
improved by providing multiple independent leader

524
00:33:48,258 --> 00:33:52,066
nodes. Say if one leader node fails, like one database node

525
00:33:52,098 --> 00:33:55,238
fails or becomes unavailable, other leaders can

526
00:33:55,404 --> 00:33:59,526
continue to accept the right request, right. Ensuring uninterrupted

527
00:33:59,558 --> 00:34:02,986
access to the data and services so the user has good experience.

528
00:34:03,168 --> 00:34:05,850
Another reason is say, fault tolerance,

529
00:34:06,750 --> 00:34:10,646
especially this multileader replication improves

530
00:34:10,678 --> 00:34:13,994
the fault tolerance by providing redundancy at the leader level itself.

531
00:34:14,112 --> 00:34:17,786
If say one leader node fails, other leader node can continue to accept

532
00:34:17,818 --> 00:34:21,022
write of business and preventing data loss and service

533
00:34:21,076 --> 00:34:25,186
disruptions and things like that. And another big important

534
00:34:25,288 --> 00:34:29,346
use, big important advantage is the

535
00:34:29,368 --> 00:34:33,614
write scalability. So this particular replication

536
00:34:33,662 --> 00:34:37,314
model allows write operations to be distributed across multiple leader nodes.

537
00:34:37,362 --> 00:34:41,254
So this enables the system to handle large volumes of

538
00:34:41,292 --> 00:34:44,866
write operations by parallelizing writes across multiple nodes,

539
00:34:44,898 --> 00:34:48,406
involving improving the overall throughput and scalability.

540
00:34:48,598 --> 00:34:52,026
So again, like geographic distribution in

541
00:34:52,048 --> 00:34:55,914
general, the data earlier I mentioned by giving the example of the

542
00:34:55,952 --> 00:34:59,450
employees database, right? So the data is always distributed geographically,

543
00:35:00,030 --> 00:35:03,274
allowing the leader nodes to be located in different regions

544
00:35:03,322 --> 00:35:07,274
or data centers. So this enables the data to be replicated closer to the users

545
00:35:07,402 --> 00:35:11,146
or replication instances, reducing latency and improving the overall

546
00:35:11,178 --> 00:35:15,054
user experience. So that's why we have multiple

547
00:35:15,102 --> 00:35:18,660
nodes and the data is always copied from

548
00:35:19,350 --> 00:35:23,060
one node to the other node. And now

549
00:35:23,910 --> 00:35:27,000
let's take this use case where

550
00:35:28,250 --> 00:35:33,974
say you have two users trying

551
00:35:34,012 --> 00:35:37,346
to edit a common shared Google document.

552
00:35:37,458 --> 00:35:40,966
Let's assume the title of the document is a and then

553
00:35:40,988 --> 00:35:44,282
the ID of the document is one, two, three. Now in the red

554
00:35:44,336 --> 00:35:47,162
flow, the user red and purple both.

555
00:35:47,296 --> 00:35:50,458
Step one happen at the same time. The user one says,

556
00:35:50,544 --> 00:35:54,106
hey, want to update the page? The Google Doc

557
00:35:54,298 --> 00:35:58,266
title is equal to b for this particular Google Doc

558
00:35:58,298 --> 00:36:01,486
one to three. And user two says yeah, even I want

559
00:36:01,508 --> 00:36:04,914
to set the title to C. And what happens? Step number

560
00:36:04,952 --> 00:36:08,850
two? In red and purple, the data is updated

561
00:36:10,310 --> 00:36:14,100
by the leader node. Internally. That means

562
00:36:16,310 --> 00:36:19,718
the leader one changes the title from A to B,

563
00:36:19,804 --> 00:36:23,142
and the leader two changes the title from A to C.

564
00:36:23,276 --> 00:36:26,774
Done. And don't focus on that follower here. It is just

565
00:36:26,812 --> 00:36:29,946
like a asynchronous copying of the

566
00:36:29,968 --> 00:36:33,206
data from leader to follower for the read operation. So that's

567
00:36:33,238 --> 00:36:37,114
again a different concept. Leader follower model of

568
00:36:37,312 --> 00:36:40,986
general replication. So let's

569
00:36:41,018 --> 00:36:44,240
focus on step four and five now. Now,

570
00:36:44,930 --> 00:36:48,846
like I said, replication involves copying data from one data center to

571
00:36:48,868 --> 00:36:52,574
the other asynchronously so

572
00:36:52,612 --> 00:36:56,366
that they are all consistent. And the way the data is

573
00:36:56,468 --> 00:37:00,286
synchronized between the leaders. Leader one, two, and there can be a lot of leaders,

574
00:37:00,318 --> 00:37:03,954
right. Leader 12345. There are a lot of topologies for it,

575
00:37:03,992 --> 00:37:07,230
say star topology, ring topology,

576
00:37:07,310 --> 00:37:10,598
mesh topology. And again, that's again a different concept. I'm not going

577
00:37:10,604 --> 00:37:13,862
to go into it, but the concept here is leader one, leader two

578
00:37:13,916 --> 00:37:17,446
should be coming into sync or syncing each

579
00:37:17,468 --> 00:37:21,610
other. So this asynchronous, during this asynchronous operation,

580
00:37:21,950 --> 00:37:25,402
what happens is let's assume red

581
00:37:25,456 --> 00:37:29,162
step four, red line, step four, red line. Step four

582
00:37:29,296 --> 00:37:32,586
says four and five says, hey,

583
00:37:32,688 --> 00:37:36,574
leader one is saying to leader two as part of step four and five.

584
00:37:36,772 --> 00:37:40,880
The old document title is A and I want to change it to B.

585
00:37:41,250 --> 00:37:44,306
But what happens? Leader two says, hey,

586
00:37:44,408 --> 00:37:47,460
what is a? I don't have a.

587
00:37:50,230 --> 00:37:53,746
It is already changed to C. So there is a conflict there. It can't be

588
00:37:53,768 --> 00:37:57,314
changed. And then now steps four and five at

589
00:37:57,352 --> 00:38:01,654
purple also you can see the reader two goes

590
00:38:01,692 --> 00:38:05,650
to leader one and says, hey, I want to change document

591
00:38:05,810 --> 00:38:10,010
which is titled as a to C.

592
00:38:10,160 --> 00:38:13,882
Then leader one says at purple, step four and five. At step

593
00:38:13,936 --> 00:38:17,386
five of purple, the leader one says, what are you

594
00:38:17,408 --> 00:38:21,562
talking about? I don't have any document with

595
00:38:21,616 --> 00:38:25,118
a. I only have it B because it's already changed to

596
00:38:25,124 --> 00:38:28,334
B. So there is the conflict. So how is this

597
00:38:28,372 --> 00:38:32,014
conflict resolved? How can you resolve such conflict during the

598
00:38:32,132 --> 00:38:34,750
multilider data replication,

599
00:38:34,910 --> 00:38:38,562
that's where we shouldn't use the regular data

600
00:38:38,616 --> 00:38:42,686
types like int or maps sets

601
00:38:42,718 --> 00:38:46,494
and all the data types we have while actually doing

602
00:38:46,552 --> 00:38:49,958
the replication, while actually copying the

603
00:38:49,964 --> 00:38:53,000
data from leader one to leader two or leader two to leader one.

604
00:38:53,450 --> 00:38:57,430
We need to use some data types, specific data types called

605
00:38:57,580 --> 00:39:01,100
conflict free replicated data types. They are different.

606
00:39:02,190 --> 00:39:05,594
They are special data types. I gave an example here. I thought

607
00:39:05,632 --> 00:39:09,274
integer is more easier to explain, so I just gave

608
00:39:09,312 --> 00:39:12,846
a code sample here. You can see that

609
00:39:13,028 --> 00:39:16,714
it's not a regular integer which is declared. It is an atomic

610
00:39:16,762 --> 00:39:20,350
integer which is coming with the concurrent atomic

611
00:39:21,250 --> 00:39:24,626
import utils. And you

612
00:39:24,648 --> 00:39:27,778
can see leader one in the

613
00:39:27,784 --> 00:39:31,282
main block. Two objects are instantiated. Imagine both

614
00:39:31,336 --> 00:39:36,446
are like this program is being run instantiated

615
00:39:36,478 --> 00:39:40,466
as a multithreaded program in leader one and leader two and leader

616
00:39:40,498 --> 00:39:43,926
one increments the counter by one and

617
00:39:43,948 --> 00:39:47,406
leader two also increments counter by one, as you can see in the main block.

618
00:39:47,538 --> 00:39:51,370
And after that each one have value

619
00:39:51,440 --> 00:39:55,414
as one. Now here the merge

620
00:39:55,462 --> 00:39:59,526
leaders is the concept of actually the replication we're

621
00:39:59,558 --> 00:40:03,246
talking about. Like merging is nothing but replication. And in that, in the

622
00:40:03,268 --> 00:40:07,146
merge logic, as you can see at the top public void merge,

623
00:40:07,338 --> 00:40:10,714
you're actually adding the logic where you're ensuring

624
00:40:10,762 --> 00:40:14,962
the data is consistent. You are not having

625
00:40:15,016 --> 00:40:18,814
any conflict in terms of the inconsistent

626
00:40:18,862 --> 00:40:22,274
data, but rather you are ensuring that the data is

627
00:40:22,312 --> 00:40:26,302
consistent across both the nodes and merging it accordingly.

628
00:40:26,366 --> 00:40:31,266
So using the conflict

629
00:40:31,298 --> 00:40:33,910
free replicated data types,

630
00:40:35,130 --> 00:40:38,694
we can ensure that these conflicts don't occur in

631
00:40:38,732 --> 00:40:41,830
any replication, mostly the multi leader replication.

632
00:40:44,170 --> 00:40:47,242
Now we will switch case again,

633
00:40:47,376 --> 00:40:50,880
move out of the storage world, and rather focus

634
00:40:52,050 --> 00:40:56,174
on some architectural considerations for

635
00:40:56,212 --> 00:41:00,126
the end to end design of the system. Now, when considering the

636
00:41:00,148 --> 00:41:03,698
end to end design of a system, there are two types, inside out and outside

637
00:41:03,784 --> 00:41:06,770
in. Now let me go into the details.

638
00:41:11,430 --> 00:41:15,220
As you can see the pictures here, they are very

639
00:41:16,730 --> 00:41:20,310
general, like whatever I have been talking

640
00:41:20,380 --> 00:41:25,494
about until now. Like say any

641
00:41:25,532 --> 00:41:29,234
system has, you can see outside in architecture

642
00:41:29,282 --> 00:41:32,270
first, where there's a user making some requests,

643
00:41:32,290 --> 00:41:35,994
say ecommerce platform, he wants to make some payment. After selecting a list of things

644
00:41:36,032 --> 00:41:39,114
to pay for, you have a user interface where he does that.

645
00:41:39,232 --> 00:41:43,194
And then you have the APIs, right? Like the APIs

646
00:41:43,242 --> 00:41:46,778
are invoked and at a particular endpoint the HTTP call comes onto

647
00:41:46,794 --> 00:41:50,682
the microservices. And then internally there is some data manipulation

648
00:41:50,746 --> 00:41:53,914
there. Writing or reading happens. Ultimately it's some crud operation,

649
00:41:53,962 --> 00:41:57,682
right? Like create, read, update or delete. And step

650
00:41:57,736 --> 00:42:01,426
four is the classes or abstraction, which is

651
00:42:01,448 --> 00:42:04,706
defined on top of the database. And then you actually write it

652
00:42:04,728 --> 00:42:07,602
to the DB. So this is the general flow.

653
00:42:07,746 --> 00:42:11,126
Now, what is outside in and inside out?

654
00:42:11,228 --> 00:42:14,758
So let's say there are two ways of designing a

655
00:42:14,764 --> 00:42:18,202
system. So when there is a use

656
00:42:18,256 --> 00:42:22,026
case, right, you have to design a

657
00:42:22,048 --> 00:42:25,466
system. Either you can define it from the

658
00:42:25,488 --> 00:42:29,354
user itself, saying user interacts the system in certain way,

659
00:42:29,472 --> 00:42:32,794
user opens certain page on the UI and user

660
00:42:32,842 --> 00:42:37,242
clicks this button. That results in calling a particular API

661
00:42:37,306 --> 00:42:40,426
onto the backend system. If you go by that approach, like a user

662
00:42:40,458 --> 00:42:43,842
centric approach, or a user interactive approach, that is

663
00:42:43,896 --> 00:42:47,540
outside in architecture, I would say it's more like a

664
00:42:48,390 --> 00:42:51,602
product management or product driven approach. When a product

665
00:42:51,656 --> 00:42:55,074
managers come to a software engineering team

666
00:42:55,112 --> 00:42:58,680
and says that hey, this is what we want to build as a product,

667
00:42:59,210 --> 00:43:02,338
then you most likely tend

668
00:43:02,354 --> 00:43:05,558
to go with outside in architecture and inside

669
00:43:05,644 --> 00:43:09,226
out architecture. Is more engineering driven. That means you

670
00:43:09,248 --> 00:43:13,322
are not starting off with the user or user perspective, but rather

671
00:43:13,376 --> 00:43:17,642
you are changing the data models, data types, and then

672
00:43:17,696 --> 00:43:21,514
accordingly you are changing the abstraction. Back end classes

673
00:43:21,562 --> 00:43:24,906
like data access layer. Like for example, you're splitting

674
00:43:24,938 --> 00:43:28,174
the database into multiple databases with

675
00:43:28,212 --> 00:43:32,000
foreign key and primary key linkings, and then

676
00:43:32,930 --> 00:43:36,594
you are writing new classes on top of it. And then you

677
00:43:36,632 --> 00:43:40,286
are, accordingly you are defining some new microservices. It is domain

678
00:43:40,318 --> 00:43:43,966
driven. So this is like the engineering

679
00:43:43,998 --> 00:43:47,942
team decided to make some architectural enhancements within

680
00:43:47,996 --> 00:43:51,270
the system. So that's when you actually

681
00:43:51,340 --> 00:43:54,994
start off with the database, and then the classes

682
00:43:55,042 --> 00:43:58,694
on wrapping around the database, and then the microservices, and then the API change

683
00:43:58,732 --> 00:44:02,726
and ultimately it propagates all the way to the user.

684
00:44:02,838 --> 00:44:05,846
So that is the inside out architecture.

685
00:44:05,878 --> 00:44:10,330
So an example of inside out architecture can be say monolithic to microservices

686
00:44:10,770 --> 00:44:14,762
decomposition. And outside in architecture

687
00:44:14,826 --> 00:44:18,186
example can be product driven, right? Or user

688
00:44:18,218 --> 00:44:22,014
driven. It can be like ecommerce platform, where the user goes and

689
00:44:22,132 --> 00:44:26,066
purchases things. And how a user interacts with the system

690
00:44:26,248 --> 00:44:30,580
is one thing, let's say

691
00:44:31,510 --> 00:44:35,314
inside out. Another example for inside out can be a

692
00:44:35,352 --> 00:44:38,994
banking system. In developing a banking system, the core domain

693
00:44:39,042 --> 00:44:42,354
revolves around financial transactions, accounts,

694
00:44:42,482 --> 00:44:46,278
customer relationships. All these are like entity relationship model needs to

695
00:44:46,284 --> 00:44:50,634
be defined and then written, right? And then the

696
00:44:50,752 --> 00:44:54,678
domain driven design starts by modeling these concepts

697
00:44:54,774 --> 00:44:58,154
and then defining the business rules governing them. Once the

698
00:44:58,272 --> 00:45:01,742
domain is well defined, then the

699
00:45:01,796 --> 00:45:04,890
infrastructure things such as the storage,

700
00:45:04,970 --> 00:45:08,586
user interfaces and all the external integrations are addressed

701
00:45:08,618 --> 00:45:12,174
and it's propagated out. So that's the inside out

702
00:45:12,212 --> 00:45:16,034
and like outside in. I told about ecommerce platform, right? So imagine a company

703
00:45:16,072 --> 00:45:19,698
is building ecommerce platform that aims to provide a

704
00:45:19,704 --> 00:45:24,114
seamless shopping experience to its customers. So now

705
00:45:24,152 --> 00:45:27,538
to apply an outside in architecture approach

706
00:45:27,634 --> 00:45:31,826
for such use. Case, the development starts by identifying

707
00:45:31,858 --> 00:45:35,238
the key user interactions and requirements from the

708
00:45:35,244 --> 00:45:38,374
perspective of both customers and sellers. Then they prioritize

709
00:45:38,422 --> 00:45:42,380
features that directly impact the user experience, such as product search,

710
00:45:42,750 --> 00:45:45,962
browsing, purchasing and order tracking and all of that,

711
00:45:46,016 --> 00:45:49,274
right? Yeah, so that's what

712
00:45:49,312 --> 00:45:52,666
I have just described here. I gave some examples as

713
00:45:52,688 --> 00:45:56,762
point number four. Inside out you can see monolithic to microservices

714
00:45:56,826 --> 00:46:00,266
like domain driven or domain driven applications

715
00:46:00,298 --> 00:46:03,938
like banking system. And outside in

716
00:46:04,024 --> 00:46:09,410
user centric design. As I just explained, API driven inside

717
00:46:09,480 --> 00:46:12,658
out, as you can imagine, right? It's a

718
00:46:12,664 --> 00:46:16,242
push architecture or a push strategy because you're going

719
00:46:16,296 --> 00:46:19,446
from database, which is inside the back end

720
00:46:19,468 --> 00:46:23,298
system. You can think of it as inside the back end system, and then you're

721
00:46:23,314 --> 00:46:26,630
going out to the user, so it's inside out or

722
00:46:26,700 --> 00:46:29,946
push. And then that's why the outside in is

723
00:46:29,968 --> 00:46:33,750
more coming from the user, the end user,

724
00:46:33,830 --> 00:46:37,430
all the way until the system, right? So that is user

725
00:46:37,510 --> 00:46:41,574
into the system. So you can imagine yourself as the system you're either pushing

726
00:46:41,622 --> 00:46:45,550
or then for pulling. So that's how the strategies are defined.

727
00:46:48,210 --> 00:46:51,982
Since if you're doing something

728
00:46:52,036 --> 00:46:55,298
like monolithic to microservices rearchitecture, like an inside

729
00:46:55,384 --> 00:46:58,498
out, you know all the details of the system,

730
00:46:58,584 --> 00:47:02,466
like what needs to be changed. And you

731
00:47:02,488 --> 00:47:05,970
don't know about UI changes in that particular

732
00:47:06,120 --> 00:47:10,040
case. Right? So that's why you start off with internal things and

733
00:47:12,730 --> 00:47:16,098
that's why I mentioned at the second point, like forecast the demands

734
00:47:16,114 --> 00:47:19,914
of the UI needs, and outside in is exactly opposite. You start

735
00:47:19,952 --> 00:47:23,594
from the UI, you know what UI is demanding and then you

736
00:47:23,632 --> 00:47:27,370
go inside. These are the four

737
00:47:27,520 --> 00:47:31,054
topics I wanted to cover as part of

738
00:47:31,092 --> 00:47:34,842
the architectural practices,

739
00:47:34,986 --> 00:47:38,826
the important architectural trade offs or design decisions

740
00:47:38,858 --> 00:47:43,230
that one needs to consider, especially a software architect

741
00:47:43,590 --> 00:47:48,546
designing these data intensive systems, knowing the details of the

742
00:47:48,568 --> 00:47:52,286
back end to make the right decisions based on some crucial trade offs.

743
00:47:52,398 --> 00:47:56,070
And there are other things like say consistency

744
00:47:58,010 --> 00:48:01,320
and availability and

745
00:48:02,090 --> 00:48:05,240
lot of other aspects of the system which can be considered and

746
00:48:05,770 --> 00:48:09,478
architectural practices needs to be employed. But yeah,

747
00:48:09,564 --> 00:48:13,382
I'll keep that for some other talk. But thanks

748
00:48:13,436 --> 00:48:16,946
a lot for listening to my session

749
00:48:16,978 --> 00:48:19,700
today and I really appreciate it. Thank you.

