1
00:00:25,170 --> 00:00:29,720
Hello and welcome to Conf 42, Cloud native 2024.

2
00:00:30,250 --> 00:00:34,322
My name is Ricardo Castro and today we're going to talk about architecting

3
00:00:34,386 --> 00:00:36,710
resilient cloud native applications.

4
00:00:37,290 --> 00:00:41,142
Specifically, we're going to focus on practical tips for

5
00:00:41,196 --> 00:00:44,678
deployment and runtime patterns. What do we have on

6
00:00:44,684 --> 00:00:48,630
the menu for today? We'll explore some of the patterns to build

7
00:00:48,700 --> 00:00:52,254
resilient cloud native applications. Here's what

8
00:00:52,292 --> 00:00:55,630
we'll cover. We will see deployment patterns,

9
00:00:56,210 --> 00:01:00,042
blue green deployments, exploring seamless transitions to minimize

10
00:01:00,106 --> 00:01:03,998
downtime updates. We'll see rolling updates.

11
00:01:04,174 --> 00:01:07,570
We'll try to minimize user disruption by using

12
00:01:07,640 --> 00:01:10,862
gradual code changes. We'll explore

13
00:01:10,926 --> 00:01:14,446
canary deployments. We will examine strategies for controlled

14
00:01:14,478 --> 00:01:17,766
rollouts and early feedback end to end with

15
00:01:17,788 --> 00:01:22,194
deployment patterns. We will see dark launches. We will delve into the prerelease

16
00:01:22,242 --> 00:01:26,082
testing and feature gating. After that, we will explore

17
00:01:26,146 --> 00:01:29,622
runtime resilience patterns. We will explore

18
00:01:29,766 --> 00:01:34,294
popular patterns like timeouts and retries. We'll see how to prevent applications

19
00:01:34,342 --> 00:01:37,290
from stalling due to slow dependencies.

20
00:01:37,790 --> 00:01:41,802
We'll also see rate limiting, a technique to ensure fair resource

21
00:01:41,866 --> 00:01:45,742
allocation and prevent overload. We'll also

22
00:01:45,796 --> 00:01:49,534
see bulkheads. We'll understand how to isolate failures and

23
00:01:49,572 --> 00:01:53,186
improve overall stability. And finally, we will see

24
00:01:53,208 --> 00:01:57,074
circuit breakers. We will learn how to protect critical services

25
00:01:57,192 --> 00:02:01,262
from castaining failures. The world of cloud native

26
00:02:01,326 --> 00:02:05,902
applications promises remarkable benefits, incredible scalability,

27
00:02:06,046 --> 00:02:09,706
rapid development cycles, and the agility to meet ever changing

28
00:02:09,758 --> 00:02:13,510
business demands. There's an inherent tradeoff.

29
00:02:14,730 --> 00:02:18,966
This distributed architecture, with its reliance on microservices,

30
00:02:19,078 --> 00:02:21,862
external APIs, and managed infrastructure,

31
00:02:22,006 --> 00:02:25,370
introduces a unique set of fragility concerns.

32
00:02:25,790 --> 00:02:29,078
To truly harness the power of cloud native development,

33
00:02:29,174 --> 00:02:32,670
we must make resilience a foundational principle.

34
00:02:33,250 --> 00:02:36,762
This means ensuring our applications can withstand component

35
00:02:36,826 --> 00:02:40,842
failures, network glitches, and unexpected traffic surges,

36
00:02:40,986 --> 00:02:44,100
all while maintaining a seamless user experience.

37
00:02:44,870 --> 00:02:48,610
Let's start by addressing the core challenge of updates.

38
00:02:49,190 --> 00:02:52,642
How do we deploy new code or features without taking our

39
00:02:52,696 --> 00:02:56,722
applications offline? This is where deployment patterns

40
00:02:56,786 --> 00:03:00,246
come into play. These are strategic approaches to

41
00:03:00,268 --> 00:03:04,294
rolling out changes in a way that minimizes or even eliminates any

42
00:03:04,332 --> 00:03:08,342
disruptions to our users. We'll explore four

43
00:03:08,396 --> 00:03:12,722
key patterns, bluegreen deployments, rolling updates, canary deployments,

44
00:03:12,786 --> 00:03:16,006
and dart launches. The concept behind bluegreen

45
00:03:16,038 --> 00:03:19,100
deployments is elegantly simple.

46
00:03:19,710 --> 00:03:23,374
You maintain two identical production environments. Blue is

47
00:03:23,412 --> 00:03:26,720
where your current live environment, serving users lives,

48
00:03:27,090 --> 00:03:30,682
while green stands by fully updated with the latest

49
00:03:30,746 --> 00:03:34,574
code. Once you're ready to deploy, you seamlessly

50
00:03:34,622 --> 00:03:37,220
redirect traffic from blue to green.

51
00:03:37,830 --> 00:03:40,690
The beauty lies in the rollback capability.

52
00:03:41,190 --> 00:03:44,354
If any issues arise, you can

53
00:03:44,552 --> 00:03:48,066
instantly switch back to blue. This offers

54
00:03:48,098 --> 00:03:51,810
a safety net for large updates, minimizing the potential

55
00:03:51,890 --> 00:03:55,506
for downtime. Let's see an example. Let's imagine

56
00:03:55,538 --> 00:03:59,066
that we have a set of users accessing our V one application through a

57
00:03:59,088 --> 00:04:02,602
load balancer. We deploy V two of our

58
00:04:02,656 --> 00:04:05,754
service, and we test that everything is okay.

59
00:04:05,952 --> 00:04:09,974
Once we're confident, we redirect traffic from the load balancer to our

60
00:04:10,032 --> 00:04:13,450
version two. If any error arises,

61
00:04:13,530 --> 00:04:16,640
we simply switch back from V two to V one.

62
00:04:17,090 --> 00:04:20,286
Rolling updates offer a controlled approach to

63
00:04:20,308 --> 00:04:23,762
introducing new code changes. Instead of

64
00:04:23,816 --> 00:04:27,922
updating our entire environment in one go, the new version is

65
00:04:27,976 --> 00:04:32,066
gradually rolled out across your instances. This is

66
00:04:32,088 --> 00:04:35,798
like changing the tires of a moving car one at a time,

67
00:04:35,964 --> 00:04:39,270
allowing you to minimize any potential disruption.

68
00:04:39,850 --> 00:04:43,286
With each updated instance, you carefully monitor for

69
00:04:43,308 --> 00:04:47,094
any errors or any unexpected behavior. If any

70
00:04:47,132 --> 00:04:50,694
issue arises, the rollout can be paused or reversed,

71
00:04:50,742 --> 00:04:54,874
limiting the impact. Rolling updates are particularly well

72
00:04:54,912 --> 00:04:58,874
suited for containerized environments where tools like Kubernetes can

73
00:04:58,912 --> 00:05:02,270
seamlessly manage this process. In this example,

74
00:05:02,340 --> 00:05:06,734
we see that we have V one of our applications deployed one

75
00:05:06,772 --> 00:05:10,206
by one. We start by replacing V one with v

76
00:05:10,228 --> 00:05:13,934
two of our application. If at any point we see

77
00:05:13,972 --> 00:05:17,598
a problem, we can simply stop that rollout and even reverse

78
00:05:17,614 --> 00:05:21,582
it to a previous version. This doesn't mean that we have to update

79
00:05:21,646 --> 00:05:25,326
one verse one node at a time. We can deploy a percentage

80
00:05:25,358 --> 00:05:29,030
of nodes each time, but the idea is that this change

81
00:05:29,100 --> 00:05:32,166
is rolling, so we have a set of replicas that

82
00:05:32,188 --> 00:05:35,810
are updated at each time. Canary deployments

83
00:05:35,890 --> 00:05:40,054
take their name from the historical practice of miners bringing canaries

84
00:05:40,102 --> 00:05:43,926
underground. These birds were sensitive to dangerous

85
00:05:43,958 --> 00:05:47,210
gases, alerting the miners to potential hazards.

86
00:05:47,710 --> 00:05:51,326
Similarly, a canary deployment exposes your code to

87
00:05:51,348 --> 00:05:54,954
a small subset of users. You closely monitor

88
00:05:55,002 --> 00:05:58,526
key metrics, waiting, watching for any performance degradation or

89
00:05:58,548 --> 00:06:01,994
any error. If all goes well, you gradually

90
00:06:02,042 --> 00:06:05,810
roll out the updates to a larger and larger segment of your audience.

91
00:06:06,470 --> 00:06:09,698
This cautious approach helps catch issues early,

92
00:06:09,784 --> 00:06:13,426
before they impact your entire user base. So in

93
00:06:13,448 --> 00:06:16,854
this example, we start by rolling out the new version, v two, of our

94
00:06:16,892 --> 00:06:20,594
service. Then we start gradually shifting

95
00:06:20,642 --> 00:06:23,254
a percentage of our users to that v two.

96
00:06:23,452 --> 00:06:27,382
If everything goes well, we increase the switch between

97
00:06:27,436 --> 00:06:30,602
V one and V two, eventually arriving at 100%

98
00:06:30,656 --> 00:06:34,154
of users using V two. If any problem

99
00:06:34,272 --> 00:06:37,738
arises in this process, we can simply switch back and continue

100
00:06:37,824 --> 00:06:41,802
using V one. And our last pattern in the deployment

101
00:06:41,946 --> 00:06:46,046
patterns is dark launches. And dark launches introduce a

102
00:06:46,068 --> 00:06:49,822
fascinating twist. You deploy your new feature or code

103
00:06:49,876 --> 00:06:54,030
changes completely behind the scenes, hidden from your users.

104
00:06:54,370 --> 00:06:58,014
This allows you to conduct live testing, collect real world performance

105
00:06:58,062 --> 00:07:01,566
data, and even gather feedback from targeted and selected

106
00:07:01,598 --> 00:07:04,926
groups. Once you're confident in the new feature,

107
00:07:05,038 --> 00:07:08,546
you simply turn on the switch, making it instantly available

108
00:07:08,648 --> 00:07:12,002
to everyone. Narc launches are powerful

109
00:07:12,066 --> 00:07:15,526
when you need extensive pre release validation or you

110
00:07:15,548 --> 00:07:18,310
want to gradually ramp up a feature's usage.

111
00:07:18,890 --> 00:07:22,458
So the basic concept behind dark launches is this, you have a

112
00:07:22,464 --> 00:07:25,994
new feature, and then you are able to select who is able

113
00:07:26,032 --> 00:07:29,258
to access that new feature or not. You can use, for example,

114
00:07:29,344 --> 00:07:32,526
feature flags, where you can turn a feature on and on, and you

115
00:07:32,548 --> 00:07:36,430
can specify which users have access to it. You can

116
00:07:36,500 --> 00:07:40,154
also do things like providing a specific header

117
00:07:40,202 --> 00:07:43,282
that only certain users are able to use to access

118
00:07:43,336 --> 00:07:46,654
that feature. We've addressed how to safely deploy

119
00:07:46,702 --> 00:07:49,954
changes, but what about the unpredictable events that

120
00:07:49,992 --> 00:07:52,660
can happen while your application is live?

121
00:07:53,190 --> 00:07:56,546
Runtime resiliency patterns provide mechanisms to cope

122
00:07:56,578 --> 00:07:59,986
with partial failures, network issues, and incoming

123
00:08:00,018 --> 00:08:04,402
surging traffic. Let's dive into some essential patterns.

124
00:08:04,546 --> 00:08:08,214
Timeouts and retries rate limiting bulkheads and

125
00:08:08,252 --> 00:08:11,998
circuit breakers even the best designed

126
00:08:12,034 --> 00:08:16,410
systems components can become slow and unresponsive.

127
00:08:17,070 --> 00:08:20,406
Maybe a database is struggling or an external service is

128
00:08:20,448 --> 00:08:23,774
down. In these scenarios, timeouts can act

129
00:08:23,812 --> 00:08:27,022
as a deadline. If a dependent service doesn't respond within

130
00:08:27,076 --> 00:08:31,310
a fixed set of time, it stops waiting and signals failure.

131
00:08:31,730 --> 00:08:35,506
But that's just half of the equation. Retries give your

132
00:08:35,528 --> 00:08:38,930
application a second or third or fourth chance to succeed.

133
00:08:39,430 --> 00:08:43,214
Retries will automatically attempt a repeated fail

134
00:08:43,262 --> 00:08:47,046
request, often with increasing intervals, to avoid overwhelming the

135
00:08:47,068 --> 00:08:50,386
struggling service. This combination help prevent

136
00:08:50,418 --> 00:08:53,750
single failures from cascading through your system, keeping things running

137
00:08:53,820 --> 00:08:57,654
as smoothly as possible. So in this example, we see that

138
00:08:57,692 --> 00:09:01,386
service A tries to do a request to service B because we have

139
00:09:01,408 --> 00:09:04,714
no timeout. Service B can take how long it

140
00:09:04,752 --> 00:09:07,786
needs to actually give a response back. In this example, we see that

141
00:09:07,808 --> 00:09:11,958
it takes 5 seconds, but maybe 5 seconds for us is unacceptable.

142
00:09:12,054 --> 00:09:14,970
So we can set a timeout, for example, for 3 seconds.

143
00:09:15,130 --> 00:09:18,606
This means that after 3 seconds we will mark that request as

144
00:09:18,628 --> 00:09:21,546
a failure. In the case of retries,

145
00:09:21,738 --> 00:09:24,750
your services can do a request to a downstream service.

146
00:09:24,900 --> 00:09:28,254
If that becomes as an error, we can automatically retry

147
00:09:28,302 --> 00:09:31,922
that request until it eventually succeeds, or until

148
00:09:31,976 --> 00:09:35,442
we have a limit of the amount of retries that we can do. It's important

149
00:09:35,496 --> 00:09:38,834
to note that these requests usually increase in these

150
00:09:38,872 --> 00:09:43,234
retry requests easily increase in time so that we don't overwhelm downstream

151
00:09:43,282 --> 00:09:46,626
services. Rate limiting acts as a traffic

152
00:09:46,658 --> 00:09:50,214
cop for your applications. It controls the incoming

153
00:09:50,262 --> 00:09:54,234
flow of requests, preventing sudden spikes from

154
00:09:54,432 --> 00:09:58,058
overwhelming a service. Think of it like a

155
00:09:58,064 --> 00:10:01,438
line outside a popular club. Only a

156
00:10:01,444 --> 00:10:04,400
certain number of people get in at a time.

157
00:10:04,770 --> 00:10:08,666
Rate limiting is also crucial for fairness.

158
00:10:08,858 --> 00:10:12,662
It ensures that a single user or a burst of requests

159
00:10:12,746 --> 00:10:16,530
cannot monopolize resources, causing slowdowns for everyone

160
00:10:16,600 --> 00:10:20,434
else simultaneously. It's also a

161
00:10:20,472 --> 00:10:24,158
protective measure against potential malicious attacks

162
00:10:24,254 --> 00:10:27,638
designed to flood your system. So in this example,

163
00:10:27,724 --> 00:10:31,574
we have a client making a request to an API. If the

164
00:10:31,612 --> 00:10:34,994
client eventually does too many requests,

165
00:10:35,042 --> 00:10:38,426
the rate limiting capability will send too

166
00:10:38,448 --> 00:10:42,454
many requests response back to the client, preventing it from affecting

167
00:10:42,502 --> 00:10:46,090
other users or to flood your system on purpose.

168
00:10:46,430 --> 00:10:50,140
The book have pattern draws inspiration from ship design.

169
00:10:50,930 --> 00:10:55,182
Ships compartmentalize, so if one area floods, the whole

170
00:10:55,316 --> 00:10:58,686
ship doesn't sink. We can apply this to

171
00:10:58,708 --> 00:11:02,458
cloud native applications as well. By isolating different services

172
00:11:02,564 --> 00:11:06,274
or functionalities, we might limit the number of

173
00:11:06,312 --> 00:11:09,886
concurrent connections to a backend component or allocate fixed

174
00:11:09,918 --> 00:11:13,234
memory resources. The key idea is this,

175
00:11:13,352 --> 00:11:16,834
if one part of your system fails, the failure doesn't spread

176
00:11:16,882 --> 00:11:20,600
uncontrollably, potentially taking down your entire application.

177
00:11:21,370 --> 00:11:24,418
Bulkheads help maintain partial functionality,

178
00:11:24,514 --> 00:11:27,938
improving overall experience. In the example that

179
00:11:27,964 --> 00:11:31,770
we have here, we see clients accessing a service if we only have

180
00:11:31,840 --> 00:11:36,010
one service instance. This means that if that service is overwhelmed,

181
00:11:36,430 --> 00:11:40,294
all clients are affected. It's common practice

182
00:11:40,342 --> 00:11:43,854
to split that service into several service instance, so that

183
00:11:43,892 --> 00:11:47,134
if one replica is overwhelmed, it means

184
00:11:47,172 --> 00:11:50,910
that only the clients accessing that replica are affected.

185
00:11:51,410 --> 00:11:54,590
This can be extrapolated to also use entire features.

186
00:11:54,670 --> 00:11:58,146
So this means that if one feature from your system is overwhelmed or

187
00:11:58,168 --> 00:12:02,194
has a problem, it doesn't mean that the other features are

188
00:12:02,232 --> 00:12:06,058
stopped as well. Circuit breakers think of circuit breakers

189
00:12:06,094 --> 00:12:09,842
like those in your home. They prevent electrical overload

190
00:12:09,906 --> 00:12:13,782
by cutting off the flow of power. If there's a search in

191
00:12:13,836 --> 00:12:17,726
software, the principle is similar. When a service repeatedly

192
00:12:17,778 --> 00:12:21,610
fails, the circuit breaker patterns trips. This means

193
00:12:21,680 --> 00:12:26,102
temporarily blocking all calls to that service. It prevents

194
00:12:26,166 --> 00:12:29,526
fruitless retries from clogging up the network and lets

195
00:12:29,558 --> 00:12:33,326
the failing service potentially recover. After a

196
00:12:33,348 --> 00:12:37,520
set period, the circuit breaker tries to let some requests through.

197
00:12:38,050 --> 00:12:41,866
If it succeeds, the service is considered health again and normal

198
00:12:41,898 --> 00:12:46,138
operations resume. In this example, we see an HTTP request

199
00:12:46,234 --> 00:12:50,414
arriving at a circuit breaker command. The circuit breaker command checks

200
00:12:50,462 --> 00:12:54,450
is the circuit open? If it is open, it automatically says

201
00:12:54,520 --> 00:12:57,414
the result is not okay. You are not allowed to make this request at this

202
00:12:57,452 --> 00:13:01,074
point in time. If the circuit breaker is closed,

203
00:13:01,202 --> 00:13:04,582
it means that we can execute burner command and if everything

204
00:13:04,636 --> 00:13:08,306
went okay, return a good result to the user.

205
00:13:08,498 --> 00:13:12,346
This diagram also shows that we can use these patterns in combination. So I

206
00:13:12,368 --> 00:13:15,814
can use a circuit breaker, but I can also use timeouts and retries to throw

207
00:13:15,862 --> 00:13:19,580
exceptions so that our requests are okay or not okay.

208
00:13:20,130 --> 00:13:23,386
In today's digital landscape, resiliency isn't

209
00:13:23,418 --> 00:13:27,246
a luxury. It's a fundamental requirement for any application

210
00:13:27,348 --> 00:13:30,554
that demands continuous runtime and positive user

211
00:13:30,602 --> 00:13:34,398
experience. By thoughtfully applying the deployment and

212
00:13:34,564 --> 00:13:38,206
runtime patterns we've discussed, you lay the groundwork for systems that

213
00:13:38,228 --> 00:13:41,310
are not just fast and scalable, but truly robust.

214
00:13:41,890 --> 00:13:45,734
The result is peace of mind, knowing that your applications can

215
00:13:45,772 --> 00:13:49,814
weather the inevitable storms of the cloud. Native weather and this

216
00:13:49,852 --> 00:13:53,410
was all from my part. I hope this talk was informative for you, and don't

217
00:13:53,490 --> 00:13:57,240
hesitate in contacting me through social media.

218
00:13:57,610 --> 00:13:59,410
Thank you very much and have a good conference.

