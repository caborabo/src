1
00:00:27,459 --> 00:00:31,170
Hi Im Pavel and today were gonna talk about NLP techniques for getting more insights

2
00:00:31,202 --> 00:00:34,898
from git commit messages. Ill show you what we can do with git commit

3
00:00:35,066 --> 00:00:39,298
message history to learn more about our projects, team members or project maturity

4
00:00:39,346 --> 00:00:43,426
stage or even portfolio of the projects. I hope this video

5
00:00:43,490 --> 00:00:46,610
would be interesting for the team leads, managers and hrs who is

6
00:00:46,642 --> 00:00:49,894
interested in getting more context about their projects and organization.

7
00:00:50,594 --> 00:00:54,114
The use cases which I will be describing here are theoretical.

8
00:00:55,294 --> 00:00:58,950
We will use the open source project for the analysis, but hope

9
00:00:59,022 --> 00:01:03,074
examples are close enough to the real processes in software development companies.

10
00:01:03,974 --> 00:01:07,710
Before we start, let me introduce myself. My name is Paolo Perfilov.

11
00:01:07,782 --> 00:01:11,406
I'm having 15 plus years of experience in fintech and

12
00:01:11,430 --> 00:01:15,286
during my career I was working as a developer, engineer, project manager and

13
00:01:15,310 --> 00:01:18,790
product manager. I have a master degrees in finance and master's degrees

14
00:01:18,822 --> 00:01:21,958
in computer science. I'm very enthusiastic about the data engineering

15
00:01:22,006 --> 00:01:25,142
and practical usage of the ML. A small disclaimer

16
00:01:25,198 --> 00:01:28,686
here, I'm not representing any of my employers and I'm

17
00:01:28,710 --> 00:01:31,766
speaking for myself. Again. The examples that I

18
00:01:31,790 --> 00:01:35,126
would be showing you are theoretical and the projects we

19
00:01:35,150 --> 00:01:39,006
would use for the analysis are open source.

20
00:01:39,190 --> 00:01:42,902
Feel free to reach me out on LinkedIn and download

21
00:01:43,038 --> 00:01:46,718
the notebook from my GitHub. Let's begin with the theory.

22
00:01:46,886 --> 00:01:50,132
Here are the four building blocks of the classical management, planning,

23
00:01:50,188 --> 00:01:53,772
organizing, leading and controlling and four building blocks of the people

24
00:01:53,948 --> 00:01:57,064
recruiting, training, evaluating and motivating.

25
00:01:57,364 --> 00:02:00,304
Is it enough to start managing people and projects?

26
00:02:00,844 --> 00:02:04,708
It's just a theory which is missing the information about the culture,

27
00:02:04,796 --> 00:02:08,716
environment, missing emotions and sentiments of the individuals.

28
00:02:08,900 --> 00:02:12,844
I'll give you a practical example of the problem. Imagine that a software development

29
00:02:12,924 --> 00:02:16,612
company is hiring new project manager and he gets five projects

30
00:02:16,668 --> 00:02:20,250
which were running for quite some time already. He needs to read

31
00:02:20,282 --> 00:02:23,250
and process huge amount of information to get up to speed.

32
00:02:23,362 --> 00:02:27,186
Most likely the main sources of information would be there is as requirements to

33
00:02:27,210 --> 00:02:31,106
project, plan, the documentation and he would need to talk to many people to get

34
00:02:31,130 --> 00:02:34,922
the overview. But it might be not colorful enough to

35
00:02:34,938 --> 00:02:37,374
get the sense of what is going on in reality.

36
00:02:37,834 --> 00:02:40,994
From time perspective, it might take a few months or even

37
00:02:41,034 --> 00:02:44,450
a year to get some understanding of people's behavior, get their feelings,

38
00:02:44,522 --> 00:02:48,306
get the knowledge about the individual profiles and communication style to

39
00:02:48,330 --> 00:02:51,794
become to be efficient in the team. But how to get this

40
00:02:51,834 --> 00:02:55,082
insights fasting? I'll try to answer these questions in

41
00:02:55,098 --> 00:02:58,802
this video and we'll be using NLP. We'll be using

42
00:02:58,898 --> 00:03:02,494
one non obvious data source which is git commit messages.

43
00:03:02,994 --> 00:03:06,490
Let's look at the git messages from the angle of different roles in the team,

44
00:03:06,642 --> 00:03:10,594
the most of the roles would not use it as a data source. It's too

45
00:03:10,634 --> 00:03:14,250
noisy, it's too low level, it's a lot of text, and most people

46
00:03:14,322 --> 00:03:18,506
would not be able to extract meaningful information. But NLP

47
00:03:18,570 --> 00:03:21,970
could help with that. From my personal experience, I can tell

48
00:03:22,002 --> 00:03:26,042
you that comment messages might produce enough insights for all of the managerial roles

49
00:03:26,058 --> 00:03:29,534
in the company. I'll try to show you some examples to prove it.

50
00:03:29,874 --> 00:03:33,418
Okay, now we understand the problem and there is a lot of questions and

51
00:03:33,466 --> 00:03:36,794
inspiration, but how we could turn data into

52
00:03:36,834 --> 00:03:40,786
the insights. Let's talk about NLP. What is NLP?

53
00:03:40,850 --> 00:03:44,714
NLP stands for natural language processing, which helps to turn words,

54
00:03:44,794 --> 00:03:48,602
sentences, or any text into the numbers. Well, skip the theory

55
00:03:48,698 --> 00:03:52,674
as I want to focus on the practical usage. NLP techniques

56
00:03:52,714 --> 00:03:56,074
are used for sentiment analysis and categorization of the text.

57
00:03:56,234 --> 00:04:00,130
It could tag the data, classify the data, and provide some emotional

58
00:04:00,202 --> 00:04:03,426
levels. Here are some python libraries which I will

59
00:04:03,450 --> 00:04:06,922
be showing you. And there are many more libraries which are

60
00:04:07,018 --> 00:04:10,530
not in the scope of the video. Let's begin with

61
00:04:10,562 --> 00:04:13,618
coding. Here are the libraries that you would need to install

62
00:04:13,666 --> 00:04:16,386
to run the notebook. Select Python,

63
00:04:16,490 --> 00:04:19,874
explore NLK. I will download

64
00:04:19,914 --> 00:04:23,730
the repo and GitHub pandas.

65
00:04:23,922 --> 00:04:28,482
This repo, most popular data science library takes

66
00:04:28,498 --> 00:04:31,978
some time to download it. Okay, let's run the second

67
00:04:32,026 --> 00:04:35,242
symbol. Let's grab the messages, the commit time,

68
00:04:35,298 --> 00:04:38,884
and emails. All right, we have a result in

69
00:04:38,924 --> 00:04:42,012
the resulting dataframe. We have three columns as I

70
00:04:42,028 --> 00:04:46,196
expect. The shape of the dataframe is 335

71
00:04:46,260 --> 00:04:49,940
thousand commits. Let's pre process the messages.

72
00:04:50,012 --> 00:04:53,716
Let's delete the git keywords, CI, CD keywords,

73
00:04:53,780 --> 00:04:56,684
some emails, some HTTP links,

74
00:04:56,724 --> 00:04:59,984
and some purge pull request messages.

75
00:05:00,804 --> 00:05:05,382
We need to make sure that the message and the text is looking good before

76
00:05:05,438 --> 00:05:08,274
we start doing the sentiment analysis.

77
00:05:08,894 --> 00:05:12,194
And also we see a lot of abbreviations here. Look doc,

78
00:05:12,494 --> 00:05:16,534
es, zero, one, and something else. So it

79
00:05:16,574 --> 00:05:20,566
might make sense to clean this up as well. So here is the

80
00:05:20,750 --> 00:05:24,006
cleaned version of the message. We just apply the regex to

81
00:05:24,030 --> 00:05:27,950
delete the verse that we don't want. We also extracted

82
00:05:27,982 --> 00:05:31,870
the abbreviations. Here are the longest abbreviation. It seems like the

83
00:05:31,902 --> 00:05:35,594
developer was a little bit annoyed by the somewhere this

84
00:05:36,234 --> 00:05:39,730
let's start with descriptive statistics. Here's a chart

85
00:05:39,762 --> 00:05:43,474
which is showing you the amount of contributions per year and number of

86
00:05:43,594 --> 00:05:47,722
unique contributors, unique developers per year. This reminds

87
00:05:47,738 --> 00:05:51,014
me very well the classical product life cycle.

88
00:05:51,354 --> 00:05:54,746
So it does look like MT was a peak indicator

89
00:05:54,810 --> 00:05:58,386
has reached the maturity. Let's look at the seasonality.

90
00:05:58,450 --> 00:06:02,154
If there is any patterns. Indeed there is. In the summer

91
00:06:02,194 --> 00:06:06,000
time there is a less amount of contributions. And let's look at the

92
00:06:06,112 --> 00:06:09,688
top contributors. It seems there are like about

93
00:06:09,776 --> 00:06:13,112
seven top main contributors who is contributing to

94
00:06:13,128 --> 00:06:17,016
cadcastly. We could extract the word frequencies as

95
00:06:17,040 --> 00:06:20,560
well. But what do we see here? We see not a lot of

96
00:06:20,592 --> 00:06:23,792
meaningful words. There are some words like two in

97
00:06:23,848 --> 00:06:28,112
four. There is a concept of stop words in the NLP.

98
00:06:28,208 --> 00:06:32,352
So the stopword word is the words which has to be deleted because

99
00:06:32,408 --> 00:06:35,884
it doesn't add any additional information into the sentence.

100
00:06:36,204 --> 00:06:40,084
Let's check the stop words. Yes, indeed, there are quite a lot the

101
00:06:40,124 --> 00:06:44,412
words marked as true as stop words. After we deleted the stop words, the vocabulary

102
00:06:44,468 --> 00:06:47,384
look as we would expect.

103
00:06:48,244 --> 00:06:52,428
Okay, let's start with the tokenization and lemmezation.

104
00:06:52,596 --> 00:06:56,348
This concept basically standardized the form of the message the

105
00:06:56,436 --> 00:07:00,052
it takes into account the NLTK library

106
00:07:00,108 --> 00:07:03,544
has built in Wordnet Lemodizer. You can look at

107
00:07:03,584 --> 00:07:07,736
the lexical database from Princeton University and

108
00:07:07,760 --> 00:07:10,768
you can search for some words and that would give you the

109
00:07:10,896 --> 00:07:14,464
part of speech and basically the explanation

110
00:07:14,504 --> 00:07:18,288
of the words that appear dictionary. So let's apply the

111
00:07:18,376 --> 00:07:21,760
tokenizing functions and tag the words by the

112
00:07:21,792 --> 00:07:25,856
part of speeches. And let's try to count the

113
00:07:26,000 --> 00:07:29,666
words again because this would be the

114
00:07:29,690 --> 00:07:32,994
more appropriate and more filtered. Yeah,

115
00:07:33,034 --> 00:07:36,874
here's the how message look like through the lemmatizing.

116
00:07:37,034 --> 00:07:40,170
So it's very standardized. There is no noise at all

117
00:07:40,202 --> 00:07:44,450
pretty much. And here are the most frequent words in

118
00:07:44,482 --> 00:07:47,962
our it does look like a developer's

119
00:07:48,058 --> 00:07:51,906
vocabulary just to compare the original message versus

120
00:07:51,970 --> 00:07:55,542
the lemmatized message. By using some lemmas,

121
00:07:55,598 --> 00:07:59,046
we can classify messages as features and as

122
00:07:59,070 --> 00:08:02,886
a bugs. Okay. And we can build the vocabulary for

123
00:08:02,910 --> 00:08:06,286
the bugs and features. And let's see what

124
00:08:06,350 --> 00:08:10,374
are the statistics or the features and the bugs over the time here we

125
00:08:10,414 --> 00:08:13,558
clearly see that the project kickstarted in 2012.

126
00:08:13,646 --> 00:08:17,094
There was a stable period of development to 2020, and in

127
00:08:17,134 --> 00:08:20,514
2022 there was rapid growth features.

128
00:08:21,104 --> 00:08:24,120
As we are trying to look at the sentiments,

129
00:08:24,312 --> 00:08:28,232
the best way of finding the negative sentiments is to search for the

130
00:08:28,248 --> 00:08:31,536
bad words. Let's try to find them.

131
00:08:31,640 --> 00:08:35,224
Oh yeah, indeed. There are quite a few comments with the bad

132
00:08:35,264 --> 00:08:38,592
words and there are a few developers

133
00:08:38,648 --> 00:08:42,616
who are using bad words more frequently than others.

134
00:08:42,800 --> 00:08:46,840
Yeah, we can analyze this. I hope in your organization

135
00:08:46,912 --> 00:08:51,160
you have a policy around that. But definitely the

136
00:08:51,232 --> 00:08:54,664
empty messages with the bad words are looking

137
00:08:54,824 --> 00:08:58,320
negatively and they would provide you a negative sentiment

138
00:08:58,352 --> 00:09:01,904
and negative emotions. After we run the sentiment

139
00:09:01,944 --> 00:09:05,720
analysis for sentiments, we would use the same word

140
00:09:05,752 --> 00:09:09,232
note dictionary it has some additional information on the

141
00:09:09,248 --> 00:09:12,860
top of the words and the part of speeches. So we could get

142
00:09:12,932 --> 00:09:16,036
some scores, negative scores and positive scores

143
00:09:16,140 --> 00:09:19,604
for every single word like that. As you can see,

144
00:09:19,644 --> 00:09:23,060
the negative words include the error still problem

145
00:09:23,172 --> 00:09:25,420
difference, and the positive words are, well,

146
00:09:25,572 --> 00:09:29,068
improving, refinement and so on.

147
00:09:29,236 --> 00:09:33,308
We can calculate the total score and average score per

148
00:09:33,396 --> 00:09:37,260
period. As we can see in constant 2014,

149
00:09:37,372 --> 00:09:40,744
there was a representative positive sentiment.

150
00:09:41,354 --> 00:09:45,498
At this time AP running. And we can calculate these colors

151
00:09:45,546 --> 00:09:49,374
per person per period. To see if there is any dynamic.

152
00:09:49,954 --> 00:09:52,454
Let's plot the charts.

153
00:09:52,954 --> 00:09:56,538
Okay. See that the green developer

154
00:09:56,626 --> 00:10:01,258
was improving his negative score. There was the

155
00:10:01,306 --> 00:10:05,322
orange guy also was improving his score. And we

156
00:10:05,338 --> 00:10:08,914
can get some context about what people were doing

157
00:10:08,994 --> 00:10:11,762
and see I talk to them,

158
00:10:11,818 --> 00:10:14,134
maybe get some more feedback in the organization.

159
00:10:14,594 --> 00:10:18,322
Let's look at the sentiments. There is one

160
00:10:18,378 --> 00:10:22,074
nice library, which is called text plot, which is providing you

161
00:10:22,154 --> 00:10:26,114
quite nice features. And you don't need to write a lot of code

162
00:10:26,274 --> 00:10:30,374
to get and extract some polarity and subjectivity.

163
00:10:31,394 --> 00:10:35,018
Let's add the polarity and subjectivity fields into our

164
00:10:35,066 --> 00:10:37,964
data sets. Here's how it looked like.

165
00:10:38,464 --> 00:10:42,352
There's a polarity column over here. And the polarity could be positive

166
00:10:42,408 --> 00:10:46,080
or negative. And here is a polarity over the years.

167
00:10:46,272 --> 00:10:49,284
It does look like a sinusoid, very interesting pattern.

168
00:10:50,024 --> 00:10:53,672
After 2013, the negative polar g goes down,

169
00:10:53,808 --> 00:10:57,952
the positive polar g goes up, likely at this time,

170
00:10:58,048 --> 00:11:01,204
developers were very satisfied of the project.

171
00:11:01,844 --> 00:11:05,492
And we can calculate the dynamic of the changes of the polarity.

172
00:11:05,668 --> 00:11:09,588
It's red and green. When the features are delivered, the bugs are being

173
00:11:09,636 --> 00:11:13,540
fixed, and we can look at the polarity of all three individual

174
00:11:13,572 --> 00:11:17,116
contributors. We can calculate the ratio and

175
00:11:17,180 --> 00:11:20,756
ratio of the subjectivity so you can make a judgment.

176
00:11:20,900 --> 00:11:24,664
We can look at the polarity of the overall project per year.

177
00:11:25,164 --> 00:11:28,692
And it's interesting to see that the polarity of the bugs and

178
00:11:28,708 --> 00:11:32,332
polarity of the sentiments are different. The features

179
00:11:32,388 --> 00:11:36,108
have polarity more positive. It's biased towards the right hand side.

180
00:11:36,276 --> 00:11:39,484
Let's look at the deep learning models and let's try to get some

181
00:11:39,524 --> 00:11:42,504
emotions out of our git. Commit messages.

182
00:11:43,684 --> 00:11:48,304
The easiest way is to run existing models and run the transformers.

183
00:11:48,644 --> 00:11:52,500
You can get the models from the website tagging

184
00:11:52,532 --> 00:11:55,884
face. There are a lot of models. It's available for

185
00:11:55,924 --> 00:11:59,184
everyone. And you can download any of these and run it.

186
00:11:59,754 --> 00:12:03,906
Let's try to find the model which we search

187
00:12:03,930 --> 00:12:08,018
for the model. There is a description over here. There's a 1.5

188
00:12:08,066 --> 00:12:12,214
billion downloads. And we can try the API as well.

189
00:12:12,754 --> 00:12:15,490
So we have this model we just downloaded it.

190
00:12:15,562 --> 00:12:19,250
Sometimes the models are very big. This one might

191
00:12:19,282 --> 00:12:21,814
be like one gig or something like that.

192
00:12:22,194 --> 00:12:25,386
As you can see, it provides us with the attributes of the

193
00:12:25,410 --> 00:12:28,164
sentence, provides the emotions like love,

194
00:12:28,244 --> 00:12:32,156
annoyance and anger. Let's make

195
00:12:32,180 --> 00:12:36,060
a sample of our data frame because it's too big. It's 35K

196
00:12:36,132 --> 00:12:40,340
commits. Let's take just 2000 and try to enrich

197
00:12:40,412 --> 00:12:43,984
the messages by emotions with a pre trained dataset.

198
00:12:44,444 --> 00:12:47,628
It might take some time to run. I usually

199
00:12:47,796 --> 00:12:51,464
on my laptop, I get the results within five minutes.

200
00:12:52,224 --> 00:12:56,280
Running about five minutes. Okay, we got emotions.

201
00:12:56,392 --> 00:13:00,032
Here are the dopamine steps we get from our 2000

202
00:13:00,088 --> 00:13:03,832
messages and we can do some analysis

203
00:13:03,928 --> 00:13:08,004
further on and group the data and look how the

204
00:13:08,584 --> 00:13:12,400
dynamics of these emotions. Let's look on

205
00:13:12,432 --> 00:13:16,416
the particular examples. Here's the confusion. I think

206
00:13:16,440 --> 00:13:20,370
the confusion is caused by the word. Yeah, it looks

207
00:13:20,522 --> 00:13:22,694
at least in the second sentence.

208
00:13:23,314 --> 00:13:26,770
Okay, let's look at some others. Yeah, we can

209
00:13:26,802 --> 00:13:30,494
select any. Let's look at the anger.

210
00:13:31,154 --> 00:13:34,694
The anger probably caused by this line and the capital layers.

211
00:13:35,074 --> 00:13:38,594
The model has to be fine tuned because the git commit

212
00:13:38,634 --> 00:13:42,922
messages are very specific. Let's look at the git discussed.

213
00:13:43,098 --> 00:13:46,650
Not very clear why this emotion popped up, but let's

214
00:13:46,682 --> 00:13:50,646
look at the dynamics of of our movements and let's see how

215
00:13:50,670 --> 00:13:54,518
they look for developer. Of course, the top per developer

216
00:13:54,566 --> 00:13:58,630
as well. Neutral and approval. Let's drop these

217
00:13:58,742 --> 00:14:01,822
first two columns and look at the remaining part of

218
00:14:01,838 --> 00:14:06,554
the motions. And the remaining part are annoyance and disapproval.

219
00:14:07,174 --> 00:14:10,614
Let's look at how was the dynamics of every single

220
00:14:10,654 --> 00:14:14,638
emotion over the time. And you can see that

221
00:14:14,726 --> 00:14:18,126
annoyance correlates a lot with the dynamics of the

222
00:14:18,150 --> 00:14:21,596
project and disapproval as well. There are not

223
00:14:21,620 --> 00:14:23,864
a lot of positive promotions, by the way.

224
00:14:24,564 --> 00:14:28,124
Let's look at the last cycle again in 2020,

225
00:14:28,204 --> 00:14:32,452
the annoyance was the top and was among the highest amount of contributions.

226
00:14:32,628 --> 00:14:36,844
So yeah, probably developers don't like much of the periods

227
00:14:36,884 --> 00:14:41,304
when there's a lot of features and a lot of bugs are being submitted

228
00:14:41,684 --> 00:14:45,100
to create the pressure on them. And let's look

229
00:14:45,132 --> 00:14:48,594
at the heat map graph. Oh yeah,

230
00:14:48,674 --> 00:14:51,610
and white is the top. And disapproval as well.

231
00:14:51,722 --> 00:14:55,810
Disappointment, a little bit surprise. In 2014,

232
00:14:55,882 --> 00:14:59,254
there was a lot of surprises, sadness, anger.

233
00:14:59,994 --> 00:15:03,522
The positive emotions are not very present and we can look

234
00:15:03,538 --> 00:15:06,874
at the dynamics. That's just a different chart, just to

235
00:15:06,994 --> 00:15:10,698
see how the scores are growing or failing.

236
00:15:10,866 --> 00:15:14,794
Yeah. The next thing that I wanted to show you is summarization.

237
00:15:14,874 --> 00:15:18,326
Again, we will be using the hugging face model. There are a

238
00:15:18,350 --> 00:15:21,686
bunch of models and we would use the, one of the

239
00:15:21,710 --> 00:15:25,670
most popular Facebook learned the model, the CNN

240
00:15:25,742 --> 00:15:29,278
Daily Mail News and yeah, let's see what

241
00:15:29,326 --> 00:15:32,622
we would get with this summarization. The idea here

242
00:15:32,678 --> 00:15:36,086
is to reduce amount of text that we would need

243
00:15:36,110 --> 00:15:39,994
to read. So we would run the

244
00:15:41,254 --> 00:15:43,874
summarization function over the text.

245
00:15:44,594 --> 00:15:48,642
If you need to store a huge text, which is having

246
00:15:48,738 --> 00:15:52,386
a very different context than small pieces, I would

247
00:15:52,410 --> 00:15:55,762
recommend you to run it two times or three times. So basically

248
00:15:55,818 --> 00:15:59,014
first layer you run on the original message,

249
00:15:59,434 --> 00:16:03,514
then you combine all these summaries that you got and

250
00:16:03,554 --> 00:16:07,014
then you run the summarization again as a second layer.

251
00:16:07,514 --> 00:16:10,842
That would improve the quality of the

252
00:16:10,898 --> 00:16:14,850
output that you get. Otherwise the outputs might

253
00:16:14,882 --> 00:16:18,456
be very messy, not let's run it over

254
00:16:18,480 --> 00:16:22,192
there, let's take a sample, we'll take one top

255
00:16:22,248 --> 00:16:26,256
contributor and twin last minutes and

256
00:16:26,320 --> 00:16:29,896
let's build the let's enrich and let's get the

257
00:16:29,920 --> 00:16:33,096
summary of every individual message and then get a summary of the

258
00:16:33,120 --> 00:16:37,604
joint text. It might take some time to process.

259
00:16:38,384 --> 00:16:42,524
Okay, we got the results. These are individual summaries for every single message.

260
00:16:43,244 --> 00:16:46,596
Look at it and yeah,

261
00:16:46,660 --> 00:16:50,224
the messages are a little bit more clean and clear.

262
00:16:50,924 --> 00:16:55,164
The summary over the last ten messages

263
00:16:55,244 --> 00:16:59,236
combined, so we could see what

264
00:16:59,300 --> 00:17:04,492
the person was busy with and

265
00:17:04,508 --> 00:17:08,464
we can specify what should be the length of the outlook message.

266
00:17:09,394 --> 00:17:12,922
Here is the results. Yeah, the text look better

267
00:17:12,978 --> 00:17:15,614
than it used to be and is a nice summary.

268
00:17:16,274 --> 00:17:20,058
But again, this model that we were using is the model

269
00:17:20,106 --> 00:17:23,578
create on the news. Let's try to use the chat Jpt

270
00:17:23,706 --> 00:17:27,106
API. It's quite fun. It does provide a

271
00:17:27,130 --> 00:17:30,914
nice quality of the summaries. We also can specify

272
00:17:31,034 --> 00:17:34,734
what amount of tokens we need to have in

273
00:17:34,774 --> 00:17:37,914
output and we specify the content.

274
00:17:38,214 --> 00:17:41,734
Basically is prompt request as we would write it

275
00:17:41,774 --> 00:17:45,474
to the chatbot summary is the

276
00:17:46,494 --> 00:17:49,926
which is like joint text messages over the past.

277
00:17:50,070 --> 00:17:53,994
Then I want to change the prompt middle

278
00:17:54,534 --> 00:17:58,318
and we see output. We can play

279
00:17:58,366 --> 00:18:01,870
with the prompt a little. If I want to have an

280
00:18:01,902 --> 00:18:05,150
emotional response, I can make

281
00:18:05,182 --> 00:18:08,954
it and ask Judge beauty to make it in a shorter way.

282
00:18:09,454 --> 00:18:13,846
And I can ask I want to

283
00:18:14,030 --> 00:18:17,454
summarize it in a way, in a binary

284
00:18:17,494 --> 00:18:20,846
way, what is bad and what is good. We get the result.

285
00:18:20,990 --> 00:18:24,286
The result is very structured. I highly recommend you

286
00:18:24,310 --> 00:18:27,832
to try this out on the copy my notebook and run over

287
00:18:27,888 --> 00:18:30,936
your twitter some insights that you

288
00:18:30,960 --> 00:18:34,344
have never seen before. The most of the words of the dev

289
00:18:34,384 --> 00:18:37,976
slang are having the negative sentiments, so don't be surprised if

290
00:18:38,000 --> 00:18:41,472
you get the horrible scores. Check the original message and check the

291
00:18:41,488 --> 00:18:44,624
dates that you get. NLP programming is very

292
00:18:44,664 --> 00:18:48,184
iterative so be ready. Hope my video was

293
00:18:48,224 --> 00:18:52,280
interesting. Thanks, Ocon 42, for hosting

294
00:18:52,312 --> 00:18:52,384
me.

