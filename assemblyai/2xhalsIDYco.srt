1
00:00:20,760 --> 00:00:24,630
Thanks for joining my session. My name is Samuel Baruffi. I am a

2
00:00:24,662 --> 00:00:27,912
solutions architect with AWS and I'm very excited

3
00:00:27,968 --> 00:00:31,684
to talk about vectorizing into the future

4
00:00:32,104 --> 00:00:36,216
AWS retrieval augmented generation systems using

5
00:00:36,320 --> 00:00:39,600
large language models. So a quick agenda

6
00:00:39,632 --> 00:00:42,364
for today will be the following.

7
00:00:43,384 --> 00:00:46,688
We're going to quickly talk about what are foundational

8
00:00:46,776 --> 00:00:50,504
models, large language models. Then we're going

9
00:00:51,004 --> 00:00:56,254
to talk about some of the capabilities that are very easy

10
00:00:56,334 --> 00:01:00,194
and important to use when it comes to generative AI.

11
00:01:00,614 --> 00:01:04,822
Then we're going to talk about some limitations of those foundational models.

12
00:01:04,958 --> 00:01:08,478
Those models are amazing. It has revolutionized

13
00:01:08,566 --> 00:01:12,566
and it's still revolutionizing many, many industries across

14
00:01:12,630 --> 00:01:16,166
the world, but they have limitations. So we're

15
00:01:16,190 --> 00:01:19,566
going to talk about what are those limitations, and we're going to talk about potential

16
00:01:19,630 --> 00:01:24,324
solutions, especially using retrieval augmented generations,

17
00:01:24,904 --> 00:01:28,320
which Reg is short for. Then we're

18
00:01:28,352 --> 00:01:32,216
going to talk about what type of databases

19
00:01:32,400 --> 00:01:35,768
can help us, you know, improve those

20
00:01:35,816 --> 00:01:39,552
foundational models with Reg. So we're going to go through

21
00:01:39,688 --> 00:01:43,384
the list of currently supported databases offerings on

22
00:01:43,424 --> 00:01:47,506
AWS for vector. We're going to explain, explain at

23
00:01:47,530 --> 00:01:50,922
a high level the capabilities

24
00:01:51,018 --> 00:01:54,654
and the differentiations across those offerings.

25
00:01:54,994 --> 00:01:58,746
And then after that we're going to talk about Amazon Bedrock, which is a

26
00:01:58,810 --> 00:02:02,218
generative AI managed service

27
00:02:02,306 --> 00:02:05,970
on AWS that allows you to very easily consume

28
00:02:06,162 --> 00:02:09,402
different foundational models, both image generation

29
00:02:09,498 --> 00:02:12,894
text to text, and also embeddings. And then

30
00:02:12,974 --> 00:02:16,350
we're going to talk about Amazon Bedrock knowledge base,

31
00:02:16,542 --> 00:02:21,182
which combines the powerful rack

32
00:02:21,238 --> 00:02:24,638
systems into the bedrock ecosystem

33
00:02:24,766 --> 00:02:28,874
and it allows users to very easily configure

34
00:02:29,334 --> 00:02:32,646
retrieval augmented generation systems using

35
00:02:32,710 --> 00:02:36,486
bedrock foundational models and also using AWS

36
00:02:36,630 --> 00:02:40,236
vector databases that are managed. So we're

37
00:02:40,260 --> 00:02:43,612
going to talk about how those two words can come together

38
00:02:43,748 --> 00:02:47,268
to really empower a lot of companies and users

39
00:02:47,316 --> 00:02:50,984
to create very powerful generative AI solutions.

40
00:02:51,484 --> 00:02:54,756
And then in the end, we're going to do a quick demo just showcasing

41
00:02:54,820 --> 00:02:58,620
the capabilities of bedrock and open search.

42
00:02:58,812 --> 00:03:02,700
So without further ado, let's get started. So WiFi

43
00:03:02,732 --> 00:03:08,056
national models, right in a before transformers

44
00:03:08,160 --> 00:03:11,848
and generative AI was really powerful in

45
00:03:11,856 --> 00:03:15,024
the past, traditional machine learning models

46
00:03:15,144 --> 00:03:18,840
were really trained and deployed for specific

47
00:03:18,912 --> 00:03:22,368
tasks. So you might have some models that were for specific task

48
00:03:22,416 --> 00:03:25,808
generation, some models that were really able to do Q

49
00:03:25,856 --> 00:03:29,896
and a, some bots, some models that maybe were able to do some type

50
00:03:29,920 --> 00:03:34,578
of predictions. So they're really specific

51
00:03:34,666 --> 00:03:39,294
models, but you need to deploy all these different models to potentially achieve

52
00:03:40,674 --> 00:03:44,454
the combination or the collection of different tasks

53
00:03:45,034 --> 00:03:47,814
with generative AI and transformers,

54
00:03:48,354 --> 00:03:52,098
the foundational models, if you think about quickly on

55
00:03:52,106 --> 00:03:55,698
the traditional machine learning models, you'd have a lot of label

56
00:03:55,746 --> 00:03:58,914
data, and you train those models to that specific label

57
00:03:58,954 --> 00:04:03,000
data. Right? What foundational models?

58
00:04:03,192 --> 00:04:07,392
Using transformers enables users

59
00:04:07,568 --> 00:04:11,256
to actually do all of those tasks within a

60
00:04:11,320 --> 00:04:15,136
simple, not simple, but within a single model

61
00:04:15,320 --> 00:04:19,456
that has been trained with unlabeled data. So foundational

62
00:04:19,520 --> 00:04:23,264
models sometimes are also referred to as general models

63
00:04:23,424 --> 00:04:26,624
that have good word representations and

64
00:04:26,664 --> 00:04:30,500
can do a lot of different tasks that in the

65
00:04:30,532 --> 00:04:32,904
past, you need to select the different models.

66
00:04:33,804 --> 00:04:37,692
It is very powerful because with a single model now

67
00:04:37,748 --> 00:04:41,236
you can perform a combination of different

68
00:04:41,300 --> 00:04:44,624
tasks that in the past wouldn't have been possible.

69
00:04:45,284 --> 00:04:49,116
So generative AI, you can use for

70
00:04:49,220 --> 00:04:53,034
many, many different use cases. Here, it's just

71
00:04:53,204 --> 00:04:57,034
demonstrating into four different categories,

72
00:04:57,334 --> 00:05:01,158
the capabilities of generative AI. So you

73
00:05:01,166 --> 00:05:05,030
can enhance customer experience by having, you know, agent assistance

74
00:05:05,142 --> 00:05:08,334
or, you know, personalizations or chat bots that will

75
00:05:08,374 --> 00:05:11,406
help enhance your customer experience. You can

76
00:05:11,430 --> 00:05:15,390
also have boost, you can also help boost employee productivity

77
00:05:15,542 --> 00:05:19,006
with conversational search. Let's say you

78
00:05:19,030 --> 00:05:22,342
have vast amount of internal data and

79
00:05:22,358 --> 00:05:26,006
you want to make very easy for users internally to consume

80
00:05:26,030 --> 00:05:29,990
the data to improve the productivity. Foundational models can

81
00:05:30,062 --> 00:05:33,670
help solve that problem and a very good solution. You can

82
00:05:33,702 --> 00:05:37,398
also improve business operation. So if you're doing a lot of document

83
00:05:37,446 --> 00:05:41,158
processing that maybe before was done by manual labor,

84
00:05:41,326 --> 00:05:44,558
you can use those foundational models to potentially process,

85
00:05:44,726 --> 00:05:48,182
you know, some entity extraction or maybe document

86
00:05:48,238 --> 00:05:51,968
processing or maybe generation of documents. You can use generative

87
00:05:52,016 --> 00:05:54,920
AI, and then of course, creativity.

88
00:05:55,072 --> 00:05:59,016
With a stable diffusion models, you can create many different

89
00:05:59,120 --> 00:06:02,936
images. You can do video enhancements, you can create music.

90
00:06:03,080 --> 00:06:07,384
So those generative AI models are not only text generations,

91
00:06:07,464 --> 00:06:11,304
but you can generate images, videos. And this is a very

92
00:06:11,464 --> 00:06:14,244
fast paced, evolving technology.

93
00:06:14,624 --> 00:06:18,132
So what is capable today might

94
00:06:18,188 --> 00:06:21,300
very quickly advance in the near future. The text

95
00:06:21,332 --> 00:06:24,596
to text models are really, really powerful today. Images have

96
00:06:24,620 --> 00:06:28,500
become very powerful. And now we can see that video generations are

97
00:06:28,532 --> 00:06:31,024
just starting to get more powerful than ever.

98
00:06:31,564 --> 00:06:35,596
So what does aws in

99
00:06:35,620 --> 00:06:40,412
terms of generative AI? Right, so AWS

100
00:06:40,508 --> 00:06:44,290
is very quickly growing

101
00:06:44,402 --> 00:06:48,298
the list of services and capabilities that support customers. To use

102
00:06:48,346 --> 00:06:52,282
generative AI, we can, we have Amazon Sagemaker,

103
00:06:52,338 --> 00:06:56,778
which is the platform for any machine

104
00:06:56,826 --> 00:06:59,866
learning AI requirements, training,

105
00:06:59,970 --> 00:07:03,666
inference, evaluation, you know, data ingestion,

106
00:07:03,730 --> 00:07:07,762
data cleaning, you can name it. But when it comes to generative

107
00:07:07,818 --> 00:07:11,438
AI, Amazon Sagemaker has a, a foundational hub

108
00:07:11,486 --> 00:07:15,142
called Jumpstart, where you can actually deploy many, many different

109
00:07:15,198 --> 00:07:17,874
foundational models that are going to be,

110
00:07:18,214 --> 00:07:21,582
that you're going to deploy within Sagemaker. Sagemaker is going to deploy the

111
00:07:21,598 --> 00:07:24,834
infrastructure for you and it's going to match that infrastructure.

112
00:07:25,334 --> 00:07:28,726
But then we also have Amazon bedrock, which is a

113
00:07:28,750 --> 00:07:32,422
completely managed service with pay as you go approach, that you

114
00:07:32,438 --> 00:07:36,502
can select a variety of different model providers

115
00:07:36,558 --> 00:07:40,106
and models within those model providers. We're going to talk in

116
00:07:40,130 --> 00:07:43,330
a couple of slides into the future of this

117
00:07:43,362 --> 00:07:47,026
presentation that are going to present some of the models that are capable.

118
00:07:47,210 --> 00:07:50,802
And Amazon has also done a lot of

119
00:07:50,978 --> 00:07:55,018
innovation at the hardware level. So you can see with Amazon

120
00:07:55,066 --> 00:07:58,890
EC two, TRN one, which is

121
00:07:58,922 --> 00:08:02,770
training instances, which are instances that

122
00:08:02,802 --> 00:08:07,878
have proprietary innovative accelerators

123
00:08:07,966 --> 00:08:12,006
for machine learning training from Amazon that really optimizes the cost

124
00:08:12,070 --> 00:08:15,846
performance for companies that wants to train their own model.

125
00:08:15,910 --> 00:08:19,870
Those could be foundational models or could be traditional

126
00:08:19,902 --> 00:08:23,918
machine learning models. But we also have Amazon EC

127
00:08:23,966 --> 00:08:27,942
two, InF two, which is short for inferential

128
00:08:27,998 --> 00:08:32,462
two, which is a chip that is optimized for accelerating

129
00:08:32,558 --> 00:08:36,114
inferential inference from your machine

130
00:08:36,154 --> 00:08:40,194
learning models. Those could be foundational models or any other type of model.

131
00:08:40,354 --> 00:08:44,770
And then last but not least, Amazon Codewisper,

132
00:08:44,882 --> 00:08:48,994
which is a generative AI power coding assistant that

133
00:08:49,034 --> 00:08:52,754
helps developers with code completion security scams.

134
00:08:52,834 --> 00:08:56,234
You know, chat, you can chat with your code

135
00:08:56,274 --> 00:09:00,406
and receive recommendations and different helps

136
00:09:00,470 --> 00:09:03,582
in terms of fixing bugs and so forth. So those are

137
00:09:03,598 --> 00:09:07,750
the things that AWS offers for generative AI capabilities.

138
00:09:07,862 --> 00:09:11,526
And, you know, there are a lot more that goes within those services in

139
00:09:11,550 --> 00:09:15,654
terms of functionality and features as

140
00:09:15,694 --> 00:09:19,594
much as those models. Foundational models are really, really powerful.

141
00:09:20,014 --> 00:09:23,134
There are limitations of large language models and, you know,

142
00:09:23,174 --> 00:09:28,064
large language models and foundational models sometimes just use together.

143
00:09:28,444 --> 00:09:31,796
But you know, large language models are just models that

144
00:09:31,820 --> 00:09:36,924
can generate text or embeddings that really made

145
00:09:36,964 --> 00:09:40,796
it possible to use generative AI as

146
00:09:40,820 --> 00:09:44,396
we know today. But what are some of those limitations that we

147
00:09:44,420 --> 00:09:48,236
know? So first of all, there is really limited contextual

148
00:09:48,300 --> 00:09:51,732
understanding. So the model, because it has

149
00:09:51,788 --> 00:09:55,978
been pre trained, he only knows information

150
00:09:56,106 --> 00:09:59,922
to the date and is not going to know proprietary,

151
00:10:00,058 --> 00:10:04,386
you know, private information. So he has limited contextual understanding

152
00:10:04,410 --> 00:10:07,898
of what you are asking. You might be asking some

153
00:10:07,946 --> 00:10:12,178
question that is ambiguous and it might have, you know, a contextual

154
00:10:12,306 --> 00:10:16,098
limitation. In that sense, he also

155
00:10:16,226 --> 00:10:19,590
has lack of domain specific knowledge. So if you, if you work for

156
00:10:19,622 --> 00:10:23,462
company a and company a has a lot of private documentation that

157
00:10:23,478 --> 00:10:26,758
it was not on the Internet, or even if it was in

158
00:10:26,766 --> 00:10:30,438
the Internet, it might not be an expert on that domain specific.

159
00:10:30,526 --> 00:10:33,942
So they are known to not be super good in

160
00:10:33,998 --> 00:10:37,342
specific domains, especially if those domains don't have a lot

161
00:10:37,358 --> 00:10:41,126
of data on the Internet. Which most of those models

162
00:10:41,190 --> 00:10:43,754
get trained on top of it.

163
00:10:45,144 --> 00:10:48,640
So this is a big one, lacks explainability of interval

164
00:10:48,672 --> 00:10:52,264
ability. So it's very common that those large language

165
00:10:52,304 --> 00:10:55,632
models might hallucinate. And hallucinate is it

166
00:10:55,648 --> 00:10:59,488
just means when a response, an output from

167
00:10:59,536 --> 00:11:03,040
one of those models are generated is stating

168
00:11:03,112 --> 00:11:06,440
a inaccurate and not factual correct

169
00:11:06,552 --> 00:11:10,520
information, right. So there is very little explainability of

170
00:11:10,552 --> 00:11:14,242
why that information began to be. The way those models works is

171
00:11:14,258 --> 00:11:17,666
just predicting the next word and they might just spit

172
00:11:17,690 --> 00:11:20,146
it out. A lot of not factual,

173
00:11:20,290 --> 00:11:23,602
accurate data. And it's really hard to know why

174
00:11:23,658 --> 00:11:27,214
they have done that. So they lack explainability and interpretability.

175
00:11:27,994 --> 00:11:31,442
And again, inaccurate information. It's what

176
00:11:31,498 --> 00:11:35,290
we just described, which you might ask a question, the model

177
00:11:35,322 --> 00:11:39,576
might give you an answer that sounds very, very confident

178
00:11:39,640 --> 00:11:43,376
that answer is correct, but in fact, it's just a made up answer and

179
00:11:43,400 --> 00:11:46,256
is not accurate, not neither factual,

180
00:11:46,400 --> 00:11:50,208
accurate. So with that said,

181
00:11:50,256 --> 00:11:53,888
with the limitations that we know, how can we potentially,

182
00:11:53,976 --> 00:11:57,776
what are the solutions that we can put in place to help solve

183
00:11:57,840 --> 00:12:01,504
this problem? So there is something called vector embeddings.

184
00:12:01,624 --> 00:12:05,192
And what are vector embeddings? So vector embeddings

185
00:12:05,328 --> 00:12:07,844
are using these foundational models.

186
00:12:08,464 --> 00:12:12,608
Embeddings are semantic representations of

187
00:12:12,696 --> 00:12:15,848
words by translating

188
00:12:15,936 --> 00:12:19,872
into vector, mathematical vectors, float vector

189
00:12:19,928 --> 00:12:23,080
vectors. So you can think about if a user inputs,

190
00:12:23,152 --> 00:12:26,688
you know, New York and it runs into an embedded model,

191
00:12:26,776 --> 00:12:30,504
and an embedded model is just a large language model that is able to

192
00:12:30,624 --> 00:12:34,040
convert text into a array

193
00:12:34,152 --> 00:12:37,336
of float numbers in a vector.

194
00:12:37,480 --> 00:12:41,760
So you can see New York might be the

195
00:12:41,792 --> 00:12:45,568
vector representation of New York, might be the one you see here.

196
00:12:45,656 --> 00:12:48,888
There are different dimensions on vectors embeddings.

197
00:12:49,056 --> 00:12:52,840
The bigger the dimensions, the more data and the more float numbers

198
00:12:52,872 --> 00:12:54,924
you're going to have on the vector array.

199
00:12:55,664 --> 00:12:59,296
And why are vectors embedding?

200
00:12:59,320 --> 00:13:02,848
Is important because they carry

201
00:13:02,936 --> 00:13:06,704
with those numbers, with these mathematical arrays

202
00:13:06,824 --> 00:13:11,168
of flow numbers, they carry the semantic understanding

203
00:13:11,296 --> 00:13:14,088
behind the text that you are embedding.

204
00:13:14,176 --> 00:13:17,964
So, and we're going to talk in a moment why they are important.

205
00:13:18,264 --> 00:13:21,400
But it's really important that if you have, you know,

206
00:13:21,552 --> 00:13:25,086
terabytes of data that you want to store and you want to

207
00:13:25,110 --> 00:13:29,054
very easily retrieve that data based on semantic understanding.

208
00:13:29,094 --> 00:13:33,318
So you're not doing just an exactly match search, you're asking

209
00:13:33,366 --> 00:13:36,582
a question. And that question might be related

210
00:13:36,678 --> 00:13:40,726
to some of those, the context in your text that is also

211
00:13:40,830 --> 00:13:44,238
known as semantic search. So the numbers will carry

212
00:13:44,286 --> 00:13:47,686
a representation of the text in

213
00:13:47,710 --> 00:13:51,578
itself. So now that

214
00:13:51,626 --> 00:13:55,706
we might have generated. So it's very common on,

215
00:13:55,810 --> 00:13:59,458
when you have those type of limitations into large

216
00:13:59,506 --> 00:14:03,090
language models that we just described. One of the common

217
00:14:03,202 --> 00:14:06,562
and best approaches to solve that is to add

218
00:14:06,698 --> 00:14:10,298
an ability to retrieve the context from

219
00:14:10,386 --> 00:14:14,354
your vector space and add the vector,

220
00:14:14,474 --> 00:14:17,842
the text chunks that will be converted back from numbers

221
00:14:17,898 --> 00:14:21,806
into text as context to your large language models.

222
00:14:21,990 --> 00:14:25,998
But one of the challenges that you have once you create

223
00:14:26,086 --> 00:14:30,054
all these embeddings, let's say you have multiple documents internally

224
00:14:30,174 --> 00:14:33,422
and you want to translate all those documents, maybe PDF,

225
00:14:33,518 --> 00:14:37,354
into vectors, what do you do with those vectors?

226
00:14:37,974 --> 00:14:41,566
And here where vector databases play a big role.

227
00:14:41,750 --> 00:14:45,614
So you want to make sure you can store those vectors representations,

228
00:14:45,694 --> 00:14:49,674
those vector embeddings in a database. And then

229
00:14:49,794 --> 00:14:53,442
after you restore there in the database, you have the ability to retrieve

230
00:14:53,578 --> 00:14:57,546
by doing semantic search chunks of text that

231
00:14:57,610 --> 00:15:01,122
are similar to the question or topic you

232
00:15:01,138 --> 00:15:04,410
are trying to retrieve from. So how does vector

233
00:15:04,442 --> 00:15:07,890
database works or this vector embedding system?

234
00:15:07,962 --> 00:15:11,602
So if you think about in this diagram, you're going to have some raw data.

235
00:15:11,738 --> 00:15:15,026
You know, it could be images, it could be documents, it could be audio.

236
00:15:15,130 --> 00:15:18,690
For the sake of simplicity, for today's presentation, let's just focus on

237
00:15:18,722 --> 00:15:22,090
text. So let's say you have a word document and you

238
00:15:22,122 --> 00:15:26,162
want to create embeddings that behind the

239
00:15:26,178 --> 00:15:29,778
scenes are going to create vectors, the arrays of vectors

240
00:15:29,826 --> 00:15:33,786
for you. So what do you do? You create, you chunk that document

241
00:15:33,930 --> 00:15:37,634
into different pieces, because there are limitations of

242
00:15:37,794 --> 00:15:41,174
how many words you can create a vector.

243
00:15:41,914 --> 00:15:46,170
And it is of course very depending on the embedding model, the foundation embedding

244
00:15:46,202 --> 00:15:49,386
model that you use. But then once you have created

245
00:15:49,410 --> 00:15:52,882
the chunks, you go through the model and you say, hey, here is the chunk

246
00:15:52,898 --> 00:15:56,586
of text. Can you create a dense vector encoding for

247
00:15:56,610 --> 00:15:59,922
me? So that is where it creates the vector embedding space

248
00:16:00,058 --> 00:16:03,266
which will return an array of flow numbers for you that you

249
00:16:03,290 --> 00:16:04,934
create your vector embeddings.

250
00:16:06,614 --> 00:16:10,414
You can also create sparse vectors encoding, which is

251
00:16:10,494 --> 00:16:14,470
a different way to perform and being more optimized when doing

252
00:16:14,502 --> 00:16:18,022
the retrieval. Once you have those vectors, then you can

253
00:16:18,158 --> 00:16:21,718
stores those vectors in a database. And we're going to talk about some

254
00:16:21,766 --> 00:16:25,278
databases that AWS offers with the ability to

255
00:16:25,326 --> 00:16:28,462
store those vector databases. And then after,

256
00:16:28,598 --> 00:16:31,974
finally you can build applications that are able to

257
00:16:32,014 --> 00:16:37,064
retrieve query your database using semantic understanding

258
00:16:37,184 --> 00:16:40,924
and using different techniques like KNN

259
00:16:41,224 --> 00:16:44,352
and few other ones that you can just ask a question

260
00:16:44,408 --> 00:16:47,224
and you find the close similarities,

261
00:16:47,384 --> 00:16:51,296
vectors from the probe and query that you've provided.

262
00:16:51,360 --> 00:16:54,824
And after that you just, you copied

263
00:16:54,864 --> 00:16:58,344
the vectors from your database. You run again in the embedding

264
00:16:58,384 --> 00:17:02,584
model though that embedding model, just convert the vectors into

265
00:17:03,284 --> 00:17:06,484
text and then you can consume the text into

266
00:17:06,524 --> 00:17:10,372
the foundational models as texture text models that you

267
00:17:10,388 --> 00:17:13,636
might have available. Now let's just talk

268
00:17:13,700 --> 00:17:17,444
about the capabilities and databases that AWS offers

269
00:17:17,484 --> 00:17:21,452
you into storing those vectors.

270
00:17:21,508 --> 00:17:25,428
So there are a wide array of

271
00:17:25,476 --> 00:17:28,344
databases that AWS provides.

272
00:17:29,034 --> 00:17:32,162
They have vector capabilities you

273
00:17:32,178 --> 00:17:35,266
can see here on the list. We are going to go through most of them

274
00:17:35,370 --> 00:17:41,042
and I'm just going to talk to you about a high level why

275
00:17:41,178 --> 00:17:44,978
and how they are different from each other. So we're going to have search engines

276
00:17:45,026 --> 00:17:48,706
like open search. We're going to have relational databases like

277
00:17:48,850 --> 00:17:52,818
Postgres Aurora Postgres and RDS postgres.

278
00:17:52,866 --> 00:17:56,016
You're going to have document databases like document DB.

279
00:17:56,160 --> 00:17:59,840
You're going to have memory ink in memory

280
00:17:59,912 --> 00:18:03,144
databases like memory DB, and graph

281
00:18:03,184 --> 00:18:06,504
databases like Neptune. And all of those databases

282
00:18:06,584 --> 00:18:10,984
now have capabilities to run and store vector

283
00:18:11,144 --> 00:18:14,912
functionality. So let's just start with our first

284
00:18:14,968 --> 00:18:18,408
database. Amazon Zarora is

285
00:18:18,456 --> 00:18:22,324
a relational database that is a managed database on AWS.

286
00:18:22,834 --> 00:18:26,866
So Amazon Aurora Postgres flavor now has

287
00:18:26,890 --> 00:18:30,642
the capability to run vectors

288
00:18:30,778 --> 00:18:34,058
using a extension called, which is an

289
00:18:34,106 --> 00:18:37,930
open source extension called PG Vector. What it allows

290
00:18:37,962 --> 00:18:42,314
you to do is to have vector embeddings

291
00:18:42,434 --> 00:18:46,154
stored on your relation database. So if you're already storing

292
00:18:46,194 --> 00:18:49,966
your data using a relational approach and you just want to store

293
00:18:50,090 --> 00:18:53,430
an additional vector representation

294
00:18:53,502 --> 00:18:57,558
of the data, you can install PG vector both on Amazon Aurora

295
00:18:57,646 --> 00:19:00,486
and RDS postgres flavor.

296
00:19:00,630 --> 00:19:04,446
And once you restore those embeddings, you can

297
00:19:04,510 --> 00:19:08,662
support different algorithms such as KNN ANN

298
00:19:08,838 --> 00:19:12,166
H and SW and IV flat. Those are

299
00:19:12,190 --> 00:19:15,830
just different approaches and solutions on

300
00:19:15,862 --> 00:19:20,148
how to retrieve close similarities and chunks of embeddings

301
00:19:20,196 --> 00:19:23,900
and text for you. And you know, for postgres apps,

302
00:19:23,932 --> 00:19:28,260
the good thing is you don't need to make any driver

303
00:19:28,332 --> 00:19:32,148
change. You can just literally use install the extension on Amazon Aurora

304
00:19:32,196 --> 00:19:35,908
or RDS Aurora and continue to use your database.

305
00:19:36,036 --> 00:19:40,220
So this solution is a very good solution for existing

306
00:19:40,252 --> 00:19:43,300
postgres SQL users or any users

307
00:19:43,332 --> 00:19:46,698
that prefer relation database. You can actually use them.

308
00:19:46,716 --> 00:19:50,182
That right? So it's really powerful. There are a lot

309
00:19:50,198 --> 00:19:54,154
of integration. So if you have ML

310
00:19:54,574 --> 00:19:58,862
background but you are focused on relation database you,

311
00:19:58,958 --> 00:20:03,902
I would recommend you taking a look at Amazon Aurora with PG Vector

312
00:20:04,038 --> 00:20:07,902
and talking about PG Vector. PG Vector is an open source postgres

313
00:20:07,958 --> 00:20:11,542
SQL extension that is designed for efficient vector

314
00:20:11,598 --> 00:20:15,444
similarity search and perfect for levering machine learning with

315
00:20:15,484 --> 00:20:18,988
your databases. So it supports storing data

316
00:20:19,076 --> 00:20:22,564
along with your traditional data types while maintaining

317
00:20:22,604 --> 00:20:26,824
postgres robustness features such as acid compliant

318
00:20:27,484 --> 00:20:31,228
point in time recover and PG vector handles

319
00:20:31,316 --> 00:20:35,324
exactly an approximate nearest neighbor. Search accommodates in

320
00:20:35,364 --> 00:20:38,774
various distance measures like l two indian product

321
00:20:38,924 --> 00:20:43,418
and cosine distance. Those are just different mathematical expressions

322
00:20:43,466 --> 00:20:47,178
that are going to retrieve the similarity semantic

323
00:20:47,226 --> 00:20:50,690
search for you as you can see here, PG vector

324
00:20:50,722 --> 00:20:54,394
and with Aurora and RDS, sorry with Aurora are

325
00:20:54,434 --> 00:20:58,210
also integrated with Amazon bedrock knowledge base. We're going to talk about

326
00:20:58,242 --> 00:21:02,122
that in a moment. You have configurable require rate using

327
00:21:02,178 --> 00:21:05,728
these different approaches like HM and SW

328
00:21:05,856 --> 00:21:09,896
EF underscore search and IV IVF flat

329
00:21:09,960 --> 00:21:13,392
probes. The good thing about PG vector, it can

330
00:21:13,448 --> 00:21:16,736
scale to support over 1 billion vectors and the

331
00:21:16,760 --> 00:21:19,984
dimension it can support vectors with a 16 up to

332
00:21:20,024 --> 00:21:23,528
16,000 dimension. So that is a very good

333
00:21:23,576 --> 00:21:27,040
way if you have relational databases and you want to store vectors and

334
00:21:27,072 --> 00:21:29,564
this could be the place you you go.

335
00:21:30,184 --> 00:21:34,460
Second, we nietzsche talked about a very powerful

336
00:21:34,652 --> 00:21:38,148
service which is Amazon open search. So Amazon

337
00:21:38,196 --> 00:21:42,264
Open Search is a NoSQL database that is

338
00:21:42,684 --> 00:21:46,492
has been built from the beginning with scalability

339
00:21:46,668 --> 00:21:49,972
and as a distributed database for

340
00:21:50,028 --> 00:21:54,108
search. So you can use search and analytics engine

341
00:21:54,156 --> 00:21:57,180
on top of open search. You have different

342
00:21:57,252 --> 00:22:00,908
types of deployment for open source. So you can have a managed service that you

343
00:22:00,956 --> 00:22:04,670
manage different instance behind the scene for you. But it's also

344
00:22:04,822 --> 00:22:08,382
have the capability to deploy a serverless open search

345
00:22:08,478 --> 00:22:11,950
where you don't need to manage, you know, even the service doesn't need to

346
00:22:11,982 --> 00:22:15,670
manage any server for you. It doesn't abstract abstracts that

347
00:22:15,702 --> 00:22:18,910
away from you. Open search has also the

348
00:22:18,942 --> 00:22:22,526
capability restore vector using the KNN plugin.

349
00:22:22,630 --> 00:22:26,686
It also supports different algorithms such

350
00:22:26,710 --> 00:22:30,350
as KNN, AM, HMSW and IV

351
00:22:30,422 --> 00:22:34,458
flat. IVF flat. So you can see that similar

352
00:22:34,506 --> 00:22:38,098
to the Aurora postgres, Opensearch has

353
00:22:38,186 --> 00:22:40,014
similar algorithm capability.

354
00:22:41,074 --> 00:22:44,618
And if you have DynoDB tables, you can actually use zero ETL

355
00:22:44,666 --> 00:22:49,050
from dynoDB to move the data into open source service

356
00:22:49,202 --> 00:22:53,178
and you can vectorize those as well. So who are

357
00:22:53,226 --> 00:22:57,050
open source service? Very. It's a good fit.

358
00:22:57,162 --> 00:23:01,048
So if you are already an open source user or if you prefer NoSQL and

359
00:23:01,056 --> 00:23:04,160
you want to do hybrid search as well. So let's say you have a piece

360
00:23:04,192 --> 00:23:07,696
of text and you want to search both maybe search or

361
00:23:07,720 --> 00:23:11,724
field from the text, but also using the vector semantic capability,

362
00:23:12,184 --> 00:23:15,124
open search support that capability for you.

363
00:23:15,984 --> 00:23:19,872
And with open search service

364
00:23:19,968 --> 00:23:23,632
on AWS for vector it supports.

365
00:23:23,808 --> 00:23:27,976
I really like the open search and we'll do a demo later on because you

366
00:23:28,000 --> 00:23:32,202
can very easily and cost efficient deploy an open search serverless

367
00:23:32,258 --> 00:23:36,338
vector database that will behind the scenes manage all the

368
00:23:36,386 --> 00:23:40,082
index shared and manipulation of the data for you

369
00:23:40,178 --> 00:23:44,378
and it can scale for over a billion vectors with very high performance

370
00:23:44,546 --> 00:23:48,498
with the same dimensionality as Aurora. You can also

371
00:23:48,586 --> 00:23:52,362
have configurable recall rates via different segments and EF

372
00:23:52,418 --> 00:23:56,214
search. And similar to Amazon Aurora,

373
00:23:56,354 --> 00:24:00,630
OpenSearch is one of the main vector databases on AWS

374
00:24:00,742 --> 00:24:04,734
and integrates very well with knowledge base

375
00:24:04,774 --> 00:24:07,950
on bedrock. But also open search has

376
00:24:07,982 --> 00:24:11,646
a plugin called Neuro search that it can provide a

377
00:24:11,670 --> 00:24:16,246
very seamless integration between your text ingestion

378
00:24:16,350 --> 00:24:20,110
and the vector embedding creation. It can talk to Bedrock,

379
00:24:20,142 --> 00:24:23,292
you can talk to OpenAI, you can talk with cohere.

380
00:24:23,388 --> 00:24:27,020
By using this neural search it can automatically do all the

381
00:24:27,132 --> 00:24:32,220
retrieval generation of the battings for you continuing

382
00:24:32,252 --> 00:24:36,348
the segment. Vector support on AWS is

383
00:24:36,396 --> 00:24:39,972
also made available through document DB. So document DB is

384
00:24:39,988 --> 00:24:43,316
a very fast cloud native document database.

385
00:24:43,420 --> 00:24:47,428
So again it's a NoSQL database that has MongoDB API

386
00:24:47,476 --> 00:24:51,210
compatibility. You have different provision deployment

387
00:24:51,282 --> 00:24:55,994
options that it's a managed service. It also supports

388
00:24:56,114 --> 00:24:59,014
the same algorithms that I mentioned before,

389
00:24:59,314 --> 00:25:02,614
KNN Am IVF flat.

390
00:25:03,434 --> 00:25:08,930
By using MongoDB you can just elevate

391
00:25:09,002 --> 00:25:12,650
the capability of your vector search if you're already using documentDB

392
00:25:12,722 --> 00:25:15,886
or MongoDB. And what we

393
00:25:15,910 --> 00:25:19,142
see here is the good thing about documentDB if

394
00:25:19,158 --> 00:25:23,646
you're very familiar with document databases specific

395
00:25:23,750 --> 00:25:27,030
JSON usage because document database are really powerful

396
00:25:27,062 --> 00:25:30,094
with JSON, if you want to vectorize that information

397
00:25:30,214 --> 00:25:33,398
by just enabling vector capabilities

398
00:25:33,526 --> 00:25:37,274
on your document DB, it becomes very very powerful

399
00:25:37,814 --> 00:25:41,274
and continue. This is a very interesting service.

400
00:25:41,594 --> 00:25:45,386
Amazon Memory DB for Redis now also

401
00:25:45,450 --> 00:25:48,786
have a feature that is currently in preview and hopefully very soon is

402
00:25:48,810 --> 00:25:52,314
going to become GA general available that adds the ability

403
00:25:52,394 --> 00:25:56,174
for memory DB, which is already a very popular and

404
00:25:58,074 --> 00:26:01,938
performant database to have multi zero

405
00:26:02,026 --> 00:26:05,890
ability to handle vector storage, index and

406
00:26:05,922 --> 00:26:09,382
search capabilities. So memory DB,

407
00:26:09,438 --> 00:26:12,790
like the name says, is a database that stores all the data in

408
00:26:12,822 --> 00:26:16,742
memory and is ready's API compatible. It's a fully

409
00:26:16,758 --> 00:26:20,902
managed service. You can see it supports different word vector

410
00:26:21,038 --> 00:26:24,414
searches, algorithms that we mentioned. It has

411
00:26:24,534 --> 00:26:28,662
abilities to support up to 32,000 dimensions

412
00:26:28,718 --> 00:26:32,590
of vectors. And this is ideal if you really have a workflow

413
00:26:32,622 --> 00:26:35,974
that requires single digit millisecond

414
00:26:36,054 --> 00:26:39,494
latencies and throughput for your vector.

415
00:26:39,534 --> 00:26:43,054
So let's say you are building a chatbot that should be really quickly or trying

416
00:26:43,094 --> 00:26:46,754
to do retrieval augmented generation. That is super powerful.

417
00:26:47,054 --> 00:26:50,262
Memory DB might be the best place to look for because

418
00:26:50,318 --> 00:26:54,006
that very powerful capability and

419
00:26:54,030 --> 00:26:57,134
then fine. Last but not least, you also have Amazon

420
00:26:57,174 --> 00:27:00,462
Neptune analytics. So Amazon Neptune is the

421
00:27:00,518 --> 00:27:04,054
Amazon graph database. It allows you

422
00:27:04,214 --> 00:27:07,526
with the Amazon Neptune analytics allows you to have analytic

423
00:27:07,590 --> 00:27:11,078
memory optimized graph database engines. You have

424
00:27:11,126 --> 00:27:14,790
different discrete capacity deployments to deploy this database.

425
00:27:14,942 --> 00:27:18,990
It supports agents w similarity algorithm.

426
00:27:19,102 --> 00:27:22,750
You can see the dimension of that. This database for vectors are

427
00:27:22,782 --> 00:27:26,422
much bigger with up to 65,000 and it complements.

428
00:27:26,478 --> 00:27:30,510
So it's an addition plugin on top of your Amazon Neptune database.

429
00:27:30,702 --> 00:27:34,766
And if you why would you use Neptune

430
00:27:34,790 --> 00:27:38,934
analytics for your vector database? So if you're using neural networks, use cases

431
00:27:39,014 --> 00:27:42,846
where you need to do vector search graph traversals.

432
00:27:42,990 --> 00:27:46,230
This would be a very good approach. You can

433
00:27:46,262 --> 00:27:49,794
also use Neptune database with serverless deployment,

434
00:27:50,654 --> 00:27:54,894
but Neptune analytics only supports discrete capacity levels

435
00:27:54,934 --> 00:27:58,466
at this time. So if you're curious to

436
00:27:58,490 --> 00:28:01,882
learn more, I know I just covered very quickly these databases. I would

437
00:28:01,898 --> 00:28:05,730
highly recommend that you just do a quick Google and search

438
00:28:05,842 --> 00:28:08,734
our AWS documentation about how they work.

439
00:28:09,194 --> 00:28:12,614
But now I want to talk about Amazon Bedrock.

440
00:28:12,994 --> 00:28:17,130
I mentioned before in the beginning of my presentation that Amazon Bedrock

441
00:28:17,242 --> 00:28:21,050
is the easiest way for you to build generative AI applications

442
00:28:21,162 --> 00:28:24,376
on AWS. And the amazing thing about Bedrock

443
00:28:24,400 --> 00:28:28,456
is a completely managed service for Genai models. So you

444
00:28:28,520 --> 00:28:32,880
have a choice of multiple models with industry leading

445
00:28:32,912 --> 00:28:36,224
foundational model providers that are available with a single API

446
00:28:36,264 --> 00:28:39,496
call if you want. You can also customize and

447
00:28:39,520 --> 00:28:42,552
fine tune your models using your own organization data.

448
00:28:42,688 --> 00:28:45,896
And Bedrock has taken security

449
00:28:46,040 --> 00:28:49,784
as job number zero and it has all

450
00:28:49,824 --> 00:28:53,136
the encryption capabilities, privacy capabilities,

451
00:28:53,240 --> 00:28:57,248
not using your data to train any of those models. So it's an enterprise

452
00:28:57,296 --> 00:29:01,400
grade security and private service. With Amazon Bedrock

453
00:29:01,432 --> 00:29:04,696
you have a broad choice of models, as you can see here. This list

454
00:29:04,760 --> 00:29:08,736
is just as of today in March 30

455
00:29:08,760 --> 00:29:12,296
as I'm recording this session 2024. Right now there

456
00:29:12,320 --> 00:29:15,640
are seven different model providers,

457
00:29:15,712 --> 00:29:19,302
AI 21, Amazon and tropic cohere,

458
00:29:19,398 --> 00:29:21,514
meta nest row and stability.

459
00:29:22,454 --> 00:29:25,846
Those models have different capabilities. So you're going to

460
00:29:25,870 --> 00:29:29,710
have a text to text model where it's just a foundational model that you send

461
00:29:29,742 --> 00:29:33,006
text and it returns text back by predicting the next

462
00:29:33,070 --> 00:29:36,918
word. But you also have embedded models such as Amazon

463
00:29:37,086 --> 00:29:41,318
text embeddings and Amazon Titan multi model embeddings.

464
00:29:41,406 --> 00:29:45,138
But you also have an embeddings with cohere, which is the coherent

465
00:29:45,286 --> 00:29:48,762
embedding multilingual. And on top of that,

466
00:29:48,818 --> 00:29:52,882
you also have the ability to use bedrock to generate images with

467
00:29:52,938 --> 00:29:57,202
stability, AI stable diffusion Excel 1.0,

468
00:29:57,378 --> 00:30:01,294
but also with Titan image generator,

469
00:30:01,834 --> 00:30:05,866
it's pay as you go. You pay per token that you consume and

470
00:30:05,890 --> 00:30:09,506
you can choose the model that you're going to have access. In my demo I'm

471
00:30:09,530 --> 00:30:12,934
going to show you actually in the demo, the demo that we're going to show

472
00:30:12,974 --> 00:30:16,214
to you today is knowledge base for Amazon

473
00:30:16,254 --> 00:30:19,910
bedrock. And this is where I'm trying to bring all my

474
00:30:19,942 --> 00:30:24,214
presentation into a single place. Knowing the limitations of large language

475
00:30:24,254 --> 00:30:27,790
models that I've discussed in the beginning, one of the ways

476
00:30:27,822 --> 00:30:32,062
that you can work around the limitation is by creating a

477
00:30:32,118 --> 00:30:35,526
rack system, a retrieval augmented generation. What is a

478
00:30:35,550 --> 00:30:40,282
retrieval generation augmented is to bring pieces

479
00:30:40,378 --> 00:30:43,818
of data on text into your

480
00:30:43,866 --> 00:30:47,066
context before sending to a foundational model.

481
00:30:47,210 --> 00:30:50,426
And the ability that you do that, the first thing you need to do is

482
00:30:50,450 --> 00:30:54,946
to have a vector database where you can store all the vector embeddings

483
00:30:55,090 --> 00:30:58,534
from your specific domain data.

484
00:30:59,354 --> 00:31:03,344
You can retrieve the data at the query time. That data

485
00:31:03,384 --> 00:31:06,696
is going to be converted from vectors to text and

486
00:31:06,720 --> 00:31:10,024
then that data is going to be put it as the context of

487
00:31:10,064 --> 00:31:13,560
your query to the foundational model. It's,

488
00:31:13,592 --> 00:31:17,000
it can be very cumbersome to build this completely

489
00:31:17,072 --> 00:31:21,344
rag solution. So what knowledge basis for Amazon bedrock

490
00:31:21,384 --> 00:31:26,044
achieves is to automatically automate

491
00:31:26,384 --> 00:31:29,688
all the ingestion and retrieval for

492
00:31:29,736 --> 00:31:33,680
you on this reg system. So you connect

493
00:31:33,792 --> 00:31:38,000
your knowledge base with a database, you there

494
00:31:38,032 --> 00:31:41,576
are currently different supports for databases that are going to show in a moment for

495
00:31:41,600 --> 00:31:45,248
vector databases. Then you select an embedding

496
00:31:45,296 --> 00:31:48,824
model. Then you put your data on s

497
00:31:48,864 --> 00:31:52,544
three simple storage service and

498
00:31:52,704 --> 00:31:56,184
as soon as the data hits on that

499
00:31:56,224 --> 00:31:59,680
s three you can sync knowledge base which

500
00:31:59,752 --> 00:32:03,072
behind the scenes is going to create the embeddings, start embedding in

501
00:32:03,088 --> 00:32:07,016
the database and then when you make a call to

502
00:32:07,120 --> 00:32:11,104
knowledgebase for bedrock, that call you can decide

503
00:32:11,144 --> 00:32:14,512
if that call just retrieved the data from your database

504
00:32:14,568 --> 00:32:18,232
or if you want to do retrieve and generation, which means

505
00:32:18,288 --> 00:32:21,872
just retrieve the data from Myvector database, send to the

506
00:32:21,888 --> 00:32:24,874
foundation model, generate a response with my contacts,

507
00:32:24,914 --> 00:32:28,874
awareness information and then give the answer back to the customer.

508
00:32:28,914 --> 00:32:32,306
And you can select the model that you want to be used as the foundational

509
00:32:32,370 --> 00:32:34,814
model and also the embedding as well.

510
00:32:35,274 --> 00:32:38,730
So knowledge base on Bedrock has support for

511
00:32:38,882 --> 00:32:42,570
currently different databases. So right now it supports vector engine

512
00:32:42,602 --> 00:32:45,594
for open source serverless, redis, enterprise, cloud,

513
00:32:45,714 --> 00:32:49,856
Pinecone and Amazon Aurora. There are more capabilities coming soon.

514
00:32:49,970 --> 00:32:53,860
For example Mongodb. It's coming to be one of the vector

515
00:32:53,892 --> 00:32:57,436
databases support on Amazon Bedrock and hopefully in the future more

516
00:32:57,460 --> 00:33:00,996
of the databases that I talked today are also going to be available on

517
00:33:01,020 --> 00:33:05,348
bedrock. And the last thing I want to show is with knowledge

518
00:33:05,396 --> 00:33:08,852
base for bedrock you can use a single API call to do

519
00:33:08,868 --> 00:33:12,444
the retrieval and generation. So if you look at this diagram

520
00:33:12,524 --> 00:33:16,196
with a single API call on number one you can think about

521
00:33:16,260 --> 00:33:18,144
a search query. So you can say,

522
00:33:19,384 --> 00:33:22,632
let's just give an example. You are asking about a

523
00:33:22,648 --> 00:33:26,272
proprietary question of your company,

524
00:33:26,368 --> 00:33:29,488
right? And you know the foundation model doesn't know the answer.

525
00:33:29,616 --> 00:33:33,064
So you can do a search query what bedrock

526
00:33:33,104 --> 00:33:36,576
knowledge base you do, realizing that you need to do a retrieval on

527
00:33:36,600 --> 00:33:40,576
your vector database. So number two is going to go there, do the retrieval,

528
00:33:40,720 --> 00:33:44,024
then behind the scenes going to call your vector

529
00:33:44,064 --> 00:33:48,290
database is going to retrieve that

530
00:33:48,322 --> 00:33:52,858
embedding. The vector embedding is going to then convert

531
00:33:52,946 --> 00:33:56,138
the vector into text. And then on four

532
00:33:56,186 --> 00:34:00,482
it's going to send that text as context into your

533
00:34:00,658 --> 00:34:03,914
bedrock foundational model, texture text generation.

534
00:34:04,074 --> 00:34:07,738
And then finally it's going to send back the generation

535
00:34:07,826 --> 00:34:11,788
of answer that it chose. And you can see here soon,

536
00:34:11,956 --> 00:34:14,584
you know it's also going to support s three.

537
00:34:15,404 --> 00:34:18,620
And now let's jump in to do a

538
00:34:18,652 --> 00:34:22,664
quick demo of knowledge base for bedrock.

539
00:34:28,844 --> 00:34:32,228
Awesome. So let's just jump into the demo.

540
00:34:32,356 --> 00:34:35,144
The demo will be a very straightforward.

541
00:34:35,884 --> 00:34:39,604
I have downloaded some files

542
00:34:40,064 --> 00:34:44,400
from Amazon shareholder ladder.

543
00:34:44,552 --> 00:34:48,432
So you can see here I have the 2019,

544
00:34:48,608 --> 00:34:51,680
the 2020, the 2021 and the

545
00:34:51,712 --> 00:34:55,160
2022 Amazon shareholder.

546
00:34:55,352 --> 00:34:58,920
What I want to show is I have already created a

547
00:34:58,992 --> 00:35:03,284
open search database and I have then linked

548
00:35:04,044 --> 00:35:07,716
that database into bedrock knowledge base

549
00:35:07,900 --> 00:35:11,268
and I want to show you that it created the vectors automatically

550
00:35:11,316 --> 00:35:14,588
from s three. So just first let me show you.

551
00:35:14,636 --> 00:35:18,004
I have an s three here. So I created an s three

552
00:35:18,044 --> 00:35:22,204
bucket on that s three bucket. I just true

553
00:35:22,364 --> 00:35:26,660
those four files. I could have as many files as, you know,

554
00:35:26,852 --> 00:35:30,994
I wanted here. And what I've done then of

555
00:35:31,034 --> 00:35:34,378
course I've created an open search database. So this open

556
00:35:34,426 --> 00:35:38,130
search database you can see here, it's an open search serverless database.

557
00:35:38,202 --> 00:35:41,130
I have a collection. So let me just close these ones.

558
00:35:41,242 --> 00:35:44,746
I have a collection here I call bedrock sample.

559
00:35:44,930 --> 00:35:48,210
So I created this database. There is a dashboard also created for

560
00:35:48,242 --> 00:35:51,842
this database that I'm going to show in a moment. But the interesting part here

561
00:35:51,898 --> 00:35:55,364
is if I go on bedrock, which bedrock is the service that,

562
00:35:55,394 --> 00:35:59,192
that allows a no easy and scalable

563
00:35:59,248 --> 00:36:03,124
way to create generative AI on bedrock.

564
00:36:03,584 --> 00:36:06,840
The first thing we're going to do is let's just ask

565
00:36:06,912 --> 00:36:10,384
a very specific question to a foundational model

566
00:36:10,504 --> 00:36:13,968
without a reg system. So without using knowledge

567
00:36:14,016 --> 00:36:17,832
base. So you can go here on text we can first

568
00:36:17,888 --> 00:36:21,804
let's just look for a very specific, I think on the 2020.

569
00:36:22,694 --> 00:36:26,262
There is a mention. Let me

570
00:36:26,278 --> 00:36:30,206
just find the mention. There is a mention of 3000. Just bear

571
00:36:30,230 --> 00:36:33,678
with me. Let me see if I can find on the document.

572
00:36:33,806 --> 00:36:37,114
There is a mention somewhere here. I just need to find

573
00:36:37,574 --> 00:36:41,910
that AWS has released over 3000

574
00:36:42,102 --> 00:36:43,194
features,

575
00:36:45,374 --> 00:36:48,682
3000 features and services. I don't think

576
00:36:48,698 --> 00:36:51,134
it's highlighting here. So just bear with me.

577
00:36:52,514 --> 00:36:55,730
Let me just, let me download this file. So what we're gonna do, we're gonna

578
00:36:55,762 --> 00:36:59,538
download the file. Let me just download the file.

579
00:36:59,706 --> 00:37:04,094
Let me open the file here. And I think if I search now here

580
00:37:06,234 --> 00:37:09,874
features here. So 33 times I was

581
00:37:09,954 --> 00:37:13,522
searching wrong. You can see here AWS continues

582
00:37:13,538 --> 00:37:17,050
to deliver new capability over 3300

583
00:37:17,122 --> 00:37:20,146
new features and services launch in 2022.

584
00:37:20,330 --> 00:37:24,294
So what you're going to ask the foundational model without rag is

585
00:37:24,754 --> 00:37:28,282
this. Let's go here. Let's go on bedrock.

586
00:37:28,418 --> 00:37:31,338
Let's just choose one of the better models in tropic.

587
00:37:31,386 --> 00:37:35,066
Let's just go with instant because I know this is just a fast

588
00:37:35,130 --> 00:37:36,934
model and say how.

589
00:37:38,634 --> 00:37:42,494
So let's ask the model how many new features and services

590
00:37:43,684 --> 00:37:47,184
did AWS services

591
00:37:48,364 --> 00:37:51,740
did AWS launch in

592
00:37:51,772 --> 00:37:55,028
2022? So there is going to be the question.

593
00:37:55,196 --> 00:37:58,092
You can see I'm going to go in the model you're going to ask and

594
00:37:58,108 --> 00:38:01,384
the model says I don't have exact, I do not have.

595
00:38:01,804 --> 00:38:05,036
Let's just wait the finish. And it says I

596
00:38:05,060 --> 00:38:09,020
do not have the exact count of numbers or new features services

597
00:38:09,092 --> 00:38:12,634
like launch 2022. So what this means in this place

598
00:38:12,714 --> 00:38:16,594
here is that the foundational model itself doesn't have

599
00:38:16,634 --> 00:38:20,618
that information, right? Exactly. But the document

600
00:38:20,666 --> 00:38:24,618
that we have knows. So how do you put these two pieces together?

601
00:38:24,706 --> 00:38:28,882
Well, the first thing we can do is if we go on

602
00:38:28,898 --> 00:38:32,122
the knowledge base. So let me show you how I've created a knowledge base.

603
00:38:32,218 --> 00:38:35,868
So I've already created a knowledge base on dialog.

604
00:38:36,026 --> 00:38:40,128
And let me show you how the knowledge base works. So let me just scroll.

605
00:38:40,216 --> 00:38:43,904
So you create a knowledge base. Then you choose a

606
00:38:43,944 --> 00:38:47,344
data source. So in this case the data source is s

607
00:38:47,384 --> 00:38:51,104
three. So you can see that is the s three I showed you. If I

608
00:38:51,144 --> 00:38:54,724
go here and I show you can see this, we have these files.

609
00:38:55,264 --> 00:38:58,512
So you put, you choose the data source first, which is just an s

610
00:38:58,528 --> 00:39:02,648
three bucket. Then you choose the model that you want, bedrock knowledge

611
00:39:02,696 --> 00:39:06,592
base to create the vectors for you. So we are using a

612
00:39:06,608 --> 00:39:10,416
model that is offered within bedrock, which is the title

613
00:39:10,480 --> 00:39:14,520
embedding model version 1.2. Then after that

614
00:39:14,592 --> 00:39:17,712
you choose a database that you want to store those

615
00:39:17,768 --> 00:39:21,256
vectors. Right? So you want to have a database where the

616
00:39:21,280 --> 00:39:25,040
vectors can be stored and then you can retrieve that after the fact.

617
00:39:25,152 --> 00:39:28,288
So if you look here we have a vector database. We're using

618
00:39:28,336 --> 00:39:31,084
vector engine Amazon open search serverless.

619
00:39:31,514 --> 00:39:35,434
We have created the index name. So open search works with multiple

620
00:39:35,474 --> 00:39:38,834
index and within those indexes you can have a combination

621
00:39:38,914 --> 00:39:42,634
of items and documents. So, and we said when

622
00:39:42,674 --> 00:39:46,834
you create new vectors please add the,

623
00:39:46,954 --> 00:39:50,578
add the vector into the vector field on that

624
00:39:50,626 --> 00:39:54,802
item, on that document and add the text, the text itself

625
00:39:54,938 --> 00:39:59,148
into the text field. Because remember open search can do hybrid. So search

626
00:39:59,316 --> 00:40:02,544
in this case we're just going to do semantic search which is

627
00:40:03,124 --> 00:40:07,624
doing a similarity algorithm on top of your vector.

628
00:40:08,124 --> 00:40:11,556
So before I ask a question here, let me

629
00:40:11,580 --> 00:40:15,212
show you. So I'm going to go on. So this is the open

630
00:40:15,268 --> 00:40:19,428
search dashboard where you can run some open search commands to

631
00:40:19,476 --> 00:40:22,948
see the data. So if I, this query,

632
00:40:22,996 --> 00:40:26,158
what is this query is going to return? Is just going to return all the

633
00:40:26,206 --> 00:40:30,270
different documents. So all the different ids

634
00:40:30,382 --> 00:40:33,534
within that doc, within that specific index.

635
00:40:33,574 --> 00:40:37,574
So you can see this index called bedrock sample index 665

636
00:40:37,734 --> 00:40:41,222
is the same index that we've said here. So if you see here

637
00:40:41,278 --> 00:40:44,990
is the same vector index, right. And these open search

638
00:40:45,102 --> 00:40:48,886
serverless vector database there is nothing more than just the

639
00:40:48,910 --> 00:40:52,426
vectors from the s three files that we have uploaded.

640
00:40:52,590 --> 00:40:56,054
So you can see here I have multiple, these specific

641
00:40:56,674 --> 00:40:59,986
item has a chunk of

642
00:41:00,050 --> 00:41:03,450
this file here. So what we can do, we can just copy any chunk.

643
00:41:03,482 --> 00:41:06,794
In this case I've already selected this chunk and I want to show

644
00:41:06,834 --> 00:41:10,666
you how the vector is stored. So if you go and you compute this

645
00:41:10,810 --> 00:41:13,654
you can see that it creates the index, it creates the id.

646
00:41:14,474 --> 00:41:17,978
The sequence number might be because this specific file

647
00:41:18,026 --> 00:41:21,492
has been chunk, has been, you know, parsing to multiple chunks. And this

648
00:41:21,508 --> 00:41:24,852
is the sequence number 13. And here you can see the vector,

649
00:41:24,908 --> 00:41:28,644
right? So you can see a bunch of numbers. I'm just going to, you know,

650
00:41:28,684 --> 00:41:32,188
minimize this. But this is the vector. This is where the titan

651
00:41:32,236 --> 00:41:35,628
embedding model has been called to generate this

652
00:41:35,676 --> 00:41:38,452
vector. And here is the text.

653
00:41:38,548 --> 00:41:41,932
So what knowledge base,

654
00:41:41,988 --> 00:41:46,358
bedrock knowledge base automatically did for me was copy,

655
00:41:46,406 --> 00:41:49,750
copy this chunk, ran this chunk of text

656
00:41:49,822 --> 00:41:53,862
into my embedding model and then it generated the vector.

657
00:41:53,958 --> 00:41:57,886
So this is the factor. So now what we can do and

658
00:41:57,910 --> 00:42:01,374
you can see here, I think this is the one that I want

659
00:42:01,414 --> 00:42:04,634
to show if I'm not mistaken. Let me see.

660
00:42:05,414 --> 00:42:09,078
Yeah, here. So this is the chunk that we were gonna,

661
00:42:09,246 --> 00:42:12,822
that my, I want to show you that bedrock knowledge

662
00:42:12,878 --> 00:42:16,246
base will automatically retrieve and generate an answer for

663
00:42:16,270 --> 00:42:20,134
me. So remember we tried with just the foundation model, it didn't

664
00:42:20,174 --> 00:42:24,238
know, right. But now I have this piece of text and with the vector

665
00:42:24,286 --> 00:42:27,718
embedding itself that has this information. So what we can do,

666
00:42:27,766 --> 00:42:31,174
if you go back to backdrop, you can go on this

667
00:42:31,214 --> 00:42:34,278
tab just for I guess usage,

668
00:42:34,406 --> 00:42:37,698
you can select a model. Let's use the same

669
00:42:37,746 --> 00:42:41,014
model before and let's copy.

670
00:42:41,554 --> 00:42:45,250
Let's actually go. I think that the data,

671
00:42:45,402 --> 00:42:48,618
let me just, let's do this. Just give 1 second.

672
00:42:48,666 --> 00:42:52,026
Let's go here. I remember I copied this new features

673
00:42:52,050 --> 00:42:55,346
and service launch 2022. And if you

674
00:42:55,370 --> 00:42:58,746
go back to bedrock and you can

675
00:42:58,770 --> 00:43:02,738
see here that I can just say knowledge

676
00:43:02,786 --> 00:43:06,596
base for bedrock allows you to just retrieve the data

677
00:43:06,740 --> 00:43:10,116
or retrieve and generate, I'm going to show you both. So if I just

678
00:43:10,180 --> 00:43:13,860
go and I answer this, how many new features

679
00:43:13,892 --> 00:43:17,708
and service AWS launch in 2022? Remember this is

680
00:43:17,756 --> 00:43:21,052
exactly the same question I asked the model before and he

681
00:43:21,068 --> 00:43:24,372
said he didn't know. So what, what I'm going to do first is

682
00:43:24,388 --> 00:43:27,684
to generate an answer. So this is going to retrieve the piece of

683
00:43:27,724 --> 00:43:31,066
text and then he's going to send the piece of text to cloud instance as

684
00:43:31,090 --> 00:43:34,694
the model. And then finally it's going to generate an answer based on that.

685
00:43:35,034 --> 00:43:38,850
You can see here, it's saying retrieving and generating the response.

686
00:43:39,002 --> 00:43:43,330
And voila. It worked. So over three 3300

687
00:43:43,402 --> 00:43:47,234
new features and service were launched by AWS in 2022. And you can see

688
00:43:47,274 --> 00:43:50,386
that I have the source detail. So if I click to source this

689
00:43:50,450 --> 00:43:54,386
layer, you can see that he actually retrieved from my database

690
00:43:54,450 --> 00:43:58,470
a chunk and the same chunk that I was showing before that has these piece

691
00:43:58,502 --> 00:44:02,014
of data. So what that rock did automatically with a single

692
00:44:02,054 --> 00:44:05,774
API was retrieve the chunk, you know, convert back

693
00:44:05,814 --> 00:44:09,166
to text, add that text as the context

694
00:44:09,230 --> 00:44:12,886
of my question and then send back finally

695
00:44:12,910 --> 00:44:16,286
to my cloud instant model to give the answer that

696
00:44:16,310 --> 00:44:20,126
you can see here what you can also do. So if you clear this,

697
00:44:20,270 --> 00:44:23,174
what we can also do, we can just say generate response.

698
00:44:23,214 --> 00:44:26,802
Sorry, let's disable generate response. I'm just going

699
00:44:26,818 --> 00:44:28,574
to give the answer this question.

700
00:44:29,754 --> 00:44:32,414
Many new services and features.

701
00:44:33,034 --> 00:44:38,274
How many new features and service did AWS

702
00:44:38,354 --> 00:44:42,194
launch in 2022? When I click run

703
00:44:42,354 --> 00:44:46,298
what this does. So you see that I disabled and just said I don't

704
00:44:46,346 --> 00:44:50,334
do not generate response, just do the retrieval. So you can see

705
00:44:52,214 --> 00:44:54,794
that he has, if you go source detail,

706
00:44:56,014 --> 00:45:01,902
it has retrieved multiple

707
00:45:02,078 --> 00:45:06,034
chunks for me and I would expect some of them

708
00:45:06,574 --> 00:45:10,102
see here, the 3301

709
00:45:10,118 --> 00:45:13,958
of the chunks has responded so in this case it returned multiple

710
00:45:14,006 --> 00:45:17,508
chunks. You can decide how many chunks you want to

711
00:45:17,606 --> 00:45:21,048
retrieve here, right? You can see here maximum number of chunks.

712
00:45:21,176 --> 00:45:24,840
And finally what I want to show you everything that I'm doing. The console,

713
00:45:24,952 --> 00:45:29,484
you can actually also run via APIs.

714
00:45:30,024 --> 00:45:33,324
So you can see I have, let me just run this for you.

715
00:45:34,504 --> 00:45:38,296
What you see here, this retrieve and generate is

716
00:45:38,320 --> 00:45:41,504
the API that I'm calling. And here we can

717
00:45:41,584 --> 00:45:44,932
give the same answer, just copy the same answer,

718
00:45:45,108 --> 00:45:49,024
the same question. Apologies. How many new features and service

719
00:45:49,684 --> 00:45:54,144
did a launch in 2022?

720
00:45:55,524 --> 00:45:59,084
And you can see this is just going to call this a specific function,

721
00:45:59,244 --> 00:46:03,364
which is this function here that is calling a bedrock agent

722
00:46:03,404 --> 00:46:06,900
client API call, retrieve and generated. I pass some

723
00:46:06,932 --> 00:46:10,336
information like my knowledge base id, the model id that I

724
00:46:10,360 --> 00:46:13,960
want to use and the session id, and then it's just

725
00:46:14,032 --> 00:46:17,072
actually going to generate the information back for me. So if

726
00:46:17,088 --> 00:46:20,608
I run this, you can see it's running and the

727
00:46:20,656 --> 00:46:24,280
answer is back here. So what I wanted to show is you

728
00:46:24,312 --> 00:46:27,848
don't need to only use the console. Of course there are a lot of

729
00:46:27,896 --> 00:46:31,536
APIs that you can use and you know, we can actually see the

730
00:46:31,560 --> 00:46:34,440
citations, you can see the citations here.

731
00:46:34,472 --> 00:46:37,680
Again, the same citation that I have, it comes

732
00:46:37,752 --> 00:46:41,984
from. So the API and you can see the response comes

733
00:46:42,024 --> 00:46:45,336
with a citation part automatically. And this

734
00:46:45,360 --> 00:46:48,376
is pretty good because what open search

735
00:46:48,480 --> 00:46:52,280
the combination of knowledge base backdrop and

736
00:46:52,312 --> 00:46:56,208
open source serverless is super powerful because it pretty much

737
00:46:56,336 --> 00:47:01,040
removes all the cumbersome and manual actions

738
00:47:01,072 --> 00:47:05,094
that you need to do in order to create an ad events. Very powerful rack

739
00:47:05,134 --> 00:47:08,790
system. So I hopefully you enjoy. Please feel free

740
00:47:08,822 --> 00:47:12,374
to reach out if you have any questions. Have a great conference

741
00:47:12,454 --> 00:47:13,542
and talk to you soon.

