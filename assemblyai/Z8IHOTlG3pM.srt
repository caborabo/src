1
00:00:20,680 --> 00:00:24,510
Hi, hello everyone and welcome to my talk. Today I'm

2
00:00:24,542 --> 00:00:28,430
gonna talk about security by testing and how I

3
00:00:28,462 --> 00:00:31,662
try to improve the security of my go projects just

4
00:00:31,718 --> 00:00:35,126
by writing more tests. Before starting the

5
00:00:35,150 --> 00:00:38,502
talk, I will give you a little introduction about myself.

6
00:00:38,638 --> 00:00:41,894
So, my name is Alessio Veggie. I'm a software

7
00:00:41,934 --> 00:00:45,822
engineer, full time cat food opener for my furry friend.

8
00:00:45,998 --> 00:00:49,174
And jokes apart, I'm passionate about reading and

9
00:00:49,214 --> 00:00:52,606
taking long walks on the social media. You can find me

10
00:00:52,630 --> 00:00:56,428
on GitHub, LinkedIn, Twitter and so on

11
00:00:56,606 --> 00:01:01,044
with this unique account and this amazing avatar.

12
00:01:01,864 --> 00:01:06,136
So let's start the talk first concept to

13
00:01:06,160 --> 00:01:09,792
know is about code coverage code coverage is

14
00:01:09,808 --> 00:01:13,784
a metric that can help developers understanding

15
00:01:13,904 --> 00:01:17,808
how much of their source code is tested and

16
00:01:17,976 --> 00:01:21,592
how much is not. It is mostly used when

17
00:01:21,648 --> 00:01:25,390
writing a unit test, but not only

18
00:01:25,462 --> 00:01:29,406
related to them, and it's expressed

19
00:01:29,590 --> 00:01:30,954
as a percentage.

20
00:01:32,854 --> 00:01:37,206
Let's go a bit more in depth with code coverage. With Golang it

21
00:01:37,230 --> 00:01:40,954
was first time introduced in version 1.2,

22
00:01:41,454 --> 00:01:45,150
April 2013, if I remember well, and this

23
00:01:45,182 --> 00:01:49,030
support was specifically for unit tests. Here's the link

24
00:01:49,182 --> 00:01:52,998
to the announcement. And the story continued

25
00:01:53,086 --> 00:01:56,590
after almost ten years with version 1.20

26
00:01:56,742 --> 00:02:00,542
with a new grid support for the integration test.

27
00:02:00,718 --> 00:02:04,142
So this means that combining the unit test with

28
00:02:04,158 --> 00:02:08,118
the integration test coverage, the coverage

29
00:02:08,286 --> 00:02:12,422
percentage of our projects sensibly increased thanks to

30
00:02:12,478 --> 00:02:15,918
the last feature. During this time. Also, the go

31
00:02:15,966 --> 00:02:19,332
community introduced some nice tools, like for example the

32
00:02:19,388 --> 00:02:23,356
go to cover that gives you the ability to see

33
00:02:23,500 --> 00:02:27,276
the to render the source code with its coverage in

34
00:02:27,300 --> 00:02:31,132
an HTML page and so on. So that's,

35
00:02:31,228 --> 00:02:34,708
that's what happened. Another important

36
00:02:34,796 --> 00:02:37,684
concept is about Secomp profile.

37
00:02:37,844 --> 00:02:41,508
First of all, Seccomp is a security feature that resides

38
00:02:41,556 --> 00:02:44,724
on the Linux kernel and the second profile is

39
00:02:44,764 --> 00:02:48,824
basically list of syscalls that you can use to

40
00:02:48,984 --> 00:02:52,328
put them into a rule and attach this rule

41
00:02:52,416 --> 00:02:55,864
to a program by defining if these

42
00:02:55,904 --> 00:02:59,736
syscalls could be executed or not by the program itself.

43
00:02:59,920 --> 00:03:03,336
So it works as a firewall for system

44
00:03:03,400 --> 00:03:07,368
calls. Additionally, it is extensively used in the kubernetes

45
00:03:07,456 --> 00:03:11,516
ecosystem, especially when you enable the second

46
00:03:11,580 --> 00:03:14,916
default feature flag. So this means that

47
00:03:15,020 --> 00:03:18,396
all the workloads that you are going to run will be,

48
00:03:18,540 --> 00:03:21,716
will be attached to this default profile. That is

49
00:03:21,740 --> 00:03:25,092
a default second profile that have inside

50
00:03:25,148 --> 00:03:28,916
the most dangerous syscalls that you should never use in

51
00:03:28,940 --> 00:03:32,548
your run. Let's see

52
00:03:32,636 --> 00:03:36,464
now, the main idea that I had during the tasks,

53
00:03:36,784 --> 00:03:40,664
so the main thought that I had was to create to

54
00:03:40,704 --> 00:03:44,304
generate a second profile as an artifact

55
00:03:44,424 --> 00:03:47,184
at the end of a test pipeline.

56
00:03:47,344 --> 00:03:50,712
Why specifically the test pipeline because in

57
00:03:50,728 --> 00:03:54,136
the test pipeline, we are testing, as much

58
00:03:54,160 --> 00:03:57,960
as we can, our test our code through the

59
00:03:57,992 --> 00:04:01,368
test that we write. And depending on the percentage

60
00:04:01,456 --> 00:04:04,590
that cover our, our source code,

61
00:04:04,702 --> 00:04:08,854
we can rely on them for a security profile.

62
00:04:08,974 --> 00:04:12,478
So if we are testing the 70% of our code,

63
00:04:12,526 --> 00:04:16,358
the syscalls that we are going to extract on the

64
00:04:16,406 --> 00:04:20,206
test pipeline will be reliable for the 70%.

65
00:04:20,390 --> 00:04:23,326
So that was the main idea. Additionally,

66
00:04:23,510 --> 00:04:27,194
this second profile could be used in different

67
00:04:27,494 --> 00:04:30,994
ways. The, the most common that came into

68
00:04:31,034 --> 00:04:34,594
my mind was to use it through

69
00:04:34,714 --> 00:04:37,842
an init container. When we deploy our application,

70
00:04:37,978 --> 00:04:41,330
the init container basically injected the second

71
00:04:41,442 --> 00:04:45,490
by downloading it from the artifact

72
00:04:45,602 --> 00:04:49,858
registry and store it into the Kubernetes

73
00:04:49,906 --> 00:04:54,002
node in order to allow the application container

74
00:04:54,058 --> 00:04:56,814
to load it and run with it.

75
00:04:58,434 --> 00:05:02,202
And there's the example. So the init container basically download it

76
00:05:02,258 --> 00:05:05,654
and store it under Barlib Kubelet second,

77
00:05:05,954 --> 00:05:09,770
and then the container, in this case the NginX container

78
00:05:09,802 --> 00:05:13,770
for example, uses the security context second profile

79
00:05:13,882 --> 00:05:17,514
of type localhost by referring to the second profile

80
00:05:17,554 --> 00:05:19,614
itself, but with the localhost profile.

81
00:05:22,574 --> 00:05:25,686
So now that we have the main concept in our mind,

82
00:05:25,830 --> 00:05:29,246
let me explain you what was the step that I

83
00:05:29,270 --> 00:05:32,606
followed and how I tried to achieve this goal.

84
00:05:32,750 --> 00:05:35,982
So in this image, you can see basically

85
00:05:36,038 --> 00:05:39,438
a call graph of an example

86
00:05:39,486 --> 00:05:42,790
program. So having that

87
00:05:42,822 --> 00:05:45,918
in mind and having all the tests that are

88
00:05:45,966 --> 00:05:49,286
rendered can basically understand what is missing and what

89
00:05:49,310 --> 00:05:52,984
is not. So we have a general overview about the

90
00:05:53,064 --> 00:05:56,688
potential syscall that you are missing if you are not testing

91
00:05:56,816 --> 00:06:00,576
the binary. So in

92
00:06:00,600 --> 00:06:04,256
order to extract the syscalls from the test with

93
00:06:04,280 --> 00:06:08,144
the integration test, that was the easiest

94
00:06:08,184 --> 00:06:11,432
part. What we have to do is to build a binary,

95
00:06:11,568 --> 00:06:15,600
provide some script to check for the expected result,

96
00:06:15,712 --> 00:06:18,922
general scripts for the integration test.

97
00:06:19,058 --> 00:06:22,786
An example that I really

98
00:06:22,890 --> 00:06:26,414
appreciate is the test script suite.

99
00:06:27,354 --> 00:06:31,694
And basically we can run our binary

100
00:06:32,394 --> 00:06:36,294
by using strace or pair for whatever you want.

101
00:06:36,994 --> 00:06:40,378
So in this case we can extract, we can collect

102
00:06:40,426 --> 00:06:44,306
all the executed syscalls from the binary

103
00:06:44,450 --> 00:06:48,094
by testing all the possible branch that

104
00:06:48,554 --> 00:06:52,334
the executioner has. So this was the first part,

105
00:06:53,114 --> 00:06:56,714
but it was not enough in my opinion, because we were

106
00:06:56,754 --> 00:07:00,818
missing the unit test that are such a big part of

107
00:07:00,986 --> 00:07:05,346
the test pipeline. So how I tried to extract

108
00:07:05,490 --> 00:07:08,834
also the syscalls from the unit test, first of all,

109
00:07:08,874 --> 00:07:13,020
it's quite simple to say, but it was a bit more complicated.

110
00:07:13,212 --> 00:07:15,764
First of all, the gotest command,

111
00:07:15,924 --> 00:07:19,620
we have to think that the gotest command compile and run the

112
00:07:19,652 --> 00:07:23,068
test binary all at once. So when we run go tests,

113
00:07:23,116 --> 00:07:26,900
we are basically compiling the test and then automatically

114
00:07:26,972 --> 00:07:30,196
run with the same command. At first glance

115
00:07:30,340 --> 00:07:34,068
we couldn't do strace of go test because

116
00:07:34,156 --> 00:07:37,888
we were going to hook, we were going to trace

117
00:07:38,036 --> 00:07:41,248
calls that were not related to our specific test,

118
00:07:41,376 --> 00:07:45,216
but syscalls that were included in the go test command

119
00:07:45,360 --> 00:07:48,844
that were out of school. So what we could do

120
00:07:50,744 --> 00:07:54,776
at first I thought that we could for example compile

121
00:07:54,840 --> 00:07:58,848
only the test binary without running it using go

122
00:07:58,896 --> 00:08:03,804
test, but running it separately. So if we basically

123
00:08:04,834 --> 00:08:08,458
type gotest c, we could compile the test

124
00:08:08,506 --> 00:08:12,294
binary and run it by ourselves.

125
00:08:13,114 --> 00:08:17,098
The problem in this case is that even

126
00:08:17,146 --> 00:08:20,794
doing strace about of the test binary,

127
00:08:20,954 --> 00:08:24,274
we could include some noise that are not related to our

128
00:08:24,354 --> 00:08:27,642
specific function that we are testing, because for

129
00:08:27,658 --> 00:08:31,320
example we can include some function that

130
00:08:31,442 --> 00:08:34,652
load some test data from, from the,

131
00:08:34,788 --> 00:08:38,596
from the environment. So as in as an example we could

132
00:08:38,740 --> 00:08:42,708
open a file, read the file content, and this

133
00:08:42,756 --> 00:08:46,252
syscalls will be collected by strace.

134
00:08:46,308 --> 00:08:51,164
But we don't need that, we should try to find a way to

135
00:08:51,244 --> 00:08:55,012
avoid this kind of noise. My personal idea,

136
00:08:55,068 --> 00:08:59,196
I don't know if it's the good one, but it

137
00:08:59,220 --> 00:09:02,772
seems to work, at least in some cases. But the

138
00:09:02,788 --> 00:09:06,740
main idea was to create using a BPF to define

139
00:09:06,772 --> 00:09:11,068
a trace point that basically start tracing the syscalls.

140
00:09:11,116 --> 00:09:14,836
When a probe that is attached to the function that

141
00:09:14,860 --> 00:09:18,796
we want to trace inform us that the

142
00:09:18,820 --> 00:09:22,388
execution of the function started and we can stop the

143
00:09:22,476 --> 00:09:26,274
trace point when the uert probe inform

144
00:09:26,354 --> 00:09:29,394
us that the execution of the function is finished.

145
00:09:29,514 --> 00:09:32,730
So we have a range of

146
00:09:32,762 --> 00:09:36,146
time that we can rely on in order to

147
00:09:36,290 --> 00:09:40,162
collect the syscholes that derives from our

148
00:09:40,258 --> 00:09:44,194
function. An additional information is that Arpun

149
00:09:44,274 --> 00:09:47,962
was based on go BPF at

150
00:09:47,978 --> 00:09:51,982
the beginning, but then I moved to Libpfgo

151
00:09:52,118 --> 00:09:55,998
and I will explain later why I took

152
00:09:56,166 --> 00:09:57,434
this decision.

153
00:09:59,814 --> 00:10:03,254
So let's see the juice part. So in order

154
00:10:03,294 --> 00:10:07,022
to run harpoon what we have to do, we should basically

155
00:10:07,158 --> 00:10:10,342
build the test binary first as we were trying to

156
00:10:10,358 --> 00:10:13,934
do before. So just typing gotest c

157
00:10:14,054 --> 00:10:17,524
followed by the package pop that host

158
00:10:17,604 --> 00:10:21,012
our function. So in this case we are going to

159
00:10:21,148 --> 00:10:25,036
build the test binary. So as a result we are going to have a

160
00:10:25,060 --> 00:10:29,524
binary that will execute the test where

161
00:10:29,604 --> 00:10:31,704
our function is located.

162
00:10:33,764 --> 00:10:37,564
Consequently, we have to extract from

163
00:10:37,604 --> 00:10:41,100
this binary the symbol name of the function that we

164
00:10:41,132 --> 00:10:44,988
want to trace. So in the example

165
00:10:45,036 --> 00:10:47,820
I typed the myfunction.

166
00:10:47,972 --> 00:10:51,316
So myfunction is the function

167
00:10:51,500 --> 00:10:55,684
that we want to trace and we are using objdump

168
00:10:55,844 --> 00:10:59,900
since followed by the name of the binary test

169
00:11:00,092 --> 00:11:02,744
by graphing for the function name.

170
00:11:03,484 --> 00:11:07,452
In this case we are going to find the symbol

171
00:11:07,548 --> 00:11:11,682
of the function name. So as you can see in the example below,

172
00:11:11,818 --> 00:11:15,954
so we are doing objdump to test binary

173
00:11:15,994 --> 00:11:20,066
of mine. It was an independent project from

174
00:11:20,090 --> 00:11:23,762
this talk and we are graphing for the function

175
00:11:23,858 --> 00:11:27,186
interface exist. So interface exists is a

176
00:11:27,210 --> 00:11:30,334
function that I've created in my personal project,

177
00:11:30,634 --> 00:11:34,586
a go function that we can find on the binary on the

178
00:11:34,610 --> 00:11:38,656
test binary with the following name. So GitHub.com

179
00:11:38,840 --> 00:11:42,696
allegra 91 forwardctlash packages

180
00:11:42,840 --> 00:11:46,928
iptables dot interface exists. So once

181
00:11:46,976 --> 00:11:50,248
we have the symbol, the symbol name of the function,

182
00:11:50,416 --> 00:11:54,080
we can use arpun in order to extract the syscalls

183
00:11:54,152 --> 00:11:58,656
from the binary. So by typing this command arpun

184
00:11:58,800 --> 00:12:02,284
fm to specifying the the symbol

185
00:12:02,324 --> 00:12:05,916
name of the function followed by the command

186
00:12:06,060 --> 00:12:07,544
for the test binary.

187
00:12:08,444 --> 00:12:12,188
So as I explained before, what is going to

188
00:12:12,236 --> 00:12:15,724
happen with arpun is that arpun will take the elf

189
00:12:15,764 --> 00:12:19,348
binary. So binary test and we'll attach

190
00:12:19,436 --> 00:12:23,604
a u probe and a u ref probe to the main dot. Do something

191
00:12:23,724 --> 00:12:27,044
in this case, but whatever is the name of the

192
00:12:27,084 --> 00:12:30,048
symbol or of the function and will,

193
00:12:30,176 --> 00:12:33,392
after it attached these probes to

194
00:12:33,408 --> 00:12:36,648
the function, will basically run the binary

195
00:12:36,736 --> 00:12:40,096
and the trace point will be informed by the u probe and

196
00:12:40,120 --> 00:12:43,844
the u rh probe about the starting and the xd

197
00:12:44,824 --> 00:12:48,160
and the end of the function itself.

198
00:12:48,352 --> 00:12:52,232
So in this limited range of time we are going to extract the

199
00:12:52,248 --> 00:12:55,652
syscalls. And here it is

200
00:12:55,748 --> 00:13:02,084
an example. So by typing arfun fn

201
00:13:02,244 --> 00:13:05,772
followed by the function, the symbol name of

202
00:13:05,788 --> 00:13:09,732
the function, followed by the command of the test binary.

203
00:13:09,788 --> 00:13:12,624
So iptables test.

204
00:13:13,164 --> 00:13:17,028
So here's the list of the functions that are related only

205
00:13:17,156 --> 00:13:20,334
to the function in interface exists.

206
00:13:20,674 --> 00:13:23,786
Let's see now the worst part of this of this project,

207
00:13:23,970 --> 00:13:27,762
everything was looking nice, but at some point I

208
00:13:27,818 --> 00:13:31,482
realized that not all the things were working properly.

209
00:13:31,578 --> 00:13:35,986
Main thing that was not working properly was that the u rat probe sometime

210
00:13:36,130 --> 00:13:40,178
was not informing the program that the function

211
00:13:40,346 --> 00:13:44,010
was returned. What was the problem? Basically the

212
00:13:44,042 --> 00:13:48,074
Europe probe overwrite the return address of the probed

213
00:13:48,114 --> 00:13:52,194
function with an address of a trampoline. This trampoline is

214
00:13:52,234 --> 00:13:55,842
basically pointing to our EPF program.

215
00:13:56,018 --> 00:13:59,490
So once the EBBF program

216
00:13:59,682 --> 00:14:03,194
is executed and after it sends the instruction

217
00:14:03,234 --> 00:14:07,634
pointer should restore tool to point to the next instruction.

218
00:14:07,794 --> 00:14:11,754
But this thing doesn't happen all the time,

219
00:14:11,914 --> 00:14:15,570
since the stack in the go binaries dynamically

220
00:14:15,642 --> 00:14:19,604
changes due to the garbage collector, for example.

221
00:14:19,904 --> 00:14:24,472
So this kind of behavior could

222
00:14:24,528 --> 00:14:27,644
cause the program corruption.

223
00:14:28,704 --> 00:14:32,760
So I had to find a way

224
00:14:32,792 --> 00:14:36,264
to solve this issue, and luckily for me I

225
00:14:36,304 --> 00:14:38,880
found this workaround on Internet.

226
00:14:39,072 --> 00:14:42,854
So the workaround consists in starting

227
00:14:42,894 --> 00:14:47,238
from the fact that the U probes could be attached

228
00:14:47,366 --> 00:14:51,270
to a specific offset. So we don't

229
00:14:51,342 --> 00:14:55,318
need to attach the U probes only on the symbol function

230
00:14:55,366 --> 00:14:59,310
names, but we can do the same to a specific offset

231
00:14:59,382 --> 00:15:03,686
in the function, in the binary function. So in

232
00:15:03,710 --> 00:15:06,902
order to simulate the URET probe,

233
00:15:06,998 --> 00:15:10,850
what you what we could do is of adding for

234
00:15:10,882 --> 00:15:14,618
each rEt instruction that is inside the function,

235
00:15:14,746 --> 00:15:19,010
a uprobe that basically simulates the functioning

236
00:15:19,042 --> 00:15:22,386
of a UART probe. So instead of attaching

237
00:15:22,450 --> 00:15:25,826
one single u ret probe in the function, we can

238
00:15:25,850 --> 00:15:30,250
add the one u probe for each ret instruction

239
00:15:30,402 --> 00:15:32,894
within the function that we are tracing,

240
00:15:33,654 --> 00:15:36,874
and the rest of the function is the same.

241
00:15:38,654 --> 00:15:42,286
So benefits of moving to lib bpf go

242
00:15:42,470 --> 00:15:45,830
so at the beginning when I introduced arkun,

243
00:15:45,942 --> 00:15:49,446
I mentioned the thing that was based on go bpf, that is

244
00:15:49,470 --> 00:15:53,994
a library from the iovisor organization

245
00:15:54,374 --> 00:15:57,734
and that is using bc under the hood.

246
00:15:57,894 --> 00:16:01,628
So now I decided to move to lib bpfgo,

247
00:16:01,756 --> 00:16:05,940
mainly because libpfgo gives you the ability

248
00:16:06,092 --> 00:16:09,788
of attaching the u probes to specific offset,

249
00:16:09,876 --> 00:16:13,740
and this thing was not supported by go bpf.

250
00:16:13,892 --> 00:16:17,284
So we can basically simulate the functioning of our

251
00:16:17,324 --> 00:16:21,492
UART probe by attaching the U probes

252
00:16:21,628 --> 00:16:25,218
to the RET instructions, thanks to Libbypfgo.

253
00:16:25,396 --> 00:16:29,350
And the use of LibfDo makes the project

254
00:16:29,462 --> 00:16:33,594
even more distributable, easily distributable because

255
00:16:34,254 --> 00:16:38,118
the LibPF Go is a library that is a wrapper of

256
00:16:38,166 --> 00:16:41,750
Lib BPF. So Lib BPF gives

257
00:16:41,782 --> 00:16:45,394
us the ability to write the program

258
00:16:46,014 --> 00:16:49,918
with Cory. Cory means compile once runs

259
00:16:49,966 --> 00:16:53,434
everywhere. We don't have to build the binary every

260
00:16:53,474 --> 00:16:57,666
time we run the application as we did before with the Go BPF

261
00:16:57,850 --> 00:17:02,034
that was based on BCC that needs GCC

262
00:17:02,194 --> 00:17:04,810
as a dependency to do this thing.

263
00:17:04,962 --> 00:17:08,906
So this time we can simply compile the binary the

264
00:17:08,930 --> 00:17:12,458
first time from the pipeline, for example, and then

265
00:17:12,506 --> 00:17:17,760
distribute the entire program through

266
00:17:17,792 --> 00:17:19,004
the repository.

267
00:17:21,904 --> 00:17:25,696
So the talk is almost finished. I just want to

268
00:17:25,840 --> 00:17:29,520
point you to some links that helped me a lot

269
00:17:29,672 --> 00:17:33,760
understanding this problem and links

270
00:17:33,832 --> 00:17:37,176
from which I learned a lot. I also want to

271
00:17:37,280 --> 00:17:40,840
thank some people that helped me doing this

272
00:17:40,872 --> 00:17:44,120
project. Thank you for your attention and I hope

273
00:17:44,152 --> 00:17:44,904
you enjoyed the talk.

