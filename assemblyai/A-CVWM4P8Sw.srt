1
00:00:20,650 --> 00:00:24,538
Hello everyone. For today we'll be discussing

2
00:00:24,634 --> 00:00:28,226
how to unleash the power of retrieval augmented generation

3
00:00:28,338 --> 00:00:31,190
to enhance aipowered applications.

4
00:00:31,770 --> 00:00:35,570
We'll quickly introduce ourselves. I am Sophie Sullivan,

5
00:00:35,650 --> 00:00:39,186
and I am the director of operations for Edamama.

6
00:00:39,298 --> 00:00:42,914
I have over nine years of experience in e commerce,

7
00:00:43,042 --> 00:00:45,618
fintech, and retail in the Philippines.

8
00:00:45,794 --> 00:00:49,510
Over the years I have built my expertise on process

9
00:00:49,580 --> 00:00:52,718
management, AI, and everything else in between.

10
00:00:52,884 --> 00:00:56,734
And I am Joshua Arvin Lat, the chief technology officer of

11
00:00:56,772 --> 00:01:00,542
Nuworks Interactive Labs. I am also an AWS machine Learning

12
00:01:00,596 --> 00:01:04,282
hero, and I am the author of the following books.

13
00:01:04,426 --> 00:01:07,634
Here in the screen we can see three books I've written so far this past

14
00:01:07,672 --> 00:01:10,766
three years. The first one is machine learning with Amazon

15
00:01:10,798 --> 00:01:13,954
Sagemaker cookbook. The second one is machine learning

16
00:01:13,992 --> 00:01:17,894
engineering on AWS, and finally building and

17
00:01:17,932 --> 00:01:20,630
automating penetration testing labs.

18
00:01:20,970 --> 00:01:24,822
So right now we are probably wondering what

19
00:01:24,876 --> 00:01:28,406
this talk is all about. And it's about generative AI.

20
00:01:28,518 --> 00:01:32,406
And of course we'll dive deeper on retrieval augmented

21
00:01:32,438 --> 00:01:36,154
generation later. But of course, no AI talk

22
00:01:36,192 --> 00:01:40,038
is complete without having a few examples on how AI really works.

23
00:01:40,224 --> 00:01:44,158
So here in our chat playground, we basically ask

24
00:01:44,324 --> 00:01:47,834
the generative AI service, what is the meaning

25
00:01:47,882 --> 00:01:52,170
of life? So here our generative AI service simply answers

26
00:01:52,330 --> 00:01:56,066
the meaning of life is a self filled question that has

27
00:01:56,088 --> 00:02:00,638
been debated throughout time. Different people have different beliefs

28
00:02:00,734 --> 00:02:04,114
and perspectives on this matter. As you can see,

29
00:02:04,232 --> 00:02:08,166
the generative AI service aipowered our question, and of

30
00:02:08,188 --> 00:02:12,150
course the answer is basically its own interpretation on

31
00:02:12,220 --> 00:02:16,150
what the meaning of life is. Now, let's try a different

32
00:02:16,300 --> 00:02:20,118
example. This time we have a text input,

33
00:02:20,214 --> 00:02:24,314
and the generative AI tool gives us

34
00:02:24,432 --> 00:02:28,406
an image response instead. So here we input

35
00:02:28,438 --> 00:02:32,714
the prompt. Here the generative AI service simply

36
00:02:32,762 --> 00:02:36,334
returns how it interprets our prompt in the

37
00:02:36,372 --> 00:02:40,110
form of an image. Now let's try a similar

38
00:02:40,180 --> 00:02:43,838
example, but this time let's input the prompt cat flying

39
00:02:43,854 --> 00:02:47,906
with wings. So even if it's not really possible at this point

40
00:02:47,928 --> 00:02:52,222
in time for a cat to have wings, the generative

41
00:02:52,286 --> 00:02:56,538
AI solution is still able to provide us an image.

42
00:02:56,734 --> 00:03:00,214
And it generated this image where this

43
00:03:00,252 --> 00:03:03,730
image has a cat, and of course this cat has wings,

44
00:03:03,890 --> 00:03:07,582
and it basically lets us know that this cat can probably fly

45
00:03:07,746 --> 00:03:10,618
because it has wings. Then finally,

46
00:03:10,704 --> 00:03:13,994
let's replace the word cat with dog. And here,

47
00:03:14,112 --> 00:03:18,470
surprisingly, we have an image of a dog with wings,

48
00:03:18,550 --> 00:03:22,800
and it's also flying. There are a lot of different possible

49
00:03:23,410 --> 00:03:26,586
applications of generative AI, and you'll

50
00:03:26,618 --> 00:03:29,962
be surprised with how the recent

51
00:03:30,026 --> 00:03:33,602
innovations and findings have

52
00:03:33,656 --> 00:03:37,634
helped this field progress further this

53
00:03:37,672 --> 00:03:41,394
last couple of months. So before we start I

54
00:03:41,432 --> 00:03:44,834
want to pose a question to everyone. Do you think

55
00:03:44,872 --> 00:03:48,422
you can build a generative aipowered application in

56
00:03:48,476 --> 00:03:51,926
just 24 hours? If you were to deploy your

57
00:03:51,948 --> 00:03:55,846
own self hosted LLM, then yes, it's possible.

58
00:03:56,028 --> 00:03:59,786
However, setting up a rag powered generative AI system

59
00:03:59,888 --> 00:04:04,010
may take longer. We'll see this in action later in our presentation.

60
00:04:04,670 --> 00:04:08,534
We can categorize and group AI into artificial narrow

61
00:04:08,582 --> 00:04:12,778
intelligence, artificial general intelligence, and artificial

62
00:04:12,874 --> 00:04:16,334
superintelligence. Currently, what we have right

63
00:04:16,372 --> 00:04:19,806
now is ANI. We're still in the infancy of

64
00:04:19,828 --> 00:04:23,642
AI, wherein it hasn't advanced yet to the point where usage

65
00:04:23,706 --> 00:04:27,202
is widespread. Definitely a stage where there are already

66
00:04:27,256 --> 00:04:30,398
some limited practical applications of it, but there's

67
00:04:30,414 --> 00:04:33,746
still room to further improve in terms of integrating AI in

68
00:04:33,768 --> 00:04:37,046
a broader way. In AGI, this is what

69
00:04:37,068 --> 00:04:40,454
we are hoping to achieve, where AI is used in a broad and

70
00:04:40,492 --> 00:04:43,922
wide range of domains. Lastly, ASI,

71
00:04:43,986 --> 00:04:48,066
or artificial superintelligence. This means that AI has surpassed

72
00:04:48,098 --> 00:04:51,626
even human intelligence, to a point that technology can

73
00:04:51,648 --> 00:04:56,006
even solve all the world's problems. Again, we're still in AnI

74
00:04:56,118 --> 00:04:59,514
then, after knowing the different types of AI, we also need to know

75
00:04:59,552 --> 00:05:03,434
how to get there. Machine learning is a subset

76
00:05:03,482 --> 00:05:07,226
of AI, where the focus is on building systems

77
00:05:07,258 --> 00:05:10,522
that can learn from data. ML involves

78
00:05:10,586 --> 00:05:14,382
deciphering patterns and trends in order to make the predictions

79
00:05:14,446 --> 00:05:18,270
or decisions based on their learning. Under ML,

80
00:05:18,350 --> 00:05:22,370
there are three main types of ML supervised learning,

81
00:05:22,520 --> 00:05:25,720
unsupervised learning, and reinforcement learning.

82
00:05:26,250 --> 00:05:29,906
Supervised unleashing involves labeling data or providing

83
00:05:29,938 --> 00:05:33,494
the data the machine can learn from. One of the most

84
00:05:33,532 --> 00:05:37,490
common examples is identifying if an email is a spam mail.

85
00:05:37,650 --> 00:05:41,482
As for unsupervised learning, the machine has given the data,

86
00:05:41,616 --> 00:05:44,620
but we don't inform the machine what it is.

87
00:05:45,150 --> 00:05:48,762
The machine will have to figure out itself and make sense of the data

88
00:05:48,816 --> 00:05:53,102
that it was given. An example would be cohorting customers

89
00:05:53,236 --> 00:05:56,734
based on purchase behavior without being told how these

90
00:05:56,772 --> 00:06:01,114
groups should be categorized. Lastly, for reinforcement

91
00:06:01,162 --> 00:06:04,706
learning, just like Pavlov's theory, the machine is either

92
00:06:04,808 --> 00:06:08,114
given penalties or rewards in order to make the best

93
00:06:08,152 --> 00:06:11,634
decision based on this system. Then we have

94
00:06:11,672 --> 00:06:15,146
deep learning. Deep unleashing is a subset of machine

95
00:06:15,198 --> 00:06:18,610
learning. It involves neural networks with many layers,

96
00:06:18,690 --> 00:06:22,594
hence the term deep. These deep neural networks

97
00:06:22,642 --> 00:06:27,042
are designed to mimic the way human brains operate, to recognize

98
00:06:27,106 --> 00:06:29,900
patterns and make decisions based on data.

99
00:06:30,510 --> 00:06:34,202
Deep learning especially excels at processing large

100
00:06:34,256 --> 00:06:37,754
amounts of complex, high dimensional data such

101
00:06:37,792 --> 00:06:41,674
as images, sound, and text. From deep

102
00:06:41,722 --> 00:06:45,982
learning comes generative AI, where models can generate new

103
00:06:46,036 --> 00:06:49,914
text or data. This can include images,

104
00:06:50,042 --> 00:06:54,594
audio, videos, and other forms of media or content for

105
00:06:54,632 --> 00:06:58,398
generating text based on vast amounts of corpus.

106
00:06:58,494 --> 00:07:02,430
This is called large language model or LLM.

107
00:07:02,590 --> 00:07:06,406
It is a type of artificial system designed to understand,

108
00:07:06,588 --> 00:07:10,214
generate and interact with human language at

109
00:07:10,252 --> 00:07:14,066
a large scale. These models can grasp the nuances,

110
00:07:14,178 --> 00:07:18,330
context, and complexity of human knowledge or language.

111
00:07:18,910 --> 00:07:22,890
There are numerous limitations under

112
00:07:22,960 --> 00:07:26,522
llMs, but I'll share just a couple of them, so I have five here.

113
00:07:26,656 --> 00:07:29,398
The first one is fairness and bias.

114
00:07:29,574 --> 00:07:33,758
LLMs can amplify biases present in their training data.

115
00:07:33,924 --> 00:07:37,418
Since these models learn from vast amounts of corpus,

116
00:07:37,514 --> 00:07:41,546
which may contain bias or discriminatory viewpoints,

117
00:07:41,658 --> 00:07:45,410
the models can produce outputs that reflect these biases.

118
00:07:45,830 --> 00:07:49,422
This issue raises concerns about fairness and the potential

119
00:07:49,566 --> 00:07:54,110
perpetuation of stereotypes. Second is hallucination

120
00:07:54,190 --> 00:07:57,890
or the lack of true understanding. These models

121
00:07:57,970 --> 00:08:02,114
can provide outputs that are plausible sounding but factually incorrect

122
00:08:02,162 --> 00:08:06,118
or nonsensical. Third is training

123
00:08:06,204 --> 00:08:10,150
LLMS requires substantial computational resources

124
00:08:10,230 --> 00:08:13,146
which make them very, very expensive to run.

125
00:08:13,328 --> 00:08:16,742
Processing a single page of text requires computations

126
00:08:16,806 --> 00:08:19,942
across billions of parameters, which can result

127
00:08:20,016 --> 00:08:24,058
in high response times, especially for longer input documents.

128
00:08:24,234 --> 00:08:28,442
Fourth is security and misuse. The advanced capabilities

129
00:08:28,506 --> 00:08:32,090
of LLMs can be misused for malicious purposes,

130
00:08:32,170 --> 00:08:36,034
such as generating deceptive content such as

131
00:08:36,152 --> 00:08:39,390
deep fakes, fake news, automating spam

132
00:08:39,470 --> 00:08:43,374
or phishing attacks, and creating propaganda. The potential

133
00:08:43,422 --> 00:08:46,774
for misuse raises ethical and security concerns that

134
00:08:46,812 --> 00:08:50,274
need to be addressed to ensure the responsible development

135
00:08:50,322 --> 00:08:53,266
and deployment of these technologies. Lastly,

136
00:08:53,378 --> 00:08:57,222
interpretability and explainability. It is often difficult

137
00:08:57,356 --> 00:09:00,822
to understand or explain why an LLM

138
00:09:00,886 --> 00:09:04,266
produces a specific output. The complexity and

139
00:09:04,288 --> 00:09:07,606
opacity of these models make it challenging to trace

140
00:09:07,638 --> 00:09:11,374
the decision making process, which is a significant issue in

141
00:09:11,412 --> 00:09:15,198
applications where transparency and accountability are

142
00:09:15,364 --> 00:09:18,026
crucial, such as in healthcare,

143
00:09:18,138 --> 00:09:21,902
finance and legal applications. I'll now discuss

144
00:09:21,956 --> 00:09:25,746
what foundation models are and how integral this is in

145
00:09:25,768 --> 00:09:29,554
the realm of AI. Previously, AI was

146
00:09:29,592 --> 00:09:33,490
used and created to solve specific tasks. For example,

147
00:09:33,640 --> 00:09:37,206
an AI application before would be trained using a specific

148
00:09:37,308 --> 00:09:40,386
library CTO perform a specific action.

149
00:09:40,578 --> 00:09:44,418
But now we have foundation models that have a capability

150
00:09:44,594 --> 00:09:48,086
to generate output encompassing multitude

151
00:09:48,118 --> 00:09:51,786
of applications and cases. These are trained with

152
00:09:51,808 --> 00:09:55,466
a wider range of data, billions and trillions of

153
00:09:55,488 --> 00:09:58,730
data points in order to provide the best outcome,

154
00:09:59,150 --> 00:10:02,682
and with this we are able to use the model to any

155
00:10:02,736 --> 00:10:06,814
number and a variety of tasks. This isn't also

156
00:10:06,852 --> 00:10:10,142
limited to just text, but also encompasses other

157
00:10:10,196 --> 00:10:13,646
media like audio, video and images,

158
00:10:13,758 --> 00:10:17,490
unlike llms, where it's focused mainly on large

159
00:10:17,640 --> 00:10:20,930
or large language understanding and generation.

160
00:10:21,270 --> 00:10:24,658
An example of a foundation model is OpenAI style e,

161
00:10:24,744 --> 00:10:28,310
which generates images from textual descriptions.

162
00:10:28,650 --> 00:10:32,502
What makes foundation models incredibly powerful is these

163
00:10:32,556 --> 00:10:36,834
models are trained using unstructured data in an unsupervised

164
00:10:36,882 --> 00:10:40,166
manner. You could build on top of foundation models

165
00:10:40,198 --> 00:10:43,386
too. You could introduce new data to the model to

166
00:10:43,408 --> 00:10:46,774
tune them to do specific tasks, or nlps,

167
00:10:46,902 --> 00:10:50,498
or natural language processing like sentiment analysis

168
00:10:50,614 --> 00:10:54,142
and classification. This action is called fine

169
00:10:54,196 --> 00:10:58,602
tuning. We also have Rag, a retrieval augmented generation,

170
00:10:58,746 --> 00:11:02,122
where you can augment knowledge without changing pretrained

171
00:11:02,186 --> 00:11:05,566
model weights. Usually this external knowledge

172
00:11:05,598 --> 00:11:09,026
source pertains to data related to internal company

173
00:11:09,128 --> 00:11:12,866
knowledge bases. So again, we're not changing anything in

174
00:11:12,888 --> 00:11:15,986
the foundation model itself, but we're simply retrieving the

175
00:11:16,008 --> 00:11:20,242
data from a different source in order to obtain the necessary context

176
00:11:20,306 --> 00:11:23,554
and generate the proper response. You don't

177
00:11:23,602 --> 00:11:26,786
need to fine tune all the time to get the output you require.

178
00:11:26,898 --> 00:11:30,778
For certain scenarios, you could provide a sentence and ask a question

179
00:11:30,864 --> 00:11:34,534
to existing models. This is called prompting or prompt

180
00:11:34,582 --> 00:11:37,786
engineering. On the right side of the screen you

181
00:11:37,808 --> 00:11:41,194
can see I've also illustrated the different methods based on the

182
00:11:41,232 --> 00:11:44,766
difficulty level of the implementation. The easiest to do

183
00:11:44,788 --> 00:11:48,782
is prompt engineering, and the hardest would be, of course, if you built your own

184
00:11:48,836 --> 00:11:52,346
foundation model. But why even bother customizing

185
00:11:52,458 --> 00:11:55,954
your own foundation models? It's precisely the fact that you can

186
00:11:55,992 --> 00:12:00,094
adapt to domain specific language. So for example, in ecommerce,

187
00:12:00,142 --> 00:12:03,954
you would need the model to understand all of the products you want to

188
00:12:03,992 --> 00:12:07,574
sell on the site. You might also want these models to perform

189
00:12:07,772 --> 00:12:11,430
better at really unique tasks specific for your company.

190
00:12:11,580 --> 00:12:14,934
Another would be if you want to improve context and awareness of these

191
00:12:14,972 --> 00:12:18,410
models of your external company data. So, for example,

192
00:12:18,560 --> 00:12:22,774
you might want to train your customer service team based on the specific policies

193
00:12:22,822 --> 00:12:26,282
and rules that you have in the company. Let's now

194
00:12:26,336 --> 00:12:29,510
focus on retrieval augmented generation

195
00:12:29,590 --> 00:12:33,198
so what is rag? From the name itself,

196
00:12:33,284 --> 00:12:37,386
it's about retrieving relevant context from external knowledge

197
00:12:37,418 --> 00:12:41,162
bases and then augmenting it with your original

198
00:12:41,306 --> 00:12:44,990
query, passing that CTO the foundation model to generate

199
00:12:45,070 --> 00:12:48,754
an accurate response. There are a number of use

200
00:12:48,792 --> 00:12:52,690
cases for RAG, and one of which is being able to improve content

201
00:12:52,760 --> 00:12:56,466
quality to reduce hallucinations with internal sources that

202
00:12:56,488 --> 00:13:00,706
are up to date. Another would be to be able to create contextbased

203
00:13:00,738 --> 00:13:04,406
chat bot for enterprise related questions. So instead of

204
00:13:04,428 --> 00:13:08,258
sifting through hundreds of company documents or faqs, it will

205
00:13:08,284 --> 00:13:11,802
now be easier for employees to look up the relevant information based

206
00:13:11,856 --> 00:13:15,434
on their prompt. Lastly, you could integrate this with

207
00:13:15,472 --> 00:13:18,682
online retail by implementing personalized search.

208
00:13:18,816 --> 00:13:22,702
Since the system should know customer purchase behaviors, it could

209
00:13:22,756 --> 00:13:26,698
more accurately provide personalized recommendations to increase

210
00:13:26,874 --> 00:13:30,798
relevance and conversion. There are three different

211
00:13:30,884 --> 00:13:34,926
types of rag. The first one is naive rag is the easiest

212
00:13:34,958 --> 00:13:38,126
to implement and the most straightforward. There are three steps

213
00:13:38,158 --> 00:13:41,422
involved for this type indexing, retrieval,

214
00:13:41,486 --> 00:13:45,406
and generation. In indexing, this is where chunking happens,

215
00:13:45,528 --> 00:13:49,334
where data is transformed into vector representations through an

216
00:13:49,372 --> 00:13:53,250
embedding model. There are a couple of challenges with native

217
00:13:53,330 --> 00:13:57,026
rag. The first one is usually it has low precision,

218
00:13:57,138 --> 00:14:00,614
which leads to misaligned retrieved chunks, or hallucination

219
00:14:00,742 --> 00:14:04,278
usually happens. Secondly, it has low recall,

220
00:14:04,374 --> 00:14:07,910
which means that it's unable to retrieve all the relevant chunks.

221
00:14:08,070 --> 00:14:11,886
Thirdly, it could have an outdated information, which means that

222
00:14:11,908 --> 00:14:14,990
there might be inaccurate retrieval results. And lastly,

223
00:14:15,970 --> 00:14:19,070
the generated response risk might be repetitive.

224
00:14:19,490 --> 00:14:23,074
As for advanced rag, this was created to solve some

225
00:14:23,112 --> 00:14:27,006
of the shortcomings of naive rag. In terms of retrieval

226
00:14:27,038 --> 00:14:30,910
quality, there are pre and postretrieval strategies

227
00:14:30,990 --> 00:14:34,754
in order to improve quality. Some of these strategies are

228
00:14:34,792 --> 00:14:38,706
sliding window, fine grain, segmentation and metadata.

229
00:14:38,898 --> 00:14:42,438
Lastly, for moderal rag, it's an offshoot of

230
00:14:42,444 --> 00:14:45,858
the previous types, but this time it provides greater versatility

231
00:14:45,954 --> 00:14:49,798
and flexibility. The great thing about modular rag

232
00:14:49,894 --> 00:14:54,246
is its organization. Structure allows substitution and rearrangement

233
00:14:54,278 --> 00:14:57,610
of modules within the model to fit your requirements.

234
00:14:57,950 --> 00:15:01,390
I'm now handing you over to Josh for the next steps.

235
00:15:02,050 --> 00:15:05,978
So now that we have a better understanding of the concepts involved

236
00:15:06,154 --> 00:15:09,434
about generative AI, large language models,

237
00:15:09,482 --> 00:15:11,790
and even retrieval augmented generation,

238
00:15:12,290 --> 00:15:16,402
let's now talk about a quick example on how to implement this in

239
00:15:16,456 --> 00:15:20,146
production. So there are various services and

240
00:15:20,168 --> 00:15:23,570
solutions available, and here we can see how we're able to use

241
00:15:23,720 --> 00:15:27,778
a managed machine unleashing service called Amazon Sagemaker,

242
00:15:27,874 --> 00:15:31,314
and how we're able to use it to deploy a large language

243
00:15:31,362 --> 00:15:34,854
model in our own cloud environment. Here we

244
00:15:34,892 --> 00:15:38,646
are able to use an SDK called the Sagemaker

245
00:15:38,678 --> 00:15:42,214
Python SDK. And inside a notebook

246
00:15:42,262 --> 00:15:45,434
instance environment, or maybe in a studio, we're able

247
00:15:45,472 --> 00:15:49,254
to use this to deploy our own self hosted

248
00:15:49,382 --> 00:15:52,810
large language model in its own inference endpoint.

249
00:15:52,970 --> 00:15:56,894
When we say inference endpoint, we basically have some sort of

250
00:15:56,932 --> 00:16:00,510
web server where the model lives

251
00:16:00,580 --> 00:16:04,430
there, and we're able to use that server to perform inference.

252
00:16:04,590 --> 00:16:08,050
That means that our questions and answers are

253
00:16:08,120 --> 00:16:12,082
passing through that web server in that server is

254
00:16:12,136 --> 00:16:15,818
used for its generative AI applications.

255
00:16:16,014 --> 00:16:19,826
In order for us to deploy a model using the sagemaker

256
00:16:19,938 --> 00:16:23,574
Python SDK, we simply use a few

257
00:16:23,612 --> 00:16:27,294
lines of code, and these lines of code include the following.

258
00:16:27,442 --> 00:16:30,394
So here we have our model, and we just use,

259
00:16:30,512 --> 00:16:34,102
deploy and specify the initial instance

260
00:16:34,166 --> 00:16:37,274
count as well as the instance type along

261
00:16:37,312 --> 00:16:41,114
with the other parameters. Here we can definitely choose

262
00:16:41,232 --> 00:16:44,750
a large instance type depending on the type

263
00:16:44,900 --> 00:16:48,414
of model that we're trying to deploy and of course if you use something

264
00:16:48,452 --> 00:16:52,554
like lanching, we're able to use it and

265
00:16:52,612 --> 00:16:56,530
we're able to utilize the large language model deployed inside

266
00:16:56,600 --> 00:16:59,666
that inference endpoint. So if we are to

267
00:16:59,688 --> 00:17:03,298
complete this large language model

268
00:17:03,384 --> 00:17:06,742
setup, of course we need to have some sort of front

269
00:17:06,796 --> 00:17:10,360
end application. And then this front end application

270
00:17:10,970 --> 00:17:14,102
points to a backend API and

271
00:17:14,156 --> 00:17:18,190
this backend API server or serverless

272
00:17:18,370 --> 00:17:21,818
system the serverless system makes use of

273
00:17:21,824 --> 00:17:25,894
the large language model and it basically processes

274
00:17:25,942 --> 00:17:29,222
the question and then it returns a response

275
00:17:29,286 --> 00:17:32,622
back to the front end application. In some cases you would need

276
00:17:32,676 --> 00:17:36,014
a database, but of course that depends on

277
00:17:36,052 --> 00:17:39,742
your type of application as well as the users using

278
00:17:39,796 --> 00:17:43,140
it. What if we have different

279
00:17:43,510 --> 00:17:47,282
files, let's say PDF files, and we store them inside

280
00:17:47,416 --> 00:17:51,310
a folder or directory in our machine called sources,

281
00:17:51,470 --> 00:17:54,706
and we decide to upload it inside a

282
00:17:54,728 --> 00:17:59,330
storage bucket like s three? Here we use the following command

283
00:17:59,910 --> 00:18:03,350
dispatch command to upload different files

284
00:18:03,850 --> 00:18:07,206
from our local directory up to an

285
00:18:07,228 --> 00:18:10,554
s three bucket. And now once this s three

286
00:18:10,592 --> 00:18:14,810
bucket has these PDf files, we're now able

287
00:18:14,960 --> 00:18:18,202
to use different solutions and services, for example

288
00:18:18,256 --> 00:18:22,222
Textrac, as well as Langchain, sagemaker and

289
00:18:22,276 --> 00:18:25,594
FIS, where we're able to extract

290
00:18:25,642 --> 00:18:29,070
the needed info from these Pdf files and

291
00:18:29,140 --> 00:18:33,410
convert them to a format which is easily processed

292
00:18:33,990 --> 00:18:37,426
with what we have in llms. So of course

293
00:18:37,528 --> 00:18:41,646
now this time we're now no longer limited

294
00:18:41,838 --> 00:18:44,990
to what the large language model has to offer.

295
00:18:45,160 --> 00:18:49,202
We're now able to utilize what's also stored

296
00:18:49,346 --> 00:18:53,670
inside the documents, let's say using Langchain,

297
00:18:54,250 --> 00:18:57,394
we now have a new chain which makes

298
00:18:57,452 --> 00:19:02,042
use document information and

299
00:19:02,096 --> 00:19:05,690
extracted and processed from the different files.

300
00:19:06,030 --> 00:19:09,260
If we were to ask it some questions,

301
00:19:10,290 --> 00:19:14,494
it will now utilize the content of

302
00:19:14,532 --> 00:19:18,410
the PdF files. And now we will now have a set of answers

303
00:19:18,570 --> 00:19:22,334
which is now definitely more relevant compared to the

304
00:19:22,372 --> 00:19:26,126
previous setup where we didn't use the PdF files

305
00:19:26,158 --> 00:19:28,980
at all. Going back to the question,

306
00:19:29,590 --> 00:19:32,946
can we build a generative aipowered application in

307
00:19:32,968 --> 00:19:35,538
24 hours? Definitely yes.

308
00:19:35,704 --> 00:19:39,394
But once we have to implement a rag powered

309
00:19:39,442 --> 00:19:42,566
generative aipowered application, of course it may

310
00:19:42,588 --> 00:19:46,102
take a bit more time because you would need to of course set

311
00:19:46,156 --> 00:19:49,720
up the necessary resources and services,

312
00:19:50,410 --> 00:19:53,542
as well as making sure that the

313
00:19:53,596 --> 00:19:57,154
data and the files needed for this rag

314
00:19:57,202 --> 00:20:01,166
setup. And hope you learned. So thank you

315
00:20:01,188 --> 00:20:03,260
again and have a great day ahead.

