1
00:00:24,730 --> 00:00:28,594
Thank you so much for coming to my talk today. I am super excited

2
00:00:28,642 --> 00:00:31,718
to be part of comfort two cloud native 2024.

3
00:00:31,724 --> 00:00:34,838
And today I'm going to be talking

4
00:00:34,924 --> 00:00:38,502
about synthesizing threat informed defense when

5
00:00:38,556 --> 00:00:42,258
cloud attack emulation meets detection engineering.

6
00:00:42,434 --> 00:00:46,546
All right, a few words about me. I'm the CTO

7
00:00:46,578 --> 00:00:50,078
and one of the founders at Mitigant. Mitigant is

8
00:00:50,124 --> 00:00:52,922
a cloud security company. These I breathe in Berlin.

9
00:00:53,066 --> 00:00:56,190
I have spent about twelve years in cybersecurity.

10
00:00:57,090 --> 00:01:00,634
Within these years I've held different positions.

11
00:01:00,682 --> 00:01:04,260
I've worked in academia doing academic research.

12
00:01:04,870 --> 00:01:08,514
During my research, I was one of the

13
00:01:08,552 --> 00:01:12,718
pioneers of the concept of security chaos engineering.

14
00:01:12,894 --> 00:01:16,798
But I also worked in the industry, in different startups and

15
00:01:16,984 --> 00:01:20,406
held different technical positions. And I am a

16
00:01:20,428 --> 00:01:24,502
member of the AWS community builder program. All right,

17
00:01:24,556 --> 00:01:27,846
so what are we going to be talking about today? We are going to be

18
00:01:27,868 --> 00:01:30,150
looking at a few topics.

19
00:01:30,970 --> 00:01:34,266
First we will look at trade informed defense and then

20
00:01:34,288 --> 00:01:37,210
the three pillars that constitute this concept.

21
00:01:37,550 --> 00:01:41,166
Then we will look at adversary emulation, and then we will

22
00:01:41,188 --> 00:01:44,640
go and look at cloud attack emulation, which is actually

23
00:01:45,250 --> 00:01:49,150
a subdomain under adversary emulation.

24
00:01:49,810 --> 00:01:54,690
Then after that we're going to be looking at a use case where

25
00:01:54,760 --> 00:01:58,718
we see how we can use cloud attack emulation to validate

26
00:01:58,814 --> 00:02:02,946
cloud trade detection. And I will give you a very brief demo of the

27
00:02:02,968 --> 00:02:06,200
mitigan cloud attack emulation platform.

28
00:02:07,770 --> 00:02:11,458
So let's get started. So, cybersecurity,

29
00:02:11,554 --> 00:02:13,880
the domain most of ours are,

30
00:02:15,290 --> 00:02:18,694
it's a very noisy domain. It's noisy in

31
00:02:18,732 --> 00:02:21,558
this sense because there are a lot of attacks,

32
00:02:21,654 --> 00:02:26,026
and we hear of attacks virtually every day on

33
00:02:26,048 --> 00:02:30,330
the news. We hear of different companies, we hear of different threat vectors,

34
00:02:30,850 --> 00:02:34,800
and it sometimes gets a little bit challenges to be able to

35
00:02:35,410 --> 00:02:38,686
sift these noise. To sift the signal from the

36
00:02:38,708 --> 00:02:42,446
noise. And what I mean here by signals is kind

37
00:02:42,468 --> 00:02:46,802
of how to know what part of this news

38
00:02:46,856 --> 00:02:50,658
that is more important to you, what part of it is relevant for you,

39
00:02:50,744 --> 00:02:54,418
relevant for your organization. And I

40
00:02:54,504 --> 00:02:58,026
compare it in a way to the needle in the haystack

41
00:02:58,078 --> 00:03:01,286
problem. So as you see in this picture here, you got a

42
00:03:01,308 --> 00:03:05,266
needle and the needle is very little. And if you drop

43
00:03:05,298 --> 00:03:09,098
a needle in these haystack, it's kind of challenging for you to kind of

44
00:03:09,184 --> 00:03:13,034
identify the needle. So it's kind of the

45
00:03:13,072 --> 00:03:16,822
problem we have in cybersecurity. Probably not as complex

46
00:03:16,886 --> 00:03:20,618
as defending needle, but you get what I'm saying. And the ability

47
00:03:20,714 --> 00:03:24,394
to be able to sift the signal from the noise

48
00:03:24,442 --> 00:03:28,186
is very important because the signals

49
00:03:28,378 --> 00:03:32,222
is what you want to be focused on the noise will

50
00:03:32,276 --> 00:03:35,182
eventually distract you and reduce your proactively,

51
00:03:35,326 --> 00:03:38,958
and if you're not careful, will be the very problem, or let's

52
00:03:38,974 --> 00:03:42,850
say, will be the very reason for which you might be attacked.

53
00:03:45,210 --> 00:03:48,630
So that leads straight to trade informed defense,

54
00:03:49,050 --> 00:03:52,802
which is by definition, these systematic

55
00:03:52,866 --> 00:03:57,262
application of a deep understanding of adversary

56
00:03:57,426 --> 00:04:00,566
tradecraft and technology to improve defenses.

57
00:04:00,678 --> 00:04:03,926
And this is the definition that has been provided

58
00:04:03,958 --> 00:04:07,914
by the mitre ingenuity, which is basically the

59
00:04:07,952 --> 00:04:12,058
center for trade informed Defense. It is a non for profit organization

60
00:04:12,154 --> 00:04:16,990
in the United States. And they came up with this

61
00:04:17,060 --> 00:04:22,506
idea which you can use as a strategy for

62
00:04:22,548 --> 00:04:26,850
your company to ensure that your security architecture

63
00:04:27,990 --> 00:04:31,874
is effective, it actually works and

64
00:04:31,912 --> 00:04:34,530
is able to toward attacks.

65
00:04:35,450 --> 00:04:39,094
So we're going to be looking deeper into what this means. We hear

66
00:04:39,132 --> 00:04:43,526
about it every now and then, and I

67
00:04:43,548 --> 00:04:47,826
took a look at what this informed

68
00:04:47,858 --> 00:04:51,174
defense means, and that's what we're going to be exploring.

69
00:04:51,222 --> 00:04:54,918
So there are these pillars of trade informed

70
00:04:54,934 --> 00:04:58,380
defense, as we see in the symbol in the last page.

71
00:04:59,550 --> 00:05:03,242
And the first one is defensive measures. So what is defensive

72
00:05:03,306 --> 00:05:06,638
measures? So basically, the moment you begin to talk

73
00:05:06,804 --> 00:05:10,800
about the defensive measures, you are basically looking at

74
00:05:12,470 --> 00:05:15,406
the security controls, the security tools,

75
00:05:15,518 --> 00:05:19,234
the security strategies that you're actually going to be implementing to help

76
00:05:19,272 --> 00:05:22,078
you to stay ahead of attacks.

77
00:05:22,254 --> 00:05:25,638
And one of the major reference points when it

78
00:05:25,644 --> 00:05:28,902
comes to defenses is the Mitre attack

79
00:05:29,036 --> 00:05:32,200
framework. And the Mitre attack framework itself,

80
00:05:32,570 --> 00:05:36,934
which is also another program by

81
00:05:36,972 --> 00:05:40,778
Mitre, which is also a US government

82
00:05:40,864 --> 00:05:43,530
agency or non for profit agency.

83
00:05:44,270 --> 00:05:47,734
It is basically a globally accessible

84
00:05:47,782 --> 00:05:51,626
knowledge base of adversary tactics and techniques that

85
00:05:51,648 --> 00:05:55,454
is based on real world observations. And here it's very

86
00:05:55,492 --> 00:05:59,338
important for you to take note of adversary

87
00:05:59,514 --> 00:06:02,666
tactics, which is basically the way attackers

88
00:06:02,858 --> 00:06:06,834
compromise systems. And also, it's important for you to take

89
00:06:06,872 --> 00:06:10,770
note of real world observations. So these are based

90
00:06:10,840 --> 00:06:14,622
on real attacks that are happening and not theory.

91
00:06:14,766 --> 00:06:17,958
So they try to kind of focus

92
00:06:18,044 --> 00:06:21,474
on real attacks rather than theoretical attacks,

93
00:06:21,522 --> 00:06:25,334
rather than attacks that people are thinking that will occur. These are

94
00:06:25,372 --> 00:06:29,322
actually based on different companies that are part of this program.

95
00:06:29,456 --> 00:06:33,114
They monitor devices, these monitor, they're being used by

96
00:06:33,152 --> 00:06:37,194
different companies and they're gathering this information. And they are basically

97
00:06:37,312 --> 00:06:41,946
kind of using this to understand how attackers compromise

98
00:06:42,058 --> 00:06:46,010
systems, how these compromise organizations, and they classify

99
00:06:46,090 --> 00:06:48,990
these under different tactics,

100
00:06:49,650 --> 00:06:52,898
and also under these tactics also have

101
00:06:52,984 --> 00:06:56,754
techniques. And we're going to be looking deeper into these in the next

102
00:06:56,792 --> 00:07:00,018
slides. So the Mitra attack

103
00:07:00,104 --> 00:07:03,460
framework itself is divided into,

104
00:07:04,390 --> 00:07:08,246
let's say, technological categories in

105
00:07:08,268 --> 00:07:12,360
the form of the enterprise matrix, which basically

106
00:07:12,730 --> 00:07:16,754
looks at most systems, whether web applications,

107
00:07:16,882 --> 00:07:20,300
cloud systems, software as a service

108
00:07:21,230 --> 00:07:24,998
systems and so forth. We also have the mobile matrix,

109
00:07:25,094 --> 00:07:28,374
rooks and mobile applications, mobile technologies,

110
00:07:28,422 --> 00:07:31,814
and we have the ICs, which is the industrial control systems.

111
00:07:31,942 --> 00:07:35,462
But today we are going to be focusing more on the enterprise matrix,

112
00:07:35,526 --> 00:07:38,926
which has us at version 14, which is the

113
00:07:38,948 --> 00:07:43,618
most recent version. It has 14 tactics and 234

114
00:07:43,704 --> 00:07:47,106
techniques. That's a whole

115
00:07:47,128 --> 00:07:50,722
lot of, let's say it's a lot.

116
00:07:50,776 --> 00:07:54,578
And most companies cannot. Even if you use a tool that

117
00:07:54,744 --> 00:07:58,150
implements all of these techniques,

118
00:07:58,570 --> 00:08:02,342
it is very difficult for you as a company to

119
00:08:02,396 --> 00:08:07,286
focus on all of that. Right. It's going to be overcoming the

120
00:08:07,308 --> 00:08:11,610
idea. These, which I want to really state

121
00:08:11,680 --> 00:08:16,586
is the idea is not to cover the

122
00:08:16,608 --> 00:08:20,506
entire tactics and techniques, but to kind of select which of

123
00:08:20,528 --> 00:08:24,480
these that is more relevant to you.

124
00:08:25,250 --> 00:08:28,558
All right. And this is kind of a larger view for you to see.

125
00:08:28,644 --> 00:08:32,480
But ideally, you're not going to be covering every

126
00:08:33,430 --> 00:08:37,154
of these techniques. What you will do eventually is

127
00:08:37,192 --> 00:08:41,406
something like this. And this visualization is created

128
00:08:41,518 --> 00:08:45,074
by van Vlad. He wrote a very nice

129
00:08:45,112 --> 00:08:49,078
blog, which I will leave the link in the slides. And basically

130
00:08:49,164 --> 00:08:53,122
here you see out of 14 tactics,

131
00:08:53,186 --> 00:08:56,934
you have something around seven. And from there you see these

132
00:08:56,972 --> 00:09:02,154
clusters represent techniques which

133
00:09:02,192 --> 00:09:06,394
might be clustered. So under each tactic there are techniques and

134
00:09:06,512 --> 00:09:09,786
there could also be subtechs. And you also see

135
00:09:09,808 --> 00:09:13,674
this red line, which kind of shows how an attacker

136
00:09:13,722 --> 00:09:18,206
will navigate through

137
00:09:18,308 --> 00:09:21,658
an infrastructure. And this line most likely

138
00:09:21,754 --> 00:09:25,806
kind of determines for you what is relevant

139
00:09:25,838 --> 00:09:29,298
to you, what you have to really take care of what is important

140
00:09:29,384 --> 00:09:32,260
for you. And you can see that in the end,

141
00:09:32,630 --> 00:09:37,106
it really slings down the areas

142
00:09:37,218 --> 00:09:40,920
that a company should actually be really concerned about.

143
00:09:41,530 --> 00:09:45,350
All right. We just looked at the first pillar, which is kind of

144
00:09:45,420 --> 00:09:49,174
looking at what you do, but that's not. All right. The second pillar

145
00:09:49,222 --> 00:09:52,394
brings in more context. And the second pillar is

146
00:09:52,432 --> 00:09:56,518
basically cyber threat intelligence. And what is cyber

147
00:09:56,614 --> 00:10:00,022
threat intelligence is basically information that has been

148
00:10:00,096 --> 00:10:04,014
aggregated, transformed, analyzed, interpreted or enriched to

149
00:10:04,052 --> 00:10:07,486
provide the necessary context for decision making.

150
00:10:07,588 --> 00:10:11,338
And you have to understand here, we always say in cybersecurity,

151
00:10:11,434 --> 00:10:14,722
that context is king. Context is

152
00:10:14,776 --> 00:10:18,450
what differentiates you from other organizations.

153
00:10:18,870 --> 00:10:22,894
You got to know your context. And cyber threat

154
00:10:22,942 --> 00:10:26,374
intelligence helps you to kind of fine

155
00:10:26,412 --> 00:10:29,830
tune your context more. It helps you to further

156
00:10:31,210 --> 00:10:34,322
sift the signal from the noise.

157
00:10:34,466 --> 00:10:38,362
And again, the mitre actually

158
00:10:38,416 --> 00:10:41,690
also has a section here, as you see here,

159
00:10:41,760 --> 00:10:45,290
where they provide cyber trade intelligence,

160
00:10:45,630 --> 00:10:49,450
which is here they actually talk about different trade actors, and they

161
00:10:49,520 --> 00:10:53,306
describe who they are. They describe the campaigns that

162
00:10:53,328 --> 00:10:56,942
they've noticed these trade actors to be involved in, in real life and

163
00:10:56,996 --> 00:11:00,906
also talk about the map. They provide a mapping of these threat

164
00:11:00,938 --> 00:11:04,114
actors to the tactics and techniques that they have

165
00:11:04,152 --> 00:11:08,046
observed them using, and that narrows

166
00:11:08,078 --> 00:11:11,826
down your focus as a company. So, for example, scattered spider has

167
00:11:11,848 --> 00:11:15,060
been notorious in the last two years.

168
00:11:15,370 --> 00:11:19,474
They were behind the ransomware attack against the MGM resorts

169
00:11:19,522 --> 00:11:23,800
in the United States. And they're actually

170
00:11:25,130 --> 00:11:28,314
interested in a specific sector in not all

171
00:11:28,352 --> 00:11:32,010
verticals. I think they're interested in entertainment. They're interested in

172
00:11:32,080 --> 00:11:35,866
telecommunications. They're interested in technology companies.

173
00:11:36,048 --> 00:11:39,542
And this already gives a kind of definition

174
00:11:39,606 --> 00:11:44,554
of these sectors that should be interested in implementing

175
00:11:44,682 --> 00:11:48,350
defenses against scattered spider.

176
00:11:49,410 --> 00:11:53,226
Right. And this is actually the mitre

177
00:11:53,258 --> 00:11:57,006
attack navigator, and it's also free, and it

178
00:11:57,028 --> 00:12:01,022
helps you, as I said before, it creates a mapping of

179
00:12:01,156 --> 00:12:04,918
threat actors to tactics and techniques here.

180
00:12:05,044 --> 00:12:08,774
These orange colored techniques are actually the

181
00:12:08,812 --> 00:12:12,162
ones that scattered spider implements.

182
00:12:12,306 --> 00:12:15,990
And you must understand that I already

183
00:12:16,060 --> 00:12:19,130
kind of slimmed down this mitre

184
00:12:19,870 --> 00:12:24,262
attack. The techniques slimmed it down to the ones that are related

185
00:12:24,326 --> 00:12:27,914
to infrastructure as a service. And this is all

186
00:12:27,952 --> 00:12:31,726
possible. You can actually sift and

187
00:12:31,748 --> 00:12:36,154
just narrow down to the areas that are more relevant

188
00:12:36,202 --> 00:12:40,190
for you. And in the end, you have a very minimal

189
00:12:40,930 --> 00:12:44,100
techniques to be concerned about.

190
00:12:45,030 --> 00:12:48,094
Okay, so let's go to the third pillar,

191
00:12:48,142 --> 00:12:52,126
which is testing and evaluation. And this is a pillar

192
00:12:52,238 --> 00:12:55,026
that is mostly not talked about,

193
00:12:55,128 --> 00:12:58,614
right? Most of the time when people talk about the

194
00:12:58,652 --> 00:13:02,226
miter, when people talk about a threatinformed

195
00:13:02,258 --> 00:13:05,858
defense, they kind of talk about the defensive measures.

196
00:13:05,954 --> 00:13:08,490
These talk about cyber threat intelligence.

197
00:13:08,910 --> 00:13:13,494
Testing and evaluation is most of the time not discussed.

198
00:13:13,542 --> 00:13:17,590
And I'm going to be talking more about this aspect

199
00:13:17,670 --> 00:13:21,214
because you have to understand that these three pillars are

200
00:13:21,252 --> 00:13:25,054
complementary of themselves, and they work together as a

201
00:13:25,092 --> 00:13:28,686
feedback loop. So none of them is more important

202
00:13:28,788 --> 00:13:32,094
than the other. And if actually want to have a very

203
00:13:32,212 --> 00:13:36,606
robust and a very efficient security strategy,

204
00:13:36,798 --> 00:13:40,178
you have to implement the three pillars and you

205
00:13:40,184 --> 00:13:44,114
have to make sure that they work together in

206
00:13:44,152 --> 00:13:47,810
synchrony. So testing and evaluation, Basically,

207
00:13:47,960 --> 00:13:51,494
Mitre engineer recommends these use

208
00:13:51,532 --> 00:13:55,362
of adversary emulation for testing and evaluating

209
00:13:55,426 --> 00:13:58,680
your defenses. And why is that?

210
00:13:58,990 --> 00:14:03,126
We will see a bunch of questions in the next slide. But adversary emulation,

211
00:14:03,238 --> 00:14:06,790
simply put, allows you to mimic the behavior

212
00:14:06,870 --> 00:14:10,954
of real world threat actors in a safe and in a repeatable

213
00:14:11,002 --> 00:14:14,730
manner. This is very important because in cybersecurity,

214
00:14:14,810 --> 00:14:18,414
we have different kinds of security testing. We got

215
00:14:18,452 --> 00:14:21,290
penetration testing, we got vulnerability assessment.

216
00:14:21,450 --> 00:14:25,938
There's a lot of security

217
00:14:26,024 --> 00:14:29,822
testing methodologies. But when it comes to trade detection,

218
00:14:29,886 --> 00:14:34,290
trade incident response, you want a testing methodology

219
00:14:34,970 --> 00:14:38,466
that mimics the exact behavior

220
00:14:38,578 --> 00:14:42,646
of how attackers behave in the real world. You want something that

221
00:14:42,668 --> 00:14:44,120
is really close.

222
00:14:46,730 --> 00:14:50,162
It's a very close semblance of attackers behavior,

223
00:14:50,306 --> 00:14:54,086
and you want to do that in a safe way. And most importantly,

224
00:14:54,198 --> 00:14:57,306
you want to do that in a way that's repeatable, meaning that you can do

225
00:14:57,328 --> 00:15:01,210
it multiple times. And the reason for this repeatability

226
00:15:01,370 --> 00:15:05,374
is because when you go through this process, you want

227
00:15:05,412 --> 00:15:09,262
to test again your defenses and to be sure that

228
00:15:09,316 --> 00:15:11,470
after hardening, after improving,

229
00:15:13,510 --> 00:15:18,018
you see some progress. So that's the reason why it's important

230
00:15:18,184 --> 00:15:21,410
that these testing methodologies are repeatable.

231
00:15:22,310 --> 00:15:26,520
All right, now these five questions are actually questions

232
00:15:27,050 --> 00:15:30,278
from the Mitre ingenuity website.

233
00:15:30,364 --> 00:15:33,302
And I also left a link below here.

234
00:15:33,436 --> 00:15:38,086
And these questions are very important because they

235
00:15:38,108 --> 00:15:41,622
help you to kind of determine whether you need

236
00:15:41,676 --> 00:15:45,362
adversary emulation. It kind of also provides

237
00:15:45,426 --> 00:15:49,202
more context to the reason why adversary emulation

238
00:15:49,266 --> 00:15:55,514
is, is kind of recommended

239
00:15:55,562 --> 00:15:59,146
for testing trait detection and incident response.

240
00:15:59,178 --> 00:16:02,686
So the first question is, how do we build a resilient defense that

241
00:16:02,708 --> 00:16:06,590
is not static and is easily and easily evaded

242
00:16:08,370 --> 00:16:11,906
and indicators of compromise. So how do

243
00:16:11,928 --> 00:16:14,690
you have a defense that it's not static,

244
00:16:16,170 --> 00:16:19,506
it's dynamic in nature, and it cannot

245
00:16:19,538 --> 00:16:22,966
be easily evaded, and it gives you

246
00:16:22,988 --> 00:16:26,166
a very clear indicator of compromise. So indicators of

247
00:16:26,188 --> 00:16:29,850
compromise are events that are indicative of an actual

248
00:16:29,920 --> 00:16:33,546
attack. Adversary emulation helps you to kind

249
00:16:33,568 --> 00:16:36,934
of satisfy this requirement. These next one is how do we detect,

250
00:16:36,982 --> 00:16:40,426
mitigate, respond to, or prevent against

251
00:16:40,528 --> 00:16:44,606
threat actor X. Here you are talking, as we saw

252
00:16:44,628 --> 00:16:48,538
in the last slide, we were looking at a specific threat actor,

253
00:16:48,714 --> 00:16:52,714
scattered spider. And this is kind of the questions you ask yourself

254
00:16:52,852 --> 00:16:56,690
if you are trying to defend your company against

255
00:16:56,760 --> 00:17:00,414
specific threat actors, and there's a narrow

256
00:17:00,462 --> 00:17:04,882
focus here, and you want to prepare that either

257
00:17:04,936 --> 00:17:08,626
you can detect activities that indicate

258
00:17:08,658 --> 00:17:12,034
these threat actors, or you can mitigate, or you can respond

259
00:17:12,082 --> 00:17:15,254
to these activities, or you can actually prevent them from

260
00:17:15,292 --> 00:17:18,826
occurring in the first place. Right. So let's move

261
00:17:18,848 --> 00:17:22,346
forward to the next question. It says, are we collecting the

262
00:17:22,368 --> 00:17:25,994
right data and run the right queries to

263
00:17:26,032 --> 00:17:29,434
detect technique y. So we talked about

264
00:17:29,472 --> 00:17:33,354
techniques. Techniques are basically how threat actors

265
00:17:33,482 --> 00:17:37,006
behave, how they attack, the kind of tools they use,

266
00:17:37,188 --> 00:17:41,754
and the way most threat detection systems

267
00:17:41,802 --> 00:17:44,946
work is they collect data. These data are in the

268
00:17:44,968 --> 00:17:48,114
form of log events, and then they perform some

269
00:17:48,152 --> 00:17:54,446
kind of queries over this data. And from that they're

270
00:17:54,478 --> 00:17:58,258
able to conclude that these are kind of indicators

271
00:17:58,274 --> 00:18:02,006
of compromise. And oftentimes you might not have

272
00:18:02,028 --> 00:18:05,254
the right data, oftentimes your queries might actually not be

273
00:18:05,292 --> 00:18:09,782
correct. And for you to reduce problems like

274
00:18:09,916 --> 00:18:12,986
false positives or alert fatigue, you have to

275
00:18:13,008 --> 00:18:16,730
use the right data sets. You have to perform the right queries.

276
00:18:17,070 --> 00:18:20,450
Otherwise, so it's kind of, in the beginning, it's like try and error,

277
00:18:20,550 --> 00:18:23,870
and adversary emulation allows you to kind of

278
00:18:23,940 --> 00:18:27,658
get this right. And we will see later in the next slides,

279
00:18:27,834 --> 00:18:30,960
we're going to see much more, let's say

280
00:18:32,630 --> 00:18:36,322
much more good examples. So next question

281
00:18:36,376 --> 00:18:40,034
says, how do we build experience and skills on our team

282
00:18:40,072 --> 00:18:43,634
to defend against real world trades? So I like this

283
00:18:43,672 --> 00:18:47,094
part because you see these, that it's kind of

284
00:18:47,132 --> 00:18:50,882
moving from actual technology, the technological

285
00:18:50,946 --> 00:18:54,406
aspect of cybersecurity. It's moving to

286
00:18:54,428 --> 00:18:57,254
the people aspect. So the people, when you talk about people,

287
00:18:57,372 --> 00:19:01,034
you begin to talk about experience and skills. And this is

288
00:19:01,072 --> 00:19:04,634
really important because oftentimes it's not just about technology,

289
00:19:04,752 --> 00:19:08,540
right? We have this concept of people, processes and technology.

290
00:19:09,230 --> 00:19:12,960
And you always have to think not just about these technology,

291
00:19:13,330 --> 00:19:17,102
but the people, because the people are very important. Even if the

292
00:19:17,236 --> 00:19:21,520
technology, if you have the best kind of the best products,

293
00:19:22,130 --> 00:19:26,194
if the people are not able to know how to use them properly, it's still

294
00:19:26,232 --> 00:19:28,770
going to be challenging, it's still going to be attacked.

295
00:19:30,630 --> 00:19:34,334
And the last question says, how do we tune our tools and processes

296
00:19:34,462 --> 00:19:38,354
to maximize efficacy against real

297
00:19:38,392 --> 00:19:42,406
world threats? All right, so here we're talking again about tools and

298
00:19:42,428 --> 00:19:44,950
processes. Remember, I talked about processes.

299
00:19:46,330 --> 00:19:49,370
Processes are very important. Tools are also important,

300
00:19:49,440 --> 00:19:52,874
but they have to be tuned. Right in the beginning, we started talking about

301
00:19:52,912 --> 00:19:57,878
noise. And remember that one of the major reasons

302
00:19:58,054 --> 00:20:01,358
behind trading from defense is to allow us to

303
00:20:01,364 --> 00:20:04,794
be able to sift signals from noise.

304
00:20:04,922 --> 00:20:08,458
And even the tools and processes, they might become noisy,

305
00:20:08,554 --> 00:20:11,326
and you have to tune them, you have to customize them.

306
00:20:11,428 --> 00:20:15,026
And adversary emulation actually helps to go

307
00:20:15,048 --> 00:20:17,970
through this customization in a very efficient manner.

308
00:20:19,430 --> 00:20:22,580
Okay, let's look at an example. Now,

309
00:20:22,950 --> 00:20:26,440
this is a very interesting example of

310
00:20:27,130 --> 00:20:29,910
a company that uses adversary emulation.

311
00:20:30,330 --> 00:20:33,990
This is GitLab. And actually, this is all open.

312
00:20:34,060 --> 00:20:37,754
So in the link here, if you go to this link, you will

313
00:20:37,792 --> 00:20:41,322
see GitLab talking about their

314
00:20:41,376 --> 00:20:44,842
purple team and red team operations. And they

315
00:20:44,896 --> 00:20:48,554
actually call it stealth operations. So basically, they do this

316
00:20:48,592 --> 00:20:52,266
attack emulation without telling the company. So they do it in

317
00:20:52,288 --> 00:20:55,914
a clandestine manner. And just very few managers

318
00:20:55,962 --> 00:20:59,806
and very few people are aware. And what

319
00:20:59,828 --> 00:21:03,294
I wanted to point out here is just the process here. So you

320
00:21:03,332 --> 00:21:06,530
see, there are three main phases of this attack emulation,

321
00:21:08,230 --> 00:21:12,386
adversary emulation, attack emulation, actually the same thing. You got the

322
00:21:12,408 --> 00:21:16,210
attack planning, you get the attack emulation. Itself. And you got a conclusion

323
00:21:16,370 --> 00:21:20,390
and you see that it's color coded. So these purple

324
00:21:20,970 --> 00:21:25,538
colored circles represents activities

325
00:21:25,714 --> 00:21:28,170
that are shared between the red and the blue team,

326
00:21:28,320 --> 00:21:31,946
and the blue colored ones are the blue team. And then you have the

327
00:21:31,968 --> 00:21:36,646
red team owning these red colored circles.

328
00:21:36,838 --> 00:21:39,494
And so you see that there's brainstorming,

329
00:21:39,542 --> 00:21:43,294
there's logistics part, there's adversary profiling, which is actually where

330
00:21:43,332 --> 00:21:46,462
they are doing research to understand the kind of

331
00:21:46,596 --> 00:21:50,154
adversaries they should focus on. And they do some tabletop

332
00:21:50,202 --> 00:21:54,242
exercises, and then they develop capabilities. Then they emulate attacks in

333
00:21:54,296 --> 00:21:57,746
step six, so they don't just start emulating attacks right from the

334
00:21:57,768 --> 00:22:01,406
beginning. Step seven is validate

335
00:22:01,598 --> 00:22:05,410
detection and response, which is actually a function

336
00:22:05,480 --> 00:22:08,774
of detection engineering to a very large extent. We're going to talk

337
00:22:08,812 --> 00:22:12,406
more about that. And they write a report in

338
00:22:12,428 --> 00:22:15,686
the eight step. And finally, there is a retrospective where they

339
00:22:15,708 --> 00:22:19,670
come together and sit down and look at the learnings, what they've learned, and they

340
00:22:19,740 --> 00:22:23,206
actually discuss with the

341
00:22:23,228 --> 00:22:26,634
right team, could even be the DevOps. They talk about what

342
00:22:26,672 --> 00:22:30,630
they learned from this exercise, what are the takeaways, how can they improve?

343
00:22:30,790 --> 00:22:34,686
And things like that. All right, so now

344
00:22:34,708 --> 00:22:37,934
we're going to talk a little bit about cloud attack emulation. So cloud attack

345
00:22:37,972 --> 00:22:41,582
emulation, putting it in a very clear, straightforward way,

346
00:22:41,636 --> 00:22:45,474
is adversary emulation for the cloud. And at

347
00:22:45,512 --> 00:22:49,042
Mitigan, we actually, because our focus is cloud and

348
00:22:49,096 --> 00:22:52,770
cloud native technologies, and we basically have taken

349
00:22:52,840 --> 00:22:56,174
the whole idea, the concept of adversary emulation,

350
00:22:56,222 --> 00:22:59,766
and we apply directly to the cloud. And the reason why

351
00:22:59,788 --> 00:23:03,320
we do this is because the cloud comes with very specific

352
00:23:03,930 --> 00:23:07,506
attacks, very specific problems, very specific challenges.

353
00:23:07,698 --> 00:23:11,594
And the best way to tackle these challenges is

354
00:23:11,632 --> 00:23:15,162
by narrowing down your focus to cloud, which is

355
00:23:15,216 --> 00:23:19,158
actually a lot of things if you think about AWS and you begin to spread

356
00:23:19,334 --> 00:23:23,182
to other cloud service providers like Azure, like Google Cloud,

357
00:23:23,236 --> 00:23:27,326
and even Kubernetes. And so we

358
00:23:27,348 --> 00:23:30,654
have designed this whole concept to be

359
00:23:30,692 --> 00:23:32,080
really cloud specific.

360
00:23:34,230 --> 00:23:38,034
Now we're going to be talking about detection engineering. So what

361
00:23:38,072 --> 00:23:41,214
is detection engineering? So detection engineering is an aspect

362
00:23:41,262 --> 00:23:45,414
of cybersecurity that focuses on developing, fine tuning and

363
00:23:45,452 --> 00:23:49,202
maintaining systems designed to identify and alert

364
00:23:49,266 --> 00:23:52,514
organizations to potential security threats,

365
00:23:52,562 --> 00:23:55,890
breaches, malicious or suspicious activities.

366
00:23:56,050 --> 00:24:00,380
And it's a very new, let's say,

367
00:24:01,790 --> 00:24:06,060
division or subdomain of cybersecurity that appeared just

368
00:24:06,430 --> 00:24:09,990
two or three years ago. And basically,

369
00:24:10,080 --> 00:24:12,880
why do we have detection engineering? So,

370
00:24:13,650 --> 00:24:17,678
like, a decade ago, most of our cybersecurity tools were

371
00:24:17,844 --> 00:24:21,226
kind of focused on prevention. So we had firewalls,

372
00:24:21,258 --> 00:24:24,154
we have web application firewalls,

373
00:24:24,202 --> 00:24:27,434
conventional firewalls, identity and access management.

374
00:24:27,482 --> 00:24:31,230
And all of these were basically on the front door,

375
00:24:31,310 --> 00:24:34,738
more or less kind of trying to prevent attacks coming in,

376
00:24:34,824 --> 00:24:38,822
inspecting traffic and all of that stuff. But as technology

377
00:24:38,956 --> 00:24:42,710
improved or let's say, got more complicated and

378
00:24:42,780 --> 00:24:45,778
things like cloud technologies appear on the scene,

379
00:24:45,954 --> 00:24:49,438
attackers, these whole peripheral defense collapsed.

380
00:24:49,554 --> 00:24:53,430
And now we have the cloud that has an open API that is exposed.

381
00:24:53,510 --> 00:24:57,146
And all of this has led to a scenario we

382
00:24:57,168 --> 00:25:01,438
find ourselves where attackers just jump into our system

383
00:25:01,524 --> 00:25:05,246
straight off. And because of this,

384
00:25:05,348 --> 00:25:09,054
the idea of detection and response, which before used

385
00:25:09,092 --> 00:25:13,242
to be really not very, people weren't really putting

386
00:25:13,316 --> 00:25:16,900
so much effort in detection and response. But now

387
00:25:17,430 --> 00:25:20,526
it becomes more relevant because you can't

388
00:25:20,558 --> 00:25:24,420
focus completely on prevention. You also have to take care of things that

389
00:25:24,890 --> 00:25:27,942
happen when attackers are already in your

390
00:25:27,996 --> 00:25:31,842
environment. And you have products like SIMs,

391
00:25:31,906 --> 00:25:35,666
these have extended detection and response,

392
00:25:35,858 --> 00:25:39,498
network detection, response, cloud detection, response. All these

393
00:25:39,664 --> 00:25:42,954
products have appeared on the scene to take care of this

394
00:25:43,072 --> 00:25:46,586
specific issue of detecting and responding to

395
00:25:46,608 --> 00:25:50,102
attacks that kind of circumvent these

396
00:25:50,256 --> 00:25:52,830
preventive controls.

397
00:25:53,890 --> 00:25:58,190
Right? So what do detection engineers do? This is a detection

398
00:25:58,530 --> 00:26:02,694
development lifecycle, which is highly inspired by the software

399
00:26:02,762 --> 00:26:06,194
development lifecycle. And if you look at it and

400
00:26:06,232 --> 00:26:09,602
compare with the software development lifecycle, you will see

401
00:26:09,656 --> 00:26:14,206
a bunch of similarities. And basically detection

402
00:26:14,238 --> 00:26:18,214
engineers and we will see some examples later, they basically

403
00:26:18,332 --> 00:26:20,870
are doing a lot of things,

404
00:26:20,940 --> 00:26:24,262
including trying to understand these way

405
00:26:24,316 --> 00:26:27,800
that attackers compromise our systems, trying to see whether

406
00:26:30,190 --> 00:26:33,830
our detection tools are able to identify

407
00:26:33,910 --> 00:26:37,514
the correct attacker behavior and trying to

408
00:26:37,552 --> 00:26:40,634
see improving that on the fly, which actually in

409
00:26:40,672 --> 00:26:44,414
a lot of times requires some kind of software development or

410
00:26:44,452 --> 00:26:48,046
some kind of bash writing, scripting and

411
00:26:48,068 --> 00:26:52,422
things like that. And this is kind of the workflow

412
00:26:52,586 --> 00:26:56,642
which most detection engineering teams kind of follow this

413
00:26:56,696 --> 00:27:00,382
process where they develop detection logic

414
00:27:00,446 --> 00:27:04,242
or detection algorithm. They push these, deploy it and they test

415
00:27:04,296 --> 00:27:08,482
it. And it's basically very similar to software

416
00:27:08,626 --> 00:27:12,246
development. And here we see

417
00:27:12,428 --> 00:27:16,066
an example of a sigma rule, and this is actually written

418
00:27:16,098 --> 00:27:19,926
in Yaml. And most of the detection response

419
00:27:19,958 --> 00:27:22,620
systems are using some kind of,

420
00:27:22,990 --> 00:27:26,490
let's say, format, which sigma actually

421
00:27:26,560 --> 00:27:30,562
tries to make these various formats

422
00:27:30,726 --> 00:27:34,960
to be interoperable. And basically this very

423
00:27:35,970 --> 00:27:39,422
sigma rule is, if you see line 20,

424
00:27:39,476 --> 00:27:43,154
21, 22, is basically it

425
00:27:43,192 --> 00:27:47,262
detects when cloud trail is either stopped, it's updated

426
00:27:47,326 --> 00:27:50,914
or deleted AWS cloud trail. And this can

427
00:27:50,952 --> 00:27:54,370
be an indicator of compromise. It can mean that

428
00:27:54,440 --> 00:27:58,274
attackers are in the system and are beginning to tamper with your

429
00:27:58,312 --> 00:28:01,606
detection with cloud trail. And this very

430
00:28:01,708 --> 00:28:04,230
rule basically detects it.

431
00:28:04,300 --> 00:28:07,080
So this is a very good example, actually.

432
00:28:07,770 --> 00:28:11,274
All right, so now let's look at an example. And in this

433
00:28:11,312 --> 00:28:15,030
example we're going to be looking at how to validate threat detections

434
00:28:15,110 --> 00:28:18,202
in the cloud. And we will go through these

435
00:28:18,256 --> 00:28:21,870
three pillars that we discussed in the previous slides,

436
00:28:22,450 --> 00:28:26,986
starting from the top right here under the cyber threat intelligence.

437
00:28:27,178 --> 00:28:31,002
Let's say you kind of received intelligence

438
00:28:31,066 --> 00:28:34,314
report or your threat intelligence

439
00:28:34,442 --> 00:28:38,670
provider kind of told you about scattered spider trade actor,

440
00:28:38,750 --> 00:28:42,434
which we already talked about before. And the next

441
00:28:42,472 --> 00:28:46,070
thing you do here is let's say you have

442
00:28:46,140 --> 00:28:49,666
implemented some threat detection

443
00:28:49,858 --> 00:28:53,590
algorithms or you have a system that takes care

444
00:28:53,660 --> 00:28:57,110
of, that basically tries to identify

445
00:28:58,430 --> 00:29:01,994
scattered spider techniques. And here we are looking at this

446
00:29:02,032 --> 00:29:06,490
technique which basically is about credential harvesting.

447
00:29:07,550 --> 00:29:10,718
And these, the next thing here, which is the

448
00:29:10,724 --> 00:29:15,262
third pillar is you're going to be emulating this

449
00:29:15,316 --> 00:29:18,958
technique specifically to be sure that

450
00:29:19,124 --> 00:29:22,794
your detection is able to capture it, is able to detect

451
00:29:22,842 --> 00:29:23,440
it.

452
00:29:26,630 --> 00:29:30,034
So that all of the three pillars are put

453
00:29:30,072 --> 00:29:30,660
into.

454
00:29:33,670 --> 00:29:37,502
So this is basically our use cases AWS.

455
00:29:37,646 --> 00:29:41,190
And this diagram shows, kind of gives a very

456
00:29:41,260 --> 00:29:42,680
clear high level,

457
00:29:44,010 --> 00:29:47,334
there's an illustration of what we're going to be looking at. So on the left

458
00:29:47,372 --> 00:29:51,334
here we have the emulation which is here pertaining

459
00:29:51,382 --> 00:29:55,290
or let's say mimicking the attacker. And you have the AWS

460
00:29:56,030 --> 00:29:59,738
secret manager which stores different

461
00:29:59,824 --> 00:30:03,466
kinds of secrets, which could be API keys,

462
00:30:03,498 --> 00:30:07,040
could be tokens, could be other kinds of

463
00:30:08,850 --> 00:30:12,606
secrets. And just for

464
00:30:12,628 --> 00:30:16,318
you to understand the implication of this attack, if it succeeds,

465
00:30:16,414 --> 00:30:20,034
if it's a real attacker, if they are able to

466
00:30:20,072 --> 00:30:23,874
compromise your AWS secret manager and they get

467
00:30:23,912 --> 00:30:27,766
the keys, these, and let's say the keys are not encrypted, it means these

468
00:30:27,788 --> 00:30:31,446
have access to all of this stuff which could be access to

469
00:30:31,468 --> 00:30:35,698
your databases like RDS, redshift document database,

470
00:30:35,874 --> 00:30:40,090
your other applications, maybe kubernetes clusters, it could be

471
00:30:40,240 --> 00:30:44,054
whatever you're using the keys

472
00:30:44,102 --> 00:30:47,866
here to protect. And on the other hand here

473
00:30:48,048 --> 00:30:52,182
down below here we see cloud trail. So usually this is the setup

474
00:30:52,326 --> 00:30:56,640
most threat detection systems have. They are basically

475
00:30:57,010 --> 00:31:00,334
fetching logs from cloudtrail and basically cloud

476
00:31:00,372 --> 00:31:03,806
trail, it kind of collects different kinds of logs

477
00:31:03,838 --> 00:31:07,550
from different AWS services and they're fetching these logs.

478
00:31:07,630 --> 00:31:11,474
And here we have just for example, for the sake of this

479
00:31:11,592 --> 00:31:15,702
demonstration, we're going to be using datadog cloud

480
00:31:15,756 --> 00:31:19,366
CM, which is actually kind of a threat detection system.

481
00:31:19,548 --> 00:31:23,014
And on other hand here we have, let's say the

482
00:31:23,052 --> 00:31:27,122
admin, maybe like the security engineer

483
00:31:27,186 --> 00:31:29,900
who is basically in charge of this system.

484
00:31:30,830 --> 00:31:34,570
So here we see that we are emulating the attack

485
00:31:34,640 --> 00:31:38,410
and this is a screenshot from the mitigant attack

486
00:31:38,480 --> 00:31:42,238
emulation. And there are actually two attacks that we are

487
00:31:42,244 --> 00:31:45,678
emulating here. The first one is basically

488
00:31:45,764 --> 00:31:51,326
a malicious secret retrieval, and this

489
00:31:51,348 --> 00:31:55,810
is an implementation of the technique we saw before. There are two implementations.

490
00:31:56,230 --> 00:32:00,178
The first implementation basically retrieves these

491
00:32:00,344 --> 00:32:01,330
secrets.

492
00:32:04,890 --> 00:32:08,854
It's kind of limited, it cannot retrieve a

493
00:32:08,892 --> 00:32:12,520
bulk secrets and bulk, so it has to do one after the other.

494
00:32:13,050 --> 00:32:16,454
And the second attack here actually is doing

495
00:32:16,572 --> 00:32:20,026
batch secret retriever. And this is a feature that was

496
00:32:20,048 --> 00:32:23,354
released by AWS just in November last year,

497
00:32:23,552 --> 00:32:27,318
which allows you to say, hey, give me 20 secrets,

498
00:32:27,334 --> 00:32:30,862
for example, or 100. And basically you can take it

499
00:32:30,996 --> 00:32:36,654
with just one API call and

500
00:32:36,772 --> 00:32:40,366
that's kind of bad. So here is

501
00:32:40,388 --> 00:32:43,890
the cloud trail record that corresponds to these attack

502
00:32:43,960 --> 00:32:47,714
emulation. We can see the name of this event and here

503
00:32:47,752 --> 00:32:51,010
we're focusing on the batch meets secret value,

504
00:32:51,080 --> 00:32:55,794
which is the attack where you are basically fetching a

505
00:32:55,832 --> 00:32:59,158
whole lot of secrets. And you can see here that

506
00:32:59,244 --> 00:33:03,346
this is the secret ID list. This is about ten secrets

507
00:33:03,378 --> 00:33:06,646
that were fetched by this API call and

508
00:33:06,668 --> 00:33:10,586
you have it registered in cloud trail. Then on

509
00:33:10,608 --> 00:33:14,426
the other hand, remember I talked about Datadog and

510
00:33:14,448 --> 00:33:19,094
cloud CM, and this is kind of the Datadog

511
00:33:19,222 --> 00:33:24,474
investigator. So it kind of has this nice user

512
00:33:24,522 --> 00:33:28,014
interface where it shows you on these left here

513
00:33:28,052 --> 00:33:31,950
you have the mitigant role which

514
00:33:32,020 --> 00:33:35,470
actually emulates these attacks.

515
00:33:35,630 --> 00:33:38,946
And basically you see here the secret manager, which is

516
00:33:38,968 --> 00:33:42,018
a service that is called,

517
00:33:42,184 --> 00:33:44,980
and then this service basically has,

518
00:33:45,370 --> 00:33:49,400
we have done different activities here. What we're interested here is

519
00:33:50,090 --> 00:33:53,554
two. So basically there are 30 get secret

520
00:33:53,602 --> 00:33:58,522
value API calls. So this basically gets

521
00:33:58,576 --> 00:34:03,370
basically single, as I said before, single secrets.

522
00:34:03,950 --> 00:34:07,702
Unfortunately, the get bad secret value, it's not detected

523
00:34:07,766 --> 00:34:11,274
by this system, so it's not able to detect

524
00:34:11,402 --> 00:34:14,990
that. Also, there were calls that allowed

525
00:34:15,330 --> 00:34:18,526
here the emulation to be able to collect a

526
00:34:18,548 --> 00:34:21,806
huge amount of secrets with just one API call. And this

527
00:34:21,828 --> 00:34:25,406
is exactly what we are trying to say here, that the threat

528
00:34:25,438 --> 00:34:28,350
detection systems might miss some detections,

529
00:34:28,430 --> 00:34:31,906
either because the cloud

530
00:34:32,008 --> 00:34:35,262
service provider kind of had new APIs

531
00:34:35,326 --> 00:34:39,286
or they released new features, or even MIT attack framework had

532
00:34:39,388 --> 00:34:42,674
some updates which have to be kind of integrated

533
00:34:42,722 --> 00:34:46,566
into the threat detection system. So this is a very good example

534
00:34:46,668 --> 00:34:49,610
of what could go wrong.

535
00:34:49,760 --> 00:34:53,082
And what is the solution here. Again, we have gone back

536
00:34:53,136 --> 00:34:56,986
to sigma rule, and although this is not exactly

537
00:34:57,088 --> 00:35:00,846
what they use at Datadog, but this is just for the

538
00:35:00,868 --> 00:35:03,790
sake of kind of an illustration.

539
00:35:04,370 --> 00:35:09,262
We talked before, if you remember when we were talking about looking

540
00:35:09,316 --> 00:35:13,022
at the questions why you should use attack emulation. We were

541
00:35:13,076 --> 00:35:16,722
talking about whether we're getting the right data sets or

542
00:35:16,776 --> 00:35:20,402
whether we are making the right queries. So you can see between

543
00:35:20,456 --> 00:35:24,322
line 96 to actually 100 here that

544
00:35:24,376 --> 00:35:28,214
actually these query is made

545
00:35:28,332 --> 00:35:32,120
against cloud trail. And that is how this

546
00:35:32,890 --> 00:35:36,918
event is actually more like

547
00:35:37,004 --> 00:35:42,006
identified. This event of getting secrets

548
00:35:42,118 --> 00:35:45,562
is identified and what you can see on this

549
00:35:45,616 --> 00:35:49,190
line 98 is here a query

550
00:35:49,270 --> 00:35:52,766
to fetch get secret value. And this

551
00:35:52,788 --> 00:35:56,830
is basically here again we see that

552
00:35:56,900 --> 00:36:00,622
there is just the old API that is put

553
00:36:00,676 --> 00:36:04,046
into consideration. The API

554
00:36:04,078 --> 00:36:07,954
that gets a batch amount of secrets is not

555
00:36:07,992 --> 00:36:11,490
considered here and definitely that event will be missed.

556
00:36:11,910 --> 00:36:15,358
So to correct this problem, this query has

557
00:36:15,384 --> 00:36:19,282
to be updated and the correct get batch secret

558
00:36:19,346 --> 00:36:23,160
value has to be added here. And as simple as that,

559
00:36:23,850 --> 00:36:27,494
once that is added, you basically will be able to

560
00:36:27,532 --> 00:36:31,078
identify their tracks where batch

561
00:36:31,254 --> 00:36:33,050
secrets are collected.

562
00:36:34,350 --> 00:36:37,866
All right, so we're coming to an end now. So these are the

563
00:36:37,888 --> 00:36:41,722
resources that I want to leave. Most of them are blogs.

564
00:36:41,786 --> 00:36:45,134
I have written about the whole

565
00:36:45,172 --> 00:36:48,474
topic of threat informed defense

566
00:36:48,602 --> 00:36:52,282
as well as Mitre tag cloud matrix

567
00:36:52,346 --> 00:36:55,506
as well as threat led emulation, which I will just

568
00:36:55,528 --> 00:36:58,500
give a quick demo right away.

569
00:36:59,830 --> 00:37:03,666
So I just want to give a very quick demonstration of

570
00:37:03,768 --> 00:37:07,938
mitigant cloud attack emulation.

571
00:37:08,114 --> 00:37:11,720
And I am going to log in into my own account

572
00:37:12,570 --> 00:37:14,870
using the Google SSO.

573
00:37:15,770 --> 00:37:20,746
All right, so the platform has different products,

574
00:37:20,848 --> 00:37:25,030
but let's go straight to the cloud attack emulation

575
00:37:25,110 --> 00:37:29,740
and switch to this cloud

576
00:37:30,210 --> 00:37:34,062
AWS account. So what you see here are

577
00:37:34,116 --> 00:37:37,534
different statistics about attacks that have run

578
00:37:37,732 --> 00:37:41,150
before. And you can see the attacks by

579
00:37:41,220 --> 00:37:44,734
different metrics, for example by status, by service AWS

580
00:37:44,782 --> 00:37:49,154
services. And here are these tactics that

581
00:37:49,192 --> 00:37:52,100
have executed against different AWS services.

582
00:37:53,510 --> 00:37:57,074
What's interesting here is if you scroll down, you will see that

583
00:37:57,112 --> 00:38:00,658
we currently support up to title attack actions

584
00:38:00,834 --> 00:38:03,986
and we also support different attack scenarios.

585
00:38:04,018 --> 00:38:07,640
So the attack actions are things as simple

586
00:38:08,030 --> 00:38:11,642
as for example, we got the very popular one

587
00:38:11,696 --> 00:38:15,466
which s three, let me

588
00:38:15,488 --> 00:38:18,906
search for it. So we have public s three bucket and this

589
00:38:18,928 --> 00:38:22,686
one is very popular. And basically what this does, it basically

590
00:38:22,788 --> 00:38:25,998
goes to the cloud, looks for buckets that are

591
00:38:26,084 --> 00:38:29,518
private, and out of these private buckets makes one of

592
00:38:29,524 --> 00:38:32,558
them public. And the aim is to see whether

593
00:38:32,644 --> 00:38:36,626
the threat detection system is basically able to

594
00:38:36,728 --> 00:38:40,606
identify that event and it's also mapped to the mitre

595
00:38:40,638 --> 00:38:44,626
attack framework. We can see the tactic here is discovery and the

596
00:38:44,648 --> 00:38:48,726
technique is cloud storage object discovery. But we

597
00:38:48,748 --> 00:38:53,042
also have the idea of attack scenarios.

598
00:38:53,106 --> 00:38:54,680
So for example,

599
00:38:57,390 --> 00:39:00,618
different attack scenarios. We have ransomware for example.

600
00:39:00,704 --> 00:39:04,518
We have also the s three object exfiltration

601
00:39:04,694 --> 00:39:10,426
and the ransomware attack to

602
00:39:10,448 --> 00:39:14,574
run an attack is pretty much simple. So you just hit the run

603
00:39:14,612 --> 00:39:17,262
attack there and then you can select,

604
00:39:17,396 --> 00:39:20,986
let's say once you just select the attacks,

605
00:39:21,018 --> 00:39:24,530
they're queuing up there. So we've selected new Im

606
00:39:24,600 --> 00:39:27,780
user, let's select another one,

607
00:39:28,230 --> 00:39:31,346
disable s three login, which is basically going

608
00:39:31,368 --> 00:39:35,474
to disable the login facility for an

609
00:39:35,512 --> 00:39:39,030
S three bucket. And let's choose also public

610
00:39:39,100 --> 00:39:43,014
s three bucket, the one we just talked about. And basically on the right

611
00:39:43,052 --> 00:39:46,434
here you can see these attacks that I just selected.

612
00:39:46,562 --> 00:39:49,842
And there's this slot for attack objectives.

613
00:39:49,906 --> 00:39:53,350
So we say testing threat,

614
00:39:54,190 --> 00:39:57,658
right? So that's going to be documented and you

615
00:39:57,664 --> 00:40:02,190
can see the attack steps here, just kind of giving very brief

616
00:40:03,730 --> 00:40:07,086
descriptions of what you expect to happen. And then you

617
00:40:07,108 --> 00:40:11,054
can basically hit these start attack button. And this

618
00:40:11,092 --> 00:40:15,406
happens really fast because we're

619
00:40:15,438 --> 00:40:19,006
connecting over the AWS API, we don't

620
00:40:19,038 --> 00:40:22,434
install agents at all. And that makes it super simple to

621
00:40:22,472 --> 00:40:26,206
onboard your account and to also execute

622
00:40:26,238 --> 00:40:31,654
this mean to execute attacks. And what

623
00:40:31,692 --> 00:40:35,890
you can see already is the new im user attack is already completed

624
00:40:36,050 --> 00:40:39,334
and you can begin to actually look at what occurred.

625
00:40:39,382 --> 00:40:42,246
So we kind of print out some of the steps.

626
00:40:42,438 --> 00:40:45,834
You see the name of the user that was created these

627
00:40:46,032 --> 00:40:49,878
and it created a user. It created also

628
00:40:50,064 --> 00:40:54,320
API keys for that user and

629
00:40:55,330 --> 00:40:59,054
it also created a policy for the user. In this

630
00:40:59,092 --> 00:41:03,262
case, the user has, a policy has been attached

631
00:41:03,406 --> 00:41:07,330
to grant a user full access to s three.

632
00:41:07,400 --> 00:41:11,634
And these are all kinds of activities that a

633
00:41:11,672 --> 00:41:14,866
very robust system might not even permit it

634
00:41:14,888 --> 00:41:18,230
to occur, or there's going to be some notification

635
00:41:20,650 --> 00:41:24,246
being streamed to the tools at this

636
00:41:24,268 --> 00:41:28,342
point in time. And we see the other attack also already completed,

637
00:41:28,406 --> 00:41:31,914
disable s these bucket login. And what

638
00:41:31,952 --> 00:41:36,060
does it do? Let's have a look. So basically

639
00:41:36,590 --> 00:41:40,206
that attack. So basically it

640
00:41:40,228 --> 00:41:42,800
goes into Aws s three.

641
00:41:43,650 --> 00:41:47,390
It acquires the targets, it finds the buckets.

642
00:41:47,730 --> 00:41:51,498
It looks whether there's any bucket that is exempted with tags.

643
00:41:51,514 --> 00:41:56,110
So you can actually exempt some resources from being attacked using tags.

644
00:41:56,270 --> 00:42:00,274
And then it selects a bucket that has

645
00:42:00,312 --> 00:42:03,954
the login feature enabled. It disables it,

646
00:42:04,152 --> 00:42:07,206
which is kind of malicious, which is what attackers will do.

647
00:42:07,308 --> 00:42:09,430
And then it basically finishes.

648
00:42:10,250 --> 00:42:13,478
So let's see the comprehensive attack report.

649
00:42:13,564 --> 00:42:18,066
So here we see the comprehensive attack report steps

650
00:42:18,098 --> 00:42:21,306
again, which we already looked at. And of course there's a

651
00:42:21,328 --> 00:42:24,970
remediation section that we basically describe what

652
00:42:25,040 --> 00:42:28,746
you should do as a defender. And the attack evidence is

653
00:42:28,768 --> 00:42:32,414
being collected. So we're going to be getting some evidence from Cloudtreel where

654
00:42:32,452 --> 00:42:35,758
you will see the exact cloud trail record

655
00:42:35,844 --> 00:42:39,518
that was created due to these attacks. And we're going

656
00:42:39,524 --> 00:42:43,182
to get it because cloud trail doesn't provide it in real time.

657
00:42:43,236 --> 00:42:47,218
So it's going to take something around ten minutes for that to come

658
00:42:47,384 --> 00:42:50,754
here. Interestingly, I want to talk

659
00:42:50,792 --> 00:42:54,498
to you about this pain and recovery. So the cleanup is going

660
00:42:54,504 --> 00:42:58,054
to be automated. So immediately, let's say about five

661
00:42:58,092 --> 00:43:01,110
minutes after this attack has occurred,

662
00:43:01,850 --> 00:43:04,870
there's going to be a rollback, which basically means,

663
00:43:04,940 --> 00:43:08,346
for example, this new im user is going to be

664
00:43:08,368 --> 00:43:11,706
deleted along with all the resources that were created during the

665
00:43:11,728 --> 00:43:15,466
process of the attack so

666
00:43:15,488 --> 00:43:18,890
that it's cleaned. It's kind of back to how it was before

667
00:43:18,960 --> 00:43:23,182
the attack. Same team, this bucket that

668
00:43:23,236 --> 00:43:26,186
had the login disabled will be re enabled,

669
00:43:26,378 --> 00:43:30,334
exactly how we saw it. And the public bucket will

670
00:43:30,372 --> 00:43:34,226
also be taken back to a private mode, exactly how it

671
00:43:34,248 --> 00:43:37,634
was before the attack. So on the right

672
00:43:37,672 --> 00:43:41,822
here, you can see we already had written our attack objective,

673
00:43:41,966 --> 00:43:45,486
and you can also enter your observations here. So in this

674
00:43:45,528 --> 00:43:48,966
case, you go to the cloud or you look

675
00:43:48,988 --> 00:43:52,530
at your threat detection system and observe,

676
00:43:52,690 --> 00:43:56,470
kind of look at whether it was able to detect these activities,

677
00:43:56,890 --> 00:44:00,314
if it detected it, whether what it told you,

678
00:44:00,512 --> 00:44:04,010
whatever will help you to make the system to become

679
00:44:04,080 --> 00:44:07,786
more secure. You can note it here and you can always come back

680
00:44:07,808 --> 00:44:11,134
to these reports. All right,

681
00:44:11,332 --> 00:44:18,526
so I will switch back to the slide, and I

682
00:44:18,548 --> 00:44:22,366
think we're almost at the end of the presentation already.

683
00:44:22,468 --> 00:44:26,430
So that's actually the last slide. So thank you very much for

684
00:44:26,500 --> 00:44:29,694
listening to me. Feel free to reach out to me.

685
00:44:29,732 --> 00:44:33,582
That's my email here. I'm also on Twitter, and I'm always open

686
00:44:33,636 --> 00:44:36,840
to talking to anyone who wants to ask questions.

687
00:44:37,690 --> 00:44:40,566
Yes, thank you so much for staying this long for my talk,

688
00:44:40,668 --> 00:44:42,850
and I wish you a very nice conference.

