1
00:00:27,240 --> 00:00:30,942
Hello. So happy that you've joined me here at Conf 42,

2
00:00:30,998 --> 00:00:34,998
SRE 2024. I'm coming at you from beautiful New Haven,

3
00:00:35,046 --> 00:00:38,198
Connecticut, the Elm city. And I'm going to talk to

4
00:00:38,206 --> 00:00:41,566
you today about clinical troubleshooting, which is a technique you can

5
00:00:41,590 --> 00:00:45,438
use every day in your career as an SRE to diagnose problems

6
00:00:45,486 --> 00:00:48,678
faster and solve them for good. And I can tell you that

7
00:00:48,726 --> 00:00:51,846
if you and your team do use clinical troubleshooting consistently,

8
00:00:51,990 --> 00:00:56,144
you will experience shorter incidents and less

9
00:00:56,184 --> 00:00:59,776
stressful incidents. That all sounds pretty good, right? But what do

10
00:00:59,800 --> 00:01:02,844
I know? I am Dan Slimmon,

11
00:01:03,424 --> 00:01:06,456
and I've worked for about 16 years of

12
00:01:06,480 --> 00:01:09,924
my life in operations, Sre DevOps.

13
00:01:10,824 --> 00:01:14,416
Most recently, I've worked at companies like Hashicorp

14
00:01:14,480 --> 00:01:18,112
and Etsy, and I've troubleshot.

15
00:01:18,248 --> 00:01:22,244
I've investigated thousands of production issues during my

16
00:01:22,714 --> 00:01:26,362
time as an SRE. Over those 16 years and thousands

17
00:01:26,378 --> 00:01:30,570
of issues, I've developed this clinical troubleshooting methodology that

18
00:01:30,602 --> 00:01:34,234
I'm so excited to tell you about today. It allows

19
00:01:34,274 --> 00:01:38,494
groups of people to troubleshoot problems much more effectively.

20
00:01:39,234 --> 00:01:43,882
Clinical troubleshooting is a scientific procedure for collaborative

21
00:01:44,018 --> 00:01:47,418
diagnosis. Essentially, that means you can use it anytime

22
00:01:47,466 --> 00:01:51,306
you have a group that needs to work together to explain why a complex system

23
00:01:51,370 --> 00:01:55,170
is malfunctioning. It doesn't have to be under intense time pressure,

24
00:01:55,202 --> 00:01:58,730
like during an incident. But incidents are a great example

25
00:01:58,762 --> 00:02:02,762
of a time when you need to do collaborative diagnosis. You get

26
00:02:02,778 --> 00:02:06,586
a bunch of people on a call, maybe each of

27
00:02:06,610 --> 00:02:10,210
them only knows part of the system. They have an imperfect view of each

28
00:02:10,242 --> 00:02:14,506
other's thinking processes, and so you're doing diagnosis

29
00:02:14,570 --> 00:02:17,658
collaboratively. Clinical troubleshooting is a scientific

30
00:02:17,706 --> 00:02:21,122
way to do that. So let's dive into a

31
00:02:21,138 --> 00:02:24,374
story. It's a wonderful, calm day,

32
00:02:25,074 --> 00:02:28,814
and the flower service in our stack

33
00:02:29,154 --> 00:02:32,570
is clicking along, doing its job, serving up nectar tokens

34
00:02:32,602 --> 00:02:36,402
for our users, and then suddenly it

35
00:02:36,418 --> 00:02:40,170
catches on fire. The throughput of the flower service drops

36
00:02:40,202 --> 00:02:43,818
by 40% right in the middle of the business day, which should never

37
00:02:43,866 --> 00:02:46,934
happen. Here's a little graph showing the throughput.

38
00:02:47,474 --> 00:02:51,574
It measured in terms of pollen tokens per second served,

39
00:02:51,954 --> 00:02:55,690
dropping from about 1000 to about 600 /second

40
00:02:55,882 --> 00:02:59,546
that's bad. And it's so bad that

41
00:02:59,730 --> 00:03:03,494
Barb gets paged. Barb is an SRE,

42
00:03:04,274 --> 00:03:07,546
and she just got paged about this problem with the flower service

43
00:03:07,610 --> 00:03:12,588
throughput dropping down to from 1000 to 606,600

44
00:03:12,636 --> 00:03:16,468
/second she only knows a little bit about the flower service, but she's here on

45
00:03:16,476 --> 00:03:19,444
the incident call. She's ready to go. She's going to figure this out.

46
00:03:19,564 --> 00:03:22,972
It's a chance for Barb, captain of SRE, to show her quality,

47
00:03:23,028 --> 00:03:26,420
so to speak. So Barb spends a few minutes

48
00:03:26,452 --> 00:03:30,212
looking at graphs. She's searching for the error message on Google and

49
00:03:30,228 --> 00:03:33,584
the source code. She's building up context.

50
00:03:34,444 --> 00:03:37,688
And so she's holding a lot in her head. She's holding a

51
00:03:37,696 --> 00:03:40,880
lot of abstractions, a big house of cards in her head.

52
00:03:41,032 --> 00:03:45,444
When Alice joins the call and Alice says,

53
00:03:45,944 --> 00:03:49,096
Alice is an engineer on a different team, she says, hi,

54
00:03:49,120 --> 00:03:52,684
Barb. This is Alice. I saw the alert in slack. Can I help?

55
00:03:53,224 --> 00:03:56,320
But Barb, as we discussed, is holding a lot in her head.

56
00:03:56,512 --> 00:03:59,776
She's got several competing theories that are maybe not

57
00:03:59,800 --> 00:04:03,304
fully baked yet. She's still processing what she

58
00:04:03,384 --> 00:04:06,800
sees on the graph dashboards and on Google. And so she says,

59
00:04:06,952 --> 00:04:10,324
thanks, Alice. You can sit tight for a moment. I'll fill you in soon.

60
00:04:11,744 --> 00:04:15,144
She doesn't want to stop and explain everything to

61
00:04:15,304 --> 00:04:19,284
Alice when she hasn't totally explained it to herself yet.

62
00:04:19,944 --> 00:04:23,712
So Alice can watch Barb screen share, watch what she's doing. But she

63
00:04:23,728 --> 00:04:26,284
has even less context than Barb does on this issue.

64
00:04:26,904 --> 00:04:31,120
This goes on for a few minutes, and then suddenly another

65
00:04:31,192 --> 00:04:34,284
service breaks, the honeybee service.

66
00:04:34,984 --> 00:04:38,440
Barb gets a page saying that the error rate for the honeybee

67
00:04:38,472 --> 00:04:42,248
service is now elevated. She doesn't have time for this. She's trying to

68
00:04:42,256 --> 00:04:45,712
fix flour. So Alice jumps in, says, oh,

69
00:04:45,728 --> 00:04:49,400
I can look at honeybee. So now

70
00:04:49,432 --> 00:04:52,824
you have Barb over here looking to flower and Alice

71
00:04:52,864 --> 00:04:56,572
over here looking at honeybee. They're both looking around

72
00:04:56,628 --> 00:04:59,784
for data to explain their respective issues.

73
00:05:00,644 --> 00:05:04,236
This is kind of good because they can work in parallel. And then

74
00:05:04,260 --> 00:05:07,532
suddenly, boom, straight through

75
00:05:07,548 --> 00:05:10,424
the brick wall comes crashing. Seth.

76
00:05:10,764 --> 00:05:13,624
Seth is Barb and Alice's grand boss.

77
00:05:14,084 --> 00:05:17,452
He wants to know the answers to lots of questions. And he's

78
00:05:17,508 --> 00:05:20,704
spitting out those questions like so many watermelon seeds. He's saying,

79
00:05:21,014 --> 00:05:23,998
how are customers affected? Do we need anyone else on the call? How are the

80
00:05:24,006 --> 00:05:27,110
flower and honeybee problems related? What's our plan? These are

81
00:05:27,142 --> 00:05:30,606
good questions, and it's reasonable that Seth wants to know the answers

82
00:05:30,630 --> 00:05:33,918
to them. But because all the context on these issues

83
00:05:33,966 --> 00:05:37,114
is stored inside the heads of our heroes, Barb and Alice,

84
00:05:37,814 --> 00:05:41,742
Barb now has to take her hands off the keyboard and spend her time answering.

85
00:05:41,838 --> 00:05:45,966
Seth's very reasonable, but perhaps disruptively delivered

86
00:05:46,070 --> 00:05:49,516
questions. And while she's answering those questions,

87
00:05:49,700 --> 00:05:52,024
guess who else shows up on the incident call?

88
00:05:52,724 --> 00:05:56,744
Ding, ding, ding. It's the support team.

89
00:05:57,884 --> 00:06:01,424
Supporters started getting customer reports of errors from the honeybee service.

90
00:06:02,204 --> 00:06:05,436
And they say, is this the right call to talk about that? I know it's

91
00:06:05,460 --> 00:06:08,984
supposed to be about flour, but, you know, there's an incident.

92
00:06:10,364 --> 00:06:13,952
They have a lot of the same questions as Seth, but the support team's questions

93
00:06:13,968 --> 00:06:17,216
are going to have to wait because. Ding ding.

94
00:06:17,400 --> 00:06:20,728
Two more devs join the call, Devin and Charlie. Ok,

95
00:06:20,896 --> 00:06:24,696
so Barb has to put her conversation on Seth, with Seth on hold

96
00:06:24,800 --> 00:06:28,232
for a minute so she can assign these new responders to

97
00:06:28,248 --> 00:06:32,504
help herself and Alice respectively. So once she's answered Seth and supports

98
00:06:32,544 --> 00:06:35,656
questions, then she and Alice can spin

99
00:06:35,680 --> 00:06:39,240
up Devon and Charlie on context and everybody can get

100
00:06:39,272 --> 00:06:41,604
back to troubleshooting the issue.

101
00:06:42,964 --> 00:06:46,604
It's a mess because the effort is fractured. Essentially, we have

102
00:06:46,644 --> 00:06:50,304
two independent teams now, both trying to coordinate on a single call.

103
00:06:50,644 --> 00:06:53,996
We have a mess because every new person who

104
00:06:54,020 --> 00:06:57,052
joins the effort now has to interrupt Barb or Alice to get

105
00:06:57,068 --> 00:07:00,304
the call to get context on what's going on.

106
00:07:00,844 --> 00:07:04,300
And it's a mess because despite having been in the incident call

107
00:07:04,332 --> 00:07:08,358
for 20 minutes, there's still no real plan about how we're going to

108
00:07:08,556 --> 00:07:12,178
diagnose and fix this problem. If you've been on incident

109
00:07:12,226 --> 00:07:15,330
calls, you know what this kind of mess feels like.

110
00:07:15,442 --> 00:07:18,778
It wastes time. People step on each other's toes, we get

111
00:07:18,826 --> 00:07:22,202
disorganized, we miss things, and the incident goes on way longer than it

112
00:07:22,218 --> 00:07:25,466
needs to. And that's why it's useful to have a

113
00:07:25,490 --> 00:07:30,194
process like clinical troubleshooting. Clinical troubleshooting

114
00:07:30,314 --> 00:07:33,574
is what's called a structured diagnostic process.

115
00:07:34,374 --> 00:07:38,142
Having a structured diagnostic process makes a lot of these problems that we just.

116
00:07:38,238 --> 00:07:42,074
That just turned our incident into a mess go away.

117
00:07:43,574 --> 00:07:47,582
And does this by exposing the plan so that

118
00:07:47,678 --> 00:07:51,566
everyone who joins the call knows what's up and what we're doing. It does

119
00:07:51,590 --> 00:07:54,234
this by helping you avoid dead ends,

120
00:07:54,654 --> 00:07:58,034
which allows you to solve the issue faster.

121
00:07:58,774 --> 00:08:02,792
And most importantly, I think it lets you audit

122
00:08:02,888 --> 00:08:06,480
each other's thinking. When we audit each other's thinking,

123
00:08:06,512 --> 00:08:10,576
by which I mean how our coworkers are

124
00:08:10,600 --> 00:08:14,684
thinking about the issue and compare it to our own mental model,

125
00:08:15,664 --> 00:08:19,136
we can reason collectively, and because we're

126
00:08:19,160 --> 00:08:22,384
reasoning collectively, we can reason better. And that's how clinical

127
00:08:22,424 --> 00:08:26,456
troubleshooting gives us shorter incidents, fewer incidents, and less stressful

128
00:08:26,520 --> 00:08:30,008
incidents. So what is this structured

129
00:08:30,056 --> 00:08:33,724
diagnostic process that makes so many of Barb's analysis problems go away?

130
00:08:34,464 --> 00:08:36,924
It's this simple workflow.

131
00:08:37,784 --> 00:08:41,536
First we get a group of people together who have as diverse

132
00:08:41,560 --> 00:08:45,164
as possible set of viewpoints that'll be important for later.

133
00:08:45,904 --> 00:08:49,016
Working together as a group, we list the symptoms of the

134
00:08:49,040 --> 00:08:53,064
problem under investigation. Symptoms are objective

135
00:08:53,144 --> 00:08:55,804
observations about the system's behavior.

136
00:08:57,704 --> 00:09:02,040
Next, working from those symptoms, we brainstorm

137
00:09:02,072 --> 00:09:05,496
a number of hypotheses to explain the symptoms we're observing.

138
00:09:05,680 --> 00:09:09,464
And finally, we decide what actions to take next.

139
00:09:09,624 --> 00:09:13,480
Given the relative likelihoods and scarinesses of the hypotheses we've

140
00:09:13,512 --> 00:09:16,484
listed, we take those actions,

141
00:09:17,264 --> 00:09:20,928
and if they don't fix the problem, we go back to

142
00:09:21,096 --> 00:09:23,614
the symptoms. If they do fix the problem,

143
00:09:24,354 --> 00:09:27,826
we're done. So let's see

144
00:09:27,850 --> 00:09:31,722
how this works. Let's go back in time, through this time

145
00:09:31,778 --> 00:09:35,654
portal to the beginning of our wonderful calm day.

146
00:09:36,234 --> 00:09:40,282
The flower service is going along, and suddenly

147
00:09:40,298 --> 00:09:44,042
it's on fire. Throughput drops by 40% in the middle of the

148
00:09:44,058 --> 00:09:47,122
workday. Oh, no. So Barb gets paged.

149
00:09:47,218 --> 00:09:50,338
Barb spends a few minutes figuring out context, just like she did in the bad

150
00:09:50,386 --> 00:09:53,730
timeline. But this time, when ding.

151
00:09:53,842 --> 00:09:57,642
Alice joins the call and says, hi, this is Alice. How can I help?

152
00:09:57,778 --> 00:10:01,074
Barb remembers this phenomenal talk she saw at con 42,

153
00:10:01,114 --> 00:10:04,734
SRE 2024, called clinical troubleshooting.

154
00:10:05,154 --> 00:10:08,226
So instead of saying, hold on,

155
00:10:08,250 --> 00:10:11,894
Alice, I'm figuring some stuff out, can you just wait for a minute? She says,

156
00:10:12,794 --> 00:10:15,934
welcome, Alice. Let's do some clinical troubleshooting.

157
00:10:16,314 --> 00:10:20,362
She makes a shared Google Doc, or whatever

158
00:10:20,418 --> 00:10:23,914
her shared document system of choice

159
00:10:23,954 --> 00:10:27,258
is. She makes a doc, she shares it with Alice, she shares it on

160
00:10:27,266 --> 00:10:30,154
her screen. And the doc has these headings,

161
00:10:30,274 --> 00:10:32,494
symptoms, hypotheses,

162
00:10:33,154 --> 00:10:36,426
and they start the process. They write down the symptoms. What are the symptoms?

163
00:10:36,450 --> 00:10:40,666
Well, we had an alert at 841 utc that the flower services,

164
00:10:40,770 --> 00:10:44,102
through wood, dropped by. And we also

165
00:10:44,198 --> 00:10:47,550
know from Barb, having poked around a little bit before Alice

166
00:10:47,582 --> 00:10:51,846
joined the call, that the latencies of requests

167
00:10:51,870 --> 00:10:54,782
to the flower service dropped at the time that the throughput dropped.

168
00:10:54,878 --> 00:10:58,206
So it's getting less traffic, but the traffic it is

169
00:10:58,230 --> 00:11:00,114
serving, it's serving faster.

170
00:11:01,254 --> 00:11:04,694
Alice's sorry. Barb's first hypothesis

171
00:11:04,734 --> 00:11:08,678
that she's been cooking up before Alice joined the call is that the flower

172
00:11:08,726 --> 00:11:12,576
service is somehow crashing when it receives certain kinds of requests.

173
00:11:12,760 --> 00:11:15,768
And that explains symptom one,

174
00:11:15,936 --> 00:11:19,192
because the crashed requests aren't getting logged and so they're

175
00:11:19,208 --> 00:11:23,104
not showing up in the throughput data. And it would also explain symptom

176
00:11:23,144 --> 00:11:27,804
two, because maybe these requests

177
00:11:28,304 --> 00:11:31,976
that are causing flower to crash are normally requests that

178
00:11:32,000 --> 00:11:35,616
take a longer time than usual. So since they're not getting

179
00:11:35,640 --> 00:11:39,138
into the logs, they're not showing up in the latency data. And the average latency

180
00:11:39,296 --> 00:11:43,034
is shown to be reasonable hypothesis.

181
00:11:43,734 --> 00:11:47,526
And just like that, Barb has brought Alice over next

182
00:11:47,550 --> 00:11:51,422
to her. So instead of Barb digging into graphs

183
00:11:51,438 --> 00:11:54,886
and Alice twiddling her thumbs, Barb and Alice are looking at the

184
00:11:54,910 --> 00:11:59,174
same thing from the same point of view. And that is so powerful

185
00:11:59,294 --> 00:12:03,102
and so critical during an incident when you're under time pressure and

186
00:12:03,118 --> 00:12:06,940
you have to come up with a plan and share the plan, looking at everything

187
00:12:07,012 --> 00:12:10,384
from the same point of view, you have to have common ground.

188
00:12:11,204 --> 00:12:14,884
So here's their common ground. Two symptoms, one hypothesis.

189
00:12:15,004 --> 00:12:18,172
And that means they're ready to act. They think of two things to

190
00:12:18,188 --> 00:12:21,724
do. The first thing they're going to do is check the local kernel

191
00:12:21,764 --> 00:12:26,092
logs for any crashes. That would be evidence of that hypothesis.

192
00:12:26,268 --> 00:12:29,452
And the second thing they're going to do is read the readme for

193
00:12:29,468 --> 00:12:33,052
the flower surface. Because neither of these people is that familiar with

194
00:12:33,108 --> 00:12:35,504
what goes on inside the flower surface and what it does,

195
00:12:36,484 --> 00:12:40,424
they assign each other to those tasks explicitly.

196
00:12:41,044 --> 00:12:44,756
Now Barb's task takes a little longer because the kernel logs

197
00:12:44,780 --> 00:12:48,824
aren't in the log centralization system that

198
00:12:49,124 --> 00:12:53,284
they have at this company. Alice finishes reading the readme

199
00:12:53,324 --> 00:12:57,140
pretty fast and she comes back says, I have a new hypothesis from

200
00:12:57,172 --> 00:13:00,908
having read the readme. It jogged my thinking process.

201
00:13:01,076 --> 00:13:04,668
So hypothesis number two, maybe some downstream

202
00:13:04,716 --> 00:13:08,412
process, some process that is a client to the flower service

203
00:13:08,548 --> 00:13:11,612
is sending the flower service less traffic. Maybe the

204
00:13:11,628 --> 00:13:15,252
flower service is running because it's getting

205
00:13:15,308 --> 00:13:18,804
less traffic and it was over provisioned. So the traffic it is still getting

206
00:13:18,884 --> 00:13:21,824
can be served with less resource contention.

207
00:13:22,484 --> 00:13:27,024
Another reasonable hypothesis. So while they're discussing this hypothesis,

208
00:13:27,404 --> 00:13:30,704
they get that second page. They get that page about the honeybee service,

209
00:13:31,484 --> 00:13:34,900
fine, no reason to panic. They take that page,

210
00:13:34,932 --> 00:13:38,116
they add it to the symptoms list. They got an alert

211
00:13:38,180 --> 00:13:41,932
at 854 utc that the honeybee services error rate

212
00:13:42,108 --> 00:13:46,276
is elevated and

213
00:13:46,420 --> 00:13:49,964
that jogs their memory and makes them come up with a new third

214
00:13:50,004 --> 00:13:53,532
hypothesis. Which is maybe connections to the flower service

215
00:13:53,708 --> 00:13:57,596
are getting dropped at the tcp level. So maybe there's a,

216
00:13:57,700 --> 00:14:01,652
maybe there's like a. I know, we know there's a proxy on the flower service,

217
00:14:01,748 --> 00:14:05,140
the little Nginx that sits there, maybe that's dropping the requests.

218
00:14:05,252 --> 00:14:07,744
And so fewer requests are getting to the flower service.

219
00:14:08,724 --> 00:14:12,844
Okay, well now they got three hypotheses so they can start coming up with actions

220
00:14:12,924 --> 00:14:17,300
that can rule out or fortify

221
00:14:17,452 --> 00:14:21,136
any number of these hypotheses. For example, action three that

222
00:14:21,160 --> 00:14:24,688
Alice and Barb come up with is what if we check whether the honeybee

223
00:14:24,736 --> 00:14:27,744
and the flower disturbances started at the same time?

224
00:14:27,784 --> 00:14:32,124
Look at some graphs, compare some graphs, see if these two things are actually related.

225
00:14:32,984 --> 00:14:36,176
And the fourth action they come up with is to get Devon

226
00:14:36,200 --> 00:14:39,872
on the call, because they both happen to know Devon, another engineer on

227
00:14:39,888 --> 00:14:43,404
the team, knows a lot more about the honeybee surface than they do.

228
00:14:43,904 --> 00:14:47,508
We're in such a better place now than we were in

229
00:14:47,596 --> 00:14:51,068
the previous. In the. In the previous

230
00:14:51,196 --> 00:14:54,996
incident, because we are all looking at the same

231
00:14:55,180 --> 00:14:58,452
plan, we all have the same information, and any

232
00:14:58,508 --> 00:15:02,068
discrepancies between how we're thinking about the problem are taken care of by the

233
00:15:02,076 --> 00:15:05,340
fact that this is all explicit. Alice can go look at those

234
00:15:05,372 --> 00:15:09,636
graphs and she sees, oh, look at that. We had a

235
00:15:09,660 --> 00:15:13,862
linearly growing error rate from the honeybee service before the

236
00:15:13,878 --> 00:15:18,222
flower services throughput dropped. That's pretty interesting.

237
00:15:18,358 --> 00:15:22,034
So that means that any hypothesis that,

238
00:15:22,414 --> 00:15:26,062
in which these two things are independent,

239
00:15:26,158 --> 00:15:29,622
or that the honeybee error rate dropped

240
00:15:29,758 --> 00:15:33,622
after this, implies that the

241
00:15:33,718 --> 00:15:37,030
honeybee problem, which showed an increasing error rate before

242
00:15:37,102 --> 00:15:41,154
there were any observations from the pollen tokens count,

243
00:15:41,854 --> 00:15:45,774
must be prior in the causal chain to

244
00:15:45,854 --> 00:15:49,566
whatever's causing the throughput of the honey bee service to drop.

245
00:15:49,750 --> 00:15:53,278
That's really important because that lets us

246
00:15:53,366 --> 00:15:56,966
rule out hypothesis one, which is that the flower service is

247
00:15:57,030 --> 00:16:00,630
crashing on some kind of request. And it lets us rule out

248
00:16:00,702 --> 00:16:04,150
hypothesis three, which was that the connections

249
00:16:04,182 --> 00:16:07,674
to the flower service are getting dropped at the tcp level, because that

250
00:16:07,814 --> 00:16:11,978
would not have been caused by anything that shows

251
00:16:12,026 --> 00:16:16,594
the flower, the honeybee surface to be getting errors

252
00:16:16,634 --> 00:16:20,266
before the flower service. Sawney,

253
00:16:20,370 --> 00:16:24,338
any results? So we've ruled out two hypotheses,

254
00:16:24,386 --> 00:16:28,130
which is more progress toward a solution. We also

255
00:16:28,162 --> 00:16:31,866
get Devin on the call. There's Devin. So now when

256
00:16:31,890 --> 00:16:35,436
Seth shows up and starts asking questions like, are these

257
00:16:35,460 --> 00:16:38,756
two alerts part of the same issue? What's our plan? Many of the answers to

258
00:16:38,780 --> 00:16:42,380
Seth's questions are already on screen. Since Seth

259
00:16:42,412 --> 00:16:46,196
was mostly asking those questions because he was stressed out and not sure if his

260
00:16:46,220 --> 00:16:49,884
team was on it, he can now rest

261
00:16:49,924 --> 00:16:53,356
easy in the corner and lurk, secure in the knowledge

262
00:16:53,380 --> 00:16:57,060
that his team is on it. And they do have a plan. And likewise,

263
00:16:57,092 --> 00:17:00,942
when ding, ding, ding, the support team joins and

264
00:17:00,958 --> 00:17:04,286
they want to tell us about their honeybee problem, well,

265
00:17:04,430 --> 00:17:07,742
we can say we're aware of that. We're taking it

266
00:17:07,758 --> 00:17:11,606
seriously. We have that here on our symptom list. If you'd like

267
00:17:11,630 --> 00:17:14,886
us to add the customer reports that you've got, like, we can

268
00:17:14,910 --> 00:17:19,234
add those to the symptom list so support can

269
00:17:20,414 --> 00:17:23,686
tell customers that we're working on their problem. They can post

270
00:17:23,710 --> 00:17:27,190
to the status page, and they can go on the sidelines

271
00:17:27,222 --> 00:17:30,765
and do their job while leaving the

272
00:17:30,789 --> 00:17:33,393
incident calls bandwidth mostly untouched.

273
00:17:34,173 --> 00:17:37,113
So compared to the chaos of the other timeline,

274
00:17:37,893 --> 00:17:41,213
which looked like this, we're in a much better place.

275
00:17:41,333 --> 00:17:45,221
We're in a much better place because we've leveraged Alice much more despite

276
00:17:45,277 --> 00:17:47,673
her limited familiarity with the systems in question.

277
00:17:48,653 --> 00:17:52,341
We're much better placed because anyone new who joins the call

278
00:17:52,397 --> 00:17:56,056
can easily spin up context, and we're much closer to

279
00:17:56,080 --> 00:17:59,704
understanding the problem. We've already ruled out a whole class of hypotheses,

280
00:17:59,864 --> 00:18:03,856
and we have more symptoms that we can

281
00:18:03,960 --> 00:18:07,240
use to generate more hypotheses. And that's all

282
00:18:07,272 --> 00:18:11,000
because we followed through on a simple commitment to

283
00:18:11,192 --> 00:18:15,000
clinical troubleshooting. Now, clinical troubleshooting is very

284
00:18:15,032 --> 00:18:18,272
simple. You can use it unilaterally today. You can just start using it,

285
00:18:18,368 --> 00:18:21,652
and it's simple enough to explain it on the

286
00:18:21,668 --> 00:18:24,972
fly to whoever you're troubleshooting with.

287
00:18:25,108 --> 00:18:27,984
And I guarantee you'll get results immediately.

288
00:18:29,244 --> 00:18:32,556
You'll be blown away by how fast the scientific procedure helps

289
00:18:32,580 --> 00:18:36,292
you solve issues and how consistently

290
00:18:36,348 --> 00:18:39,584
it helps you get to the bottom of issues, even when they're very confusing.

291
00:18:40,204 --> 00:18:43,580
But I can give you a few tips for how to

292
00:18:43,612 --> 00:18:47,624
use the process as effectively as possible,

293
00:18:48,564 --> 00:18:51,956
starting with when you're assembling a team. When you're assembling the

294
00:18:51,980 --> 00:18:55,144
group that's going to do clinical troubleshooting together,

295
00:18:55,564 --> 00:18:59,624
you need to make sure that you're bringing

296
00:19:00,444 --> 00:19:02,904
as diverse perspectives as you can.

297
00:19:03,324 --> 00:19:08,076
So you're going to want to have engineers who

298
00:19:08,100 --> 00:19:13,276
are specialists in different parts of the stack. You're going to want to have maybe

299
00:19:13,300 --> 00:19:16,712
a support person because they have perspective on the customers

300
00:19:16,808 --> 00:19:20,680
or, you know, a solutions

301
00:19:20,752 --> 00:19:24,484
engineer or something because they're going to have perspectives on how customers use the product.

302
00:19:25,264 --> 00:19:29,064
You're going to want to have, you know, as many different roles

303
00:19:29,104 --> 00:19:32,284
as you can, because when you have more roles,

304
00:19:32,864 --> 00:19:36,160
more more perspectives on the call, you're going to generate

305
00:19:36,192 --> 00:19:39,872
a wider array of hypotheses, which is going to help you solve the

306
00:19:39,888 --> 00:19:43,930
issue faster. You also want to make sure that as

307
00:19:43,962 --> 00:19:47,546
you talk about the issue, you keep bringing focus back to the

308
00:19:47,570 --> 00:19:51,034
dock. People are going to propose different ways of doing things,

309
00:19:51,074 --> 00:19:55,146
and they're maybe not going to be thinking about the clinical troubleshooting

310
00:19:55,210 --> 00:19:58,874
procedure unless you, as the leader of the troubleshooting

311
00:19:58,914 --> 00:20:02,130
effort, keep bringing focus back to the doc, adding the things

312
00:20:02,162 --> 00:20:05,970
that they're saying to the doc if they

313
00:20:06,002 --> 00:20:09,652
fit, and trying to in

314
00:20:09,668 --> 00:20:13,308
a different direction if they don't fit. You'll see what I

315
00:20:13,316 --> 00:20:16,684
mean in a second. When we talk about symptoms and hypotheses. So symptoms,

316
00:20:16,844 --> 00:20:20,156
when you're coming up with symptoms, you want your symptoms to

317
00:20:20,180 --> 00:20:23,724
be meaning that they are statements of

318
00:20:23,764 --> 00:20:27,492
fact about the observed behavior of the system.

319
00:20:27,668 --> 00:20:30,184
You want them to be quantitative as possible.

320
00:20:31,204 --> 00:20:34,392
Sometimes you can't be, but to the extent that you

321
00:20:34,408 --> 00:20:38,000
can be, you want to associate your symptoms with

322
00:20:38,192 --> 00:20:41,976
numbers and dimensions. And then finally

323
00:20:42,000 --> 00:20:45,456
you want to make sure you have no supposition in your

324
00:20:45,640 --> 00:20:49,472
symptoms. So state the facts, state them as quantitatively

325
00:20:49,488 --> 00:20:52,976
as you can, and save the suppositions about what might be

326
00:20:53,000 --> 00:20:56,604
going on. For the hypothesis column. For example,

327
00:20:58,144 --> 00:21:01,584
if you have the hypothesis, the flower surface throughput dropped by about 40%

328
00:21:01,624 --> 00:21:04,726
at 841 utc. That's a well formed symptom.

329
00:21:04,870 --> 00:21:08,254
It is an objective statement about the observed

330
00:21:08,294 --> 00:21:09,074
facts.

331
00:21:12,294 --> 00:21:16,230
It is quantitative. It has numbers

332
00:21:16,262 --> 00:21:20,862
on two dimensions, time and throughput. And it

333
00:21:20,878 --> 00:21:25,354
doesn't have any supposition about why that observation,

334
00:21:25,814 --> 00:21:29,702
why that fact is occurring. Whereas if your hypoth,

335
00:21:29,758 --> 00:21:33,174
if your symptom is just the flower service is dropping requests,

336
00:21:33,334 --> 00:21:36,254
it's not quantitative, it doesn't have any numbers in it.

337
00:21:36,334 --> 00:21:40,594
It's not. And it contains a supposition about

338
00:21:41,334 --> 00:21:44,726
why the throughput number changed.

339
00:21:44,750 --> 00:21:48,542
Right? It's a subtle supposition because, yeah, if the throughput

340
00:21:48,598 --> 00:21:52,206
dropped, it looks like the service is dropping requests. But as we've seen

341
00:21:52,270 --> 00:21:56,230
from our example, maybe it's not dropping requests. Right? That's a supposition

342
00:21:56,422 --> 00:21:59,554
based on the symptom that goes in the hypothesis column.

343
00:22:00,054 --> 00:22:03,662
Speaking of the hypothesis column, you want your hypotheses to

344
00:22:03,718 --> 00:22:06,794
be explanatory,

345
00:22:07,534 --> 00:22:10,806
meaning that they explain one or more of the symptoms,

346
00:22:10,950 --> 00:22:14,222
or could potentially explain one or more of the symptoms. And you

347
00:22:14,238 --> 00:22:17,838
want them to be falsifiable, which is a

348
00:22:17,846 --> 00:22:20,234
little tricky concept, but essentially means testable.

349
00:22:20,614 --> 00:22:24,884
Falsifiable means if the hypothesis were wrong,

350
00:22:25,664 --> 00:22:28,976
you would be able to prove that it's wrong by taking some action. You should

351
00:22:29,000 --> 00:22:32,240
be able to imagine something you could do that

352
00:22:32,272 --> 00:22:36,244
would disprove that hypothesis. This is

353
00:22:36,664 --> 00:22:40,408
pretty important, because if you have

354
00:22:40,496 --> 00:22:44,376
hypotheses that are not falsifiable, then you can

355
00:22:44,400 --> 00:22:47,744
go chasing your tail for a long time trying

356
00:22:47,784 --> 00:22:51,434
to prove them. Actually, you should be trying

357
00:22:51,474 --> 00:22:54,882
to disprove them or create

358
00:22:54,938 --> 00:22:58,274
more hypotheses that you can then disprove. It's really all about

359
00:22:58,314 --> 00:23:01,770
ruling things out, not proving things,

360
00:23:01,962 --> 00:23:04,818
which is a little bit of a mental shift that you have to make if

361
00:23:04,826 --> 00:23:08,574
you're going to use this procedure effectively. For example,

362
00:23:09,634 --> 00:23:13,450
a downstream service is bottlenecked, which results in less traffic reaching

363
00:23:13,482 --> 00:23:16,472
flour. It's a pretty good simulation, pretty good hypothesis.

364
00:23:16,568 --> 00:23:20,008
It's explanatory, it explains the two symptoms that we've observed,

365
00:23:20,096 --> 00:23:23,792
and it's falsifiable because you could

366
00:23:23,968 --> 00:23:27,440
prove, you could show that the same amount of traffic is reaching

367
00:23:27,472 --> 00:23:31,232
flower, it's not actually receiving less traffic, and then that would disprove

368
00:23:31,288 --> 00:23:34,992
that hypothesis, which would be progress. If you have

369
00:23:35,008 --> 00:23:38,284
the hypothesis the flower service is crashing,

370
00:23:38,664 --> 00:23:42,176
that's not a good hypothesis because first of all,

371
00:23:42,280 --> 00:23:45,480
it might not be falsifiable. Depending on your stack,

372
00:23:45,512 --> 00:23:49,124
it may not be possible to prove that the flower service is not crashing.

373
00:23:49,904 --> 00:23:53,760
And second of all, it doesn't really provide a clear explanation

374
00:23:53,792 --> 00:23:56,984
of the symptoms. Like, okay, maybe the flower

375
00:23:57,024 --> 00:24:00,472
surface is crashing, but why is that causing throughput and latency to

376
00:24:00,488 --> 00:24:03,924
drop? It's not clear from the way the hypothesis is written.

377
00:24:04,464 --> 00:24:07,990
So finally, that brings us to the

378
00:24:08,022 --> 00:24:11,622
actions column. So there's a

379
00:24:11,638 --> 00:24:15,034
few different kinds of actions that you can take as part of a clinical troubleshooting

380
00:24:15,654 --> 00:24:20,070
effort. You can take rule out actions

381
00:24:20,222 --> 00:24:23,646
which rule out one or more of the hypotheses, and that's what gets

382
00:24:23,670 --> 00:24:26,926
you closer to the definitive diagnosis of the problem that you're

383
00:24:26,950 --> 00:24:30,422
seeking. So that's the main kind of action that you're going to

384
00:24:30,438 --> 00:24:33,892
want to take as you're going through this process. However, you can also take

385
00:24:33,948 --> 00:24:38,052
research actions which don't rule anything out precisely,

386
00:24:38,148 --> 00:24:42,212
but they will help you generate more symptoms and more hypotheses,

387
00:24:42,348 --> 00:24:45,504
which will hopefully make the path forward.

388
00:24:47,324 --> 00:24:50,900
And finally, you want to. So you should

389
00:24:50,932 --> 00:24:55,260
try wherever possible to use what are called diagnostic interventions.

390
00:24:55,412 --> 00:24:58,836
Diagnostic interventions are actions that may

391
00:24:58,940 --> 00:25:02,772
just fix the problem if a particular hypothesis is right.

392
00:25:02,948 --> 00:25:06,348
But otherwise, if they don't fix the problem, then they at

393
00:25:06,356 --> 00:25:09,436
least rule that hypothesis out. And that sort of kills two birds with

394
00:25:09,460 --> 00:25:11,704
1 st when you can find one.

395
00:25:13,444 --> 00:25:17,868
So, for example, a rule out action is

396
00:25:18,036 --> 00:25:21,324
check whether the flower and the honeybee disturbances started at the same time.

397
00:25:21,484 --> 00:25:25,076
If you, as we saw, if you do that and they,

398
00:25:25,140 --> 00:25:28,904
and they, you can learn something that will allow you to

399
00:25:28,944 --> 00:25:32,504
rule out one or more of the hypotheses. A research

400
00:25:32,584 --> 00:25:36,004
action is something like read the flower surfaces. Read me.

401
00:25:38,024 --> 00:25:41,632
Reading the readme isn't going to rule anything out, but it may

402
00:25:41,808 --> 00:25:45,776
give you some ideas about symptoms that you can go

403
00:25:45,920 --> 00:25:49,176
check, or hypotheses that you

404
00:25:49,360 --> 00:25:53,324
may be able to falsify or that may explain the symptoms.

405
00:25:53,864 --> 00:25:57,880
And then finally, an example of a diagnostic

406
00:25:57,912 --> 00:26:01,400
intervention is say we had a hypothesis that

407
00:26:01,432 --> 00:26:04,896
the honeybee service was having this elevated error rate

408
00:26:04,920 --> 00:26:08,712
because of some bad object that was in its cache.

409
00:26:08,848 --> 00:26:12,536
If you were to clear the honeybee services cache, that would be a diagnostic

410
00:26:12,560 --> 00:26:15,760
intervention. Because if it fixes the problem,

411
00:26:15,952 --> 00:26:19,340
then great, we fixed the problem. We know that was

412
00:26:19,372 --> 00:26:23,172
something like what the problem was. If we clear the cache and

413
00:26:23,188 --> 00:26:26,340
it doesn't fix the problem, then we get to rule out that

414
00:26:26,372 --> 00:26:29,944
hypothesis. So either way, we're making progress.

415
00:26:30,564 --> 00:26:34,444
So those are my tips. And like I said, if you practice clinical

416
00:26:34,484 --> 00:26:37,820
troubleshooting in your you're going to have shorter

417
00:26:37,852 --> 00:26:41,384
incidents, fewer incidents, and less stressful incidents.

418
00:26:42,204 --> 00:26:45,586
And I love to hear

419
00:26:45,610 --> 00:26:48,930
from you about that. So if you are going to do this, if you do

420
00:26:48,962 --> 00:26:52,098
this and you have questions about it, or you want to tell me

421
00:26:52,106 --> 00:26:55,534
a success story or a failure story, there's my email address. Dan,

422
00:26:56,754 --> 00:27:00,170
I also urge you to check out my blog, which covers topics

423
00:27:00,202 --> 00:27:02,734
in sre incident response, observability,

424
00:27:04,074 --> 00:27:07,442
and it's a very good blog. So I'm excited to

425
00:27:07,458 --> 00:27:10,914
hear from you as you try this out. Oh, also, I teach a

426
00:27:10,954 --> 00:27:14,054
four day incident response course for engineering teams.

427
00:27:14,234 --> 00:27:17,834
You can check that out at d two e engineering for more info on that.

428
00:27:18,254 --> 00:27:22,190
Before I go, I also want to sincerely thank Miko Polakowski,

429
00:27:22,302 --> 00:27:25,950
the indefatigable host of Conf 42, for making this incredible

430
00:27:25,982 --> 00:27:29,414
event happening happen and giving me the opportunity to

431
00:27:29,454 --> 00:27:33,514
speak to all you fine folks out there in the inner sphere.

432
00:27:33,854 --> 00:27:35,134
You've been a fantastic audience.

