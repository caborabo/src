1
00:00:27,200 --> 00:00:30,958
Hello everyone, welcome in this talk I am going to share some strategies

2
00:00:31,006 --> 00:00:34,838
and tools that can help sres in adopting AI tools in various

3
00:00:34,886 --> 00:00:38,982
aspects of their work. SAris core responsibilities are generally defined

4
00:00:39,038 --> 00:00:41,994
as improving reliability, scalability, performance,

5
00:00:42,374 --> 00:00:45,154
and response time while reducing cost.

6
00:00:46,014 --> 00:00:49,674
A good SRE generally automates themselves out of a job,

7
00:00:50,174 --> 00:00:52,914
meaning they shouldnt have to do the same task again.

8
00:00:53,594 --> 00:00:57,106
Here are a few key responsibilities that a typical sres would have

9
00:00:57,170 --> 00:01:00,610
and where AI can help. Alerting and monitoring systems and

10
00:01:00,642 --> 00:01:03,494
configurations are a big part of what sres do.

11
00:01:03,994 --> 00:01:08,362
Various AI tools and methodologies can be used for efficient filtering,

12
00:01:08,418 --> 00:01:11,578
monitoring, and anomaly detection. AI can

13
00:01:11,626 --> 00:01:15,418
also help with faster incident response by assisting with analysis

14
00:01:15,466 --> 00:01:18,938
and summarization. More and more

15
00:01:19,026 --> 00:01:22,990
tools are using AI and machine learning models for forecasting

16
00:01:23,022 --> 00:01:27,114
and predictive analysis that can be used for capacity planning.

17
00:01:27,454 --> 00:01:30,598
AI, especially generative AI, can also

18
00:01:30,646 --> 00:01:33,634
be helpful in reducing toil for many tasks.

19
00:01:34,094 --> 00:01:37,954
Let's take a look at these areas in a bit more detail.

20
00:01:38,574 --> 00:01:42,474
Supervised learning, a type of machine learning, can be useful

21
00:01:43,014 --> 00:01:47,176
in more efficient filtering and prioritization of alerts.

22
00:01:47,350 --> 00:01:51,164
By training models on historical incident data, AI can

23
00:01:51,204 --> 00:01:54,704
learn to distinguish between genuine and false alert,

24
00:01:55,244 --> 00:01:59,424
effectively reducing noise and enhancing the focus on critical issues.

25
00:02:00,044 --> 00:02:03,580
Additionally, these models can assess that the

26
00:02:03,612 --> 00:02:07,388
severity of incidents by recognizing patterns that correlates

27
00:02:07,436 --> 00:02:11,700
with major disruptions. This capability allows

28
00:02:11,732 --> 00:02:15,590
sres to prioritize the response more effectively,

29
00:02:15,782 --> 00:02:19,710
ensuring that the most damaging issues are addressed

30
00:02:19,742 --> 00:02:23,554
promptly while minimizing the distractions of false alarms.

31
00:02:24,134 --> 00:02:27,974
This approach not only improves response time, but also helps in the allocation

32
00:02:28,014 --> 00:02:30,234
of resources where they are needed the most.

33
00:02:30,934 --> 00:02:34,654
Traditional static thresholds for system alerts

34
00:02:34,774 --> 00:02:38,286
often either lead to a flood of notification during

35
00:02:38,350 --> 00:02:42,252
peak load or miss early signs of critical issues

36
00:02:42,348 --> 00:02:45,812
during lower activity period. By employing

37
00:02:45,908 --> 00:02:49,732
AI driven forecasting model, dynamic thresholds can be set

38
00:02:49,868 --> 00:02:53,444
that adjust based on predicted changes

39
00:02:53,524 --> 00:02:56,908
in the system behavior or load. This method uses

40
00:02:56,956 --> 00:03:00,196
historical data to forecast future states and adjust

41
00:03:00,260 --> 00:03:03,716
alert sensitivity accordingly, enhancing the systems

42
00:03:03,740 --> 00:03:07,944
ability to preemptively flag potential issues before they escalate.

43
00:03:08,404 --> 00:03:13,852
Dynamic thresholds help maintain system stability can

44
00:03:13,948 --> 00:03:17,940
preemptively manage potential bottlenecks or

45
00:03:17,972 --> 00:03:21,468
failures, thus allowing for more proactive

46
00:03:21,556 --> 00:03:24,464
rather than reactive management strategies.

47
00:03:25,044 --> 00:03:28,740
By continuously monitoring system metrics

48
00:03:28,932 --> 00:03:33,464
and logs, AI algorithms can detect anomalies that mean

49
00:03:33,644 --> 00:03:37,136
indicate emerging issues, often before

50
00:03:37,200 --> 00:03:41,136
they are apparent to human observers. Capability enables

51
00:03:41,160 --> 00:03:45,104
sres to quickly identify and mitigate problems, often automating

52
00:03:45,144 --> 00:03:48,960
the response to standard issues without human

53
00:03:48,992 --> 00:03:52,368
intervention. For instance, an AI system can detect

54
00:03:52,416 --> 00:03:55,920
an unusual increase in response

55
00:03:55,952 --> 00:03:59,416
time for service and can trigger an auto scaling action

56
00:03:59,480 --> 00:04:03,064
or restart the service without needing direct human oversight.

57
00:04:03,604 --> 00:04:07,468
This not only speeds up the resolution process, but also helps in maintaining

58
00:04:07,516 --> 00:04:10,904
high availability and performance consistency across services.

59
00:04:11,764 --> 00:04:15,820
Tools such as Grafana offer powerful capabilities for dynamic

60
00:04:15,852 --> 00:04:19,788
alerting and metric forecasting that are essential for

61
00:04:19,876 --> 00:04:23,420
modern sari practices. Grafana integrates

62
00:04:23,572 --> 00:04:27,532
machine learning tools that can analyze the time series

63
00:04:27,588 --> 00:04:31,364
data to forecast future trends and automatically adjust

64
00:04:31,404 --> 00:04:34,024
alert threshold based on these predictions.

65
00:04:34,524 --> 00:04:38,188
These integrations allow sres to visualize complex

66
00:04:38,236 --> 00:04:42,304
data and receive alerts that are both timely and contextually relevant,

67
00:04:42,884 --> 00:04:46,924
reducing the overhead of manual threshold management. By leveraging such

68
00:04:46,964 --> 00:04:50,676
tools, sres can enhance their monitoring system with

69
00:04:50,740 --> 00:04:53,978
automated intelligence, making it easier to handle

70
00:04:54,076 --> 00:04:57,814
large scale systems efficiently. An effective strategy

71
00:04:57,854 --> 00:05:01,590
for anomaly detection starts with establishing a

72
00:05:01,622 --> 00:05:04,878
baseline for normal operation matrix

73
00:05:04,926 --> 00:05:08,674
using statistical methods to identify numerical outliers.

74
00:05:09,134 --> 00:05:12,486
This involves calculating statistical parameters such

75
00:05:12,510 --> 00:05:15,982
as mean, median, etcetera to understand

76
00:05:16,078 --> 00:05:19,142
typical system behavior. Once the baseline is

77
00:05:19,158 --> 00:05:22,698
set, any significant deviation from these matrix can

78
00:05:22,746 --> 00:05:26,934
be flagged as an outlier. This initial setup

79
00:05:27,314 --> 00:05:31,226
is crucial as it sets the stage for more sophisticated

80
00:05:31,290 --> 00:05:34,946
analysis and helps in quickly spotting anomalies that falls

81
00:05:34,970 --> 00:05:38,362
outside of the expected pattern, thus enabling

82
00:05:38,418 --> 00:05:41,614
timely interventions to mitigate potential issues.

83
00:05:42,394 --> 00:05:46,062
Advanced techniques such as principal component analysis,

84
00:05:46,178 --> 00:05:49,806
PCA, or density based spatial

85
00:05:49,950 --> 00:05:53,646
clustering of applications commonly known as TB scan,

86
00:05:53,710 --> 00:05:57,630
are employed to further enhance the detection of anomalies

87
00:05:57,782 --> 00:06:01,118
and understand group behavior within the system.

88
00:06:01,166 --> 00:06:04,750
Data. PCA reduces the dimensionality of the data,

89
00:06:04,822 --> 00:06:08,830
highlighting the most significant variations and patterns that are often

90
00:06:08,902 --> 00:06:12,142
obscured in high dimensional data. TP scan, on the

91
00:06:12,158 --> 00:06:15,694
other hand, is excels in identifying clusters of

92
00:06:15,774 --> 00:06:19,206
similar data points in the data set and distinguishing

93
00:06:19,310 --> 00:06:22,994
these from points that do not belong in any cluster.

94
00:06:23,454 --> 00:06:26,694
These techniques together allow not only to

95
00:06:26,774 --> 00:06:31,046
pinpoint unusual activity, but also categorize them into meaningful groups

96
00:06:31,230 --> 00:06:33,754
for easier analysis and troubleshooting.

97
00:06:34,734 --> 00:06:38,190
There are several tools available that indicates machine

98
00:06:38,222 --> 00:06:41,754
learning capabilities specifically designed for anomaly detection.

99
00:06:42,534 --> 00:06:46,074
Machine learning toolkit Kafanas machine learning

100
00:06:46,414 --> 00:06:49,994
outlier detection Davis AI

101
00:06:50,694 --> 00:06:54,190
Datadogs Bitsai each offer unique

102
00:06:54,222 --> 00:06:57,554
features to automate and enhance the detection of anomalies.

103
00:06:57,894 --> 00:07:01,558
Splunk provides a robust platform for real time data analysis,

104
00:07:01,606 --> 00:07:05,198
while Grafana focuses on visualizing trends and patterns that

105
00:07:05,246 --> 00:07:08,954
deviate from the norm. David Ci, part of Dynatrace,

106
00:07:09,054 --> 00:07:12,978
and datadog bits leverage AI to provide predictive

107
00:07:13,026 --> 00:07:16,574
insights and automated root cause analysis as well.

108
00:07:16,874 --> 00:07:20,730
These tools significantly reduce the manual effort involved in monitoring and

109
00:07:20,762 --> 00:07:25,162
diagnosing systems, allowing sres to focus on

110
00:07:25,298 --> 00:07:28,694
strategic tasks and productive system management.

111
00:07:29,554 --> 00:07:32,818
Generative AI can be transformative how

112
00:07:32,866 --> 00:07:36,436
SR is managed and responsible incidents by providing

113
00:07:36,540 --> 00:07:40,684
efficient civilization tools. These AI models are trained to

114
00:07:40,764 --> 00:07:44,172
extract key information from vast amount of incident data,

115
00:07:44,228 --> 00:07:47,264
such as logs, metrics, and user reports,

116
00:07:48,284 --> 00:07:50,704
condensing them into concise summaries.

117
00:07:51,684 --> 00:07:55,164
This capability is crucial during high pressure situations where quick

118
00:07:55,204 --> 00:07:58,836
understanding and actions are required. By automating the

119
00:07:58,860 --> 00:08:02,190
summarization process, SRE teams can swiftly grasp

120
00:08:02,372 --> 00:08:06,506
the scope and impact of an incident, enabling faster decision

121
00:08:06,570 --> 00:08:11,034
making and allocation of resources to address the most critical aspects.

122
00:08:11,114 --> 00:08:15,650
First, tools like DevOps guru leverages

123
00:08:15,722 --> 00:08:18,134
machine learning to automate root cause analysis,

124
00:08:18,674 --> 00:08:22,194
significantly speeding up the identification and resolution

125
00:08:22,234 --> 00:08:26,066
of the issues. The AI power service

126
00:08:26,170 --> 00:08:29,694
continuously analyzes system data to

127
00:08:29,734 --> 00:08:33,566
detect abnormal behaviors and provide contextual insights by

128
00:08:33,590 --> 00:08:36,634
pinpointing the likely cause of operational problem.

129
00:08:37,294 --> 00:08:41,390
It offers recommendations of fixing issues before they escalate,

130
00:08:41,502 --> 00:08:44,714
thereby minimizing downtime and improving system reliability.

131
00:08:45,374 --> 00:08:49,214
By automating these complex processes, sres can address the underlying

132
00:08:49,254 --> 00:08:52,894
cause of incident more quickly and with greater accuracy,

133
00:08:53,054 --> 00:08:57,314
which is crucial for maintaining high service levels and customer satisfaction.

134
00:08:57,924 --> 00:09:01,556
Grafana offers features called Incident auto

135
00:09:01,580 --> 00:09:05,316
summary, which is designed to help team quickly comprehend

136
00:09:05,340 --> 00:09:09,388
the details of an incident without sifting through

137
00:09:09,516 --> 00:09:13,324
overwhelming data. Manually uses algorithms

138
00:09:13,364 --> 00:09:16,892
to highlight significant changes and patterns that led to the incident,

139
00:09:17,068 --> 00:09:20,644
providing a summarized view of events in a clear and digestible

140
00:09:20,684 --> 00:09:24,748
format. Such summaries are invaluable for postmortem analysis

141
00:09:24,796 --> 00:09:28,444
and for keeping stakeholders informed. By automating

142
00:09:28,864 --> 00:09:32,680
the creation of incident summaries, Grafana helps ensuring that

143
00:09:32,752 --> 00:09:36,324
all team members have a consistent understanding of each incident,

144
00:09:36,904 --> 00:09:40,328
which is essential for effective communication and collaboration during a

145
00:09:40,336 --> 00:09:43,720
crisis situation. Capacity planning in the context of

146
00:09:43,752 --> 00:09:47,800
SRE involves forecasting future demand on

147
00:09:47,832 --> 00:09:51,624
system resources and adjusting the infrastructure to handle these demands

148
00:09:51,664 --> 00:09:54,942
efficiently. By utilizing predictive analysis,

149
00:09:54,998 --> 00:09:58,118
SREs can anticipate periods of high demand,

150
00:09:58,286 --> 00:10:02,022
such as seasonal spikes or promotional events,

151
00:10:02,158 --> 00:10:05,754
and proactively scale their system to meet these needs.

152
00:10:06,174 --> 00:10:11,046
This approach helps in avoiding performance bottlenecks and ensure user

153
00:10:11,070 --> 00:10:13,914
experience by maintaining optimal service levels.

154
00:10:14,534 --> 00:10:17,862
Predictive analysis tool analyze historical data

155
00:10:17,918 --> 00:10:20,914
and user trends to model future scenarios,

156
00:10:21,054 --> 00:10:24,546
enabling organizations to make informed decisions about when and how

157
00:10:24,570 --> 00:10:28,330
to scale resources. The integration of ML with

158
00:10:28,362 --> 00:10:31,722
traditional load testing methods forms the backbone of what

159
00:10:31,738 --> 00:10:35,934
is called as machine learning assisted system performance and capacity planning.

160
00:10:36,394 --> 00:10:40,282
This involves. This innovative

161
00:10:40,338 --> 00:10:43,890
approach allows for more accurate and dynamic

162
00:10:44,042 --> 00:10:47,834
capacity planning by predicting how new software changes or user growth

163
00:10:47,914 --> 00:10:51,784
will affect the system. Machine learning algorithm

164
00:10:51,824 --> 00:10:55,368
analyzes past performance data and simulates

165
00:10:55,416 --> 00:10:58,840
various load scenarios to identify potential capacity issues

166
00:10:58,952 --> 00:11:03,032
before they occur in real environment. This proactive technology

167
00:11:03,128 --> 00:11:06,904
helps in optimizing resource allocation, reducing cost, and enhancing

168
00:11:06,944 --> 00:11:10,776
overall system efficiency by ensuring that the infrastructure is

169
00:11:10,800 --> 00:11:13,044
neither underutilized or overwhelmed.

170
00:11:14,224 --> 00:11:17,240
Several advanced tools offer machine

171
00:11:17,272 --> 00:11:20,584
learning capabilities to facilitate predictive analysis in

172
00:11:20,744 --> 00:11:24,232
capacity planning. Splunk's machine learning toolkit allows users

173
00:11:24,248 --> 00:11:27,928
to create custom models tailored to the specific system

174
00:11:28,056 --> 00:11:31,968
dynamics, enabling precise forecasting of system

175
00:11:32,016 --> 00:11:35,968
needs. Dynatrace provides a real time analytics and

176
00:11:36,016 --> 00:11:39,632
automates automatic baselining, which are

177
00:11:39,688 --> 00:11:43,760
crucial for detecting deviations in system performance and

178
00:11:43,952 --> 00:11:47,600
predicting feature. State datadog leverages these

179
00:11:47,632 --> 00:11:51,296
capabilities with a predictive monitoring feature that forecasts the potential

180
00:11:51,360 --> 00:11:54,804
outage and scaling. Need can empower

181
00:11:55,744 --> 00:11:59,104
to harness the power of AI, making more accurate predictions about

182
00:11:59,144 --> 00:12:02,784
system demands, significantly improving the effectiveness of capacity

183
00:12:02,824 --> 00:12:07,534
planning strategies. Generative AI is reshaping

184
00:12:07,704 --> 00:12:11,618
infrastructure as a core practices by offering AI driven assistant that help

185
00:12:11,666 --> 00:12:14,850
automate and optimize the creation of and management

186
00:12:14,922 --> 00:12:18,186
of infrastructure setup. An example of this

187
00:12:18,210 --> 00:12:21,746
is Pulumi, which integrates with an AI assistant to

188
00:12:21,770 --> 00:12:25,474
help developers and sres generate tests

189
00:12:25,554 --> 00:12:29,298
manage IAC script more efficiently. These AI

190
00:12:29,386 --> 00:12:33,466
assistants can suggest best practices, identify potential errors in code,

191
00:12:33,570 --> 00:12:37,180
and even recommend optimizations. This reduces

192
00:12:37,212 --> 00:12:40,644
the cognitive load on engineers and accelerates development cycle

193
00:12:40,764 --> 00:12:44,180
by enabling quicker iteration and deployments,

194
00:12:44,252 --> 00:12:48,068
thereby significantly reducing manual toil in infrastructure

195
00:12:48,116 --> 00:12:51,716
management. Machine learning is increasingly being utilized to

196
00:12:51,740 --> 00:12:55,956
enhance testing process in software development.

197
00:12:56,140 --> 00:12:59,292
Tools like Mabel testimony leverages AI to

198
00:12:59,308 --> 00:13:02,840
automatically create, execute and maintain testing

199
00:13:02,872 --> 00:13:06,352
suits. These platforms use machine learning to understand the

200
00:13:06,368 --> 00:13:09,904
application behavior over time, allowing them to adapt test

201
00:13:10,024 --> 00:13:13,616
dynamically and as the application evolves.

202
00:13:13,800 --> 00:13:17,680
These capabilities minimizes the need for manual test maintenance,

203
00:13:17,832 --> 00:13:21,656
which is often time consuming and prone to error.

204
00:13:21,840 --> 00:13:25,512
By automating these aspects, machine learning not only speeds of the testing process,

205
00:13:25,568 --> 00:13:29,132
but also enhances its accuracy reliability, freeing up the

206
00:13:29,148 --> 00:13:31,664
benefit for more complex and creative tasks.

207
00:13:32,124 --> 00:13:35,796
Managing and reducing technical debt is a crucial part of maintaining the health of health

208
00:13:35,820 --> 00:13:40,132
and scalability of software. Tools like sonar codeclimate

209
00:13:40,188 --> 00:13:43,948
provide automated code reviews, services that helps developer identify

210
00:13:43,996 --> 00:13:47,572
and fix quality issues that contributes to technical needs

211
00:13:47,628 --> 00:13:50,636
such as code smells, bulk security vulnerabilities,

212
00:13:50,740 --> 00:13:54,044
etcetera. By integrating these tools in

213
00:13:54,204 --> 00:13:58,524
the CI CD pipeline, teams can ensure continuous

214
00:13:58,684 --> 00:14:02,180
code quality checks, which helps prevent the accumulation

215
00:14:02,252 --> 00:14:06,236
of technical debt over time. Moreover, these tools offer actionable

216
00:14:06,300 --> 00:14:10,020
insight and metrics that aid in decision making regarding

217
00:14:10,092 --> 00:14:13,740
refactoring efforts, ultimately ensuring that the

218
00:14:13,772 --> 00:14:16,424
code base remains clean, efficient, and maintainable.

219
00:14:16,964 --> 00:14:20,840
Adapting to using AI tools, of course,

220
00:14:20,872 --> 00:14:24,056
comes with many challenges as well. AI technologies

221
00:14:24,160 --> 00:14:27,924
often require a level of expertise that may not exist within the current team.

222
00:14:28,384 --> 00:14:32,192
This lack of skills can be a significant barrier to

223
00:14:32,208 --> 00:14:35,496
the successful implementation of and uses of AI tools.

224
00:14:35,680 --> 00:14:39,536
Invest in training existing staff and consider hiring new

225
00:14:39,560 --> 00:14:42,896
team member with unnecessary skill sets. There are plenty

226
00:14:42,920 --> 00:14:46,624
of resources and courses available online to train your team on AI

227
00:14:46,664 --> 00:14:50,920
tools and technologies. AI tools rely on quality

228
00:14:50,952 --> 00:14:54,296
of data to deliver reliable insights. Data might

229
00:14:54,320 --> 00:14:57,736
be unclean, unstructured, or siloed across different systems,

230
00:14:57,920 --> 00:15:01,744
which can hinder the effectiveness of AI. Implement robust

231
00:15:01,784 --> 00:15:05,056
data management and governance practices to ensure your data is

232
00:15:05,080 --> 00:15:08,524
clean, structured and accessible. AI tools itself

233
00:15:09,344 --> 00:15:12,728
can also be used to assist in data cleansing and structuring

234
00:15:12,776 --> 00:15:16,976
process. People can also be resistant to new technologies,

235
00:15:17,120 --> 00:15:20,164
especially when it comes to something as transformative as AI.

236
00:15:20,784 --> 00:15:24,696
Resistance can slow down or even halt the transition to AI

237
00:15:24,760 --> 00:15:28,404
based SRE practices. Develop a strong change management

238
00:15:28,784 --> 00:15:32,336
strategy, which could involve regular communication about

239
00:15:32,360 --> 00:15:35,832
the benefits and importance of the change. Provide training

240
00:15:35,888 --> 00:15:39,120
and support, and gradually integrate AI tools into existing

241
00:15:39,152 --> 00:15:41,864
workflows to allow for us for the transition.

242
00:15:42,484 --> 00:15:45,924
AI tools needs to work in tandem with existing IT systems,

243
00:15:45,964 --> 00:15:49,180
tools and processes. Integration issues can prevent from

244
00:15:49,212 --> 00:15:53,204
AI tools from accessing necessary data or functioning

245
00:15:53,244 --> 00:15:56,932
as expected. Plan integration process carefully ensuring

246
00:15:56,988 --> 00:16:00,964
that the selected AI tools are compatible with your

247
00:16:01,004 --> 00:16:04,508
existing system. Where possible, choose AI solutions that

248
00:16:04,556 --> 00:16:08,104
offer flexible APIs and integration options.

249
00:16:08,534 --> 00:16:12,126
Implementing AI tools can also require a substantial

250
00:16:12,190 --> 00:16:15,790
investment, including purchasing or subscribing to the tool,

251
00:16:15,942 --> 00:16:19,502
integrating them into your existing system and training stock.

252
00:16:19,678 --> 00:16:23,230
Calculate the return on investment before implementation to

253
00:16:23,262 --> 00:16:27,070
understand the potential benefit and saving the AI tool

254
00:16:27,102 --> 00:16:30,982
can provide in the long run. Look for scalable solution that allows you

255
00:16:30,998 --> 00:16:35,220
to start small and increase your investment as you c

256
00:16:35,372 --> 00:16:39,584
value. That's all for

257
00:16:40,124 --> 00:16:43,156
this session. Thank you for tuning in.

258
00:16:43,340 --> 00:16:44,164
Enjoy the conference.

