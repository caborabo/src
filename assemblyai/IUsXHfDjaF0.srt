1
00:00:21,130 --> 00:00:24,966
Hi, myself Deepak. I am working as an associate director for

2
00:00:25,028 --> 00:00:28,146
data science and machine learning projects at Novartis.

3
00:00:28,258 --> 00:00:32,294
I'm also responsible for generative AI project initiatives and

4
00:00:32,332 --> 00:00:35,894
deliverables. Today I'm going to talk about the

5
00:00:35,932 --> 00:00:39,894
evolution of natural language processing by leveraging generative

6
00:00:39,942 --> 00:00:43,370
AI and transformer architecture in healthcare.

7
00:00:44,590 --> 00:00:47,994
I'm going to take a use case and I'll walk you through on the

8
00:00:48,032 --> 00:00:51,390
problems we had in using traditional machine learning

9
00:00:51,460 --> 00:00:55,482
model or the transformer architecture model, and by leveraging generative

10
00:00:55,546 --> 00:00:58,974
AI, how efficiently we can solve the business use

11
00:00:59,012 --> 00:01:02,282
case. All right, without further ado,

12
00:01:02,346 --> 00:01:05,410
let me take you to the next slide.

13
00:01:06,470 --> 00:01:10,286
Okay, the problem statement we have here is anomaly

14
00:01:10,318 --> 00:01:13,506
detection. See, the various domains are various kind

15
00:01:13,528 --> 00:01:16,658
of anomalies can be identified in finance,

16
00:01:16,834 --> 00:01:20,626
in healthcare domains. But when it comes to healthcare,

17
00:01:20,738 --> 00:01:24,322
identifying the anomaly can be any instrumental failure

18
00:01:24,386 --> 00:01:27,838
or any medical device got failured that has to be reported.

19
00:01:27,874 --> 00:01:31,942
That is an anomaly. But there are scenarios like patient

20
00:01:32,006 --> 00:01:35,654
monitoring system where any kind of a potential safety

21
00:01:35,702 --> 00:01:39,110
risk has to be reported to the FDA,

22
00:01:39,270 --> 00:01:42,606
food, drug and administrative so

23
00:01:42,708 --> 00:01:46,858
what is an patient safety risk? Here takes a medicine

24
00:01:46,954 --> 00:01:50,894
and any untoward medical experiences cost

25
00:01:50,932 --> 00:01:55,518
the patients. That is an anomaly or adverse effects

26
00:01:55,614 --> 00:01:59,982
that has to be reported to the FDA. See, anomaly detection

27
00:02:00,046 --> 00:02:03,998
plays a significant role in patient health care reasoning.

28
00:02:04,094 --> 00:02:08,562
Without identifying the anomaly, the patient

29
00:02:08,706 --> 00:02:12,258
has to go through a severe problem on consuming

30
00:02:12,274 --> 00:02:14,760
the medicine for a longer period of time.

31
00:02:15,450 --> 00:02:19,702
Right. So now we are trying to uncover the hidden

32
00:02:19,766 --> 00:02:23,766
patterns and trends by using transformers

33
00:02:23,798 --> 00:02:29,066
architecture. Now see,

34
00:02:29,248 --> 00:02:33,454
let me take a scenario without the evolution of

35
00:02:33,492 --> 00:02:37,230
social media or before the evolution of social

36
00:02:37,300 --> 00:02:41,022
media. If there isn't any anomaly that

37
00:02:41,076 --> 00:02:45,006
would be reported to the physician via email correspondences

38
00:02:45,198 --> 00:02:49,070
or by making a telephone call to the physician

39
00:02:49,150 --> 00:02:52,546
and the anomaly or adversarial event would be

40
00:02:52,568 --> 00:02:54,690
reported to the physicians.

41
00:02:55,530 --> 00:02:59,522
Then they take note of the adversarial

42
00:02:59,666 --> 00:03:03,366
effects or, sorry, adversarial events and that would be

43
00:03:03,388 --> 00:03:07,046
reported to FDA. That is a traditional process

44
00:03:07,148 --> 00:03:10,902
which has been followed. But the recent

45
00:03:10,966 --> 00:03:14,714
evolution of social media causes the

46
00:03:14,752 --> 00:03:19,146
huge amount of data can be posted in social media can

47
00:03:19,168 --> 00:03:22,430
be considered as a platform to detect an anomaly.

48
00:03:23,170 --> 00:03:26,800
Right? Now, let's think about

49
00:03:27,410 --> 00:03:31,082
a social media scenario where we get humongous

50
00:03:31,146 --> 00:03:34,894
amount of data that has to be reviewed

51
00:03:34,942 --> 00:03:38,914
manually. If there isn't any adversary events or anomaly has

52
00:03:38,952 --> 00:03:42,500
been present. Right now

53
00:03:42,950 --> 00:03:47,094
you can think of any pharmaceutical company take a social media platform

54
00:03:47,212 --> 00:03:50,934
for digitizing or making digital advertisement on

55
00:03:50,972 --> 00:03:54,646
any new product launch or any new medicine has been launched in

56
00:03:54,668 --> 00:03:57,890
the market. Now, by consuming that product,

57
00:03:58,060 --> 00:04:01,466
many of the patients may report there could

58
00:04:01,488 --> 00:04:04,970
be an adverse real effects after taking the medicine.

59
00:04:05,310 --> 00:04:08,742
Ideally that can be reported in social media channels

60
00:04:08,806 --> 00:04:11,710
like Twitter, Facebook, Instagram,

61
00:04:12,290 --> 00:04:16,398
LinkedIn or many platforms can be used to report it.

62
00:04:16,564 --> 00:04:21,262
Now, reviewing all the platform and

63
00:04:21,396 --> 00:04:25,614
identifying is there any unusual behavior would be a humongous task

64
00:04:25,662 --> 00:04:27,300
for a human to perform.

65
00:04:29,190 --> 00:04:32,610
That is a practical challenge we have in the healthcare industry.

66
00:04:33,270 --> 00:04:36,470
That is how building a technology by having

67
00:04:36,540 --> 00:04:39,654
artificial intelligence solution in place helps us

68
00:04:39,692 --> 00:04:43,074
to reduce the manual efforts and report the adverseial

69
00:04:43,122 --> 00:04:47,622
effects immediately to the FDA. Now we

70
00:04:47,676 --> 00:04:51,260
follow a process. Let me tell you what is a process.

71
00:04:52,030 --> 00:04:55,994
See now anomaly detection at a glance, right. As I was

72
00:04:56,032 --> 00:04:59,542
saying, the data can be pulled from various

73
00:04:59,606 --> 00:05:03,854
channels or various platform. It could be an email communication or

74
00:05:03,892 --> 00:05:08,014
it can be from any among the Twitter post or,

75
00:05:08,052 --> 00:05:10,746
sorry, Facebook post or Twitter tweets.

76
00:05:10,938 --> 00:05:14,266
All this data has to be pulled

77
00:05:14,298 --> 00:05:17,718
via data connector and it has to be pre processed

78
00:05:17,834 --> 00:05:21,746
to understand if any of the reported text as an

79
00:05:21,848 --> 00:05:24,958
anomaly. Right? Again, as I said,

80
00:05:25,064 --> 00:05:28,614
if we have a manual reviewer who has to go

81
00:05:28,652 --> 00:05:32,626
through humongous data, it is an impossible task

82
00:05:32,658 --> 00:05:35,766
for a human being to perform. But ideally by

83
00:05:35,788 --> 00:05:40,054
leveraging machine learning platform, the efforts can be significantly

84
00:05:40,102 --> 00:05:44,038
reduced. Let me talk on the machine

85
00:05:44,054 --> 00:05:48,070
learning platform or ML algorithm which we develop to identify

86
00:05:48,150 --> 00:05:51,482
an anomaly. Like any ML algorithm,

87
00:05:51,546 --> 00:05:55,514
there is a development process involved. Many organizations

88
00:05:55,562 --> 00:05:59,882
have taken an agile approach to do a machine learning algorithm

89
00:05:59,946 --> 00:06:03,970
development and industrialization of the algorithm development

90
00:06:04,390 --> 00:06:08,130
introduction. So we defined a problem here.

91
00:06:08,280 --> 00:06:12,210
It's more like a text classification where we have to understand

92
00:06:12,360 --> 00:06:15,686
the text as in any anomaly, and that has to

93
00:06:15,708 --> 00:06:18,710
be reported to FDA.

94
00:06:19,210 --> 00:06:23,330
Now let's discuss about the machine learning development

95
00:06:23,490 --> 00:06:26,120
or machine learning algorithm development process.

96
00:06:27,130 --> 00:06:30,070
So for any machine learning algorithm has to be developed,

97
00:06:30,150 --> 00:06:33,642
we need a training data set to train or

98
00:06:33,696 --> 00:06:37,494
fine tune the large language model where we are considering

99
00:06:37,542 --> 00:06:40,926
transformer based architectures model for training

100
00:06:41,028 --> 00:06:44,378
or fine tuning the model and deploying

101
00:06:44,394 --> 00:06:47,918
the model in production. So once we train the model,

102
00:06:48,084 --> 00:06:51,662
we have to evaluate the model with validation and test

103
00:06:51,716 --> 00:06:54,882
data set. Right now, as part

104
00:06:54,936 --> 00:06:58,814
of fine tuning the models, there could be changes in the hyperparameter

105
00:06:58,862 --> 00:07:02,062
tuning which helps us to improve

106
00:07:02,126 --> 00:07:05,226
the model precision, recall and accuracy.

107
00:07:05,358 --> 00:07:08,422
See, the terms in data science refers to how

108
00:07:08,476 --> 00:07:12,226
model is efficaciously identifying

109
00:07:12,258 --> 00:07:16,374
the anomaly. Right now,

110
00:07:16,572 --> 00:07:20,970
this is a process involved as part of algorithm development.

111
00:07:21,310 --> 00:07:25,242
Now let's talk about the data annotation process.

112
00:07:25,376 --> 00:07:28,700
Right now. Why I'm saying data annotation process.

113
00:07:29,070 --> 00:07:32,542
So to train the algorithm, we need a huge amount

114
00:07:32,596 --> 00:07:36,654
of data set to train or fine tune the model,

115
00:07:36,852 --> 00:07:40,218
large language model to perform a specific task.

116
00:07:40,394 --> 00:07:44,254
Now the data annotation is nothing but a labeling

117
00:07:44,302 --> 00:07:48,702
job which would be performed by the annotators.

118
00:07:48,846 --> 00:07:52,286
So the process involved collecting

119
00:07:52,318 --> 00:07:56,018
the training data set. Typically for fine tuning

120
00:07:56,034 --> 00:07:59,798
the large language models, we would require around 20,000

121
00:07:59,884 --> 00:08:04,294
to 30,000 data sets, right? Once we

122
00:08:04,412 --> 00:08:08,342
procure the data set, then we have to manually label

123
00:08:08,486 --> 00:08:12,250
whether that falls under an anomaly or not an anomaly.

124
00:08:12,590 --> 00:08:16,134
For doing this process we need a set of annotators

125
00:08:16,262 --> 00:08:19,590
and ideally they should be a skilled annotators.

126
00:08:19,670 --> 00:08:23,022
Then they would be performing or labeling this data set.

127
00:08:23,156 --> 00:08:26,254
Right. Now let's little bit understand on the data

128
00:08:26,292 --> 00:08:29,886
annotation process. So data annotators would

129
00:08:29,908 --> 00:08:33,534
be following a certain guidelines to understand the sample

130
00:08:33,582 --> 00:08:37,106
data and they have an interagreement on the

131
00:08:37,128 --> 00:08:40,754
training phase to understand how they wanted to label that

132
00:08:40,792 --> 00:08:44,258
as an anomaly. Now there would be a

133
00:08:44,344 --> 00:08:47,814
pick of good annotators. Once we identify them,

134
00:08:47,852 --> 00:08:51,174
we onboard them the annotators and we share the

135
00:08:51,212 --> 00:08:54,822
data set for annotating. In the case of

136
00:08:54,876 --> 00:08:58,694
annotation here, let's assume that we

137
00:08:58,812 --> 00:09:01,930
procured the data set of around 15,000.

138
00:09:02,000 --> 00:09:05,626
So 20,000 to 30,000 data set. Then we

139
00:09:05,648 --> 00:09:08,954
have to label manually whether that is an anomaly or not.

140
00:09:09,072 --> 00:09:12,238
To perform that activity, the annotator should have

141
00:09:12,244 --> 00:09:15,390
a good amount of knowledge in identifying an anomaly.

142
00:09:17,010 --> 00:09:20,682
Once as part of doing the interview process, we identify

143
00:09:20,746 --> 00:09:24,462
the good annotators and we deploy them to do the manual

144
00:09:24,526 --> 00:09:28,098
job to manually label the data set.

145
00:09:28,264 --> 00:09:32,222
Now we have a process involved like annotator

146
00:09:32,286 --> 00:09:36,002
one and annotator two where they would be manually

147
00:09:36,066 --> 00:09:39,650
labeling the data. And finally it goes for another reviewer

148
00:09:39,730 --> 00:09:43,126
who would annotate or validate the

149
00:09:43,148 --> 00:09:46,440
manually labeled data. If there isn't any

150
00:09:46,890 --> 00:09:50,226
contradict on the two annotators which are

151
00:09:50,268 --> 00:09:53,562
performing, then it goes to a fourth annotator to do a final

152
00:09:53,616 --> 00:09:57,590
annotation based on the major oating we do a final labels.

153
00:09:57,750 --> 00:10:02,094
This is the old data annotation process involved in training or

154
00:10:02,132 --> 00:10:04,350
fine tuning the machine learning algorithm.

155
00:10:06,370 --> 00:10:09,646
So now we have talked about the data annotation process.

156
00:10:09,748 --> 00:10:12,730
Then there is a comprehensive AI ML journey,

157
00:10:12,810 --> 00:10:16,446
right? So first we have to develop a balanced

158
00:10:16,478 --> 00:10:19,810
or well balanced data set which would be given for model

159
00:10:19,880 --> 00:10:23,506
fine tuning. Then we have to segregate the

160
00:10:23,528 --> 00:10:26,902
data into training, test and validation for model

161
00:10:26,956 --> 00:10:30,934
training and evaluating the model. See, the model should

162
00:10:30,972 --> 00:10:34,598
have an understanding like human understand

163
00:10:34,684 --> 00:10:38,086
the problem. So that is how the data would

164
00:10:38,108 --> 00:10:41,340
be curated and would be given for the model training.

165
00:10:41,790 --> 00:10:45,670
See, as part of the AI implementation model journey,

166
00:10:45,750 --> 00:10:50,130
we use large language models which would be based on transformer architecture.

167
00:10:50,310 --> 00:10:54,554
It can be a Bert or excel, robota or GPT

168
00:10:54,682 --> 00:10:57,886
models would be used. So as part of the

169
00:10:57,908 --> 00:11:01,546
whole process, we ensure repeatability and auditability

170
00:11:01,658 --> 00:11:04,918
is captured in our system design reasoning.

171
00:11:05,034 --> 00:11:08,382
Once we say as an anomaly, this large language models,

172
00:11:08,446 --> 00:11:12,306
again, if you do an inference or prediction, it should say as an

173
00:11:12,328 --> 00:11:15,958
anomaly, there should not be any deviation in

174
00:11:16,044 --> 00:11:20,006
the prediction or in the output. See, the whole thing is

175
00:11:20,028 --> 00:11:23,634
an complete risk management framework to identify

176
00:11:23,762 --> 00:11:25,800
the anomaly. Right?

177
00:11:27,130 --> 00:11:30,006
Now, let's take a real example.

178
00:11:30,188 --> 00:11:33,654
Once we identify the large language

179
00:11:33,702 --> 00:11:37,194
model, we perform fine tuning on the models. Then we

180
00:11:37,232 --> 00:11:40,526
evaluate the model whether it is performing according to

181
00:11:40,548 --> 00:11:43,242
a benchmark, which is called recall,

182
00:11:43,306 --> 00:11:47,306
precision and accuracy. These are all called performance metrics,

183
00:11:47,418 --> 00:11:50,814
right? So ideally we should not have

184
00:11:50,852 --> 00:11:53,970
any false negative as part of the model development.

185
00:11:54,470 --> 00:11:58,206
So when there is an anomaly, we should not miss that anomaly that isn't

186
00:11:58,238 --> 00:12:01,460
false negative right now.

187
00:12:02,150 --> 00:12:05,446
At the same time, we are skewed towards false positive. But that

188
00:12:05,468 --> 00:12:09,750
is okay reasoning. We should not miss any anomaly

189
00:12:10,170 --> 00:12:14,034
in our real data. Introduction so this is a holistic

190
00:12:14,082 --> 00:12:18,114
process in artificial intelligence implementation

191
00:12:18,162 --> 00:12:21,814
journey. Right? Now let's talk

192
00:12:21,852 --> 00:12:24,954
about the framework which we build, which is called

193
00:12:24,992 --> 00:12:28,950
anomaly identification framework. So we use aging

194
00:12:29,030 --> 00:12:32,826
phase library aging phase framework to fine tune

195
00:12:32,858 --> 00:12:36,398
the models, right? So we used model like

196
00:12:36,484 --> 00:12:39,886
Bert and bio bert for fine tuning the

197
00:12:39,908 --> 00:12:43,386
model. Ideally, we give an input

198
00:12:43,418 --> 00:12:47,150
text and we see whether the Bert can predict

199
00:12:47,230 --> 00:12:50,994
the anomaly correctly. If it predicts, that is good.

200
00:12:51,112 --> 00:12:54,302
If not, we have another rule engine or the safeguard,

201
00:12:54,366 --> 00:12:58,246
or we call it as an guardrails, which has

202
00:12:58,268 --> 00:13:01,686
a complete list of rules which will be, it's nothing but

203
00:13:01,708 --> 00:13:05,522
a heuristic rules which will be invoked to detect. Is there any further

204
00:13:05,586 --> 00:13:09,418
anomaly in the text. This is a typical process

205
00:13:09,504 --> 00:13:12,746
we follow, right? But as part of the

206
00:13:12,768 --> 00:13:15,130
whole machine, leveraging algorithm development,

207
00:13:15,630 --> 00:13:18,986
including a single large language model, may not

208
00:13:19,008 --> 00:13:22,286
be sufficient to identify the anomaly. That is

209
00:13:22,308 --> 00:13:25,774
why we use ensemble of models. It could be an

210
00:13:25,812 --> 00:13:29,594
Bert Biobert, an excel number or multiple models

211
00:13:29,642 --> 00:13:33,058
have been used to identify the anomaly. That is a

212
00:13:33,064 --> 00:13:36,974
bit novel technique here. By using multiple models,

213
00:13:37,102 --> 00:13:40,882
even if any of the model identify that as an anomaly based

214
00:13:40,936 --> 00:13:44,740
on aggregate oating, we report that as an

215
00:13:45,510 --> 00:13:49,026
now, so as I said, we have an ML algorithm.

216
00:13:49,138 --> 00:13:52,994
On top of that, we have a rule system which even the algorithm

217
00:13:53,042 --> 00:13:56,134
misses. We have a rule system to identify the

218
00:13:56,172 --> 00:13:59,386
anomaly. Also, there is a

219
00:13:59,408 --> 00:14:03,274
process involved. Let's assume that the

220
00:14:03,312 --> 00:14:06,794
social media records would be humongous. The data which

221
00:14:06,832 --> 00:14:10,170
will be flowed in like it could be in millions,

222
00:14:10,910 --> 00:14:14,202
in a month or in a week. The amount of data

223
00:14:14,256 --> 00:14:17,482
record for the manual job would be drastically reduced.

224
00:14:17,626 --> 00:14:21,754
All the junk data or which is not an anomaly would be identified

225
00:14:21,882 --> 00:14:24,750
and not be available for the human trivia.

226
00:14:24,910 --> 00:14:28,740
That is a whole anomaly identification framework we have built.

227
00:14:29,990 --> 00:14:33,742
Now, let's talk more about the machine learning model framework

228
00:14:33,806 --> 00:14:37,614
here. So we have built a framework

229
00:14:37,742 --> 00:14:41,090
where multiple pre trained models can be

230
00:14:41,160 --> 00:14:44,646
used for fine tuning the model. So today

231
00:14:44,748 --> 00:14:48,502
Bert, tomorrow it could be XLM, robota and GPT, one or two

232
00:14:48,556 --> 00:14:52,918
or three, right, or llama two from meta.

233
00:14:53,014 --> 00:14:56,650
So these models can be plugged in as part of pretrained model.

234
00:14:56,800 --> 00:15:00,842
And we provide the training data set, which we have around 20,000

235
00:15:00,896 --> 00:15:04,282
to 30,000 records which has been manually

236
00:15:04,426 --> 00:15:08,320
labeled by the annotators that would be given for the model training.

237
00:15:08,690 --> 00:15:12,106
As I said, once the model is trained, we have a pool

238
00:15:12,138 --> 00:15:16,494
of models called ensemble of models to identify the anomaly.

239
00:15:16,622 --> 00:15:20,302
Right? Further, we use a process called hyperparameter

240
00:15:20,366 --> 00:15:23,842
optimization, where learning rate,

241
00:15:23,976 --> 00:15:27,494
epoch and multiple learning parameter can

242
00:15:27,532 --> 00:15:31,314
be modified to perform much better precision,

243
00:15:31,362 --> 00:15:34,710
recall and accuracy in our whole algorithm development.

244
00:15:35,610 --> 00:15:39,634
So as part of the whole framework, we give multiple

245
00:15:39,682 --> 00:15:41,880
machine learning models and we see,

246
00:15:43,610 --> 00:15:47,386
okay, we give multiple machine learning large language models into the

247
00:15:47,408 --> 00:15:52,110
framework. And finally, we have a process to identify which

248
00:15:52,180 --> 00:15:55,610
model identifies the anomaly correctly.

249
00:15:55,690 --> 00:15:59,834
So we pick the top three or four models which can identify the anomaly

250
00:15:59,882 --> 00:16:03,426
correctly right now. Okay, this whole thing has

251
00:16:03,448 --> 00:16:07,694
been developed with hugging phase framework. We use transformer based pretrained

252
00:16:07,742 --> 00:16:10,130
model like BERT, Excel, Robota,

253
00:16:11,750 --> 00:16:15,874
and for different languages other than English, we may use Rena

254
00:16:15,922 --> 00:16:19,538
Roberta for chinese language.

255
00:16:19,714 --> 00:16:23,046
Right now, we also have an

256
00:16:23,068 --> 00:16:26,818
ML flow for tracking all the experiments

257
00:16:26,994 --> 00:16:31,014
to see which model is performing well, and we pick that model and deploy

258
00:16:31,062 --> 00:16:34,218
into the production once we move on.

259
00:16:34,304 --> 00:16:37,898
Again, in addition to the large language model,

260
00:16:38,064 --> 00:16:41,738
we are also having a guardrails, which is nothing but a heuristic business

261
00:16:41,824 --> 00:16:45,566
rules which will be used on top of it. Right now we have

262
00:16:45,588 --> 00:16:49,198
the large language models. We say, okay, this model is performing good.

263
00:16:49,284 --> 00:16:53,298
Then we use some amount of operational quality and production quality

264
00:16:53,384 --> 00:16:56,946
test data to evaluate the model which

265
00:16:56,968 --> 00:17:00,846
has been identified as part of the whole model selection

266
00:17:00,878 --> 00:17:04,814
process. So once the model crosses

267
00:17:04,862 --> 00:17:08,454
a specific benchmark, around 98 or 99% of

268
00:17:08,492 --> 00:17:12,246
recall in identifying the anomaly, that would

269
00:17:12,268 --> 00:17:16,390
be moved to higher environments like production environment.

270
00:17:16,730 --> 00:17:20,374
Right? All right, now let's

271
00:17:20,422 --> 00:17:23,962
talk about the challenges in BeRT model. So,

272
00:17:24,016 --> 00:17:28,406
BeRt is an bi directional encoder representation for transformer

273
00:17:28,438 --> 00:17:31,994
architecture. See, this is the model which has been released

274
00:17:32,042 --> 00:17:36,506
by Google in 2017, set the benchmark of understanding

275
00:17:36,538 --> 00:17:39,614
the natural language processing, right?

276
00:17:39,732 --> 00:17:44,370
So this pretrained model is

277
00:17:44,440 --> 00:17:47,860
really capable to understand the text

278
00:17:49,030 --> 00:17:53,374
by having an bi directional flow

279
00:17:53,422 --> 00:17:57,046
towards understanding the text means let's say we

280
00:17:57,068 --> 00:18:01,094
have a text, it understands the word context and

281
00:18:01,132 --> 00:18:04,582
it tries to the next word, which is called

282
00:18:04,636 --> 00:18:08,166
mask language modeling and next sentence prediction. These are all the

283
00:18:08,188 --> 00:18:12,066
techniques used in developing the BeRt, but we have fine

284
00:18:12,108 --> 00:18:15,606
tuned the model to perform a task of classification,

285
00:18:15,718 --> 00:18:18,330
in our case to identify the anomaly.

286
00:18:19,790 --> 00:18:22,926
Now, as we know, the BeRt has first set the

287
00:18:22,948 --> 00:18:26,686
industry benchmark standard for using the transformer architecture in

288
00:18:26,708 --> 00:18:30,238
bi directional way to understand the word context in

289
00:18:30,244 --> 00:18:34,340
the sentence. Then that can really help in

290
00:18:34,950 --> 00:18:38,962
predicting or classifying the anomaly based on the text.

291
00:18:39,016 --> 00:18:42,610
We give. Right now to use this BerT model,

292
00:18:42,680 --> 00:18:46,094
which I have told we need a huge amount of training data set

293
00:18:46,152 --> 00:18:49,974
to train the model. Then there is a process involved in

294
00:18:50,012 --> 00:18:54,162
deploying the model. So then we have to use pytot serving

295
00:18:54,226 --> 00:18:57,270
for serve the machine learning models in production.

296
00:18:57,950 --> 00:19:01,386
So that is how the training time is huge in

297
00:19:01,408 --> 00:19:05,110
the bird model. Also, there could be possibility

298
00:19:05,190 --> 00:19:08,678
of overfitting due to its complexity and capacity,

299
00:19:08,854 --> 00:19:12,358
because BerT can overfit on

300
00:19:12,384 --> 00:19:16,202
smaller data set. That's why I was stressing on the data annotation

301
00:19:16,266 --> 00:19:19,422
process and the data set. A huge amount of data set

302
00:19:19,476 --> 00:19:22,190
required for model training or fine tuning.

303
00:19:23,350 --> 00:19:26,962
Now, okay, we have built

304
00:19:27,016 --> 00:19:30,066
the bert or fine tuned the model, and we have to deploy the model in

305
00:19:30,088 --> 00:19:34,580
production. For identifying the anomaly right

306
00:19:35,370 --> 00:19:39,202
now comes in generative

307
00:19:39,266 --> 00:19:41,810
AI. When I talk about generative AI,

308
00:19:41,890 --> 00:19:45,606
generative AI is primarily used for content generation on question and

309
00:19:45,628 --> 00:19:49,162
answering or building chatbots. But this can be used

310
00:19:49,216 --> 00:19:52,474
for a discriminative task like classification or

311
00:19:52,512 --> 00:19:56,454
identifying the anomaly in the text. Now, how this generative

312
00:19:56,502 --> 00:20:00,486
AI can be utilized for the classification task

313
00:20:00,518 --> 00:20:04,014
is via prompt engineering techniques. So we no

314
00:20:04,052 --> 00:20:07,354
need to fine tune the model or because this generative AI

315
00:20:07,402 --> 00:20:10,986
or GPT four models have been hugely trained

316
00:20:11,018 --> 00:20:14,210
on the public data set, I believe even GPT-3

317
00:20:14,280 --> 00:20:18,114
as around 175,000,000,000 parameters or document has

318
00:20:18,152 --> 00:20:21,474
been trained. Now, the GPT four has been

319
00:20:21,512 --> 00:20:23,250
further went extensively,

320
00:20:24,710 --> 00:20:28,534
extensively to have more training has been given, and that

321
00:20:28,572 --> 00:20:32,086
model is GPT four is available. That with

322
00:20:32,108 --> 00:20:36,006
the prompt engineering technique, without fine tuning, by performing a

323
00:20:36,028 --> 00:20:39,466
prompt engineering technique, by providing in context learning

324
00:20:39,568 --> 00:20:43,574
to the GPT four, we can perform the classification

325
00:20:43,702 --> 00:20:46,358
job in identifying the anomaly.

326
00:20:46,534 --> 00:20:49,654
Right. That is the huge benefit

327
00:20:49,702 --> 00:20:54,030
of having generative AI and prompt engineering techniques

328
00:20:54,690 --> 00:20:58,206
right now, what is that I'm saying about there

329
00:20:58,228 --> 00:21:01,434
is a small solution architectures or the picture

330
00:21:01,482 --> 00:21:05,058
of what I mean by generative AI. By having the

331
00:21:05,144 --> 00:21:08,814
prompt engineering approach, we already have the foundational models

332
00:21:08,862 --> 00:21:12,482
like GPT four or Claude or llama two

333
00:21:12,616 --> 00:21:16,382
or even you can bring your old models, right? These models necessarily

334
00:21:16,446 --> 00:21:20,454
doesn't require any amount of fine tuning which is not advised as

335
00:21:20,492 --> 00:21:23,974
per the pyramid. Right? So once you have the foundational model,

336
00:21:24,092 --> 00:21:27,526
you can pass all the data to the foundational model, or you

337
00:21:27,548 --> 00:21:30,694
can use as an inference point to classify

338
00:21:30,822 --> 00:21:34,714
whether there is an anomaly or not. If not by giving some

339
00:21:34,752 --> 00:21:38,362
amount of prompt engineering technique like we have to follow

340
00:21:38,416 --> 00:21:41,530
the process, like anatomy of prompt or instruction,

341
00:21:41,610 --> 00:21:45,262
tuning, classification or chain of thought

342
00:21:45,396 --> 00:21:49,774
can be used in the prompt engineering techniques on top of the foundational model.

343
00:21:49,972 --> 00:21:53,890
Once we have the prompt engineering technique is built

344
00:21:53,960 --> 00:21:57,410
effectively, then we can classify the anomaly.

345
00:21:58,870 --> 00:22:02,530
The fine tuning and the train is not much well suggested

346
00:22:02,870 --> 00:22:06,406
by the industry to on foundational model unless and

347
00:22:06,428 --> 00:22:09,478
until the prompt engineering couldn't achieve the job.

348
00:22:09,644 --> 00:22:13,314
But most of the cases prompt engineering technique will help you to solve

349
00:22:13,362 --> 00:22:16,454
your problem in identifying the

350
00:22:16,492 --> 00:22:20,406
anomaly. Right, so that's

351
00:22:20,438 --> 00:22:24,154
all I have for now. I talked about the

352
00:22:24,192 --> 00:22:28,102
use case, the problem statement of identifying the anomaly,

353
00:22:28,246 --> 00:22:32,874
and how traditional machine learning models or the transformer based architectures

354
00:22:32,922 --> 00:22:36,366
has been used to identify the anomaly and what are all

355
00:22:36,388 --> 00:22:40,314
the challenges. We set out as part of the whole model development

356
00:22:40,362 --> 00:22:43,714
process, which includes training, validation and

357
00:22:43,752 --> 00:22:47,022
testing and deploying the model into production,

358
00:22:47,166 --> 00:22:50,686
which would require a huge amount of data to train for models

359
00:22:50,718 --> 00:22:54,306
like Bert. But by having generative AI in place,

360
00:22:54,408 --> 00:22:58,306
you are completely moving out from the whole model training phase and

361
00:22:58,328 --> 00:23:01,714
you have to give a simple prompt, not a simple, it's effective prompt

362
00:23:01,762 --> 00:23:05,202
engineering techniques to get the most out of the foundational

363
00:23:05,266 --> 00:23:08,200
models of GPT four. Right.

364
00:23:08,890 --> 00:23:13,014
With that we can solve the

365
00:23:13,052 --> 00:23:17,074
motive behind the business objective or business problem on classify

366
00:23:17,122 --> 00:23:21,374
unidentifying the anomaly. Right. With that,

367
00:23:21,572 --> 00:23:25,390
I end my session. Thank you for listening. Wish you all

368
00:23:25,460 --> 00:23:28,540
success in your career and your path ahead. Thank you so much.

