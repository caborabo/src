1
00:00:27,594 --> 00:00:31,106
Here's the too long didn't listen list the

2
00:00:31,130 --> 00:00:34,578
whole point of this talk is not to tell you exactly what to do,

3
00:00:34,706 --> 00:00:38,042
it's to show you system patterns I've seen work well and to

4
00:00:38,058 --> 00:00:41,610
give you ideas. The key takeaways are going to be

5
00:00:41,722 --> 00:00:44,494
don't over commit. Things are improving rapidly.

6
00:00:44,994 --> 00:00:48,546
Build out a small suite of working examples

7
00:00:48,730 --> 00:00:52,202
for others to use. Empower teams

8
00:00:52,298 --> 00:00:55,894
to self service. Ensure that it's easy

9
00:00:55,934 --> 00:00:59,286
for teams to do the right thing and that

10
00:00:59,310 --> 00:01:02,950
there are limitations to all of this. So don't over

11
00:01:02,982 --> 00:01:06,918
commit. Things are improving rapidly between starting this

12
00:01:06,966 --> 00:01:10,534
script and recording it. The best

13
00:01:10,614 --> 00:01:13,950
model changed three times and I didn't

14
00:01:13,982 --> 00:01:18,630
even know about the local only architecture for

15
00:01:18,662 --> 00:01:22,206
non technical folks. I'll be describing that later. What this

16
00:01:22,230 --> 00:01:25,766
means is it's better to focus on the style of problem you want to

17
00:01:25,790 --> 00:01:29,926
solve and the building blocks, rather than

18
00:01:29,990 --> 00:01:33,194
over committing to any one vendor or technology.

19
00:01:34,174 --> 00:01:38,742
Different use cases are going to benefit from different learning

20
00:01:38,878 --> 00:01:42,110
models. Don't waste opportunities by

21
00:01:42,142 --> 00:01:46,796
enforcing that your teams have to use a single LLM

22
00:01:46,950 --> 00:01:50,320
model. They will need different tools for

23
00:01:50,352 --> 00:01:53,784
different purposes, and that's fine. So build

24
00:01:53,824 --> 00:01:56,204
out a small suite of working examples.

25
00:01:56,864 --> 00:02:00,832
Not everyone will understand how LLMs can be used to

26
00:02:00,848 --> 00:02:04,816
make them productive, or what styles of problems are even suitable

27
00:02:04,880 --> 00:02:07,884
for use with large language models or other techniques.

28
00:02:08,464 --> 00:02:12,124
This can be mitigated by having a library of real examples

29
00:02:12,924 --> 00:02:16,316
or your business, which teams can interact with and then

30
00:02:16,380 --> 00:02:20,664
emulate or improve upon for their specific challenges.

31
00:02:21,484 --> 00:02:24,260
Also, a library of non examples,

32
00:02:24,412 --> 00:02:27,264
as in this would be a documentation piece.

33
00:02:28,604 --> 00:02:32,324
A library of non examples or forbidden uses

34
00:02:32,484 --> 00:02:36,588
will also help. If they're data sources which are prohibited from using

35
00:02:36,676 --> 00:02:40,142
by law or contract, list them out.

36
00:02:40,238 --> 00:02:43,990
Make it clear so that teams don't accidentally misuse

37
00:02:44,022 --> 00:02:47,354
any of this in par teams to self service.

38
00:02:48,054 --> 00:02:51,382
So another architecture I'm going to be talking about is

39
00:02:51,438 --> 00:02:53,674
retrieval augmented generation.

40
00:02:54,454 --> 00:02:57,654
If you make it possible for teams that add their own Personas,

41
00:02:57,734 --> 00:03:01,854
their own data, and add this to centralized

42
00:03:01,894 --> 00:03:05,662
service, then this is going to reduce the barriers for teams to

43
00:03:05,718 --> 00:03:09,490
try out using these tools. After all,

44
00:03:09,522 --> 00:03:13,754
you want your teams to be spending the time improving how

45
00:03:13,794 --> 00:03:18,058
they work, what data they have, rather than reinventing

46
00:03:18,106 --> 00:03:22,574
all of this middleware. The main beneficiaries of

47
00:03:23,554 --> 00:03:26,986
all of these LLM assisted tools

48
00:03:27,130 --> 00:03:30,690
are going to be the less technical folks who

49
00:03:30,722 --> 00:03:34,358
are unlikely to be able to code the machinery that makes all of these

50
00:03:34,506 --> 00:03:38,774
tools work together. They can certainly provide the raw data

51
00:03:38,894 --> 00:03:42,194
that makes it work. So, for example,

52
00:03:42,854 --> 00:03:46,382
team support teams will have user manuals,

53
00:03:46,438 --> 00:03:49,714
rum books, example tickets,

54
00:03:50,134 --> 00:03:53,870
all of these are really useful context to

55
00:03:53,902 --> 00:03:57,590
make off the shelf tools work so much better

56
00:03:57,702 --> 00:04:00,826
to make them really shine. These teams should

57
00:04:00,850 --> 00:04:04,522
be able to get the benefits without having to

58
00:04:04,538 --> 00:04:08,370
learn how to program as well. Also make sure it's easy

59
00:04:08,402 --> 00:04:12,394
for teams to do the right thing. The high performers

60
00:04:12,434 --> 00:04:16,498
are already using these tools. Regardless of what

61
00:04:16,666 --> 00:04:20,362
policies you've put in place, it's in your

62
00:04:20,418 --> 00:04:24,250
interest to make sure that they can utilize these tools in

63
00:04:24,282 --> 00:04:27,954
ways that won't cause your business harm one way or the other.

64
00:04:28,114 --> 00:04:32,654
A great way of doing this is by having garden paths. So have approved tools

65
00:04:33,274 --> 00:04:36,850
paths for teams to get it to

66
00:04:36,922 --> 00:04:40,802
use, things that they actually want to use with data

67
00:04:40,858 --> 00:04:44,634
that they can use with them. Just saying no isn't

68
00:04:44,674 --> 00:04:48,122
going to stop folks. Now the bit you've all been

69
00:04:48,138 --> 00:04:50,614
waiting for, the example architectures.

70
00:04:51,434 --> 00:04:55,638
So these are the architectures I've seen work well

71
00:04:55,806 --> 00:04:59,034
and will help your teams improve their own efficiencies.

72
00:04:59,574 --> 00:05:03,590
First up, local processing. There are tools

73
00:05:03,662 --> 00:05:06,834
like Jan AI or Olama.

74
00:05:07,694 --> 00:05:11,046
There'll be links at the end where you can

75
00:05:11,070 --> 00:05:14,206
have a front end and provided

76
00:05:14,310 --> 00:05:18,074
your teams have suitable hardware. So say you have

77
00:05:19,154 --> 00:05:23,170
macOS, you've got modern MacBooks. These run these tools fairly

78
00:05:23,202 --> 00:05:26,570
well. Windows, if they've got

79
00:05:26,602 --> 00:05:30,570
dedicated gpu's, say you've got some rendering

80
00:05:30,642 --> 00:05:34,498
workstations, they'll work again fairly well. Your teams

81
00:05:34,586 --> 00:05:38,146
can interact with these tools all locally and can even

82
00:05:38,210 --> 00:05:41,666
process the data locally. You can

83
00:05:41,730 --> 00:05:44,214
also run it on top of documents that you provide.

84
00:05:45,294 --> 00:05:49,406
Just taking one example, this Jain AI tool. You can actually

85
00:05:49,470 --> 00:05:52,766
deceive all any use of remote

86
00:05:52,830 --> 00:05:57,430
APIs and can load in LLM

87
00:05:57,502 --> 00:06:00,874
models that you folks have decided already approved,

88
00:06:01,414 --> 00:06:05,030
and then they can be used for device local processing.

89
00:06:05,102 --> 00:06:08,194
So if you have strict data residency requirements,

90
00:06:09,254 --> 00:06:12,630
you can just run it on your machine. The data never leaves your

91
00:06:12,662 --> 00:06:16,118
machine, the documents never leave your machine. The results of

92
00:06:16,166 --> 00:06:19,514
the LLM running doesn't leave the machine,

93
00:06:20,454 --> 00:06:23,582
but you can also use this a different way. So say for example,

94
00:06:23,718 --> 00:06:27,422
you've set up the next architecture I'll show, or you've already

95
00:06:27,478 --> 00:06:30,678
set up a proxy, you've already got some approved tools.

96
00:06:30,846 --> 00:06:35,246
You can have these local agents call

97
00:06:35,430 --> 00:06:39,470
those tools rather than going off to some external

98
00:06:39,502 --> 00:06:42,658
third vendor. Another advantage of these local

99
00:06:42,706 --> 00:06:46,654
only tools, they are slower than running on dedicated

100
00:06:47,274 --> 00:06:50,994
better hardware or using a remote

101
00:06:51,034 --> 00:06:53,774
API where a company will do all that for you.

102
00:06:54,314 --> 00:06:57,394
It enables folks to actually experiment and see whether this

103
00:06:57,434 --> 00:07:01,354
style of tool will actually work for them, whether it will actually give them

104
00:07:01,394 --> 00:07:04,482
any benefit without you having to invest very much in

105
00:07:04,498 --> 00:07:08,632
it at all. You just have to download it and run it. The architecture

106
00:07:08,688 --> 00:07:12,808
you possibly have been waiting for retrieval

107
00:07:12,896 --> 00:07:16,280
augmented generation. Rather than having

108
00:07:16,312 --> 00:07:19,584
to spend ten or $100 million training

109
00:07:19,664 --> 00:07:23,808
your own AI model, you can use something

110
00:07:23,856 --> 00:07:27,144
off the shelf. There are many out there. I'm not going to

111
00:07:27,264 --> 00:07:30,592
name names or recommend any specific ones because they'll all be out of date

112
00:07:30,648 --> 00:07:34,830
by the time this airs. But this

113
00:07:34,862 --> 00:07:38,174
is the architecture. This means that you can use somebody else's model,

114
00:07:38,334 --> 00:07:41,758
but make it relevant for your

115
00:07:41,806 --> 00:07:45,494
business, your data, whatever it is. So what this architecture

116
00:07:45,534 --> 00:07:49,014
looks like is the user through whatever

117
00:07:49,054 --> 00:07:52,934
it is. Maybe it's ja, maybe it's some custom front

118
00:07:52,974 --> 00:07:57,086
end, doesn't really matter, they put in their query. Heck, it could even be with

119
00:07:57,110 --> 00:08:01,778
a chatbot. And that gets sent off to your

120
00:08:01,826 --> 00:08:05,130
server. Whatever it is, that server will

121
00:08:05,162 --> 00:08:08,402
then take that query and send it over to what's

122
00:08:08,458 --> 00:08:12,202
commonly a vector database. This is just doing a

123
00:08:12,258 --> 00:08:16,266
search for relevant chunks of documentation

124
00:08:16,370 --> 00:08:19,666
which you've already put there. So this could be your internal wikis,

125
00:08:19,730 --> 00:08:23,314
this could be run books,

126
00:08:23,354 --> 00:08:26,762
this can be whatever it is. This can be many,

127
00:08:26,818 --> 00:08:30,958
many many PDF's. And all this stage is doing is

128
00:08:31,006 --> 00:08:34,758
sending you back chunks of documentation. That might help.

129
00:08:34,926 --> 00:08:40,246
So if the user is asking about how

130
00:08:40,270 --> 00:08:44,194
do I do business? Process X for customer Y,

131
00:08:44,814 --> 00:08:48,634
this might bring back the runbook for that process.

132
00:08:49,694 --> 00:08:53,234
It might bring in some extra information about that customer.

133
00:08:53,874 --> 00:08:57,226
So this then gets sent back to your, to your server.

134
00:08:57,410 --> 00:09:01,474
And then you will put together the prompt where

135
00:09:01,514 --> 00:09:04,802
you tell the language model what to do. You'll put

136
00:09:04,818 --> 00:09:08,266
in the query, you'll put in this extra context, you'll send it over to

137
00:09:08,290 --> 00:09:12,146
the thing to do text generation and you'll get back your response.

138
00:09:12,290 --> 00:09:16,490
So for example, it might be the prompt might be you

139
00:09:16,522 --> 00:09:19,374
are a helpful service desk employee.

140
00:09:19,964 --> 00:09:23,764
Help the users as much as you can based

141
00:09:23,844 --> 00:09:27,904
on only the information that is provided in the context.

142
00:09:28,804 --> 00:09:32,476
Then you might list the context. So it would say this is

143
00:09:32,500 --> 00:09:36,068
by customer x, this is the relevant process

144
00:09:36,156 --> 00:09:39,532
document. And then after that you would put the

145
00:09:39,588 --> 00:09:43,984
user's question of like how did I do this process for this customer

146
00:09:44,364 --> 00:09:47,724
that gets sent back? And then the person at the start can use

147
00:09:47,764 --> 00:09:51,672
it. This architecture can be quite nice because

148
00:09:51,728 --> 00:09:55,360
if you have this server in the middle and you've, so let's

149
00:09:55,392 --> 00:09:57,644
pretend that you've got some sort of chat system,

150
00:09:58,064 --> 00:10:01,336
you could allow teams to add different

151
00:10:01,400 --> 00:10:05,168
Personas and the Personas will tell your API

152
00:10:05,216 --> 00:10:08,480
server to use a different prompt, to use a different model,

153
00:10:08,632 --> 00:10:11,844
to use a different set of data

154
00:10:12,864 --> 00:10:15,984
to enrich these queries. Again,

155
00:10:16,064 --> 00:10:19,984
teams generally will be able to say, ah, I want to do

156
00:10:20,024 --> 00:10:23,576
this kind of thing. Here's some examples. You can work with them

157
00:10:23,600 --> 00:10:26,864
to get the prompt and they'll probably be able to go, yeah, here is

158
00:10:26,904 --> 00:10:30,560
my big stack of documentation that I think is relevant

159
00:10:30,592 --> 00:10:33,720
for this. How exactly the vector

160
00:10:33,752 --> 00:10:37,680
database works. To pull out the relevant pieces of those documents

161
00:10:37,872 --> 00:10:42,156
is dependent on what system you're using. But just think of it as it

162
00:10:42,180 --> 00:10:45,932
goes off, finds relevant information, brings it back, and then adds

163
00:10:45,948 --> 00:10:48,744
it all together for the language generation.

164
00:10:49,444 --> 00:10:52,944
So now onto the limitations.

165
00:10:54,284 --> 00:10:57,644
These large language models LLMs can make stuff

166
00:10:57,684 --> 00:11:00,064
up. This is commonly called hallucination.

167
00:11:01,404 --> 00:11:04,868
They are a piece of software designed to

168
00:11:04,916 --> 00:11:09,064
make plausible text. What that means is

169
00:11:09,104 --> 00:11:13,504
that they have no concept of truth or lies,

170
00:11:13,664 --> 00:11:17,444
they just generate text that looks plausible.

171
00:11:18,104 --> 00:11:21,904
This can mean that you end up where if you

172
00:11:21,944 --> 00:11:25,856
don't provide your own process document, it will just make something

173
00:11:25,920 --> 00:11:27,364
up that seems plausible.

174
00:11:28,704 --> 00:11:32,552
And that's a real challenge. Make sure

175
00:11:32,688 --> 00:11:35,912
that whenever you're using these tools that you have a human

176
00:11:35,968 --> 00:11:40,230
over the loop. What I mean by that is that humans

177
00:11:40,262 --> 00:11:44,430
are checking the output of these tools before

178
00:11:44,502 --> 00:11:49,350
they go any further. So if you're using it to improve your documentation,

179
00:11:49,462 --> 00:11:53,550
have someone review that. So outdated

180
00:11:53,622 --> 00:11:57,670
knowledge. Once these models are trained, they typically

181
00:11:57,742 --> 00:12:01,486
don't get updated with fresh information for a while or at all.

182
00:12:01,550 --> 00:12:05,354
Even so, you might be dealing

183
00:12:05,394 --> 00:12:09,066
with steal things like, oh, this library used to

184
00:12:09,090 --> 00:12:12,450
work this way, but now it works another way. The model doesn't

185
00:12:12,482 --> 00:12:14,854
know that it's going to tell you the old way of doing things.

186
00:12:15,594 --> 00:12:18,938
These tools are also because of,

187
00:12:19,066 --> 00:12:23,674
well, what I've just said. They're generally better for templates

188
00:12:23,794 --> 00:12:26,974
or skeletons of things rather than fine detail.

189
00:12:27,354 --> 00:12:31,018
So one example of this might

190
00:12:31,066 --> 00:12:34,774
be if you want a pitch deck for

191
00:12:35,674 --> 00:12:39,434
a specific industry, it can give you the broad strokes,

192
00:12:39,514 --> 00:12:43,266
but you're going to need an expert to put in those fine details,

193
00:12:43,290 --> 00:12:46,554
the things that actually make it relevant and

194
00:12:46,634 --> 00:12:50,146
particularly useful. You can use it for things

195
00:12:50,210 --> 00:12:53,594
like make me a bash for loop,

196
00:12:53,714 --> 00:12:57,016
for example. I can never get that right. I can have the

197
00:12:57,040 --> 00:13:00,800
bot do that, and then I fill in my specific logic

198
00:13:00,872 --> 00:13:04,752
that I actually want. These models can get very expensive.

199
00:13:04,928 --> 00:13:09,048
So if you're trying to buy equipment

200
00:13:09,136 --> 00:13:13,040
so that you can run it on your own hardware at sufficient

201
00:13:13,112 --> 00:13:16,888
speed, that can get very expensive. If you

202
00:13:16,896 --> 00:13:21,066
can even get the hardware at all. There are very long waitlists for

203
00:13:21,200 --> 00:13:24,766
some of this equipment. If you're using some

204
00:13:24,790 --> 00:13:28,734
of the cutting edge models, they will essentially bill

205
00:13:28,774 --> 00:13:32,606
you by token, which is roughly two

206
00:13:32,630 --> 00:13:36,830
or three characters, which looks like a really small number.

207
00:13:37,022 --> 00:13:40,798
But again, if you're enriching your

208
00:13:40,966 --> 00:13:44,118
queries with large documents, that can get

209
00:13:44,166 --> 00:13:48,210
very expensive very quickly. So estimate your

210
00:13:48,242 --> 00:13:52,042
costs. Choose appropriately. And again, this is

211
00:13:52,098 --> 00:13:56,250
also fast moving. The models and the vendors are

212
00:13:56,282 --> 00:14:00,658
evolving and changing so rapidly that's unlikely that

213
00:14:00,746 --> 00:14:04,306
you will choose the model today that you would

214
00:14:04,330 --> 00:14:08,122
choose in a month or in two months or even next year. So you want

215
00:14:08,138 --> 00:14:12,282
to make sure that you have flexibility. You probably don't want to sign large

216
00:14:12,338 --> 00:14:15,822
upfront contracts. You probably don't want to sign large long

217
00:14:15,918 --> 00:14:19,502
term contracts. No one knows who's going to be

218
00:14:19,518 --> 00:14:22,314
the top performer in even six months.

219
00:14:22,974 --> 00:14:26,198
There's a lot of interesting things happening, which is good, but it also

220
00:14:26,246 --> 00:14:29,590
makes it a real challenge. Key takeaways once

221
00:14:29,622 --> 00:14:33,514
again, don't over commit. Things are improving rapidly.

222
00:14:34,254 --> 00:14:37,910
Build out a small suite of working examples for folks to

223
00:14:37,942 --> 00:14:41,594
build on top of. Empower your teams to self service.

224
00:14:42,584 --> 00:14:45,924
Ensure that it's easy for teams to do the right thing.

225
00:14:46,704 --> 00:14:50,244
These tools have limitations and

226
00:14:50,864 --> 00:14:52,864
some example architectures that you can use.

