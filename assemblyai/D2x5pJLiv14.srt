1
00:00:20,570 --> 00:00:23,614
Hello everyone, this is Ivan. I will introduce the

2
00:00:23,652 --> 00:00:27,670
topic implementing a virtual physical environment system

3
00:00:27,740 --> 00:00:32,102
based on rust using Python and threejs days Twins

4
00:00:32,156 --> 00:00:35,510
was created from my previous company

5
00:00:35,580 --> 00:00:38,914
Paia focusing on educational

6
00:00:38,962 --> 00:00:42,440
system. We aimed to

7
00:00:43,370 --> 00:00:46,506
university student to help them using a

8
00:00:46,528 --> 00:00:50,254
kind of tool create, manipulate and

9
00:00:50,292 --> 00:00:53,646
the chair model in the virtual environment which

10
00:00:53,668 --> 00:00:55,760
is synchronized physical one.

11
00:00:56,530 --> 00:01:00,142
It's really helpful to decrease the

12
00:01:00,196 --> 00:01:04,640
cost in the physical environment. And here we list

13
00:01:05,490 --> 00:01:08,722
all agendas that we will talk about

14
00:01:08,776 --> 00:01:12,690
later. First of all I will explain

15
00:01:12,760 --> 00:01:15,860
why it's us and why is three z.

16
00:01:16,170 --> 00:01:20,194
And then we will introduce digital

17
00:01:20,242 --> 00:01:24,470
twins concepts. And also we provide a user interface

18
00:01:25,130 --> 00:01:28,310
to manipulate digital twins assistance.

19
00:01:28,750 --> 00:01:32,506
And also we provide

20
00:01:32,608 --> 00:01:36,410
a control panel to the physical robotic arm.

21
00:01:36,990 --> 00:01:41,022
And also we use threejs library and

22
00:01:41,076 --> 00:01:44,474
byte framework integration

23
00:01:44,602 --> 00:01:48,430
in the virtual environment. And also

24
00:01:48,500 --> 00:01:51,946
we use WebrtC skill to connect IP

25
00:01:51,978 --> 00:01:55,454
camera to display the physical environment in the virtual

26
00:01:55,502 --> 00:01:58,914
page. And then we use

27
00:01:59,112 --> 00:02:02,782
a connection to ROS cluster

28
00:02:02,846 --> 00:02:06,946
by RoS Bridge and it's training

29
00:02:07,058 --> 00:02:10,790
in Python language. Also we subscribe it

30
00:02:10,940 --> 00:02:14,742
in the front end side by RoS library and

31
00:02:14,796 --> 00:02:18,382
also provide RASC

32
00:02:18,386 --> 00:02:22,630
cloud API to integrate the systems

33
00:02:22,710 --> 00:02:26,166
between physical and virtual environments.

34
00:02:26,358 --> 00:02:30,414
And also in the end we provide a

35
00:02:30,452 --> 00:02:34,062
conclusion for overall of

36
00:02:34,116 --> 00:02:37,962
the topic. I will tell you later, my background

37
00:02:38,106 --> 00:02:41,600
is a little complex. Not only

38
00:02:42,050 --> 00:02:45,762
focus on programming but I am

39
00:02:45,896 --> 00:02:50,370
director as well. Already did some

40
00:02:50,440 --> 00:02:54,770
short twins and also I

41
00:02:54,840 --> 00:02:58,422
was volunteer some

42
00:02:58,476 --> 00:03:02,802
years ago working Central

43
00:03:02,866 --> 00:03:06,534
America on the islands near the

44
00:03:06,572 --> 00:03:10,442
Caribbean Sea. And also I

45
00:03:10,496 --> 00:03:12,570
like cycling,

46
00:03:15,070 --> 00:03:19,690
I already cycled many parts

47
00:03:20,030 --> 00:03:21,930
of different countries.

48
00:03:24,910 --> 00:03:28,398
Sometimes I use in twins kind of stories to

49
00:03:28,484 --> 00:03:31,838
encourage my students, especially young

50
00:03:31,924 --> 00:03:36,142
generation young engineers

51
00:03:36,286 --> 00:03:39,730
to help them figure out what

52
00:03:39,800 --> 00:03:42,610
they really want in their future careers.

53
00:03:43,510 --> 00:03:47,414
Here are tools and skills we use in

54
00:03:47,452 --> 00:03:51,720
our project. First of all is a design tool

55
00:03:52,090 --> 00:03:56,262
we use is figma. It's a well known tool,

56
00:03:56,396 --> 00:03:58,780
most designers use it usually.

57
00:03:59,710 --> 00:04:03,962
And then we use some frameworks. Here one

58
00:04:04,016 --> 00:04:07,462
is white and the other one is view framework.

59
00:04:07,606 --> 00:04:11,434
Yeah we integrate both in our project and

60
00:04:11,472 --> 00:04:15,694
also we use view router and Paia to code

61
00:04:15,892 --> 00:04:20,094
our back end API. And also we

62
00:04:20,132 --> 00:04:23,670
use tailwind and sauce to style our HTTP

63
00:04:23,690 --> 00:04:27,186
pages. And also we

64
00:04:27,288 --> 00:04:30,642
choose some skills. Here one is

65
00:04:30,696 --> 00:04:34,514
three z to operate the 3d model of

66
00:04:34,552 --> 00:04:38,130
robotics on in our virtual environment.

67
00:04:38,290 --> 00:04:41,480
Also we use Rosebridge to

68
00:04:42,330 --> 00:04:45,894
receive and subscribe messages from the

69
00:04:45,932 --> 00:04:49,298
party arm between physical and virtual

70
00:04:49,394 --> 00:04:52,618
environment. And also we use

71
00:04:52,704 --> 00:04:56,102
WebRTC to connect the IP camera

72
00:04:56,166 --> 00:04:59,910
to display the physical robotics on

73
00:05:00,000 --> 00:05:03,886
in our virtual page. And also we

74
00:05:04,068 --> 00:05:07,838
provide ROS cloud API to

75
00:05:07,924 --> 00:05:11,840
update and reiker the status of robotic on.

76
00:05:12,550 --> 00:05:15,858
And then we use

77
00:05:15,944 --> 00:05:19,982
some others tools like Docker

78
00:05:20,046 --> 00:05:25,002
and Jenkins for our continuous integration

79
00:05:25,086 --> 00:05:27,830
and deployments.

80
00:05:29,050 --> 00:05:32,920
Yeah, it's very helpful for quickly

81
00:05:34,490 --> 00:05:38,362
implement deployments in our projects. It's very

82
00:05:38,416 --> 00:05:41,914
important skills. Then we can

83
00:05:41,952 --> 00:05:44,060
see the architecture here.

84
00:05:45,630 --> 00:05:49,082
The left part is the front end side, we will talk about

85
00:05:49,136 --> 00:05:53,994
later. And the middle is DevOps

86
00:05:54,042 --> 00:05:57,840
or we call CI CD for

87
00:05:58,290 --> 00:06:02,366
integration deployment. Then we see

88
00:06:02,468 --> 00:06:06,130
under the DevOps with the backend side we use Python

89
00:06:07,430 --> 00:06:12,260
combined with Raspbridge and we also have

90
00:06:13,030 --> 00:06:16,886
local side. In the right part we

91
00:06:16,988 --> 00:06:20,674
use physical robotic arm and IP

92
00:06:20,722 --> 00:06:24,518
camera to record the

93
00:06:24,604 --> 00:06:28,114
environment to show in our virtual

94
00:06:28,162 --> 00:06:31,734
pages. Let's see the demonstration in the

95
00:06:31,772 --> 00:06:35,334
lab part we see the robotic

96
00:06:35,382 --> 00:06:39,338
arm in the virtual environment and see how it works.

97
00:06:39,504 --> 00:06:42,782
And also in the middle part we see there

98
00:06:42,836 --> 00:06:47,406
are many control gears here. And its

99
00:06:47,588 --> 00:06:51,086
button has information of

100
00:06:51,268 --> 00:06:55,118
the access angles and positions.

101
00:06:55,294 --> 00:06:59,202
So we can control each one assessed by

102
00:06:59,256 --> 00:07:03,010
each button. On the top

103
00:07:03,080 --> 00:07:07,400
right display we saw the

104
00:07:08,490 --> 00:07:12,310
physical robotic in the IP cameras.

105
00:07:13,290 --> 00:07:16,918
You see that it's synchronized in the virtual one

106
00:07:17,084 --> 00:07:21,918
layer under the display.

107
00:07:22,114 --> 00:07:26,620
There are some action scripts here recorded

108
00:07:27,630 --> 00:07:31,198
each steps. You control the gears in

109
00:07:31,204 --> 00:07:34,560
the middle, so you can record

110
00:07:35,330 --> 00:07:39,322
each action and repeat

111
00:07:39,386 --> 00:07:41,040
it many times.

112
00:07:42,390 --> 00:07:45,650
Beside action scripts

113
00:07:46,070 --> 00:07:50,206
we see some message here. Those messages

114
00:07:50,238 --> 00:07:53,380
is to tell user about how

115
00:07:53,990 --> 00:07:58,790
the robots, how the system works well, or if

116
00:07:58,860 --> 00:08:02,806
it has errors. It will show some message

117
00:08:02,908 --> 00:08:06,262
here to alert people now

118
00:08:06,316 --> 00:08:10,214
have some problems here. Okay, let's explain why is

119
00:08:10,252 --> 00:08:13,546
ROS. And ROS is full name

120
00:08:13,568 --> 00:08:17,114
is Lobar operating system. It's not

121
00:08:17,152 --> 00:08:21,134
really operating system. It must be installed on main

122
00:08:21,172 --> 00:08:24,826
leveraging system like Windows or Linux.

123
00:08:25,018 --> 00:08:28,842
So it's similar like a kind of framework

124
00:08:28,986 --> 00:08:32,990
to control and map device

125
00:08:34,070 --> 00:08:37,570
of robotic well. Also it

126
00:08:37,640 --> 00:08:41,070
provide some modular criteria,

127
00:08:41,230 --> 00:08:44,930
like stacks, packages and nodes.

128
00:08:45,450 --> 00:08:50,210
So an order can contain

129
00:08:50,370 --> 00:08:53,830
many packages. And it's the

130
00:08:53,900 --> 00:08:56,600
basic unit of the robotic operating system.

131
00:08:58,590 --> 00:09:01,846
Also a stack can contain

132
00:09:02,038 --> 00:09:06,218
many packages well. But a stack is more similar

133
00:09:06,304 --> 00:09:09,530
like a collation of packages.

134
00:09:10,530 --> 00:09:14,494
So for example, when you use

135
00:09:14,612 --> 00:09:17,470
anaconda in Python language,

136
00:09:18,130 --> 00:09:22,582
you use command to install Jupyter

137
00:09:22,666 --> 00:09:25,246
notebook or tensorflow.

138
00:09:25,438 --> 00:09:29,390
And after you execute the command line conduct,

139
00:09:29,470 --> 00:09:33,554
install, it will install not

140
00:09:33,592 --> 00:09:37,094
just one package and many packages will be

141
00:09:37,132 --> 00:09:40,594
installed. It's a kind of stacks

142
00:09:40,722 --> 00:09:46,738
of those packages provided

143
00:09:46,754 --> 00:09:50,806
twins kind of function to help user can easily

144
00:09:50,918 --> 00:09:55,260
install their service and functions well.

145
00:09:56,030 --> 00:10:00,250
And also it provide communication mechanism between

146
00:10:00,320 --> 00:10:04,014
Rasnode. It must

147
00:10:04,132 --> 00:10:08,030
contain topic, service action leap

148
00:10:08,610 --> 00:10:12,560
topics is similar like a channel. Then right.

149
00:10:14,390 --> 00:10:17,842
Each node can subscribe and

150
00:10:17,896 --> 00:10:21,810
listen the same topic. And then they will get the message

151
00:10:21,960 --> 00:10:26,430
only by those node they have subscribed

152
00:10:26,510 --> 00:10:30,694
this topic. And also it

153
00:10:30,812 --> 00:10:35,078
provide a kind of service. So a service

154
00:10:35,164 --> 00:10:38,826
is a kind of function

155
00:10:38,928 --> 00:10:42,860
to provide Rasnow to block current

156
00:10:43,230 --> 00:10:47,610
process, to excuse others actions

157
00:10:48,030 --> 00:10:52,842
provided by action Lib. So many

158
00:10:52,896 --> 00:10:56,954
actions lib, they combine together to

159
00:10:56,992 --> 00:11:00,560
provide different kind of actions for a service.

160
00:11:01,330 --> 00:11:05,390
And each action is blocking

161
00:11:05,730 --> 00:11:10,066
processor will be executed in

162
00:11:10,088 --> 00:11:13,218
the background of operation system. Okay,

163
00:11:13,304 --> 00:11:15,800
so let's talk about threejs.

164
00:11:17,050 --> 00:11:21,720
Three JS is useful APIs and

165
00:11:23,210 --> 00:11:27,430
developed by the Webgro specification.

166
00:11:27,850 --> 00:11:31,634
And also it is collapsed

167
00:11:31,682 --> 00:11:35,126
either and simplified well, so user

168
00:11:35,158 --> 00:11:39,002
can easily use it on

169
00:11:39,056 --> 00:11:43,280
their 3d environment from inside.

170
00:11:44,130 --> 00:11:48,126
So let's see from

171
00:11:48,228 --> 00:11:52,174
inside, we use the Figma tool to

172
00:11:52,212 --> 00:11:57,186
design our markup, right? So you can see how

173
00:11:57,288 --> 00:12:01,182
we decide markup through Figma

174
00:12:01,246 --> 00:12:04,434
and artificial intelligence as

175
00:12:04,472 --> 00:12:08,390
well for generated automatically

176
00:12:08,970 --> 00:12:12,406
by prompt message. As you see in

177
00:12:12,428 --> 00:12:17,486
the center of picture, we put a lot of keywords

178
00:12:17,538 --> 00:12:20,874
in the prompt box. Yeah.

179
00:12:20,992 --> 00:12:25,402
After we kill the random button,

180
00:12:25,536 --> 00:12:30,086
we can see this kind of picture to

181
00:12:30,128 --> 00:12:33,200
help us design our markup. Well,

182
00:12:35,810 --> 00:12:39,598
to decide our main idea

183
00:12:39,764 --> 00:12:44,560
and things,

184
00:12:45,330 --> 00:12:47,840
to decide our main color. Well,

185
00:12:48,710 --> 00:12:52,098
it's really helpful to

186
00:12:52,184 --> 00:12:55,650
use generative artificial intelligence.

187
00:12:56,890 --> 00:13:00,678
Yeah. After many steps of the kind

188
00:13:00,844 --> 00:13:05,250
of prompt message by generated

189
00:13:05,330 --> 00:13:10,966
AI, after many times execute

190
00:13:11,078 --> 00:13:13,690
the generated AI,

191
00:13:14,590 --> 00:13:18,810
you finally get this kind of markup

192
00:13:19,390 --> 00:13:22,286
with cyberpunk style. Yeah,

193
00:13:22,388 --> 00:13:26,046
I list many keywords in the

194
00:13:26,068 --> 00:13:32,506
left side of this page. You can see here, Neil, lab backgrounds

195
00:13:32,538 --> 00:13:36,014
are high contrast and metal

196
00:13:36,142 --> 00:13:40,466
and cool color manned styles in

197
00:13:40,488 --> 00:13:44,866
cyberpunk. So yeah,

198
00:13:44,968 --> 00:13:49,394
it's a cyberpunk style markup. You see the

199
00:13:49,432 --> 00:13:53,666
whole mug out here. So three parts of the user interface

200
00:13:53,698 --> 00:13:57,490
as well. You can see I already

201
00:13:57,660 --> 00:14:01,770
using box to separate three parts.

202
00:14:02,830 --> 00:14:06,154
In the green box here, we see

203
00:14:06,272 --> 00:14:10,578
it's an information displayer. So it contains

204
00:14:10,694 --> 00:14:13,982
virtual 3d robotics on here,

205
00:14:14,116 --> 00:14:16,720
and physical iv camera here,

206
00:14:17,570 --> 00:14:21,280
coordinated axis here.

207
00:14:21,730 --> 00:14:25,266
And the arrow master here. Inside the

208
00:14:25,288 --> 00:14:26,850
information display,

209
00:14:27,670 --> 00:14:31,522
it have a small part

210
00:14:31,576 --> 00:14:35,542
of control panel here. You see the red

211
00:14:35,596 --> 00:14:40,118
box, the red box show the

212
00:14:40,204 --> 00:14:44,470
reset button here. And the

213
00:14:44,620 --> 00:14:48,380
six access angle control gear here.

214
00:14:49,310 --> 00:14:53,818
And the motor movement speed here.

215
00:14:53,984 --> 00:14:57,910
Okay. And action recordings

216
00:14:57,990 --> 00:15:01,386
are added here. Action recording

217
00:15:01,418 --> 00:15:05,086
here, the last part of

218
00:15:05,108 --> 00:15:09,374
the sidebar in the orange box.

219
00:15:09,572 --> 00:15:13,950
In the orange box here, it shows logo

220
00:15:14,110 --> 00:15:17,966
and the device, lister. Yeah, we can aid

221
00:15:17,998 --> 00:15:22,014
the device or edit snan as well. And the user

222
00:15:22,062 --> 00:15:23,300
login here,

223
00:15:26,090 --> 00:15:30,454
we continue to show the

224
00:15:30,652 --> 00:15:34,486
physical robotic arm here. So here we see

225
00:15:34,588 --> 00:15:38,062
the physical robotic arm with this axis

226
00:15:38,146 --> 00:15:41,558
and control. So you see many pictures

227
00:15:41,654 --> 00:15:45,334
here, different angle

228
00:15:45,382 --> 00:15:48,970
to see the physical robotic arm.

229
00:15:49,310 --> 00:15:53,822
Yeah, it's bigger ones almost is

230
00:15:53,876 --> 00:15:57,978
higher to health of adult

231
00:15:58,074 --> 00:16:02,160
bodies. So each access

232
00:16:02,870 --> 00:16:06,898
to see each picture and

233
00:16:07,064 --> 00:16:10,658
overall has six

234
00:16:10,824 --> 00:16:13,650
axis in this robotic arm.

235
00:16:14,550 --> 00:16:18,040
The skill we use in virtual environment threejs.

236
00:16:19,610 --> 00:16:23,974
So in the three zs fundamentals we

237
00:16:24,172 --> 00:16:28,250
see layer some components here.

238
00:16:28,400 --> 00:16:31,674
One is scene, scene is

239
00:16:31,872 --> 00:16:36,314
virtual 3d stage where can

240
00:16:36,352 --> 00:16:39,030
use cameras, objects,

241
00:16:39,190 --> 00:16:44,158
light resource and all

242
00:16:44,244 --> 00:16:47,934
models we can present here. And the

243
00:16:47,972 --> 00:16:52,334
second one is camera is determined the position

244
00:16:52,452 --> 00:16:56,770
and perspective and projection of the display.

245
00:16:57,350 --> 00:17:02,674
The next one is objects like

246
00:17:02,712 --> 00:17:05,570
we see in the right side of pictures.

247
00:17:05,910 --> 00:17:09,506
The virtual robot is on. We put these kind

248
00:17:09,528 --> 00:17:13,734
of objects in the virtual environment. So it

249
00:17:13,772 --> 00:17:17,430
contains many operations such as

250
00:17:17,500 --> 00:17:21,320
rotation, scaling, translations on

251
00:17:21,850 --> 00:17:24,570
one object like cubes,

252
00:17:25,390 --> 00:17:28,682
severes and models. And the next

253
00:17:28,736 --> 00:17:33,322
one is light. So light is the brightness

254
00:17:33,386 --> 00:17:37,274
and shadow effect of objects are determined

255
00:17:37,322 --> 00:17:41,760
by the position of light sources such as

256
00:17:42,390 --> 00:17:45,742
lights and direction lights and spotlight

257
00:17:45,806 --> 00:17:49,518
as well. So you can see the light pictures.

258
00:17:49,614 --> 00:17:52,820
We put the directional light on the top

259
00:17:53,590 --> 00:17:57,074
to brighten the robotic

260
00:17:57,122 --> 00:18:01,634
on to make its models

261
00:18:01,682 --> 00:18:05,122
show the brightness and shadow effects

262
00:18:05,186 --> 00:18:08,714
on its model. And last one

263
00:18:08,752 --> 00:18:13,260
is renderer is to

264
00:18:13,870 --> 00:18:18,122
convert 3d objects and lighting information

265
00:18:18,256 --> 00:18:21,726
into two dimension. So yeah,

266
00:18:21,828 --> 00:18:26,074
actually we see the older 3d environments

267
00:18:26,202 --> 00:18:30,190
on website page is in two dimension.

268
00:18:32,130 --> 00:18:36,162
Ultimately we should convert all

269
00:18:36,216 --> 00:18:40,546
the 3d objects, include the light information into

270
00:18:40,648 --> 00:18:45,874
two dimension. Like transform

271
00:18:45,922 --> 00:18:49,862
the images on the screen by our

272
00:18:49,916 --> 00:18:53,414
camera perspective to the sim.

273
00:18:53,612 --> 00:18:57,358
So we will expand more details

274
00:18:57,474 --> 00:19:00,330
in later sliders.

275
00:19:00,910 --> 00:19:02,700
So let's see,

276
00:19:03,870 --> 00:19:07,514
first of all, we put a scene here in

277
00:19:07,552 --> 00:19:12,926
our virtual environment. Yeah, it's empathy in

278
00:19:12,948 --> 00:19:16,302
the sims at the beginning. Okay,

279
00:19:16,356 --> 00:19:19,550
let's start to put camera into scene.

280
00:19:20,050 --> 00:19:23,166
So in this case we use perspective camera.

281
00:19:23,278 --> 00:19:26,786
It contains four parameters. First of

282
00:19:26,808 --> 00:19:30,738
all is field of view and aspart ratio and

283
00:19:30,824 --> 00:19:34,786
near and far clear pan. Here we see

284
00:19:34,808 --> 00:19:39,334
the pictures in the left side there's a camera its

285
00:19:39,372 --> 00:19:43,698
direction to the right side. So its angle

286
00:19:43,874 --> 00:19:48,380
and the direction decide a field of view here.

287
00:19:49,630 --> 00:19:53,974
And how far the camera

288
00:19:54,022 --> 00:19:58,122
can see is decide by

289
00:19:58,256 --> 00:20:01,882
the two clear plans

290
00:20:01,946 --> 00:20:05,822
here. One is a near clear plan. The other one

291
00:20:05,876 --> 00:20:09,310
is far clear plan. So only between

292
00:20:09,460 --> 00:20:13,674
the near clear plan and far clear plan objects

293
00:20:13,722 --> 00:20:16,914
here we can see and display on

294
00:20:16,952 --> 00:20:21,566
our web page. Later we will talk more details

295
00:20:21,678 --> 00:20:25,830
in later sliders and

296
00:20:25,900 --> 00:20:31,414
how we decide. Each plan's size

297
00:20:31,612 --> 00:20:35,142
is by the spared ratios here.

298
00:20:35,276 --> 00:20:39,126
So we decide Aspar ratios by its width

299
00:20:39,158 --> 00:20:42,954
and high decide the

300
00:20:42,992 --> 00:20:47,306
size of the clear plan. So the

301
00:20:47,408 --> 00:20:50,586
linear clear plan and the far clear plan. Its ratio is

302
00:20:50,608 --> 00:20:54,234
the same and only

303
00:20:54,432 --> 00:20:58,240
between the two clear plans. Objects here that we can see

304
00:20:59,090 --> 00:21:03,314
on our screens later. Okay, so in

305
00:21:03,352 --> 00:21:08,542
the nest

306
00:21:08,686 --> 00:21:12,254
I will explain is to describe

307
00:21:12,382 --> 00:21:16,114
objects between the near clear

308
00:21:16,152 --> 00:21:19,686
plan and the far clear plans. So as I

309
00:21:19,708 --> 00:21:23,186
mentioned, between the two clear plans,

310
00:21:23,298 --> 00:21:27,174
all objects here we can see only on

311
00:21:27,212 --> 00:21:31,114
the screen. So here we see there are

312
00:21:31,152 --> 00:21:34,218
many blue cubes here. So only

313
00:21:34,304 --> 00:21:37,740
those blue cubes cubes we can see

314
00:21:38,350 --> 00:21:42,446
on our display and ours, like the

315
00:21:42,468 --> 00:21:46,026
purple cubes outside the two clear plans

316
00:21:46,218 --> 00:21:48,880
we cannot see on our screen.

317
00:21:50,210 --> 00:21:54,978
So you can see, it's very simple to create

318
00:21:55,064 --> 00:21:59,330
a cube into the sim by

319
00:21:59,400 --> 00:22:02,946
those function here. The first one you use in

320
00:22:02,968 --> 00:22:06,914
the bus geometry to create a new geometry

321
00:22:06,962 --> 00:22:10,838
object and decide its mesh standard

322
00:22:10,924 --> 00:22:14,438
material by its color. Then we

323
00:22:14,524 --> 00:22:18,860
put the material and the geometry into the mesh object

324
00:22:19,950 --> 00:22:24,058
to create a cube object. Then we can use sim

325
00:22:24,144 --> 00:22:28,330
eight to put the cube into the scene.

326
00:22:29,150 --> 00:22:32,526
Okay, so let's continue to set a

327
00:22:32,548 --> 00:22:36,398
light into our scene so

328
00:22:36,484 --> 00:22:40,686
you can see the pictures. We put duration of light on

329
00:22:40,708 --> 00:22:43,630
the top of those cubes.

330
00:22:43,970 --> 00:22:47,370
Like we mentioned in previous slider,

331
00:22:47,450 --> 00:22:51,220
we put light on the top of

332
00:22:51,670 --> 00:22:55,230
our robotic arm so the light

333
00:22:55,320 --> 00:23:00,440
can make those cubes looks well to

334
00:23:01,610 --> 00:23:06,150
obviously see its darkness and shadow.

335
00:23:07,050 --> 00:23:10,780
So you see only,

336
00:23:11,550 --> 00:23:15,210
it's the sense only the two clip plants

337
00:23:15,710 --> 00:23:19,900
objects, we can make

338
00:23:20,590 --> 00:23:25,370
the effect of lightness on those objects.

339
00:23:25,530 --> 00:23:28,682
So out of the two clips,

340
00:23:28,826 --> 00:23:32,786
those purple objects cannot be affected by

341
00:23:32,808 --> 00:23:36,306
the light. Then we

342
00:23:36,488 --> 00:23:42,130
use the rendered function to display

343
00:23:42,550 --> 00:23:46,360
the scenes into the screen.

344
00:23:47,210 --> 00:23:51,190
Like you see, only the blue cubes here

345
00:23:51,340 --> 00:23:56,120
will display the on the screens outside

346
00:23:56,970 --> 00:24:00,246
cleaver plans. Those purple

347
00:24:00,438 --> 00:24:04,410
cubes won't be rendered on the screens.

348
00:24:04,990 --> 00:24:10,334
So, yeah, it's the rendered functions you

349
00:24:10,372 --> 00:24:15,022
will use in the final stage also.

350
00:24:15,156 --> 00:24:18,942
Yeah. If we want to make

351
00:24:18,996 --> 00:24:22,618
the purple cube into the scenes,

352
00:24:22,794 --> 00:24:26,146
we just backwards a

353
00:24:26,168 --> 00:24:29,842
little. The near

354
00:24:29,896 --> 00:24:34,066
Korea plants measure one

355
00:24:34,248 --> 00:24:37,730
purple cube into the

356
00:24:37,800 --> 00:24:41,426
scope of the two Korea plants.

357
00:24:41,618 --> 00:24:45,990
Like you see now, purple cubes already

358
00:24:46,060 --> 00:24:50,078
in front of those blue

359
00:24:50,114 --> 00:24:52,300
cubes. And behind,

360
00:24:53,550 --> 00:24:56,890
finally, you will see the purple

361
00:24:57,710 --> 00:25:01,790
is very close to the front of the camera.

362
00:25:02,290 --> 00:25:05,870
And behind purple cubes,

363
00:25:06,370 --> 00:25:09,950
they are all blue cubes.

364
00:25:10,690 --> 00:25:14,690
So, yeah, it's the perspective from the camera.

365
00:25:15,350 --> 00:25:19,058
And then we continue

366
00:25:19,144 --> 00:25:23,486
to see how we integrate a robotic arm

367
00:25:23,678 --> 00:25:28,226
in the virtual environment. With the physical robotic

368
00:25:28,258 --> 00:25:31,814
arm here, we create a model,

369
00:25:32,012 --> 00:25:37,126
contains six access here on

370
00:25:37,148 --> 00:25:40,886
the buttons. There's one base here. So it's

371
00:25:40,918 --> 00:25:44,330
very simple architecture.

372
00:25:45,070 --> 00:25:48,170
So we can easy to build up in the

373
00:25:48,240 --> 00:25:52,478
virtual environment and synchronize each access

374
00:25:52,564 --> 00:25:56,240
to the physical one. Finally, you can see

375
00:25:56,770 --> 00:26:00,750
you can control the virtual robotic arms.

376
00:26:01,490 --> 00:26:05,060
Very easy to synchronize the physical one.

377
00:26:05,590 --> 00:26:09,598
Okay, so how we achieve the synchronization of virtual and physical.

378
00:26:09,774 --> 00:26:14,082
So you see, we have

379
00:26:14,136 --> 00:26:17,974
some steps here in the left side. On the right side,

380
00:26:18,012 --> 00:26:21,560
you see. Yeah, it's a demonstration we see before

381
00:26:22,090 --> 00:26:25,574
the CIS control and

382
00:26:25,692 --> 00:26:29,594
ancient execution. Then we combine it to

383
00:26:29,632 --> 00:26:34,490
change six Asians angles so

384
00:26:34,560 --> 00:26:39,174
those angles data will deliver to both virtual

385
00:26:39,222 --> 00:26:42,606
and the physical robotic arms. Yeah, so you can

386
00:26:42,628 --> 00:26:47,150
see it's automatically synchronized

387
00:26:48,290 --> 00:26:51,758
virtual and physical at the same time.

388
00:26:51,844 --> 00:26:54,994
Okay. It's based on

389
00:26:55,032 --> 00:26:59,214
the robot operating

390
00:26:59,262 --> 00:27:02,050
system message format.

391
00:27:02,550 --> 00:27:05,746
So they are both in the ROS cluster so

392
00:27:05,768 --> 00:27:08,980
they can easily get this message.

393
00:27:09,670 --> 00:27:13,366
And we maintain those messages and data into the cloud

394
00:27:13,468 --> 00:27:15,990
by the ROS cloud API.

395
00:27:16,490 --> 00:27:21,766
Let's continue to see another

396
00:27:21,868 --> 00:27:25,980
skio web RTC we use

397
00:27:27,310 --> 00:27:30,858
for the IP camera

398
00:27:31,034 --> 00:27:34,302
information sent to the web

399
00:27:34,356 --> 00:27:38,810
page. So you see the web RTC

400
00:27:38,890 --> 00:27:42,586
by the IP cameras. By this hardware

401
00:27:42,778 --> 00:27:47,294
we use a TP link table we buy it's

402
00:27:47,342 --> 00:27:51,860
cheaper and we're easy to use in

403
00:27:52,550 --> 00:27:56,230
our country. So it's very simple. We're using

404
00:27:56,380 --> 00:28:00,070
it's by the RTSP protocol.

405
00:28:00,650 --> 00:28:03,990
It's a general protocol.

406
00:28:06,330 --> 00:28:10,540
We set the username and password and the

407
00:28:11,150 --> 00:28:14,650
IP address is a public IP address.

408
00:28:14,720 --> 00:28:18,042
Later I will tell you how we get the

409
00:28:18,096 --> 00:28:19,340
public IP address.

410
00:28:22,530 --> 00:28:26,638
This kind tool is

411
00:28:26,724 --> 00:28:29,918
open source and already

412
00:28:30,084 --> 00:28:33,310
someone create docker files.

413
00:28:33,390 --> 00:28:37,154
We can easy to start this service

414
00:28:37,272 --> 00:28:41,534
by WebRTC streamer this GitHub

415
00:28:41,582 --> 00:28:45,986
project. Yeah it support RTSP

416
00:28:46,018 --> 00:28:50,370
protocol and also can start HTTP server.

417
00:28:50,530 --> 00:28:53,880
You can easy to connect this server by another

418
00:28:54,490 --> 00:28:58,214
server as well and compatible with Windows and

419
00:28:58,252 --> 00:29:02,886
inas. Actually it's a docker image

420
00:29:03,078 --> 00:29:07,930
easy to use in a containerized.

421
00:29:08,910 --> 00:29:12,766
So you see yeah it's very simple to

422
00:29:12,788 --> 00:29:16,798
use. We don't need to modify too much then we

423
00:29:16,804 --> 00:29:20,618
can use it well okay let's see the programming

424
00:29:20,634 --> 00:29:23,874
code of WebRTC how to use it in

425
00:29:23,912 --> 00:29:27,586
our project. So there are two

426
00:29:27,688 --> 00:29:31,582
IP addresses we need to set up. One is camera

427
00:29:31,646 --> 00:29:36,046
IP address. It's RTSP

428
00:29:36,078 --> 00:29:40,040
protocol to public for outside services

429
00:29:40,650 --> 00:29:44,280
and the otherwise RTC IP address is

430
00:29:46,170 --> 00:29:50,074
local address for our

431
00:29:50,192 --> 00:29:53,994
service to connect to the

432
00:29:54,032 --> 00:29:59,302
physical IP camera. When the components

433
00:29:59,366 --> 00:30:02,794
start up we need a WebRTC

434
00:30:02,842 --> 00:30:06,346
streamer to start a server

435
00:30:06,538 --> 00:30:10,446
in our local environment and

436
00:30:10,628 --> 00:30:13,700
then we use the connect function

437
00:30:15,030 --> 00:30:18,770
to public the RTSP

438
00:30:19,590 --> 00:30:22,834
protocol to outside service when

439
00:30:22,872 --> 00:30:26,920
we use WebRTC we encounter some issues here.

440
00:30:28,250 --> 00:30:32,278
Yeah because a little different the

441
00:30:32,364 --> 00:30:36,390
usage of WebRTC streamer in development and production.

442
00:30:37,630 --> 00:30:41,754
In development stage we run the

443
00:30:41,872 --> 00:30:45,420
WebRTC streamer locally so

444
00:30:46,590 --> 00:30:50,286
we don't care about the public IP address but

445
00:30:50,308 --> 00:30:54,174
in production our main

446
00:30:54,212 --> 00:30:58,302
system digital twins and also the web

447
00:30:58,356 --> 00:31:02,800
artist tumor API server all deployed on cloud

448
00:31:03,590 --> 00:31:07,602
simultaneously. So we choose

449
00:31:07,736 --> 00:31:11,746
the docker compose to solve twins issue to

450
00:31:11,928 --> 00:31:15,060
make land run at the same time.

451
00:31:16,090 --> 00:31:20,630
Then we still encounter

452
00:31:20,970 --> 00:31:24,854
website appearing back during the

453
00:31:24,892 --> 00:31:28,760
development. Finally we found

454
00:31:29,610 --> 00:31:33,258
we must change UDB protocol to

455
00:31:33,344 --> 00:31:37,050
TCP protocol for our

456
00:31:37,120 --> 00:31:41,040
connection between the IP camera and

457
00:31:41,570 --> 00:31:43,710
the WebRTC server.

458
00:31:45,570 --> 00:31:49,982
In the next stage we

459
00:31:50,036 --> 00:31:52,874
master to public our IP address.

460
00:31:53,012 --> 00:31:57,074
So our IP camera without the

461
00:31:57,112 --> 00:32:00,370
external IP. So finally

462
00:32:00,440 --> 00:32:03,780
we choose the poor forwarding. To solve this question

463
00:32:04,630 --> 00:32:09,006
you can see we use common Socat in Linus

464
00:32:09,118 --> 00:32:13,142
we threw the UDP, that's why we use

465
00:32:13,196 --> 00:32:18,300
UDP can work as well to

466
00:32:19,870 --> 00:32:22,966
inside service of our IP

467
00:32:22,998 --> 00:32:27,082
camera and web update servers to

468
00:32:27,216 --> 00:32:31,134
public from the outside

469
00:32:31,252 --> 00:32:34,654
computer through the public IP address. So it

470
00:32:34,692 --> 00:32:38,382
means other service can connect this

471
00:32:38,436 --> 00:32:41,920
web party service through the public IP address.

472
00:32:42,710 --> 00:32:46,594
Okay, let's continue to talk about the

473
00:32:46,632 --> 00:32:50,786
front end side analog View

474
00:32:50,888 --> 00:32:55,490
framework to subscribe

475
00:32:57,450 --> 00:33:01,218
ROS bridge to listen the ROS messages

476
00:33:01,314 --> 00:33:04,886
in the front end side. Okay, so let's talk about

477
00:33:05,068 --> 00:33:08,610
how ROS cluster connect virtual

478
00:33:08,690 --> 00:33:12,230
and physical environment through Rosebridge library.

479
00:33:12,650 --> 00:33:16,106
So ROS library defines a

480
00:33:16,128 --> 00:33:20,054
topic each node and then ROS

481
00:33:20,102 --> 00:33:24,140
node can deliver a message through the topic to

482
00:33:24,510 --> 00:33:28,334
each other from inside using the

483
00:33:28,372 --> 00:33:31,882
subscribe function to subscribe this topic

484
00:33:31,946 --> 00:33:35,726
to get the message and three

485
00:33:35,828 --> 00:33:40,020
s components will change their angle and position

486
00:33:40,470 --> 00:33:45,322
depends on those messages delivered

487
00:33:45,406 --> 00:33:48,966
from the last cluster. So you

488
00:33:48,988 --> 00:33:52,120
can see we get a lot of messages in the console log.

489
00:33:53,530 --> 00:33:58,234
So in the backend side of

490
00:33:58,272 --> 00:34:04,570
Python language also we need subscriber

491
00:34:05,710 --> 00:34:09,514
to the topic in the last cluster. So we

492
00:34:09,552 --> 00:34:13,690
see how the backend side we subscribe

493
00:34:13,770 --> 00:34:17,694
it. We use create subscription here to the

494
00:34:17,732 --> 00:34:21,950
send topic. Both the send on

495
00:34:22,020 --> 00:34:24,080
the front end side and the back inside.

496
00:34:25,330 --> 00:34:29,342
So the listener callback

497
00:34:29,406 --> 00:34:32,866
we see when we get the message from

498
00:34:32,888 --> 00:34:36,882
the loss cluster we send those messages

499
00:34:36,946 --> 00:34:40,790
into the cloud

500
00:34:40,860 --> 00:34:44,710
ROS API. We save all

501
00:34:44,780 --> 00:34:48,346
the information and data into

502
00:34:48,448 --> 00:34:53,402
cloud database and also we send

503
00:34:53,536 --> 00:34:57,482
those information by different angles and

504
00:34:57,536 --> 00:35:01,002
position to the robotic arm.

505
00:35:01,066 --> 00:35:04,622
Later we will tell more details about

506
00:35:04,676 --> 00:35:08,586
how we use the Python language connected

507
00:35:08,618 --> 00:35:11,966
with c sharp language to control the

508
00:35:11,988 --> 00:35:15,200
physical robotic arm. And so

509
00:35:15,890 --> 00:35:19,762
in the background side of Python language we also

510
00:35:19,896 --> 00:35:23,474
define Roscow API. So first

511
00:35:23,512 --> 00:35:26,626
of all it's a category device.

512
00:35:26,818 --> 00:35:30,802
So user can use this device

513
00:35:30,866 --> 00:35:34,214
API to register a new

514
00:35:34,252 --> 00:35:37,634
device when they have a new

515
00:35:37,692 --> 00:35:41,210
device into the ROS cluster.

516
00:35:42,110 --> 00:35:45,414
Also they can depend on their password

517
00:35:45,462 --> 00:35:49,290
and username to deliver the right

518
00:35:49,360 --> 00:35:52,814
certificate to the right device to make sure

519
00:35:52,852 --> 00:35:56,234
they can control or manipulate each ROS

520
00:35:56,282 --> 00:36:00,158
node in ROS cluster so they can

521
00:36:00,244 --> 00:36:04,174
do some actions by the ROS API

522
00:36:04,222 --> 00:36:07,806
to synchronize virtual and physical environment

523
00:36:07,918 --> 00:36:11,762
devices. So we continue to

524
00:36:11,816 --> 00:36:14,290
introduce ROS cloud API.

525
00:36:15,050 --> 00:36:18,214
Here we show how we

526
00:36:18,252 --> 00:36:21,686
interact with get method of

527
00:36:21,788 --> 00:36:25,478
device API. It will

528
00:36:25,564 --> 00:36:29,450
respond to JSON object to show the

529
00:36:29,520 --> 00:36:34,170
device IP, name brand and others attributes.

530
00:36:35,150 --> 00:36:38,726
You see how we put JSON

531
00:36:38,758 --> 00:36:42,750
object into our device asian API

532
00:36:43,170 --> 00:36:46,878
asian we define move and then we put some data

533
00:36:46,964 --> 00:36:51,214
like angle speed for each access and

534
00:36:51,252 --> 00:36:55,342
we execute the API. The physical

535
00:36:55,406 --> 00:36:59,986
and virtual robotic arm will follow

536
00:37:00,088 --> 00:37:03,742
those information to change the right angle

537
00:37:03,806 --> 00:37:07,634
and speed. Here we see how Python code the

538
00:37:07,672 --> 00:37:11,254
rascal API. We use the

539
00:37:11,292 --> 00:37:15,462
function compared to angle lister to make sure the

540
00:37:15,516 --> 00:37:19,250
current angle they want to change is totally different than previous

541
00:37:19,330 --> 00:37:23,260
one and if it's did

542
00:37:23,630 --> 00:37:27,622
we will code the API instantly.

543
00:37:27,686 --> 00:37:31,966
So here the second part

544
00:37:32,068 --> 00:37:36,126
we see the device asian page function we mentioned

545
00:37:36,228 --> 00:37:39,934
in previous slide. We put the asian move and

546
00:37:40,052 --> 00:37:44,210
put some data angle here to synchronize

547
00:37:45,190 --> 00:37:49,262
both virtual and physical robotic arm

548
00:37:49,326 --> 00:37:54,274
at the same time. Here we get the

549
00:37:54,312 --> 00:37:58,298
last message from the Python websocket

550
00:37:58,414 --> 00:38:02,034
into the C sharp library. To control the physical

551
00:38:02,162 --> 00:38:05,494
robotic arm we use C

552
00:38:05,532 --> 00:38:10,090
sharp SDK to encapsulate those functions

553
00:38:11,310 --> 00:38:14,810
to control the physical device like we can

554
00:38:14,880 --> 00:38:19,402
change each access and

555
00:38:19,456 --> 00:38:23,280
also we can set its angles and position

556
00:38:23,730 --> 00:38:26,670
speed as well by those functions.

557
00:38:28,610 --> 00:38:32,314
In the end we use DevOps

558
00:38:32,362 --> 00:38:35,940
skills, something tools like

559
00:38:37,270 --> 00:38:40,770
Jenkins and Docker containerize

560
00:38:41,190 --> 00:38:45,230
our applications to make them

561
00:38:45,320 --> 00:38:48,726
easy deploy. You see how

562
00:38:48,748 --> 00:38:53,010
we use Jenkins and Darkrise tool to deploy

563
00:38:53,170 --> 00:38:57,446
both on cloud and on premises at

564
00:38:57,468 --> 00:39:00,554
the same time. So you

565
00:39:00,592 --> 00:39:04,202
see the script we state

566
00:39:04,256 --> 00:39:07,740
by state to execute and then

567
00:39:08,350 --> 00:39:12,622
after the image created we put the

568
00:39:12,676 --> 00:39:16,750
image into the AWS

569
00:39:17,650 --> 00:39:20,670
ECR service. Then later

570
00:39:20,740 --> 00:39:24,660
we get the image from that to deploy on

571
00:39:25,110 --> 00:39:28,370
AWS environments.

572
00:39:29,030 --> 00:39:33,074
So all I want to present to you are

573
00:39:33,272 --> 00:39:35,640
already finished here.

574
00:39:36,730 --> 00:39:39,910
So let's give you a summary.

575
00:39:40,570 --> 00:39:44,200
So in this presentation you

576
00:39:44,970 --> 00:39:49,260
get the based concept of ros and threejs

577
00:39:49,630 --> 00:39:53,466
as well and also know

578
00:39:53,648 --> 00:39:57,386
how we integrate our system into

579
00:39:57,568 --> 00:40:02,206
virtual and physical environments and know

580
00:40:02,388 --> 00:40:07,230
how we create a cloud based interface

581
00:40:07,890 --> 00:40:11,086
to integrate rust cloud API we

582
00:40:11,108 --> 00:40:15,774
defined and the local IP

583
00:40:15,822 --> 00:40:19,890
webcam. And also you know

584
00:40:19,960 --> 00:40:25,122
how we deploy conveniently by

585
00:40:25,176 --> 00:40:27,810
the Docker and Jenkins.

586
00:40:28,330 --> 00:40:33,478
We dockerize all application and

587
00:40:33,644 --> 00:40:37,686
make them easy to deploy by

588
00:40:37,788 --> 00:40:41,542
the Jenkins. So I hope

589
00:40:41,596 --> 00:40:45,382
you can get some knowledge from my

590
00:40:45,436 --> 00:40:48,886
presentation. So if you still have any questions,

591
00:40:48,988 --> 00:40:52,220
just yeah, send me message. Thank you.

