1
00:00:27,080 --> 00:00:31,080
Ain't no ev one. Welcome to our AI

2
00:00:31,152 --> 00:00:34,464
and disability in asian or in asian.

3
00:00:34,624 --> 00:00:38,392
Dhanan and I are delighted to welcome you

4
00:00:38,488 --> 00:00:42,056
and talk to you about a subject that

5
00:00:42,120 --> 00:00:44,936
is close to our hearts.

6
00:00:45,120 --> 00:00:48,324
We end the scrap transcript.

7
00:00:48,904 --> 00:00:52,604
We give you the link during the live session.

8
00:00:53,304 --> 00:00:57,018
My name is Emanuela Bois and I am happy

9
00:00:57,066 --> 00:00:59,534
to represent this to Wisdan.

10
00:01:00,514 --> 00:01:03,954
I was born deaf with two year implants.

11
00:01:04,074 --> 00:01:06,734
I like to say that I am muni.

12
00:01:07,074 --> 00:01:10,338
I have been a developer since twelve years

13
00:01:10,506 --> 00:01:13,414
and I work at Schuddho in Paris.

14
00:01:13,874 --> 00:01:17,970
Schudo is an IT services company specialized

15
00:01:18,082 --> 00:01:22,508
in development engine and offense an

16
00:01:22,556 --> 00:01:28,220
amity to social justice for

17
00:01:28,292 --> 00:01:30,584
writer in asian intake.

18
00:01:31,484 --> 00:01:35,264
I am very committed to digital accessibility.

19
00:01:35,804 --> 00:01:39,572
I am not an expert in AI, but I use

20
00:01:39,628 --> 00:01:42,892
automated tools on a daily basis

21
00:01:43,068 --> 00:01:46,596
which allow me to analyze

22
00:01:46,700 --> 00:01:50,964
the impact of AI on my daily life.

23
00:01:51,464 --> 00:01:55,008
I am a member of the Duchess France association

24
00:01:55,136 --> 00:01:59,284
which represents women in deaf interests.

25
00:01:59,624 --> 00:02:04,768
I am also a member of the CNCF

26
00:02:04,896 --> 00:02:08,344
Deaf and Hard of hearing initiative

27
00:02:08,504 --> 00:02:12,248
which represents deaf and hard of hearing

28
00:02:12,296 --> 00:02:15,404
people around the world.

29
00:02:16,234 --> 00:02:19,850
Hello, my name is Tanlin Dobrye. I'm very proud to

30
00:02:19,882 --> 00:02:23,202
co present this talk with Emmanuel. I am a

31
00:02:23,218 --> 00:02:26,666
machine learning engineer formerly with Axafrance and

32
00:02:26,690 --> 00:02:30,538
I am volunteer for several french ngo's related to

33
00:02:30,586 --> 00:02:34,354
data, science and technology like data for

34
00:02:34,394 --> 00:02:37,826
good and latitude. As a conference speaker I cover

35
00:02:37,890 --> 00:02:42,110
topics as artificial intelligence including

36
00:02:42,262 --> 00:02:46,062
its legal framework, hemlocks and inclusion.

37
00:02:46,238 --> 00:02:49,678
I am a part of the organizing team of

38
00:02:49,726 --> 00:02:52,902
a conference named Crewneur

39
00:02:52,958 --> 00:02:56,074
which take place in Lille in the north of France.

40
00:02:56,934 --> 00:03:01,030
Additionally, I am a part of the collective of women developer

41
00:03:01,142 --> 00:03:04,514
named Chisdev. Due to a medical

42
00:03:04,814 --> 00:03:07,920
condition affecting various parts of my body,

43
00:03:08,102 --> 00:03:12,252
I am an umbilatory Wilshire user here. I became deaf when

44
00:03:12,308 --> 00:03:16,436
I was a teenager. The media

45
00:03:16,540 --> 00:03:20,084
and science fiction have given a

46
00:03:20,124 --> 00:03:24,900
very highly distorted image of artificial intelligence.

47
00:03:25,092 --> 00:03:30,452
I believe that if you follow the Conf 42

48
00:03:30,628 --> 00:03:34,108
conferences you are already quite familiar with

49
00:03:34,156 --> 00:03:38,030
the reality, but we prefer to provide a brief

50
00:03:38,222 --> 00:03:42,126
theory recap for

51
00:03:42,190 --> 00:03:45,474
explain what is artificial intelligence.

52
00:03:45,814 --> 00:03:49,714
I like to use the example of baking your cake for a cookbook.

53
00:03:50,014 --> 00:03:53,958
Imagine you follow a recipe. This recipe represents your

54
00:03:54,006 --> 00:03:57,406
classic software starting with the ingredient.

55
00:03:57,510 --> 00:04:01,942
It is your input. You execute several instructions and

56
00:04:02,078 --> 00:04:05,926
in the end you have the perfect strawberry pie look like

57
00:04:05,990 --> 00:04:09,154
the one in photo from your recipe book.

58
00:04:11,814 --> 00:04:16,118
But an application with artificial intelligence

59
00:04:16,246 --> 00:04:20,078
work a little different will still

60
00:04:20,126 --> 00:04:23,630
start from your recipe book, but in your pastry you

61
00:04:23,662 --> 00:04:27,390
don't no longer have strawberries, instead you

62
00:04:27,422 --> 00:04:31,208
have apple. Unfortunately in your cookbook doesn't have

63
00:04:31,256 --> 00:04:35,168
any apple pie recipe otherwise full of

64
00:04:35,256 --> 00:04:38,024
other fridge pie recipe P.

65
00:04:38,104 --> 00:04:41,832
Plum so you rely on

66
00:04:41,848 --> 00:04:46,112
the various recipes to try to make your perfect apple pie.

67
00:04:46,288 --> 00:04:50,600
An AI application is based on mathematics, particularly statistics

68
00:04:50,632 --> 00:04:54,108
and probabilities. But the reasoning is the same.

69
00:04:54,256 --> 00:04:57,864
We proven with the data where hold the

70
00:04:58,204 --> 00:05:01,396
pre pie recipe from the recipe book and

71
00:05:01,420 --> 00:05:03,984
you research what is the most likely.

72
00:05:04,404 --> 00:05:08,020
It's the most likely that the recipe anchored sugar,

73
00:05:08,212 --> 00:05:11,852
butter, flour, swandon in whole

74
00:05:11,908 --> 00:05:15,388
recipe of pie rather than

75
00:05:15,436 --> 00:05:17,224
finding some pickles.

76
00:05:18,084 --> 00:05:22,104
Ethics is related to morality and subjectivity.

77
00:05:22,984 --> 00:05:26,064
Just because it's legal doesn't mean it's ethical.

78
00:05:26,224 --> 00:05:30,872
As developer and solution designer, we have a moral responsibility towards

79
00:05:31,048 --> 00:05:34,264
your user. It's not because your country

80
00:05:34,344 --> 00:05:38,044
doesn't legislate against discriminating against minority,

81
00:05:38,744 --> 00:05:42,624
specifically those with disability, that it means

82
00:05:42,704 --> 00:05:46,136
it's ethically correct. Law take time

83
00:05:46,200 --> 00:05:50,136
to be created and modified and often

84
00:05:50,200 --> 00:05:54,072
adding with morality on a given society or where

85
00:05:54,128 --> 00:05:58,440
it means to be appliqu what

86
00:05:58,472 --> 00:06:01,808
is legal in one country is not necessarily moral

87
00:06:01,856 --> 00:06:05,712
for a two citizen of another country. Artificial intelligence

88
00:06:05,768 --> 00:06:09,576
is highly sensitive to the cultural environment in

89
00:06:09,600 --> 00:06:12,984
which its model well create. For example,

90
00:06:13,104 --> 00:06:17,310
the use of AI in video surveillance is ideally unply

91
00:06:17,342 --> 00:06:21,534
in certain countries, but probably by the law and heavily

92
00:06:21,614 --> 00:06:25,270
regulated in other there existing regulation

93
00:06:25,382 --> 00:06:29,526
around AI and more are the origin.

94
00:06:29,670 --> 00:06:33,394
There are AI acts in the European Union,

95
00:06:33,934 --> 00:06:37,354
but some disposition of the GDPR

96
00:06:37,934 --> 00:06:41,838
general data protection regulation

97
00:06:41,966 --> 00:06:45,674
already have an impact on the high integrated

98
00:06:46,204 --> 00:06:49,676
application we have previously. That data is

99
00:06:49,700 --> 00:06:52,584
the foundation of all AI application.

100
00:06:53,764 --> 00:06:57,544
Let me give you an upper view of disability.

101
00:06:58,564 --> 00:07:02,076
Didn't you know that 1 billion

102
00:07:02,180 --> 00:07:05,340
people in the world are disciplined?

103
00:07:05,492 --> 00:07:09,516
Is this estimated that about 15%

104
00:07:09,620 --> 00:07:12,664
of the world population has a disability?

105
00:07:13,044 --> 00:07:17,184
This fear is very difficult to estimate for

106
00:07:17,724 --> 00:07:21,268
several reasons. A person may not

107
00:07:21,396 --> 00:07:24,948
have their disability or doesn't know

108
00:07:25,116 --> 00:07:29,024
they have a disability. A disability can

109
00:07:29,324 --> 00:07:32,748
occur during one's life and be in

110
00:07:32,796 --> 00:07:37,084
diagnostic can be an honest whole host

111
00:07:37,244 --> 00:07:40,464
to have one's disability designed

112
00:07:41,054 --> 00:07:45,006
contrary to popular belief, disability is

113
00:07:45,070 --> 00:07:48,838
not just a problem for people with

114
00:07:48,926 --> 00:07:52,230
wheelchairs. A disability is often

115
00:07:52,382 --> 00:07:56,354
not very visible. Did you know that

116
00:07:56,814 --> 00:08:00,638
80% of disabilities are

117
00:08:00,686 --> 00:08:02,754
not immediately visible.

118
00:08:03,134 --> 00:08:06,894
Nevertheless, we have a fast check on

119
00:08:07,014 --> 00:08:12,008
this error. It is often said that 50%

120
00:08:12,096 --> 00:08:15,992
of disabilities are invisible. We don't

121
00:08:16,048 --> 00:08:18,964
really know the exact rails.

122
00:08:19,704 --> 00:08:23,504
What is certain is that the majority of disabilities

123
00:08:23,624 --> 00:08:26,920
are invisible. We are to eat

124
00:08:26,952 --> 00:08:31,324
to you, but before you address us,

125
00:08:31,664 --> 00:08:34,984
you did not know where deaf

126
00:08:35,604 --> 00:08:39,612
our deafness are invisible as we

127
00:08:39,668 --> 00:08:42,988
are live. You aren't yes that my

128
00:08:43,036 --> 00:08:45,944
partner death is in a welsh air.

129
00:08:47,084 --> 00:08:50,220
According to the source inference, they are

130
00:08:50,292 --> 00:08:53,024
five men families of disabilities.

131
00:08:53,404 --> 00:08:57,864
We see all disabilities socially impairment

132
00:08:58,284 --> 00:09:02,144
antimicrobial disabilities, mental disabilities,

133
00:09:02,684 --> 00:09:06,984
disability diseases such as endometriosis,

134
00:09:07,364 --> 00:09:11,304
ulcer or childhood disease, for example.

135
00:09:11,764 --> 00:09:15,284
There are disabling diseases that can be

136
00:09:15,324 --> 00:09:19,428
disabling on a daily basis. In the short or

137
00:09:19,476 --> 00:09:23,892
medium term, we can have mutine

138
00:09:23,948 --> 00:09:26,784
disabilities around you.

139
00:09:28,514 --> 00:09:32,498
You probably know someone who is

140
00:09:32,546 --> 00:09:36,322
affected by disabilities. Maybe you are

141
00:09:36,418 --> 00:09:39,938
concern yourself in the course of his life.

142
00:09:40,066 --> 00:09:44,018
We are not immune to being effective by

143
00:09:44,066 --> 00:09:47,274
a disability which I do not wish on you,

144
00:09:47,314 --> 00:09:50,362
of course. Thank you, Emmanuel,

145
00:09:50,458 --> 00:09:54,026
for your reminder. Now we have some

146
00:09:54,210 --> 00:09:59,640
theoretical knowledge and a little fact

147
00:09:59,712 --> 00:10:03,884
about disabilities. We can move to the practical example

148
00:10:04,624 --> 00:10:08,844
if we will generate some image of people with disabilities

149
00:10:09,304 --> 00:10:12,888
for using advertising. For example,

150
00:10:13,056 --> 00:10:16,104
we need data and we need to choose

151
00:10:16,144 --> 00:10:19,840
to scrap image on Google image because we don't have

152
00:10:19,992 --> 00:10:24,124
any database. With lots of images of people with disabilities

153
00:10:24,784 --> 00:10:28,314
in your companies, they are the first result

154
00:10:28,474 --> 00:10:33,334
on the Google image. In this little video,

155
00:10:33,794 --> 00:10:37,602
when you search people

156
00:10:37,738 --> 00:10:41,338
with disabilities on Google image, you see

157
00:10:41,426 --> 00:10:45,322
lots of Welshare. And before

158
00:10:45,458 --> 00:10:49,738
Emmanuel said that the majority

159
00:10:49,826 --> 00:10:53,694
of disabilities are invisible

160
00:10:54,004 --> 00:10:57,916
and it's a big problem to the one

161
00:10:57,980 --> 00:11:01,436
representation of disabilities is

162
00:11:01,500 --> 00:11:05,100
the Welshare. This representation is okay

163
00:11:05,132 --> 00:11:09,148
for me because I have disabilities and I am a Welshare user.

164
00:11:09,316 --> 00:11:12,584
But in France and in many western countries,

165
00:11:12,884 --> 00:11:17,544
we used to see this Welshare logo for people with disabilities.

166
00:11:18,004 --> 00:11:21,868
It's the same in the greater Gerwig's Barbie

167
00:11:21,956 --> 00:11:25,636
movies. We have a protagonist in a pic welsh air.

168
00:11:25,700 --> 00:11:28,284
The film is very nice, I like it a lot.

169
00:11:28,444 --> 00:11:32,824
But for a film seen as an ode of diversities,

170
00:11:33,604 --> 00:11:36,796
disability was reduced as a single character

171
00:11:36,860 --> 00:11:40,532
in the wheelchair with no dialogues. This vision of

172
00:11:40,588 --> 00:11:44,316
the disabilities, summed up just by the

173
00:11:44,340 --> 00:11:48,322
wheelchair, is a cognitive b's. It seems

174
00:11:48,338 --> 00:11:50,414
logical for us, but it's wrong.

175
00:11:51,234 --> 00:11:54,674
And this has two negative impacts.

176
00:11:54,834 --> 00:11:58,602
It going to be is

177
00:11:58,658 --> 00:12:02,162
going to be seen as the definition

178
00:12:02,218 --> 00:12:05,774
of disability. If I'm not in my wheelchair,

179
00:12:06,394 --> 00:12:09,874
that doesn't mean I'm not younger disabled or

180
00:12:09,994 --> 00:12:15,120
that I have been cured. And the second negative

181
00:12:15,192 --> 00:12:18,744
impact of that is it will exclude people

182
00:12:18,864 --> 00:12:22,664
or erase certain disabilities. For example,

183
00:12:22,744 --> 00:12:26,424
if the only criterion is the use of a wheelchair,

184
00:12:26,584 --> 00:12:30,592
it excludes many people like Emmanuel, who are still living

185
00:12:30,648 --> 00:12:34,656
with disabilities. And if

186
00:12:34,680 --> 00:12:38,736
we create your model based on the Google image or

187
00:12:38,760 --> 00:12:42,198
another B's dataset, we have this

188
00:12:42,246 --> 00:12:46,638
result. This is some image generated with Microsoft designer.

189
00:12:46,806 --> 00:12:50,134
How this image represents a caucasian woman,

190
00:12:50,254 --> 00:12:53,702
no racism, people, no man and hole in

191
00:12:53,718 --> 00:12:57,574
a wheelchair. When Whacker users are a minority

192
00:12:57,654 --> 00:12:59,754
of people with disabilities.

193
00:13:01,654 --> 00:13:05,526
Jeremy Andrew Davies his audeste and

194
00:13:05,590 --> 00:13:09,474
tested the generation of odyssey people with

195
00:13:10,984 --> 00:13:14,688
you can see it through this video on a

196
00:13:14,736 --> 00:13:18,456
sample of her entering image that

197
00:13:18,520 --> 00:13:21,724
all these images look the same.

198
00:13:22,224 --> 00:13:25,688
The AI she person in

199
00:13:25,736 --> 00:13:28,688
Omani, sad, depressed,

200
00:13:28,856 --> 00:13:32,944
always has the same weird faces in

201
00:13:32,984 --> 00:13:36,420
their diversity. Is she a

202
00:13:36,532 --> 00:13:40,228
white man for AI? Honesty people,

203
00:13:40,316 --> 00:13:44,004
I look the same way. Is it not the

204
00:13:44,044 --> 00:13:47,412
reality? Why does an

205
00:13:47,588 --> 00:13:50,864
person have to be sad and depreciate

206
00:13:51,244 --> 00:13:54,780
that? Doesn't a disabling person have the right

207
00:13:54,892 --> 00:13:58,904
to feel good about themselves, to be happy?

208
00:13:59,244 --> 00:14:04,254
It can be very that artificial intentions

209
00:14:06,074 --> 00:14:09,894
for this part we need you imagine

210
00:14:10,554 --> 00:14:14,466
that we are in the team developing an AI project

211
00:14:14,650 --> 00:14:18,114
and we will focus on the moment when you create

212
00:14:18,194 --> 00:14:22,066
some difficulties for people with disability. The first

213
00:14:22,130 --> 00:14:26,734
step in whole data science project is

214
00:14:27,334 --> 00:14:31,394
taking what is the need? It's a brainstorming

215
00:14:34,134 --> 00:14:37,234
according to your problem. For example,

216
00:14:38,494 --> 00:14:42,510
you need to choose some metric to evaluate the

217
00:14:42,582 --> 00:14:46,334
different models and for monitoring

218
00:14:46,374 --> 00:14:49,354
the model when he was in production.

219
00:14:51,254 --> 00:14:54,654
For example, in disease detection we will use it

220
00:14:54,694 --> 00:14:58,554
less serious to have a false positive positive than a false negative

221
00:14:59,054 --> 00:15:02,654
and potentially miss a patient. In the case

222
00:15:02,694 --> 00:15:05,854
of the false positive, the doctor can always check

223
00:15:05,894 --> 00:15:09,710
the test manually or perform another analyze before

224
00:15:09,782 --> 00:15:12,954
treating the patient on another end.

225
00:15:13,254 --> 00:15:16,974
For a target commercial offer, false negative

226
00:15:17,054 --> 00:15:21,022
may become less serious. If Mister

227
00:15:21,078 --> 00:15:24,270
Hicks didn't specifically receive the

228
00:15:24,302 --> 00:15:28,044
mail about the sale on

229
00:15:28,084 --> 00:15:31,144
the Welshare. This is a little impact.

230
00:15:33,164 --> 00:15:37,764
The second step is exploratory

231
00:15:37,884 --> 00:15:41,664
data analysis. It's Eda.

232
00:15:42,044 --> 00:15:45,692
It's a very important phase in all data

233
00:15:45,748 --> 00:15:50,116
science projects. As we seen

234
00:15:50,260 --> 00:15:55,318
before, whole project

235
00:15:55,406 --> 00:15:58,878
in data science was based on data. In this

236
00:15:58,926 --> 00:16:02,774
phase we analyze the data at your disposal,

237
00:16:02,854 --> 00:16:05,074
their quantity and the quality.

238
00:16:06,534 --> 00:16:07,714
For example,

239
00:16:10,534 --> 00:16:14,374
there are many missing value since the data science

240
00:16:14,454 --> 00:16:18,550
is relied to statistics and probability. We handle

241
00:16:18,622 --> 00:16:21,926
data with extremely apparent value because

242
00:16:21,990 --> 00:16:25,670
they introduce some noises into your model and make

243
00:16:25,742 --> 00:16:29,598
it less performance. If you

244
00:16:29,766 --> 00:16:33,606
see all this car like a

245
00:16:33,670 --> 00:16:37,094
human, because a car is

246
00:16:37,134 --> 00:16:40,798
like a human or person is human,

247
00:16:40,926 --> 00:16:43,154
but all people is different.

248
00:16:46,844 --> 00:16:50,596
Now you see, this is

249
00:16:50,620 --> 00:16:54,252
your data set and this is not just some people

250
00:16:54,428 --> 00:16:58,004
random. It just holds a software

251
00:16:58,084 --> 00:17:01,620
engineer in the typical it company. In the

252
00:17:01,652 --> 00:17:05,540
most of countries the majority of software

253
00:17:05,612 --> 00:17:09,100
engineers are main. However, where if we were a

254
00:17:09,132 --> 00:17:12,918
part of the data set of the software engineer Emmanuelle and

255
00:17:12,966 --> 00:17:17,114
I would be considered as a hot liar.

256
00:17:17,614 --> 00:17:19,954
Not only because we are a woman,

257
00:17:20,454 --> 00:17:23,994
but we also have disabilities,

258
00:17:24,374 --> 00:17:29,694
we don't fit with a typical profile and we

259
00:17:29,734 --> 00:17:33,702
wouldn't want to be completely erased from the tech

260
00:17:33,758 --> 00:17:38,478
industry because your profile is different diversity

261
00:17:38,606 --> 00:17:42,224
measure. It can be a very bad

262
00:17:42,304 --> 00:17:45,724
impact in some projects like

263
00:17:46,304 --> 00:17:48,884
the project relative to the recruitment.

264
00:17:50,944 --> 00:17:55,728
The first. The next part is to

265
00:17:55,816 --> 00:18:00,000
training and select and training the model. It's like

266
00:18:00,152 --> 00:18:05,124
you create a prototype eventually

267
00:18:05,434 --> 00:18:09,026
before breeding a real cow. The goal is to find

268
00:18:09,130 --> 00:18:13,018
the best model with the best results. The height

269
00:18:13,066 --> 00:18:16,730
test score on the metric will determine on the initial

270
00:18:16,802 --> 00:18:20,778
stage a common mistake would be rely this

271
00:18:20,826 --> 00:18:24,106
results to claim your model is performing well.

272
00:18:24,290 --> 00:18:28,650
For example, you can have a little bias

273
00:18:28,802 --> 00:18:33,294
if you use a dataset related to the American Sign language.

274
00:18:34,244 --> 00:18:37,972
You have a validation data

275
00:18:38,028 --> 00:18:40,740
set and test data set.

276
00:18:40,892 --> 00:18:44,540
You have a very good result on this validation

277
00:18:44,652 --> 00:18:48,116
and test data set. But when you put

278
00:18:48,180 --> 00:18:51,664
your model in production you have a very bad

279
00:18:52,844 --> 00:18:56,476
feedback from the user because you

280
00:18:56,500 --> 00:18:59,952
put your model in production. In France and people

281
00:19:00,088 --> 00:19:04,644
doesn't use the American Sign language.

282
00:19:05,544 --> 00:19:09,764
In French we use the french sign language and

283
00:19:10,544 --> 00:19:16,656
it is a big problem because we

284
00:19:16,680 --> 00:19:22,440
have a very unadapted tools in

285
00:19:22,472 --> 00:19:25,828
this project. We have the the common

286
00:19:25,996 --> 00:19:29,344
challenge for whole software maintainability, scalability,

287
00:19:29,804 --> 00:19:33,876
response time. Additionally, you need to monitor performance

288
00:19:34,020 --> 00:19:37,104
and retain the model when the decrease in performance.

289
00:19:37,444 --> 00:19:41,796
This is a discussion about drift and

290
00:19:41,940 --> 00:19:45,844
when you retrain your model, it's like when

291
00:19:45,884 --> 00:19:49,316
you make a little revision

292
00:19:49,460 --> 00:19:52,788
of your car. You need

293
00:19:52,836 --> 00:19:58,348
to remake

294
00:19:58,436 --> 00:20:01,748
an exploratory phase of the data collected

295
00:20:01,796 --> 00:20:05,636
in production. Soft models can be negatively

296
00:20:05,700 --> 00:20:09,468
influenced by their interaction with user. For example,

297
00:20:09,556 --> 00:20:13,524
some models that become more biased like

298
00:20:13,604 --> 00:20:18,760
the model will become more racist or

299
00:20:18,792 --> 00:20:20,644
validists. Yeah,

300
00:20:21,824 --> 00:20:26,088
it's because AI is based

301
00:20:26,136 --> 00:20:29,720
on statistics and probability and it's

302
00:20:29,752 --> 00:20:33,536
same for me. Journey it's not

303
00:20:33,600 --> 00:20:37,176
probable that a woman can be a software

304
00:20:37,240 --> 00:20:41,480
engineer or can be a developer who can be deaf

305
00:20:41,592 --> 00:20:46,016
and be a woman and to

306
00:20:46,040 --> 00:20:49,664
be a developer. It's more

307
00:20:50,484 --> 00:20:53,700
probable for me, Johnny, that we are an

308
00:20:53,732 --> 00:20:57,300
operator. We are definitely not an

309
00:20:57,332 --> 00:21:01,756
operator. Yes, personally I don't use an

310
00:21:01,940 --> 00:21:05,468
aid set. Wait. Well, not anymore.

311
00:21:05,636 --> 00:21:09,644
When I listen to music or when I make for all

312
00:21:09,764 --> 00:21:14,024
my oh yeah, in the plant have bluetooth, then we say nd

313
00:21:14,714 --> 00:21:18,346
airports. This means that I am listening

314
00:21:18,370 --> 00:21:22,574
to music that is neither seen nor know.

315
00:21:23,714 --> 00:21:26,978
I am going to talk to you about innovations

316
00:21:27,106 --> 00:21:30,506
that are having an impact the daily

317
00:21:30,610 --> 00:21:34,698
lives of disabled people. Let's start with

318
00:21:34,746 --> 00:21:38,482
automatic options and transcription. This is one

319
00:21:38,578 --> 00:21:41,766
of the most well known tools.

320
00:21:41,930 --> 00:21:45,118
I'm assuming this year we are seeing

321
00:21:45,206 --> 00:21:49,110
more and more and more automated emission and

322
00:21:49,142 --> 00:21:52,194
transcription in video and video platform.

323
00:21:52,614 --> 00:21:58,918
Automated emotion is used

324
00:21:59,086 --> 00:22:02,814
in everyday life, available in

325
00:22:02,894 --> 00:22:06,198
native language and used for

326
00:22:06,286 --> 00:22:10,286
machine translation. Easy to

327
00:22:10,430 --> 00:22:14,118
use is it? Because easy to

328
00:22:14,246 --> 00:22:18,190
write automatic emission into the tools as

329
00:22:18,262 --> 00:22:21,554
we really rely on it fully.

330
00:22:22,334 --> 00:22:26,006
When you are in the video conference or

331
00:22:26,070 --> 00:22:30,110
when you are watching a live video, there are often

332
00:22:30,222 --> 00:22:33,686
automation errors. We have

333
00:22:33,750 --> 00:22:38,028
to deal with it by using Monton when replacement

334
00:22:38,156 --> 00:22:41,828
sees, we ended up to tell

335
00:22:41,876 --> 00:22:45,504
the AI that is made a mistake.

336
00:22:46,364 --> 00:22:49,860
Thus we are forced

337
00:22:49,932 --> 00:22:53,184
to read leaves when the image is wood,

338
00:22:53,804 --> 00:22:57,692
listen when we have a wind heads

339
00:22:57,828 --> 00:23:01,588
and analyze the context. When there are automatic

340
00:23:01,636 --> 00:23:05,668
emissions, it is so

341
00:23:05,836 --> 00:23:09,708
so exhausting. When the video is

342
00:23:09,756 --> 00:23:13,924
not live and the video is uploaded to video platforms

343
00:23:13,964 --> 00:23:18,584
such as YouTube, for example, there are automatic emissions

344
00:23:19,004 --> 00:23:24,564
unassailed automated emotions are not yet 100%

345
00:23:24,644 --> 00:23:28,516
reliable and therefore rarely remain

346
00:23:28,580 --> 00:23:31,584
in it duration to avoid errors.

347
00:23:32,204 --> 00:23:35,944
Don't insist to use automatic emission

348
00:23:37,004 --> 00:23:40,580
to rate emission because they do

349
00:23:40,652 --> 00:23:43,704
all the work of sizes.

350
00:23:44,244 --> 00:23:47,868
So for them to check that they are all

351
00:23:47,876 --> 00:23:50,544
right if not all right.

352
00:23:51,284 --> 00:23:54,700
If by orienting you are

353
00:23:54,732 --> 00:23:58,268
showing the AI that is main mistake and

354
00:23:58,316 --> 00:24:02,024
we know that she learns from her mistakes.

355
00:24:02,484 --> 00:24:05,796
I am a tool in French on automated emissions

356
00:24:05,820 --> 00:24:09,980
and various web. If you are interested,

357
00:24:10,092 --> 00:24:14,464
I need you to watch it to better understand the emission.

358
00:24:15,204 --> 00:24:19,804
Seeing AII is an application developed by Mikrosoft

359
00:24:19,884 --> 00:24:23,304
that automatic and he describes the environment

360
00:24:23,894 --> 00:24:27,614
around us among other things

361
00:24:27,774 --> 00:24:31,286
around to you. Bring this around as

362
00:24:31,310 --> 00:24:34,430
soon as is in parents in front

363
00:24:34,502 --> 00:24:38,926
of the camera scan and ringing

364
00:24:38,990 --> 00:24:42,806
around be to ember alts and then

365
00:24:42,870 --> 00:24:46,758
analyze them to undefined products to

366
00:24:46,806 --> 00:24:50,326
unite the people around you and they prefer the

367
00:24:50,390 --> 00:24:53,966
emissions. This frame seems under a nice

368
00:24:54,030 --> 00:25:00,310
image unidentified as

369
00:25:00,462 --> 00:25:04,158
m era or be my eyes.

370
00:25:04,286 --> 00:25:08,390
Is it an app that connect brand and version is achieved

371
00:25:08,462 --> 00:25:11,958
before with volunteer volunteer

372
00:25:12,006 --> 00:25:15,350
provides visual instance to blind and

373
00:25:15,382 --> 00:25:19,234
mature in parent users via video rule

374
00:25:20,004 --> 00:25:23,948
with the arrival of CPT and recently CPT

375
00:25:24,076 --> 00:25:27,796
Four o b by has creating

376
00:25:27,860 --> 00:25:32,084
a new virtual volunteer

377
00:25:32,164 --> 00:25:35,684
tools Al would be able to analyze

378
00:25:35,724 --> 00:25:39,556
the context and heal the elsewhere just like

379
00:25:39,660 --> 00:25:43,664
the human volunteer would wachand

380
00:25:44,204 --> 00:25:48,150
and the brand and persian person

381
00:25:48,262 --> 00:25:50,714
blendy trusts AI.

382
00:25:51,414 --> 00:25:55,434
It raises an anti all and moral region.

383
00:25:56,254 --> 00:26:00,294
If the AI makes a mistake, it can

384
00:26:00,374 --> 00:26:04,434
have more or less serious consequences.

385
00:26:05,374 --> 00:26:08,846
There are plenty of innovation in progress

386
00:26:08,990 --> 00:26:12,834
in beta that can be useful.

387
00:26:13,274 --> 00:26:17,338
There are tremendous opportunities to improve the lives of

388
00:26:17,506 --> 00:26:22,210
disabled people like seniors.

389
00:26:22,322 --> 00:26:25,890
AI offer automated American Sign

390
00:26:26,002 --> 00:26:29,346
resource generation and video text

391
00:26:29,490 --> 00:26:33,826
and audios. In France we have alias

392
00:26:33,930 --> 00:26:38,174
and with french sign language

393
00:26:40,104 --> 00:26:45,048
in my French to

394
00:26:45,096 --> 00:26:48,968
help people when Suan

395
00:26:49,056 --> 00:26:50,724
refrains op ed.

396
00:26:52,304 --> 00:26:56,568
Otih release ambient noises in hearing

397
00:26:56,656 --> 00:27:00,232
hands as there are transform tests for

398
00:27:00,328 --> 00:27:03,448
the sin people under AI

399
00:27:03,496 --> 00:27:08,070
voices that unwise the memories specify

400
00:27:08,182 --> 00:27:11,534
range test allowed. Some motor is

401
00:27:11,574 --> 00:27:15,534
used to emulate using images

402
00:27:15,614 --> 00:27:19,766
and symbols. Cesar enables smartphone

403
00:27:19,830 --> 00:27:23,190
and tablet two into hand free

404
00:27:23,302 --> 00:27:26,678
device while maps make in

405
00:27:26,846 --> 00:27:30,494
20 easier by providing detailing

406
00:27:30,574 --> 00:27:34,530
in geo instruction mit detect full

407
00:27:34,602 --> 00:27:38,994
and in real time and alert emergency

408
00:27:39,114 --> 00:27:42,594
services and in the smart

409
00:27:42,674 --> 00:27:46,186
end that detects unchill and helps

410
00:27:46,250 --> 00:27:49,374
blind people to find their way around.

411
00:27:50,234 --> 00:27:53,826
There are a lot ton of possibility and

412
00:27:53,890 --> 00:27:57,414
it's very exciting. Exciting.

413
00:27:58,494 --> 00:28:02,394
In addition to the biases that are

414
00:28:03,014 --> 00:28:05,794
present in Ayi Afrocini,

415
00:28:06,374 --> 00:28:10,194
there have been traumas with aye aye

416
00:28:10,574 --> 00:28:14,254
a person tracing about global warming.

417
00:28:14,374 --> 00:28:18,550
So his maintain as

418
00:28:18,622 --> 00:28:22,486
is overseas with Elisa and

419
00:28:22,550 --> 00:28:25,434
of indeed he's finished with her.

420
00:28:26,164 --> 00:28:31,508
This person has found in the Ayi and

421
00:28:31,636 --> 00:28:35,264
has for help that Aza is devoid of feelings

422
00:28:35,764 --> 00:28:40,156
of obesity. So one day the

423
00:28:40,180 --> 00:28:43,964
person said, I want to die. Do you

424
00:28:44,004 --> 00:28:47,544
think I should? Is there a pain?

425
00:28:48,204 --> 00:28:50,584
I would like to see you dead.

426
00:28:51,184 --> 00:28:55,440
The person omitted suicide as a result

427
00:28:55,512 --> 00:28:59,040
of this, the startup that breed ESa puts

428
00:28:59,072 --> 00:29:02,176
off errors in place to prevent it

429
00:29:02,280 --> 00:29:06,064
from happening again. When there

430
00:29:06,104 --> 00:29:09,904
are obvious signs of suicide, of depression,

431
00:29:10,064 --> 00:29:12,284
there are numbers available.

432
00:29:13,104 --> 00:29:17,218
Our bacs have a strong impact and

433
00:29:17,266 --> 00:29:21,374
ends up tie have a dramatic impact on disability people.

434
00:29:21,714 --> 00:29:24,814
That's why it's important to work with

435
00:29:25,234 --> 00:29:29,466
disabling people to prevent this from happening

436
00:29:29,610 --> 00:29:32,978
again. Let me remind you.

437
00:29:33,146 --> 00:29:37,250
And we turn to end them. Artificial intentions

438
00:29:37,282 --> 00:29:43,454
is a tool. For example, sound positive.

439
00:29:43,784 --> 00:29:48,084
I have used this system and I have so many

440
00:29:48,384 --> 00:29:52,192
false positives that I end up not

441
00:29:52,248 --> 00:29:55,520
using it anymore. And at the home

442
00:29:55,592 --> 00:29:59,536
and doorbell ringing when there no

443
00:29:59,600 --> 00:30:03,560
one behind my door, I have so many

444
00:30:03,632 --> 00:30:07,088
alerts telling me I didn't know

445
00:30:07,176 --> 00:30:10,924
what and what was not. So I

446
00:30:10,964 --> 00:30:14,548
turned it off. Term and

447
00:30:14,596 --> 00:30:18,060
context then don't mean anything. I said

448
00:30:18,132 --> 00:30:21,644
he learned with automatization and I

449
00:30:21,684 --> 00:30:24,948
said, mistakes exist and must

450
00:30:24,996 --> 00:30:28,820
be arrested. Tim Hoon once gave

451
00:30:28,892 --> 00:30:31,744
a speech at Yellow Day University,

452
00:30:32,524 --> 00:30:36,132
a university for deaf and hard.

453
00:30:36,228 --> 00:30:39,456
Of every student saying aye

454
00:30:39,560 --> 00:30:42,564
is ood but is not the wood.

455
00:30:43,064 --> 00:30:46,400
This means that we are not reliably on

456
00:30:46,432 --> 00:30:50,392
it and we still need

457
00:30:50,528 --> 00:30:54,864
human attention to correct errors about

458
00:30:54,944 --> 00:30:58,624
mistake. This picture is a little robot. In Estonia they

459
00:30:58,664 --> 00:31:00,644
deliver your parcel like food.

460
00:31:02,024 --> 00:31:05,368
It's something that works quite quiet well in the country where

461
00:31:05,416 --> 00:31:09,056
it's deployed. During your research, you see projects to develop

462
00:31:09,120 --> 00:31:12,304
autonomous whale share a bite like this robot.

463
00:31:12,384 --> 00:31:16,404
But when I see this photo, I can only be worried.

464
00:31:16,904 --> 00:31:21,084
The same goes for the plight people with electronic

465
00:31:22,224 --> 00:31:25,404
blind white skin.

466
00:31:25,704 --> 00:31:29,680
This mistake can have serious consequences even

467
00:31:29,752 --> 00:31:33,220
more for disabled people than if you just

468
00:31:33,292 --> 00:31:36,624
deliver. You are delivering a burger

469
00:31:36,964 --> 00:31:40,664
like Emmanuel. I test and abundant sound recognization

470
00:31:41,244 --> 00:31:44,144
because it wasn't reliable enough.

471
00:31:44,484 --> 00:31:47,588
And projects sometimes are too expensive for

472
00:31:47,636 --> 00:31:52,744
disabled people, even if they are technologically interesting,

473
00:31:53,164 --> 00:31:56,568
are also little interest.

474
00:31:56,756 --> 00:32:03,552
You need as often different from that uninvolved

475
00:32:03,688 --> 00:32:07,600
people can imagine by

476
00:32:07,632 --> 00:32:11,384
example, translating a sign language

477
00:32:11,464 --> 00:32:14,800
like a french sign language or American

478
00:32:14,912 --> 00:32:20,136
Sign Language is very different from the image of

479
00:32:20,200 --> 00:32:23,852
lots of people of it. Deaf people seen

480
00:32:23,908 --> 00:32:28,172
very quickly. Body posture and facial expression are

481
00:32:28,228 --> 00:32:31,024
very important for the comprehension.

482
00:32:31,844 --> 00:32:36,264
What's more, this won't make the content accessible

483
00:32:37,004 --> 00:32:40,588
for all deaf people. I'm deaf and I don't

484
00:32:40,636 --> 00:32:45,504
use any sign language can

485
00:32:46,164 --> 00:32:48,544
improve website accessibility,

486
00:32:49,464 --> 00:32:53,456
but you can use automating testing to detect accessibility

487
00:32:53,600 --> 00:32:57,264
issues. I have already asked HGBT

488
00:32:57,344 --> 00:33:00,888
to incorporate accessibility into the hood.

489
00:33:01,056 --> 00:33:05,056
It did not work very well and also

490
00:33:05,240 --> 00:33:09,084
no overlap. Tools can make the website accessible.

491
00:33:09,464 --> 00:33:13,648
The only way to make a website accessible to everyone is

492
00:33:13,736 --> 00:33:16,164
to get your hand on the hold.

493
00:33:17,024 --> 00:33:20,440
AI has already changed our lives.

494
00:33:20,592 --> 00:33:24,528
Every day I use

495
00:33:24,616 --> 00:33:28,000
automatic emissions, even if it's not

496
00:33:28,152 --> 00:33:31,904
perfect. I use an automatic tools

497
00:33:31,944 --> 00:33:35,904
to translate my content or reformulate

498
00:33:36,024 --> 00:33:39,600
it. Terrific because my sentence is

499
00:33:39,632 --> 00:33:43,480
not very old. I am sure sorry that the

500
00:33:43,552 --> 00:33:46,900
AI doesn't understand me very

501
00:33:46,972 --> 00:33:50,264
well because of my deaf voices.

502
00:33:50,564 --> 00:33:54,204
But progress is being made. And for

503
00:33:54,244 --> 00:33:57,660
you Dandan, I'm deaf since 20

504
00:33:57,812 --> 00:34:03,300
years ago now and thought

505
00:34:03,372 --> 00:34:07,212
with AI changed my life. Like with

506
00:34:07,308 --> 00:34:12,024
reducing ambience on my hair ring. AIDS is more comfortable

507
00:34:12,604 --> 00:34:16,564
and tools like for detection means

508
00:34:16,684 --> 00:34:19,784
I'm safe when I'm alone at home.

509
00:34:21,524 --> 00:34:27,028
When I was a teenager I cannot imagine all

510
00:34:27,076 --> 00:34:30,844
the things I can be able

511
00:34:30,924 --> 00:34:34,380
to do. Like we

512
00:34:34,412 --> 00:34:39,920
can have chatting with people by

513
00:34:40,072 --> 00:34:43,084
phone and have a transcription automatic.

514
00:34:43,424 --> 00:34:48,044
We can prepare these conferences by distance. With Emmanuel

515
00:34:50,504 --> 00:34:53,964
we have both dev and it's

516
00:34:54,744 --> 00:34:58,024
amazing to make this one by

517
00:34:58,104 --> 00:35:01,312
distance just with tools.

518
00:35:01,368 --> 00:35:04,896
With AI 20 years

519
00:35:05,000 --> 00:35:08,488
ago he was impossible for two

520
00:35:08,576 --> 00:35:12,160
deaf people to prepare something by distance

521
00:35:12,352 --> 00:35:16,844
just with webcam and automatic

522
00:35:17,624 --> 00:35:22,044
subtitles. When I was a teenager I

523
00:35:23,504 --> 00:35:27,324
don't all the things is possible.

524
00:35:30,984 --> 00:35:34,280
I never truly had like to do so much

525
00:35:34,432 --> 00:35:37,444
on my home and tools like for detection.

526
00:35:37,944 --> 00:35:41,444
I mean, I'm safe when I'm alone at home.

527
00:35:42,184 --> 00:35:45,352
Now I can have some discussion

528
00:35:45,408 --> 00:35:49,924
by phone with transcription automatic. It's so

529
00:35:50,824 --> 00:35:54,984
nothing about us without us is a mantra from

530
00:35:55,064 --> 00:35:58,592
USA. It is important to design tools

531
00:35:58,648 --> 00:36:02,882
with disabling people to hire together so

532
00:36:02,938 --> 00:36:06,746
as not to bias is we need

533
00:36:06,810 --> 00:36:10,802
to evaluate with disabled people to reduce risk

534
00:36:10,978 --> 00:36:14,714
and bias and to communicate with

535
00:36:14,754 --> 00:36:18,522
them to build useful tools and make

536
00:36:18,578 --> 00:36:21,282
them effective. Better yet,

537
00:36:21,458 --> 00:36:24,882
we need to hire disabled people in

538
00:36:24,898 --> 00:36:28,160
the tech industry to do this. Of course

539
00:36:28,272 --> 00:36:32,408
they need to be trained and therefore made accessible

540
00:36:32,496 --> 00:36:36,044
to them. We end where

541
00:36:37,624 --> 00:36:41,680
you project army in an impact in the lives

542
00:36:41,752 --> 00:36:42,684
of these.

543
00:36:46,984 --> 00:36:49,704
Today we are talking about disabilities,

544
00:36:49,864 --> 00:36:53,936
but where some we

545
00:36:53,960 --> 00:36:58,304
are someone else to other people. It's important

546
00:36:58,424 --> 00:37:02,080
that more diversity in tech to combat

547
00:37:02,112 --> 00:37:04,724
bias in the design of model and products.

548
00:37:05,664 --> 00:37:09,640
Diversity is not just disabilities, but also

549
00:37:09,712 --> 00:37:13,640
by gender, ethnicity and religions. Your users are

550
00:37:13,672 --> 00:37:18,284
varied, so it's important that the diversity exists.

551
00:37:19,274 --> 00:37:23,026
Two in your team. Thank you so much

552
00:37:23,130 --> 00:37:27,594
for listening to us. You to

553
00:37:27,634 --> 00:37:31,774
find our presentation transcript and resources.

554
00:37:32,194 --> 00:37:33,194
Thank you so much.

