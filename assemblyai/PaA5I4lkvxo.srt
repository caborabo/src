1
00:00:27,334 --> 00:00:31,078
A recent survey done by KPMG found 77%

2
00:00:31,126 --> 00:00:34,366
of their participants thought Jinya is

3
00:00:34,390 --> 00:00:37,566
going to have the largest impact on their businesses out

4
00:00:37,590 --> 00:00:40,806
of all emerging technologies. And out

5
00:00:40,830 --> 00:00:44,494
of this survey 73 participants believe Genei will

6
00:00:44,534 --> 00:00:48,274
have a larger impact on increasing their productivity.

7
00:00:48,934 --> 00:00:52,478
And interestingly 71% of the participants of the view

8
00:00:52,526 --> 00:00:56,252
that they got to implement a Jennai solution within next two

9
00:00:56,308 --> 00:00:59,764
years and 65% believe

10
00:00:59,884 --> 00:01:03,620
Jennai will help their organization gain a competitive

11
00:01:03,692 --> 00:01:07,396
advantage. So these are some of the numbers which prove

12
00:01:07,500 --> 00:01:11,620
the impact we are having on with gene eyes. So Jenny is

13
00:01:11,652 --> 00:01:15,564
no longer hype cycle, it's here to stay and that will have the

14
00:01:15,604 --> 00:01:19,024
largest positive impacts for any organization.

15
00:01:19,864 --> 00:01:23,416
So if you look at the typical business operation functions

16
00:01:23,560 --> 00:01:28,456
and where JAi can typically implemented,

17
00:01:28,600 --> 00:01:32,592
the highest placed are your IT tech and operation.

18
00:01:32,768 --> 00:01:36,944
So that is by far standout when compared to other aspects like marketing,

19
00:01:36,984 --> 00:01:40,328
sales or customer management, product development or R and

20
00:01:40,336 --> 00:01:44,288
D, finance, accounting, HR or risk and legal. So this

21
00:01:44,336 --> 00:01:48,150
prove that everyone, the organizations

22
00:01:48,182 --> 00:01:52,030
and especially the participant of the KPMG survey was

23
00:01:52,142 --> 00:01:56,006
viewed that the most of the Genai benefits

24
00:01:56,110 --> 00:02:00,934
they are going to leverage part of IT tech and operations hello

25
00:02:00,974 --> 00:02:04,782
everyone, my name is Indiki Vimilasurier. Welcome to

26
00:02:04,958 --> 00:02:08,354
SRA 2024 organized by Conf 42.

27
00:02:08,934 --> 00:02:12,686
As part of my presentation I will discuss about SRE

28
00:02:12,750 --> 00:02:17,128
2.0 which is about leveraging this genai

29
00:02:17,256 --> 00:02:19,564
and how we can amplify reliability.

30
00:02:20,024 --> 00:02:24,136
Genei is here to stay and Gene AI definitely allow

31
00:02:24,200 --> 00:02:28,216
you to increase the productivity and the reliability

32
00:02:28,360 --> 00:02:30,964
of your SRE implementation.

33
00:02:31,664 --> 00:02:35,880
As part of this presentation we will discuss about what are the challenges

34
00:02:35,992 --> 00:02:39,732
and how what are the roles Denea is playing and

35
00:02:39,748 --> 00:02:43,564
the impact on the key pillars and some of the Genai use cases,

36
00:02:43,644 --> 00:02:47,276
potential benefits and some of the implementation strategies

37
00:02:47,460 --> 00:02:51,276
and what are the best practices and some of the pitfalls you

38
00:02:51,300 --> 00:02:55,252
need to avoid. Quick intro. About myself my

39
00:02:55,268 --> 00:02:58,908
name is Indigremera Surya. I'm based out of Colombo, Sri Lanka.

40
00:02:59,076 --> 00:03:02,652
I'm a reliable engineering advocate and a practitioner.

41
00:03:02,828 --> 00:03:05,892
My specializations are in site reliability engineering,

42
00:03:06,028 --> 00:03:09,304
observability, aiops and generative AI.

43
00:03:10,004 --> 00:03:14,084
I am a passionate technical trainer and an energetic technical

44
00:03:14,164 --> 00:03:18,196
blogger. You can find me writing at dev two. I am a

45
00:03:18,340 --> 00:03:21,460
proud AWS community builder under cloud

46
00:03:21,532 --> 00:03:25,188
operations and a very proud ambassador at DevOps

47
00:03:25,236 --> 00:03:28,780
Institute. If you look at the Gartner hype cycle for

48
00:03:28,892 --> 00:03:32,606
SRE, you realize that it's a journey.

49
00:03:32,780 --> 00:03:36,106
It's about taking you from understanding the

50
00:03:36,130 --> 00:03:40,050
innovation triggers like what is required, what is driving you a SRE

51
00:03:40,122 --> 00:03:43,962
journey. And it can be like adapting service level objectives

52
00:03:44,098 --> 00:03:46,722
coming up with monitoring as a code, solution,

53
00:03:46,898 --> 00:03:50,146
infrastructure orchestration, finops, or it

54
00:03:50,170 --> 00:03:53,858
can be more for chaos engineering. And while

55
00:03:53,906 --> 00:03:57,698
you go through this journey, you will go through a certain

56
00:03:57,746 --> 00:04:00,878
set of tasks and then finally you finish up with probably

57
00:04:00,926 --> 00:04:04,286
APA and they will say Cox and what

58
00:04:04,350 --> 00:04:07,550
I would like to walk through as part of

59
00:04:07,582 --> 00:04:11,230
this presentation is that some of these areas

60
00:04:11,382 --> 00:04:14,726
with implementation of site reliability

61
00:04:14,790 --> 00:04:18,046
engineering, we can really expedite and we

62
00:04:18,070 --> 00:04:21,998
can gain higher impact for higher productivity out by

63
00:04:22,046 --> 00:04:26,206
leveraging Gene A's. And if I take a moment and

64
00:04:26,230 --> 00:04:29,766
just to like brief that we are all in the same page,

65
00:04:29,910 --> 00:04:33,246
site reliability engineering. Some of the key principles

66
00:04:33,310 --> 00:04:36,654
are how we can reduce our organization silos.

67
00:04:36,814 --> 00:04:40,174
That's mainly I think how we can get everyone

68
00:04:40,254 --> 00:04:43,982
in the organization to be responsible

69
00:04:44,158 --> 00:04:48,238
for the customer experience. Because something sometimes

70
00:04:48,286 --> 00:04:51,630
lack in organization is how who is

71
00:04:51,662 --> 00:04:55,402
going to own the customer experience and the person, the team who

72
00:04:55,418 --> 00:04:58,654
is how to do that had to have the technical skills

73
00:04:59,194 --> 00:05:02,562
on that as well. And then it's about

74
00:05:02,618 --> 00:05:06,514
accepting failures as normal. No longer our targets are achieving

75
00:05:06,554 --> 00:05:10,242
the 100% reliability or availability or 100%

76
00:05:10,298 --> 00:05:14,818
of anything. It's about considering the business

77
00:05:14,906 --> 00:05:18,818
needs, it's about considering our deployment architecture

78
00:05:18,946 --> 00:05:23,090
and some of the limitations. And then we identify what is

79
00:05:23,242 --> 00:05:26,614
the acceptable service level objectives.

80
00:05:27,434 --> 00:05:30,250
And then we follow gradual changes.

81
00:05:30,402 --> 00:05:34,210
We not planning to do any big band changes.

82
00:05:34,362 --> 00:05:37,890
These gradual changes help us not only to ensure

83
00:05:37,962 --> 00:05:41,722
there's a decent volatility, the number of change,

84
00:05:41,778 --> 00:05:44,810
the increased number of changes we do in production environment,

85
00:05:45,002 --> 00:05:48,022
as well as in case of any issue,

86
00:05:48,158 --> 00:05:52,094
we are able to revert back these changes. And of

87
00:05:52,134 --> 00:05:55,750
course we want to leverage tooling automation.

88
00:05:55,822 --> 00:05:59,406
It's about automating the sales job away and we want

89
00:05:59,430 --> 00:06:02,902
to bring in our automation mindset for anything and everything we

90
00:06:02,918 --> 00:06:06,526
are doing, and then finally measure everything. It's about

91
00:06:06,590 --> 00:06:10,774
having your service level indicators, it's about making them actionable,

92
00:06:10,934 --> 00:06:14,424
it's about building your service level objectives. And error budgets

93
00:06:14,534 --> 00:06:17,700
make the area budgets consequences driven so that

94
00:06:17,812 --> 00:06:21,116
you have the customer experience or the service

95
00:06:21,180 --> 00:06:23,824
level objectives driving you entire,

96
00:06:24,524 --> 00:06:27,584
not only the operations, but entire your organization.

97
00:06:28,484 --> 00:06:32,304
And some of the key principles when you are trying to achieve these

98
00:06:35,084 --> 00:06:38,356
overall, the fundamentals are you want to

99
00:06:38,380 --> 00:06:42,106
work it, work on your observability. The world has moved from monitoring

100
00:06:42,130 --> 00:06:46,186
to observability. So we want to make sure that you have a comprehensive,

101
00:06:46,290 --> 00:06:50,042
solid observability platform. And then you have to identify what are

102
00:06:50,058 --> 00:06:53,714
the service level indicators, service level objectives which are

103
00:06:53,754 --> 00:06:56,338
directly correlated with your customer experience.

104
00:06:56,506 --> 00:07:00,610
So that in case of any issue that you are able to identify part

105
00:07:00,642 --> 00:07:03,882
of your SLI or SL. And then

106
00:07:03,938 --> 00:07:07,188
you have to define your error budgets accordingly. Here you have

107
00:07:07,196 --> 00:07:10,620
to practice accept failures as normal concept as

108
00:07:10,652 --> 00:07:14,004
well. You will have to have defined

109
00:07:14,044 --> 00:07:17,820
some consequences driven approach when it comes to area budgets.

110
00:07:18,012 --> 00:07:21,196
And then you will have to look at how you're going to improve your system

111
00:07:21,260 --> 00:07:25,012
architecture, the deployment architecture and what are

112
00:07:25,028 --> 00:07:28,660
the recovery objectives like RPO RPO area, what are

113
00:07:28,692 --> 00:07:32,396
your objectives. And then it's about how we're going

114
00:07:32,420 --> 00:07:35,674
to work on your release manage release engineering,

115
00:07:35,754 --> 00:07:39,002
incident engineering. It's about having the CFCD pipelines,

116
00:07:39,058 --> 00:07:42,594
it's about integrating all your test automations

117
00:07:42,674 --> 00:07:46,050
and integrate with the pipelines. It about the code

118
00:07:46,082 --> 00:07:50,242
quality, it about all those things that is ensuring a

119
00:07:50,378 --> 00:07:53,930
higher degree of reliable releases. And it's

120
00:07:53,962 --> 00:07:57,334
about making sure that you have the correct and

121
00:07:57,954 --> 00:08:02,128
agreeable incident automation workflows so that you can automate

122
00:08:02,176 --> 00:08:05,416
some of those remediations. So automation is

123
00:08:05,440 --> 00:08:09,248
a key it start from building infrastructure,

124
00:08:09,296 --> 00:08:13,472
leveraging things like infrastructure as a code or observability as

125
00:08:13,488 --> 00:08:17,864
a code or deployment automation, using your CI CD pipelines,

126
00:08:18,024 --> 00:08:22,160
ensuring is to manage your capacity growth by

127
00:08:22,232 --> 00:08:26,768
like embracing techniques like autoscaling.

128
00:08:26,936 --> 00:08:31,128
And then finally it's about resilience engineering, doing KMS engineering,

129
00:08:31,216 --> 00:08:34,776
understand what are the failure scenarios

130
00:08:34,920 --> 00:08:38,592
and here you will have to define and do the discoveries,

131
00:08:38,688 --> 00:08:42,520
then understand what are your steady state and then come up with the,

132
00:08:42,632 --> 00:08:45,864
the hypothesis or the failure scenarios and the test cases.

133
00:08:45,944 --> 00:08:49,560
And then you go through it's a continuous manner while observing

134
00:08:49,592 --> 00:08:53,408
your sister. And finally the organization, culture and awareness

135
00:08:53,456 --> 00:08:57,512
is very important. You will have to have a blameless culture where

136
00:08:57,568 --> 00:09:01,128
you understand there's a failures are normal and every

137
00:09:01,216 --> 00:09:05,240
issue you are trying to understand how you can improve and how

138
00:09:05,272 --> 00:09:09,564
you can build reliability and the fault tolerance into your system.

139
00:09:10,224 --> 00:09:14,400
The modern, the distributed systems are very complex and

140
00:09:14,432 --> 00:09:17,904
one of the reason is we have transformed from monolith

141
00:09:18,024 --> 00:09:22,188
to microservices and we have transformed from

142
00:09:22,356 --> 00:09:25,988
standard monitoring to observability, which is your logs,

143
00:09:26,076 --> 00:09:29,460
metrics and traces and events. And we have

144
00:09:29,492 --> 00:09:33,084
transformed from on premise to cloud. And it can be

145
00:09:33,244 --> 00:09:36,444
you are hosted in multiple clouds where we call poly cloud,

146
00:09:36,564 --> 00:09:40,148
or you have a combination of hybrid approach where it's

147
00:09:40,196 --> 00:09:43,772
on premise plus cloud. So the microservices,

148
00:09:43,908 --> 00:09:47,164
the observability layers and your cloud

149
00:09:48,064 --> 00:09:51,832
responsible for generating a huge amount of data

150
00:09:51,968 --> 00:09:55,280
and thus has opened up expansion of

151
00:09:55,312 --> 00:09:59,304
data sources. This exponential growth has

152
00:09:59,344 --> 00:10:03,736
resulted in, while it's a technical advancement,

153
00:10:03,880 --> 00:10:06,936
we are able to manage

154
00:10:07,000 --> 00:10:10,968
our systems and manage our customer experience and we can deliver things

155
00:10:11,016 --> 00:10:14,380
much faster and we can identify things much faster.

156
00:10:14,532 --> 00:10:18,548
But we have built a lot of failure scenarios into

157
00:10:18,596 --> 00:10:21,860
this system now. So there are a lot of touch points where it

158
00:10:21,892 --> 00:10:25,596
can go wrong. So this is a challenge, and this is

159
00:10:25,620 --> 00:10:28,784
a challenge for service site reliability engineering.

160
00:10:29,484 --> 00:10:33,268
This is the area where everyone is focusing on to

161
00:10:33,356 --> 00:10:36,996
come up with some innovation solutions. And as

162
00:10:37,020 --> 00:10:41,384
you might know, when you are starting your SRE journey,

163
00:10:41,804 --> 00:10:45,652
you interpret it as operation is a

164
00:10:45,668 --> 00:10:49,064
software problem. So I used to always think

165
00:10:49,364 --> 00:10:52,268
that if our software is in the perfect shape,

166
00:10:52,436 --> 00:10:55,900
we might not need a large operations

167
00:10:55,972 --> 00:10:59,892
teams or we might not need even to the extent of your

168
00:11:00,028 --> 00:11:03,548
high degree of sres. Why? Because usually

169
00:11:03,596 --> 00:11:07,094
what happen is your, the incident management, your problem management,

170
00:11:07,174 --> 00:11:11,126
your capacity, and most of the aspects of work coming related

171
00:11:11,190 --> 00:11:14,798
to operations are down to software has not been in great

172
00:11:14,846 --> 00:11:18,686
shape or the tactical, or some form of toil

173
00:11:18,750 --> 00:11:22,094
or the manual work we have introduced, which would

174
00:11:22,134 --> 00:11:25,486
have been built to the system itself.

175
00:11:25,670 --> 00:11:28,758
So idea is that if your system is in a better

176
00:11:28,846 --> 00:11:32,258
shape, then you have a limited

177
00:11:32,346 --> 00:11:35,778
scopes when it comes to operations. So this down to

178
00:11:35,906 --> 00:11:38,774
a fundamentally about the quality of the code.

179
00:11:39,194 --> 00:11:42,658
Usually we are writing and one of the surveys,

180
00:11:42,746 --> 00:11:45,490
it found that by 2026,

181
00:11:45,682 --> 00:11:49,378
50% of the code in our

182
00:11:49,466 --> 00:11:52,882
systems code generated through generative

183
00:11:52,938 --> 00:11:56,114
AI. So that is a big number

184
00:11:56,274 --> 00:11:59,898
that mean that half of the code in future will be

185
00:11:59,986 --> 00:12:03,930
written by generative AI. And understandably it will have

186
00:12:03,962 --> 00:12:07,498
less manual mistakes, it will align

187
00:12:07,546 --> 00:12:11,122
to some better code practices. And while

188
00:12:11,298 --> 00:12:15,186
generated to AI might not be able to exceed

189
00:12:15,250 --> 00:12:18,770
human creativity, it might definitely ensure that it's

190
00:12:18,802 --> 00:12:22,722
following a process and practices and there will be some sort of a higher

191
00:12:22,778 --> 00:12:26,394
degree of code quality. So what this result is that

192
00:12:27,374 --> 00:12:30,502
we are able to go into that Nuswana state,

193
00:12:30,558 --> 00:12:34,314
where our software will work

194
00:12:35,494 --> 00:12:38,934
more reliable in future, and that

195
00:12:38,974 --> 00:12:42,630
this resulted in, we want to ensure that

196
00:12:42,662 --> 00:12:46,462
there are more ways we can leverage generative AI.

197
00:12:46,638 --> 00:12:50,618
Not only we provide this benefit or the reliability from the software

198
00:12:50,666 --> 00:12:54,794
perspective, but the other aspect for SRE can

199
00:12:54,874 --> 00:12:58,346
also leverage generative AI so that

200
00:12:58,370 --> 00:13:01,994
we can amplify this reliability. So that's why I firmly

201
00:13:02,034 --> 00:13:05,574
believe SRE 2.0, which is adapting

202
00:13:05,994 --> 00:13:09,734
generative AI, will amplify your reliability.

203
00:13:10,354 --> 00:13:14,266
So generative AI is about letting

204
00:13:14,370 --> 00:13:17,990
your machine learning models coming up with new creative

205
00:13:18,062 --> 00:13:21,518
content, so it can be form of text messages

206
00:13:21,646 --> 00:13:25,654
or images for audio. So this is very powerful

207
00:13:25,774 --> 00:13:29,566
because the combinations of and different aspects

208
00:13:29,590 --> 00:13:33,710
of the way we can leverage this, have opened

209
00:13:33,742 --> 00:13:38,238
up lot of opportunities in software development

210
00:13:38,406 --> 00:13:41,638
and maintenance area. So this is one of the

211
00:13:41,686 --> 00:13:45,550
nice aspects of what LLM can do considered

212
00:13:45,582 --> 00:13:48,950
by Gartner. So what we can see here is that

213
00:13:49,102 --> 00:13:52,806
we are able to input natural language structured

214
00:13:52,870 --> 00:13:56,914
data for multilingual text and transcription.

215
00:13:57,454 --> 00:14:01,542
And what are the capabilities of flat language models?

216
00:14:01,718 --> 00:14:05,710
They are able to come up with text or code generation,

217
00:14:05,862 --> 00:14:09,074
text compilation, text classification,

218
00:14:09,464 --> 00:14:13,484
text summarization, text translation,

219
00:14:13,824 --> 00:14:18,164
sentiment analysis, text correction, text manipulation,

220
00:14:19,024 --> 00:14:22,564
name energy recognition, question and answering

221
00:14:23,104 --> 00:14:26,760
style translation format translation and

222
00:14:26,792 --> 00:14:30,644
simple analytics. And the outputs are naturally,

223
00:14:30,944 --> 00:14:34,896
it can be your natural language text or structured data.

224
00:14:35,080 --> 00:14:38,688
Again, a multilingual text or computer code.

225
00:14:38,856 --> 00:14:42,568
So if you can see there's a lot of work, it can be done

226
00:14:42,656 --> 00:14:46,680
using computer code. And this literally means lot of

227
00:14:46,832 --> 00:14:50,352
coding. Like it's not only form of the typescript

228
00:14:50,408 --> 00:14:54,312
or your Java, it's about like Python and it's about the

229
00:14:54,408 --> 00:14:58,416
automation, it's about your shell scripting. So lot of these aspect

230
00:14:58,520 --> 00:15:02,226
we are able to leverage Genaid and this open

231
00:15:02,290 --> 00:15:05,674
up lot of opportunities. So once you go through

232
00:15:05,714 --> 00:15:09,354
in detail, these are some of the great capabilities which

233
00:15:09,394 --> 00:15:12,274
we are able to leverage to our,

234
00:15:12,434 --> 00:15:14,774
to amplify our reliability,

235
00:15:15,634 --> 00:15:19,614
while large language models are coming up with lot of opportunities.

236
00:15:19,914 --> 00:15:23,826
Before going to the areas how we can use them to

237
00:15:23,850 --> 00:15:27,840
amplify our reliability, I want to flag and highlights

238
00:15:27,912 --> 00:15:31,680
some of the risk they're having as well. So when it comes

239
00:15:31,712 --> 00:15:35,216
to llms, so models may have some model bias.

240
00:15:35,360 --> 00:15:38,632
So model bias is based on the training data set. It can gen,

241
00:15:38,688 --> 00:15:42,152
it can build a certain degree of bias, not to a

242
00:15:42,248 --> 00:15:46,184
different site, and there can be a misinformation, lack of

243
00:15:46,224 --> 00:15:50,144
context, creativity, and then when it comes to misuse,

244
00:15:50,184 --> 00:15:54,252
it can be in cyberbullying or fraud or other

245
00:15:54,308 --> 00:15:58,332
malware. And then there can be some usage related risk as well.

246
00:15:58,468 --> 00:16:02,084
So while look at it, some of these are obviously genuine,

247
00:16:02,124 --> 00:16:05,864
and some of these risks are obviously you are able to

248
00:16:06,324 --> 00:16:09,788
eliminate by taking some of those best practices

249
00:16:09,876 --> 00:16:14,036
and following some of the guidelines and ethical genai implementation

250
00:16:14,100 --> 00:16:17,852
workflows, and what few limitations

251
00:16:17,948 --> 00:16:21,204
and challenges in geneis, we are able to

252
00:16:21,324 --> 00:16:25,036
handle using three aspects of generative AI capabilities,

253
00:16:25,140 --> 00:16:29,228
which is known as RaG, or using a knowledge base.

254
00:16:29,396 --> 00:16:33,116
And about second one is about how we can leverage LLMS

255
00:16:33,220 --> 00:16:36,316
LLM agents and then obviously how we

256
00:16:36,340 --> 00:16:39,996
can work with our prompt engineering. So Rag,

257
00:16:40,060 --> 00:16:43,184
which is also known as retrieval augmented generation,

258
00:16:43,484 --> 00:16:47,126
it's allowing us to keep our llms

259
00:16:47,190 --> 00:16:50,582
up to date. Generally what happened is that LLMS

260
00:16:50,638 --> 00:16:53,830
has been trained with certain data set, and once we are trying

261
00:16:53,862 --> 00:16:57,126
to deploy it in our organization and trying to

262
00:16:57,190 --> 00:17:01,086
have it work for us based on our

263
00:17:01,150 --> 00:17:04,310
organization data, we might see a problem

264
00:17:04,462 --> 00:17:08,446
where sometimes the trained data set is not

265
00:17:08,630 --> 00:17:12,248
inherently correlated with what we want.

266
00:17:12,406 --> 00:17:16,196
So here what we can do is we can integrate

267
00:17:16,260 --> 00:17:20,148
a knowledge base we call the vector database with all

268
00:17:20,196 --> 00:17:23,820
our organization data and it can be observability

269
00:17:23,892 --> 00:17:27,340
data design document and architecture diagrams

270
00:17:27,452 --> 00:17:30,700
and your ITSm data CMDB and all

271
00:17:30,732 --> 00:17:34,636
the data and we can feed that t. So in that way

272
00:17:34,740 --> 00:17:37,912
when we are making that prompt to the large language model,

273
00:17:38,028 --> 00:17:42,264
we are able to first go and set the knowledge base

274
00:17:42,344 --> 00:17:45,688
to retrieve the relevant information. And this relevant

275
00:17:45,736 --> 00:17:49,164
information is able to improve the context.

276
00:17:49,944 --> 00:17:53,896
When we are going to LLM, we are able to go with the the prompt

277
00:17:54,000 --> 00:17:57,504
and then improve order enhance context so

278
00:17:57,544 --> 00:18:00,912
that will resulted in a better output

279
00:18:01,008 --> 00:18:04,648
generation from LLV. So this will ensure that

280
00:18:04,736 --> 00:18:08,418
you are able to give more up to date and relevant

281
00:18:08,466 --> 00:18:12,210
data to LLM. So example, you want to build a code

282
00:18:12,242 --> 00:18:16,434
automation and you already have a code repository for script

283
00:18:16,474 --> 00:18:20,226
readers. You are building a remediation engine, you have like hundreds

284
00:18:20,250 --> 00:18:23,994
of remediation engines, you have scripts, your teams has built,

285
00:18:24,154 --> 00:18:28,306
you can introduce them part of your the knowledge base where

286
00:18:28,370 --> 00:18:31,714
the then LLM is aware of that capability

287
00:18:31,794 --> 00:18:34,738
aspect or LLM might be already aware,

288
00:18:34,786 --> 00:18:38,322
it might be able to do a good job. But you give that context,

289
00:18:38,378 --> 00:18:41,906
you give that the aspects of what you already have. So this is

290
00:18:41,930 --> 00:18:46,546
a great way the rack will allow you to keep your llms

291
00:18:46,610 --> 00:18:51,010
up to date and then do enhance the context and

292
00:18:51,042 --> 00:18:54,522
other aspects is we have something called LLM

293
00:18:54,578 --> 00:18:58,474
ages. So example, sometimes you need

294
00:18:58,514 --> 00:19:02,156
some runtime real time data when you are dealing with some

295
00:19:02,180 --> 00:19:05,540
of this use case implementation. So here what

296
00:19:05,572 --> 00:19:09,244
are the option is this is the representation using

297
00:19:09,324 --> 00:19:12,796
AWS bedrock where when we are giving a task to

298
00:19:12,820 --> 00:19:16,804
the agent and then the agent link

299
00:19:16,924 --> 00:19:20,252
in turn break into a chain of thoughts where you have

300
00:19:20,268 --> 00:19:24,564
a step, one to step in and each step you can make API calls.

301
00:19:24,604 --> 00:19:27,902
We can, you can again connect to a knowledge base.

302
00:19:27,998 --> 00:19:31,814
So what idea is that? But because you are able to make API

303
00:19:31,854 --> 00:19:35,862
calls, you are able to connect to different systems.

304
00:19:35,958 --> 00:19:39,470
You can get more up to date run time real time data

305
00:19:39,622 --> 00:19:42,902
so that the response the llms are generating

306
00:19:43,038 --> 00:19:46,774
are even more accurate. So what

307
00:19:46,814 --> 00:19:50,278
happened is once the chain of thoughts, the actions are followed,

308
00:19:50,366 --> 00:19:53,744
these results are again feed into the agent and with the

309
00:19:53,784 --> 00:19:56,784
task plus the result agent will approach the LLF.

310
00:19:56,864 --> 00:20:00,952
So yeah, now the context is improved, it has more background

311
00:20:01,008 --> 00:20:04,856
information and it is able to come up with a meta response.

312
00:20:04,960 --> 00:20:08,884
So this is like allowing us to ensure that

313
00:20:09,704 --> 00:20:12,808
the responses are we are getting not

314
00:20:12,856 --> 00:20:16,376
only have greater context, greater relevance, but we

315
00:20:16,400 --> 00:20:19,512
can make it accurate. And in some areas in real

316
00:20:19,568 --> 00:20:23,554
time. Now example, if you are creating a remediation script

317
00:20:23,634 --> 00:20:27,074
but you want to know the exact IP address, you are going to execute

318
00:20:27,114 --> 00:20:30,906
this. Then you are able to use some of these API calls into

319
00:20:30,930 --> 00:20:34,666
your CMDB to identify what are the correct server and what

320
00:20:34,690 --> 00:20:38,090
are the other details likewise. So this is a great way to

321
00:20:38,122 --> 00:20:42,130
ensuring that you are the when you need to make

322
00:20:42,162 --> 00:20:45,250
your results more accurate and some of the

323
00:20:45,282 --> 00:20:49,006
data obtained wire unties. Here you

324
00:20:49,030 --> 00:20:52,710
are again keeping your data accurate and relevant

325
00:20:52,862 --> 00:20:56,794
while leveraging the capabilities provided by llms.

326
00:20:57,534 --> 00:21:01,302
And finally, obviously working with llms you have

327
00:21:01,318 --> 00:21:05,222
to get your prompts right. So we have the whole set of prompt engineering.

328
00:21:05,358 --> 00:21:08,790
It's about giving the clear objectives, it's about providing the

329
00:21:08,822 --> 00:21:12,484
context and it's about evaluating continuously going

330
00:21:12,524 --> 00:21:15,708
with iterative refinement. And that will

331
00:21:15,756 --> 00:21:19,104
help you to ensure you get the best out of your llms.

332
00:21:19,404 --> 00:21:22,844
These three aspects of rag and then

333
00:21:22,924 --> 00:21:27,172
leveraging LLM agents and from engineering best practices will

334
00:21:27,228 --> 00:21:31,356
allow you to build a comprehensive and a better solution

335
00:21:31,500 --> 00:21:34,820
which can in some aspects mitigate some

336
00:21:34,852 --> 00:21:39,880
of the challenges you are having with llms and

337
00:21:39,912 --> 00:21:43,216
you can amplify the results. And some

338
00:21:43,240 --> 00:21:46,952
of these other properties, the from properties

339
00:21:47,008 --> 00:21:51,032
I have listed as well, things like temperature, the top fee

340
00:21:51,168 --> 00:21:54,640
and top tokens, those things, all the

341
00:21:54,672 --> 00:21:58,644
combinations and different ways using will have a greater benefit.

342
00:21:59,144 --> 00:22:02,640
And finally, we are at the important part of my

343
00:22:02,672 --> 00:22:05,808
presentation where now that we understand

344
00:22:05,976 --> 00:22:09,608
our site reliability objectives and some of the challenges,

345
00:22:09,656 --> 00:22:13,088
the modern distributed systems are presenting

346
00:22:13,136 --> 00:22:17,280
us capabilities of large language models and

347
00:22:17,312 --> 00:22:20,760
how we can even improve LLMs three

348
00:22:20,792 --> 00:22:24,808
SaaS by using how we can leverage the from

349
00:22:24,856 --> 00:22:28,408
properties. So with this all, I firmly believe

350
00:22:28,496 --> 00:22:32,162
we are able to going to the next level of site reliability

351
00:22:32,218 --> 00:22:35,586
engineering by leveraging Gene AI. I call it SRE

352
00:22:35,650 --> 00:22:38,954
2.0. And we will look at in

353
00:22:38,994 --> 00:22:42,546
next part of my presentation how we

354
00:22:42,570 --> 00:22:46,294
can use Genei to positively impact your observability,

355
00:22:46,914 --> 00:22:50,594
how you can leverage it to improve the identifying

356
00:22:50,634 --> 00:22:54,330
and measuring and tracking your Sli, SLI and error

357
00:22:54,362 --> 00:22:58,350
budgets. What are the ways we can use gene for system architecture

358
00:22:58,382 --> 00:23:02,150
and recovery objective areas and how typically we can

359
00:23:02,182 --> 00:23:06,230
use Genei in release and incident engineering and automation

360
00:23:06,382 --> 00:23:10,234
resilience and even at blameless post motors.

361
00:23:10,734 --> 00:23:14,678
And what how I will do is each of these pillars I

362
00:23:14,686 --> 00:23:18,286
will come up with a set of use cases which I have identified

363
00:23:18,430 --> 00:23:22,522
and we will discuss them part of the implementation

364
00:23:22,618 --> 00:23:26,282
feasibility and the business benefits. And then we

365
00:23:26,298 --> 00:23:30,002
will pick one of the use case and we will see we go little

366
00:23:30,058 --> 00:23:32,734
details into the implementation.

367
00:23:33,354 --> 00:23:36,634
So starting off observability is a very important

368
00:23:36,714 --> 00:23:40,506
aspects of your site reliability engineering. It's about using the

369
00:23:40,530 --> 00:23:44,090
telemetry data such as your logs, metrics and phrases to

370
00:23:44,122 --> 00:23:47,570
identify internal system state. So when you are starting

371
00:23:47,602 --> 00:23:51,882
your observability journey you definitely have some of the challenges where Jennair

372
00:23:51,938 --> 00:23:56,178
can be the answers and it can expedite your

373
00:23:56,346 --> 00:24:00,962
adoption of observability and even improve

374
00:24:01,138 --> 00:24:04,722
the results. So what are some of the use cases

375
00:24:04,818 --> 00:24:08,458
I think can be handy. So I'm looking at

376
00:24:08,546 --> 00:24:11,610
the feasibility and the business value. So high

377
00:24:11,642 --> 00:24:15,498
feasibility, high business value. Some of the use cases are automatically

378
00:24:15,546 --> 00:24:19,134
generate anomaly detection models for monitoring system metrics.

379
00:24:19,234 --> 00:24:22,550
If you are want to come up with your models

380
00:24:22,662 --> 00:24:26,638
and you are in the mode to come up develop this, then llms

381
00:24:26,686 --> 00:24:30,590
have the capabilities and you can cut down the development effort

382
00:24:30,662 --> 00:24:34,910
and some of the implementation effort by leveraging Jenny as and

383
00:24:34,942 --> 00:24:38,846
you are able to use the jennair to predict potential

384
00:24:38,950 --> 00:24:42,654
system bottlenecks and recommended proactive optimizations.

385
00:24:42,774 --> 00:24:46,210
Here you are able to we will go in detail, we can feed

386
00:24:46,242 --> 00:24:49,626
in a lot of data and Jennair can do a better job. And we are

387
00:24:49,650 --> 00:24:53,874
able to use Jenna to analyze log data to automatically

388
00:24:53,914 --> 00:24:57,834
identify root causes and performance issues. So this day and age we

389
00:24:57,874 --> 00:25:01,482
no longer required humans to spend more time

390
00:25:01,538 --> 00:25:04,594
on going through and identifying root causes. We are

391
00:25:04,634 --> 00:25:07,970
definitely tapping to the Llms to that as

392
00:25:08,002 --> 00:25:11,402
well. And of course llms are able to

393
00:25:11,418 --> 00:25:15,270
come up with high predictive features. How high predict

394
00:25:15,342 --> 00:25:19,334
predicts future resource utilization trends and recommended

395
00:25:19,414 --> 00:25:23,846
scaling strategies. So in my mind these are the high feasibility,

396
00:25:23,950 --> 00:25:27,302
high business value use cases. And some of the other

397
00:25:27,358 --> 00:25:30,982
things are identify correlation between different system

398
00:25:31,038 --> 00:25:35,406
metrics to enhance troubleshootings or to analyze network traffic patterns.

399
00:25:35,510 --> 00:25:39,794
Or you can even go into automate the correlation of comprehensive

400
00:25:39,874 --> 00:25:42,858
dashboards to tailor user needs.

401
00:25:42,986 --> 00:25:46,610
And finally such things such as recommend dynamic adjustments to

402
00:25:46,642 --> 00:25:50,314
monitoring configuration based on workload changes. So those are the

403
00:25:50,354 --> 00:25:54,094
aspects where by giving lot of meaningful

404
00:25:54,554 --> 00:25:58,778
input you are able to get lot of things out of llms

405
00:25:58,866 --> 00:26:02,290
to improve. When you are setting up your observability,

406
00:26:02,442 --> 00:26:06,056
fine tuning your observability, and when you are trying to adjust and

407
00:26:06,080 --> 00:26:09,736
do the continuous improvement into observability, you are definitely

408
00:26:09,840 --> 00:26:13,680
able to tap into these use cases and this will help you

409
00:26:13,832 --> 00:26:17,364
amplify implementation of observability.

410
00:26:18,144 --> 00:26:21,248
So here we I have pick up this one use case.

411
00:26:21,376 --> 00:26:24,968
So example analyze log data to automatically

412
00:26:25,016 --> 00:26:28,904
identify root causes to performance issues. So this is traditionally

413
00:26:28,944 --> 00:26:32,396
a manual work where our SRE teams will do,

414
00:26:32,500 --> 00:26:36,204
but what are the options we have? We are able to input our logs

415
00:26:36,284 --> 00:26:40,596
and with some of other various system components needed and llms

416
00:26:40,660 --> 00:26:43,764
able to perform and identify patterns, root causes

417
00:26:43,804 --> 00:26:47,644
and performance issue. So this is the capability LLM

418
00:26:47,684 --> 00:26:51,772
can and we can definitely impact include some feedback

419
00:26:51,828 --> 00:26:56,022
loops and go through this in iterative way to improve

420
00:26:56,188 --> 00:27:00,474
the final output. And the ways we can improve this

421
00:27:00,554 --> 00:27:04,066
implementation is enhancing some of the algorithms.

422
00:27:04,130 --> 00:27:07,258
You can pick up a LLM which is more suitable

423
00:27:07,306 --> 00:27:11,522
for this work and then you can use some rack concepts

424
00:27:11,578 --> 00:27:14,754
to provide more domain specific data so that in case,

425
00:27:14,794 --> 00:27:18,490
if required you can use the non errors and you have

426
00:27:18,522 --> 00:27:22,354
the best practices. You can also embed it into

427
00:27:22,394 --> 00:27:25,644
your LLM and provide effective feedback.

428
00:27:25,764 --> 00:27:28,964
And with some collaborative feedback loops you are able to

429
00:27:29,004 --> 00:27:32,508
improve the outputs in over period of time.

430
00:27:32,596 --> 00:27:35,788
So this is a great use case where you can provide obtain

431
00:27:35,836 --> 00:27:39,564
a lot of benefits. So moving on to the second

432
00:27:39,604 --> 00:27:42,196
pillar which is service level indicators,

433
00:27:42,300 --> 00:27:45,908
slos and error budgets. So if you look at again

434
00:27:46,076 --> 00:27:49,712
the high feasibility, high business value use cases. So one

435
00:27:49,728 --> 00:27:53,464
of the use cases recommend optimal error budget allocations

436
00:27:53,544 --> 00:27:56,904
based on business priorities and user expectation. If that's

437
00:27:56,944 --> 00:28:00,016
always a challenge to understand what is that correct target.

438
00:28:00,200 --> 00:28:04,056
And then we have the option of predicting potential violations

439
00:28:04,120 --> 00:28:07,672
of service level objectives and recommended proactive measures to

440
00:28:07,688 --> 00:28:11,832
prevent that. So identifying what are the preventive measures.

441
00:28:12,008 --> 00:28:15,816
So llms are able to not only come

442
00:28:15,840 --> 00:28:19,888
up do a better job, it's able to tap into the vast data

443
00:28:20,016 --> 00:28:23,128
to provide a lot of better options and

444
00:28:23,176 --> 00:28:26,928
recommendation and fixed details. And then some use case like

445
00:28:26,976 --> 00:28:30,808
analyze user satisfaction metrics to determine the impact of

446
00:28:30,896 --> 00:28:34,248
SLA violations on customer experience. So whenever

447
00:28:34,296 --> 00:28:37,936
there are SLA violations are happening, we are able to get ll names

448
00:28:37,960 --> 00:28:42,122
to do the business impact assessment which is again very important because our

449
00:28:42,248 --> 00:28:45,926
as service level objectives we want to ensure we correlated with

450
00:28:46,030 --> 00:28:49,374
customer experience and we now have a better way of predicting

451
00:28:49,414 --> 00:28:52,782
those the customer experience as well. And we are

452
00:28:52,798 --> 00:28:56,406
able to use automate the tracking and visualization of error budgets,

453
00:28:56,430 --> 00:29:00,094
burn down grades and things like recommend adjustment

454
00:29:00,134 --> 00:29:03,710
to error budget based on usage patterns and system performance.

455
00:29:03,902 --> 00:29:07,182
For generate insight on relationship between slIs,

456
00:29:07,238 --> 00:29:10,880
slos and business KPI's this is again a very important

457
00:29:10,952 --> 00:29:15,312
thing. We always want to ensure our slos are reflect

458
00:29:15,408 --> 00:29:18,752
a true customer experience. So we want to ensure if there

459
00:29:18,808 --> 00:29:22,304
are some specific misses KP's how we see

460
00:29:22,384 --> 00:29:26,312
that correlation going then identifying and prioritize

461
00:29:26,368 --> 00:29:29,824
critical and service level indicators based on their impact on

462
00:29:29,864 --> 00:29:33,408
user experience and business objectives. Those are typical

463
00:29:33,576 --> 00:29:37,430
use cases which we are able to leverage that will have

464
00:29:37,462 --> 00:29:41,366
a amplifying effect in implement when

465
00:29:41,390 --> 00:29:44,806
you are implementing this pillar. So here I have

466
00:29:44,830 --> 00:29:48,142
picked one of the important and interesting use case it's about

467
00:29:48,198 --> 00:29:52,366
recommend optimal error budget allocations based on business prioritize

468
00:29:52,430 --> 00:29:55,734
and use expectation. So this is always a very challenging

469
00:29:55,774 --> 00:29:59,270
thing how you come up with that, your error budgets and what are your

470
00:29:59,302 --> 00:30:02,858
SLO targets. So what we can do is we again doing

471
00:30:03,046 --> 00:30:07,634
input our error budget definitions, business priorities, user expectations

472
00:30:07,794 --> 00:30:11,906
and then let llms come up with make a smart decision

473
00:30:12,010 --> 00:30:15,066
which is like relevance to everyone. So again,

474
00:30:15,210 --> 00:30:19,330
we are able to use the feedback loop and we can get the stakeholder

475
00:30:19,362 --> 00:30:23,258
feedback here which is very important and that can be iterative way

476
00:30:23,346 --> 00:30:26,538
to improve our final output. We can

477
00:30:26,666 --> 00:30:30,790
change and adapt, let our models adapt to based on priorities

478
00:30:30,862 --> 00:30:34,974
the business objectives whenever we have the whenever

479
00:30:35,014 --> 00:30:38,046
it's time to relook at the error budgets and other targets.

480
00:30:38,070 --> 00:30:41,606
So it's iterative way. Obviously the continuous refinement

481
00:30:41,670 --> 00:30:46,154
will help you in achieving your desired objective.

482
00:30:46,574 --> 00:30:49,974
Moving on, the third pillar of our SRE is

483
00:30:50,054 --> 00:30:53,518
system architecture and recovery objectives. Here again,

484
00:30:53,686 --> 00:30:57,230
generator, we have lot of use cases which you can use

485
00:30:57,342 --> 00:31:00,886
which will help you to really have a take it out like

486
00:31:00,950 --> 00:31:04,494
hit this out of the park. And in the games we say

487
00:31:04,654 --> 00:31:07,414
like really get the benefit of Genai.

488
00:31:07,574 --> 00:31:11,574
So some of the use cases are ability to predict the different failure

489
00:31:11,614 --> 00:31:15,102
scenarios on the system availability and performance so that you

490
00:31:15,118 --> 00:31:18,974
can have better RP or RTO and you can build resilient into your

491
00:31:19,014 --> 00:31:22,454
system architectures recommend proactive measures to enhance

492
00:31:22,494 --> 00:31:25,970
system reliability and minimize downtime predict potential

493
00:31:26,042 --> 00:31:30,394
recovery times for different type of incidents based on historical data.

494
00:31:30,514 --> 00:31:33,874
So this will really help you in determine your

495
00:31:33,914 --> 00:31:37,706
RPO RTO and then build resilience and

496
00:31:37,730 --> 00:31:41,802
fault tolerance into the system architecture and few things

497
00:31:41,858 --> 00:31:45,618
other things are recommend resilience improvements to system architecture

498
00:31:45,666 --> 00:31:49,346
based on failure mode, automate the creation of disaster

499
00:31:49,410 --> 00:31:53,144
recovery plans and analyze effectiveness of recovery

500
00:31:53,184 --> 00:31:57,264
strategies and recommend optimizations based on fast historical data.

501
00:31:57,384 --> 00:32:01,176
These are some of the great user cases which are high feasible

502
00:32:01,280 --> 00:32:04,164
and will give provide you some business value as well.

503
00:32:04,704 --> 00:32:08,176
And then there are some other less feasible high business

504
00:32:08,240 --> 00:32:11,880
value generate use cases as well. Things like generate recovery

505
00:32:11,912 --> 00:32:15,284
objective based on business requirement and SLA commitments,

506
00:32:15,744 --> 00:32:19,064
analyze historical data to identify patterns and trend in

507
00:32:19,104 --> 00:32:23,034
system failures and generate personalized recovery playbooks

508
00:32:23,114 --> 00:32:26,722
for common incident scenarios. So these are very powerful

509
00:32:26,778 --> 00:32:30,490
use cases and without Genai we may not

510
00:32:30,522 --> 00:32:33,874
be able to fulfill at all. So here

511
00:32:33,994 --> 00:32:37,410
one of the use case I picked it up is predict the

512
00:32:37,442 --> 00:32:41,454
impact of different failure scenarios on system availability and performance.

513
00:32:41,834 --> 00:32:45,706
So one the inputs we have to provide is the historical

514
00:32:45,770 --> 00:32:49,426
failure data, system architecture related data and the performance

515
00:32:49,530 --> 00:32:52,810
of the telemetry data. This will allow LLM to

516
00:32:52,842 --> 00:32:56,602
predict the impact of various failure scenarios which can have

517
00:32:56,658 --> 00:33:00,466
in our system and what can have impact on our availability and

518
00:33:00,490 --> 00:33:04,010
performance and the various ways we can improve

519
00:33:04,082 --> 00:33:07,642
the output tasks. Obviously incorporating the feedback loop

520
00:33:07,778 --> 00:33:11,794
enhancing model with additional influencing factors like

521
00:33:11,834 --> 00:33:15,488
what are the other factors which can improve impact?

522
00:33:15,656 --> 00:33:19,280
Your availability and the reliability and the performance. And then of

523
00:33:19,312 --> 00:33:23,616
course the the continuous refinement of this approach and

524
00:33:23,640 --> 00:33:27,520
moving on. The next pillar of site reliability engineering is your release

525
00:33:27,592 --> 00:33:31,216
and incident engineering. This is a very important aspect

526
00:33:31,320 --> 00:33:34,808
and generative AI. Here again have lots of use

527
00:33:34,856 --> 00:33:38,552
cases which can have a lasting impact.

528
00:33:38,688 --> 00:33:42,212
If you look at the high feasible, high business impact use cases,

529
00:33:42,368 --> 00:33:46,556
some of them are ability to automate the creation of incident response

530
00:33:46,620 --> 00:33:50,804
front books and playbooks for efficient resolution. You can automate

531
00:33:50,844 --> 00:33:54,188
the entire workflow using Genai predict

532
00:33:54,236 --> 00:33:57,604
potential incident severity based on incoming alert and

533
00:33:57,644 --> 00:34:01,300
historical data. You can do that, the priority classification,

534
00:34:01,412 --> 00:34:05,092
you can understand the impact and so the capabilities are very

535
00:34:05,148 --> 00:34:08,476
high. Provide real time incident response recommendation

536
00:34:08,540 --> 00:34:11,384
based on the current situation and historical data.

537
00:34:11,784 --> 00:34:15,760
And some of the other things are finick potential release risk based

538
00:34:15,792 --> 00:34:19,016
on historical release data and quot quality matrix. So this

539
00:34:19,040 --> 00:34:23,456
is a very important aspect. You are able to come

540
00:34:23,480 --> 00:34:27,136
up with a risk factor not based on the manual way, but you are

541
00:34:27,160 --> 00:34:30,604
able to tap into generative way and come up with something smart.

542
00:34:31,384 --> 00:34:35,504
And then you can do the reverse engineering to reduce those risks

543
00:34:35,664 --> 00:34:39,712
and then analyze the impact of releases on user experience and satisfaction

544
00:34:39,768 --> 00:34:43,658
matrix. From the developing of design

545
00:34:43,746 --> 00:34:47,474
to development of the code to the testing, you can have it

546
00:34:47,554 --> 00:34:51,294
and then have that impact on the release measures,

547
00:34:52,114 --> 00:34:55,410
the recommended optimized release cycles and promotion

548
00:34:55,522 --> 00:34:59,170
strategies based on system performance and one of the other use

549
00:34:59,202 --> 00:35:03,082
cases. And if you look at other use cases, analyze past

550
00:35:03,138 --> 00:35:06,890
incident risk reports and postpartum analysis to identify

551
00:35:06,962 --> 00:35:10,666
common failure patterns. Recommend preventive measures to mitigate the

552
00:35:10,690 --> 00:35:14,794
risk of incident during failures and generate insights on root causes

553
00:35:14,834 --> 00:35:18,386
of incidents and recommend long term solution to

554
00:35:18,410 --> 00:35:22,170
prevent the reoccurrence. So those are about how you can improve

555
00:35:22,242 --> 00:35:25,586
your release engineering workflows, how you can predict some

556
00:35:25,610 --> 00:35:29,986
of the touch points which can have impact on your customer experience

557
00:35:30,170 --> 00:35:34,290
and then how you can take some measurements to ensure

558
00:35:34,442 --> 00:35:38,188
your workflows are safety and you are doing we are delivering

559
00:35:38,306 --> 00:35:42,520
quality outputs to our customers. So this is some

560
00:35:42,632 --> 00:35:46,244
great use cases. Generative AI is opening up

561
00:35:46,784 --> 00:35:50,304
and one of the use case I have picked it up is provide real time

562
00:35:50,344 --> 00:35:54,016
incident response recommendation based on the current situation and

563
00:35:54,040 --> 00:35:57,248
historical data. So that is very important in the

564
00:35:57,296 --> 00:36:00,608
incident workflows when you are trying to automate your incident management.

565
00:36:00,776 --> 00:36:04,152
So what are the inputs we can give? We can provide the current

566
00:36:04,208 --> 00:36:07,938
incident data, historical data and the system status

567
00:36:07,986 --> 00:36:11,626
and various telemetry data. And we can expect the

568
00:36:11,650 --> 00:36:15,042
output of lamps to come up and recommend us on real

569
00:36:15,098 --> 00:36:18,610
time recommendations for incident response and actions.

570
00:36:18,722 --> 00:36:22,034
And what are the other like the user impacts,

571
00:36:22,074 --> 00:36:25,922
business impact statements and even to prevention of reoccurrences.

572
00:36:26,058 --> 00:36:29,802
And even I have tested you are able to get llms to do five.

573
00:36:29,858 --> 00:36:33,934
I swear you can do a blameless postmortem

574
00:36:34,014 --> 00:36:37,794
with LLM by giving you giving all the data.

575
00:36:38,574 --> 00:36:42,518
So again, real time feedback loops, tendencing models with

576
00:36:42,566 --> 00:36:46,590
the configurations and providing better context into problem statement

577
00:36:46,782 --> 00:36:50,302
continuous refinement are few ways we can improve

578
00:36:50,438 --> 00:36:54,934
the final output. Automation, as we discussed

579
00:36:55,094 --> 00:36:58,820
earlier, plays a key roles in site reliability engineering journey.

580
00:36:58,942 --> 00:37:02,344
It's about automating the this job aware it's not

581
00:37:02,384 --> 00:37:06,120
only base of automation, but identify toil so

582
00:37:06,152 --> 00:37:10,080
in high level automation about writing UI scripts,

583
00:37:10,152 --> 00:37:13,512
writing automations to automate some of the workarounds

584
00:37:13,608 --> 00:37:17,272
or identify some of the tactical or strategic work which you

585
00:37:17,288 --> 00:37:21,440
are doing. You embedded those work and do your the systems

586
00:37:21,472 --> 00:37:25,376
itself. So the standard automations writing your

587
00:37:25,440 --> 00:37:29,434
shell script, python script and no automation with lot of scripting.

588
00:37:29,584 --> 00:37:33,022
The the effort you put to develop those scripts

589
00:37:33,118 --> 00:37:37,154
you can now outsource into Jenny so that Jenny can

590
00:37:37,454 --> 00:37:41,526
do a faster job, more productive job and you can simply

591
00:37:41,590 --> 00:37:45,518
leverage it and then do the changes and get it up and running very quickly.

592
00:37:45,606 --> 00:37:49,990
So the content creation aspect of JNA, you can really use that powerfully

593
00:37:50,022 --> 00:37:53,806
here. And apart from that, some of the the use cases

594
00:37:53,910 --> 00:37:57,906
I have come up with are analyze historical automation

595
00:37:57,970 --> 00:38:02,162
data to identify opportunities for process optimization.

596
00:38:02,338 --> 00:38:05,674
Those are high feasibility, high value use case

597
00:38:05,834 --> 00:38:09,450
automate the deployment and management of infrastructure resources.

598
00:38:09,562 --> 00:38:13,834
You are able to obviously use DNAI to come up with your

599
00:38:13,994 --> 00:38:17,962
infrastructure as a code and other CI CD pipeline.

600
00:38:18,138 --> 00:38:22,822
The development work, you can accelerate that using analyze

601
00:38:22,838 --> 00:38:26,622
the effectiveness of automation workflows and recommend improvements

602
00:38:26,678 --> 00:38:30,710
based on performance metric. Some other use case and

603
00:38:30,822 --> 00:38:34,638
a few others are recommend automated testing framework

604
00:38:34,766 --> 00:38:38,006
and tools to improve release call quality, predict the

605
00:38:38,030 --> 00:38:42,034
impact of automation on operational efficiency and resource utilization

606
00:38:42,334 --> 00:38:47,194
and generate personalized automation playbooks for different operational scenarios

607
00:38:47,864 --> 00:38:51,328
and some of the challenge to implement which is like law

608
00:38:51,376 --> 00:38:55,296
feasible but high again high business value use case.

609
00:38:55,360 --> 00:38:58,928
Recommend new automation opportunities based on manual workflow and

610
00:38:58,976 --> 00:39:03,040
look at the repetitive tasks. Predict potential bottlenecks in manual process

611
00:39:03,112 --> 00:39:07,136
and suggest automation solutions. Automate the identification

612
00:39:07,200 --> 00:39:11,040
and prioritization of repetitive tasks for the toil.

613
00:39:11,192 --> 00:39:15,062
So these are some of the great use cases generative AI is able to

614
00:39:15,168 --> 00:39:18,442
facilitate that can really accelerate and

615
00:39:18,538 --> 00:39:22,146
probably for us to achieve our high power automation

616
00:39:22,290 --> 00:39:25,850
aspirations. So one of the use case I have picked

617
00:39:25,882 --> 00:39:29,642
up here is analyze the effectiveness of automation workflows

618
00:39:29,738 --> 00:39:33,554
and recommend improvements based on performance metrics. We are very good at

619
00:39:33,594 --> 00:39:37,226
identifying some of the automation use cases and then we do automation.

620
00:39:37,370 --> 00:39:40,826
But after that we sometimes lack that ability to understand

621
00:39:40,930 --> 00:39:44,256
the effectiveness and how to measure it, how to even come

622
00:39:44,280 --> 00:39:47,992
up with some other improvements on top of that to really

623
00:39:48,128 --> 00:39:51,320
drive it home. So here we can input

624
00:39:51,352 --> 00:39:55,472
the automation workflow data, performance metric and historical other data

625
00:39:55,608 --> 00:39:59,244
where we can able to get LLMs to provide

626
00:39:59,624 --> 00:40:03,104
analysis of automation workflow effectiveness and

627
00:40:03,144 --> 00:40:06,400
recommendations for improvements based on the vast knowledge it's

628
00:40:06,432 --> 00:40:09,504
habit and obviously we have the option of

629
00:40:09,544 --> 00:40:13,300
improving this output as well. We can provide a

630
00:40:13,332 --> 00:40:16,908
more context driven feedback and LLM

631
00:40:16,956 --> 00:40:20,212
fine tuning and continuous learning will obviously help us

632
00:40:20,228 --> 00:40:23,316
to improve the output. Moving on.

633
00:40:23,420 --> 00:40:27,396
Resiliency engineering is one of the important aspects. We want

634
00:40:27,420 --> 00:40:30,796
to understand what our failure scenarios and then we want to

635
00:40:30,820 --> 00:40:34,636
ensure we do that failure testing or the chaos testing so that we

636
00:40:34,660 --> 00:40:38,692
can understand the and improve our system resilience

637
00:40:38,748 --> 00:40:42,840
and fault errors. So this is a great way of implementing

638
00:40:42,952 --> 00:40:46,776
generative AI in a chaos engineering workflow.

639
00:40:46,880 --> 00:40:50,080
I'm not going to discuss too much, but if you have look at

640
00:40:50,112 --> 00:40:54,144
my previous presentation as part of Chaos Engineering 2024

641
00:40:54,224 --> 00:40:58,320
in con 42, I did a autonomous chaos engineering workflow

642
00:40:58,352 --> 00:41:02,312
presentation where I discussed how we can leverage Genai

643
00:41:02,448 --> 00:41:06,994
from the start to end, how we can leverage Genaii to do the system discovery.

644
00:41:07,104 --> 00:41:11,278
What are the how we can use it to understand your system dependencies

645
00:41:11,406 --> 00:41:15,030
and then come up with, then come up with the

646
00:41:15,142 --> 00:41:18,534
system steady status, and then come up with the hypothesis,

647
00:41:18,574 --> 00:41:21,942
the failure scenarios, the test cases. You can even get the

648
00:41:21,998 --> 00:41:25,886
generative AI to automate your test creation, and then you can

649
00:41:25,910 --> 00:41:29,366
do the test execution so that you can create autonomous workflow

650
00:41:29,390 --> 00:41:32,390
and integrate that with your c and CD pipeline.

651
00:41:32,462 --> 00:41:36,348
So this is again a very powerful area where you are able to

652
00:41:36,396 --> 00:41:40,340
leverage a generative AI and you probably

653
00:41:40,412 --> 00:41:43,384
automate the entire chaos engineering workflow.

654
00:41:44,164 --> 00:41:47,548
Here again, let me pick up one of the use

655
00:41:47,596 --> 00:41:51,092
case. Automate the execution of chaos experiments based on

656
00:41:51,108 --> 00:41:54,940
the identified risk factor and failure scenarios. So probably once you

657
00:41:54,972 --> 00:41:58,692
have your test cases identified, you can share your test cases,

658
00:41:58,788 --> 00:42:02,524
identify risk factors, failure scenarios, system architectures,

659
00:42:02,604 --> 00:42:06,498
other data, and here then cure scene. The LLMs

660
00:42:06,546 --> 00:42:10,306
are able to automate the execution. It's able to come up with structure

661
00:42:10,330 --> 00:42:14,034
as a code for other automation script or solution

662
00:42:14,154 --> 00:42:18,474
we can promptly use it to run so that you cut down the time

663
00:42:18,554 --> 00:42:22,974
to develop your the execution script.

664
00:42:23,274 --> 00:42:27,042
So this is a great way and this is in future will help to

665
00:42:27,178 --> 00:42:31,336
for us to realize autonomous chaos engineering workflows

666
00:42:31,360 --> 00:42:35,432
in future. Moving on. Final aspects if

667
00:42:35,568 --> 00:42:39,472
how you can use it to improve your culture and the awareness when it

668
00:42:39,488 --> 00:42:43,232
comes to site reliability engineering. So Jennai can definitely come up

669
00:42:43,248 --> 00:42:46,656
with a big bandwidth here. It can have chatbots which

670
00:42:46,680 --> 00:42:50,288
can improve their knowledge and awareness. It can improve and

671
00:42:50,336 --> 00:42:53,616
get itself planted in different aspects of our process so

672
00:42:53,640 --> 00:42:57,088
that it's able to provide better feedback. And one aspect is

673
00:42:57,176 --> 00:43:01,056
genes have the capability of look at the and our incident

674
00:43:01,160 --> 00:43:04,456
data and come up with blameless post motors. In one of the

675
00:43:04,480 --> 00:43:08,120
examples we were able to automate the entire bliss

676
00:43:08,152 --> 00:43:11,168
force motor to up to a certain level,

677
00:43:11,336 --> 00:43:14,712
fully automate with gene edge and how we

678
00:43:14,728 --> 00:43:18,104
have done it. You can see you have a major incident now all the

679
00:43:18,144 --> 00:43:22,190
data, what has happened? You captured part of your ticket update data.

680
00:43:22,312 --> 00:43:25,514
So if it is service now, the ServiceNow ticket will have all the data.

681
00:43:25,634 --> 00:43:29,058
What you can do is you can feed this data with other information

682
00:43:29,146 --> 00:43:32,570
to the your large language model. And with

683
00:43:32,602 --> 00:43:36,474
that it's able to do a proper incident prevention

684
00:43:36,514 --> 00:43:40,050
of reoccurrence analysis where it's

685
00:43:40,082 --> 00:43:44,242
able to understand what is the business impact, it's able to understand the

686
00:43:44,298 --> 00:43:47,750
workflow, what has happened, the task, how you have fixed the issue.

687
00:43:47,882 --> 00:43:51,374
It's able to go through five ways to understand the root cause.

688
00:43:51,454 --> 00:43:55,478
It's able to come up with what are the preventive measures and suggest the

689
00:43:55,566 --> 00:43:59,182
short term and long term fixes which you can drive.

690
00:43:59,318 --> 00:44:02,462
So these are some of the great use cases you can go and you

691
00:44:02,478 --> 00:44:05,854
can see here as well some of the great use cases you can

692
00:44:05,894 --> 00:44:09,918
implement. One of the use case I have picked it up is analyze

693
00:44:09,966 --> 00:44:13,750
historical postmortem data to identify recurrent patterns and

694
00:44:13,782 --> 00:44:17,720
trends in incident. So this is one of the more challenging aspects.

695
00:44:17,752 --> 00:44:20,896
We are very good at doing force modems, but how you

696
00:44:21,040 --> 00:44:24,576
compare analyze lot of force modems

697
00:44:24,600 --> 00:44:28,568
or the certain force modems you have done to understand the recurrent patterns.

698
00:44:28,656 --> 00:44:32,528
So here you can provide llms, historical force quantum

699
00:44:32,576 --> 00:44:36,776
data, incident reports, root cause analysis, other aspects

700
00:44:36,840 --> 00:44:40,952
to llM, and then it's able to perform the identification

701
00:44:41,008 --> 00:44:44,686
of recurrent patterns and trends and then identify incident

702
00:44:44,790 --> 00:44:48,502
reoccurrence and root causes. So here again we can

703
00:44:48,558 --> 00:44:52,230
include some of the context driven observability data and other

704
00:44:52,302 --> 00:44:55,566
system context and those things so that llms can come

705
00:44:55,590 --> 00:44:59,734
up with the beta outputs we can provide a lot of feedback and build feedback

706
00:44:59,774 --> 00:45:02,314
loop to get a better output as well.

707
00:45:02,774 --> 00:45:06,446
With this we have closed and going through our seven pillars

708
00:45:06,550 --> 00:45:10,120
and we have looked at what are the use cases and then we have look

709
00:45:10,152 --> 00:45:13,816
at particular high value use case how we

710
00:45:13,840 --> 00:45:17,152
can implement as well. So finally what are

711
00:45:17,168 --> 00:45:20,800
the benefits like we this all has to tangible impact into benefits.

712
00:45:20,912 --> 00:45:24,200
So this will amplify your reliability targets.

713
00:45:24,272 --> 00:45:27,416
So that is what I firmly believe UI once you

714
00:45:27,480 --> 00:45:30,728
embrace genai and you embrace it to amplify your

715
00:45:30,776 --> 00:45:34,176
SRE implementations, then you must be able to

716
00:45:34,200 --> 00:45:37,676
improve your service level objectives aligned to area budgets and

717
00:45:37,700 --> 00:45:41,740
your ability to increase the change frequency,

718
00:45:41,852 --> 00:45:45,468
reduce change failure rates and ability to

719
00:45:45,636 --> 00:45:49,228
increase the lead time. The reduce the lead time for changes because

720
00:45:49,276 --> 00:45:52,996
now that when you have that requirement of your developers able to do a faster

721
00:45:53,140 --> 00:45:57,084
deep development using gene and you are also able to ensure

722
00:45:57,204 --> 00:46:00,884
you manage the risk of that particular change, you have ability of

723
00:46:00,924 --> 00:46:04,060
tracking that and then you de risk that and deploy

724
00:46:04,092 --> 00:46:08,074
it into production and obviously mean time to detect,

725
00:46:08,114 --> 00:46:12,002
mean time to repair. Meantime between failures can be positively

726
00:46:12,058 --> 00:46:16,010
impacted by leveraging genais and what

727
00:46:16,042 --> 00:46:19,466
are the best practices. While generative AI is bringing in lot

728
00:46:19,490 --> 00:46:22,938
of opportunities for you to amplify your site

729
00:46:22,986 --> 00:46:26,842
reliability experience, you have to be ensure that you align some of

730
00:46:26,858 --> 00:46:29,954
the best practices, have a clear objective, ensure that

731
00:46:29,994 --> 00:46:34,202
llms are as good as the training dataset. You have to leverage

732
00:46:34,258 --> 00:46:38,282
some of the technique which I have provided you in the early about a

733
00:46:38,298 --> 00:46:42,194
leveraging drag or the knowledge base aging LLM agents and

734
00:46:42,234 --> 00:46:45,642
using the proper the from configurations so

735
00:46:45,658 --> 00:46:49,266
that you can provide better context and get better outputs and the

736
00:46:49,290 --> 00:46:53,178
feedback loops. The continuous evaluation is a must. If you have seen

737
00:46:53,346 --> 00:46:56,826
almost all the use cases, I have flagged that the

738
00:46:56,850 --> 00:47:00,602
feedback loops and the fact that we have to provide more context and

739
00:47:00,698 --> 00:47:04,316
more refinements which will help us to get the better output.

740
00:47:04,450 --> 00:47:09,304
And you have to be very careful and consider about the ethical considerations

741
00:47:09,464 --> 00:47:13,408
and ensuring that you understand the

742
00:47:13,456 --> 00:47:16,976
ethical generative AI implementation as well. So these

743
00:47:17,000 --> 00:47:20,724
are the best practices that will obviously help you in the long run.

744
00:47:21,384 --> 00:47:25,096
And finally, what are the pitfalls, which is which you

745
00:47:25,120 --> 00:47:29,048
want to avoid? And you want to first ensure that the ethical consideration,

746
00:47:29,096 --> 00:47:32,718
because that is a big part. So you understand

747
00:47:32,886 --> 00:47:36,526
the mems which have gone in the town. It says that

748
00:47:36,630 --> 00:47:40,350
don't ask a lady their age, gentlemen about the salary

749
00:47:40,502 --> 00:47:43,774
and LLM about their training data set.

750
00:47:43,894 --> 00:47:47,254
So that's one of the challenge. Like the how

751
00:47:47,414 --> 00:47:51,094
we have trained our LLM training data or how

752
00:47:51,134 --> 00:47:54,998
we have trained our llms. So there has to be a lot of consideration

753
00:47:55,046 --> 00:47:58,600
of ethical aspects so that you are you will not fall

754
00:47:58,672 --> 00:48:02,632
apart. So this is a something you have to be mindful

755
00:48:02,728 --> 00:48:05,824
from the day one and when you're coming up with your solution

756
00:48:05,904 --> 00:48:09,952
and the design and you have to have a proper validation plan.

757
00:48:10,048 --> 00:48:14,184
So whatever you are getting from the output as generative AI, you validate

758
00:48:14,224 --> 00:48:17,680
it and build some food back loops. So that is very important.

759
00:48:17,832 --> 00:48:20,896
And then what you have to do is you want to

760
00:48:20,960 --> 00:48:24,440
avoid treating generative AI model as statistic

761
00:48:24,472 --> 00:48:28,162
solutions. Instead you want to have regular update,

762
00:48:28,258 --> 00:48:32,050
refine them, adapt to evolving requirements and environments.

763
00:48:32,122 --> 00:48:35,618
So you have to understand this is evolving thing and

764
00:48:35,746 --> 00:48:38,874
you have to provide a lot of context and go through

765
00:48:38,914 --> 00:48:42,426
these feedback loops and continuous improvements. And that has

766
00:48:42,450 --> 00:48:46,546
to be built in. It doesn't matter that you understand, you accept

767
00:48:46,610 --> 00:48:50,506
that, but that has to be built into your solution workflows so

768
00:48:50,530 --> 00:48:53,268
that you can leverage in future.

769
00:48:53,436 --> 00:48:57,704
Definitely, generative AI is obviously already have a

770
00:48:58,524 --> 00:49:02,172
full fledged impact on the way we are working. I firmly believe

771
00:49:02,228 --> 00:49:05,892
by leveraging generative AI smartly you

772
00:49:05,908 --> 00:49:09,996
are able to implement SRE 2.0 which will amplify

773
00:49:10,180 --> 00:49:13,340
your reliability targets with

774
00:49:13,372 --> 00:49:17,344
that. Thank you very much for listening in. If you have any feedback

775
00:49:17,824 --> 00:49:21,344
you can comment this video or you can search Indica

776
00:49:21,384 --> 00:49:24,752
Vimanasuria in LinkedIn and you can

777
00:49:24,888 --> 00:49:28,560
contact with in touch with me. I'm happy to hear your feedback,

778
00:49:28,672 --> 00:49:32,168
your thoughts and collectively let's amplify our

779
00:49:32,256 --> 00:49:33,064
SRe journey.

